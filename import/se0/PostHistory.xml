<?xml version="1.0" encoding="utf-8"?>
<PostHistory>
  <row>
    <Id>1</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>1437b42b-f03d-4f30-a6e7-5e70d22afa2b</RevisionGUID>
    <CreationDate>2009-09-30T14:12:07.053</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>This is the first question, more of a test rather than actual content.</Text>
  </row>
  <row>
    <Id>2</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>1437b42b-f03d-4f30-a6e7-5e70d22afa2b</RevisionGUID>
    <CreationDate>2009-09-30T14:12:07.053</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>You can ask any question here, as long as it is data analysis related.</Text>
  </row>
  <row>
    <Id>3</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>1437b42b-f03d-4f30-a6e7-5e70d22afa2b</RevisionGUID>
    <CreationDate>2009-09-30T14:12:07.053</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text> étestà </Text>
  </row>
  <row>
    <Id>4</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>0930c237-0757-403e-91cc-18abf38258b6</RevisionGUID>
    <CreationDate>2009-09-30T14:18:11.27</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>first post</Comment>
    <Text>This is the first question, more of a test rather than actual content.

Hopefully we will be able to jump start the system to contain more useful information.</Text>
  </row>
  <row>
    <Id>5</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>0930c237-0757-403e-91cc-18abf38258b6</RevisionGUID>
    <CreationDate>2009-09-30T14:18:11.27</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>first post</Comment>
    <Text> étestà  éstartà </Text>
  </row>
  <row>
    <Id>6</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>2</PostId>
    <RevisionGUID>3b032e93-5b6e-4969-934e-cd047dc84659</RevisionGUID>
    <CreationDate>2009-09-30T14:55:00.133</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I have a file in GFF format and I need to convert it to BED format. What do I do?</Text>
  </row>
  <row>
    <Id>7</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>2</PostId>
    <RevisionGUID>3b032e93-5b6e-4969-934e-cd047dc84659</RevisionGUID>
    <CreationDate>2009-09-30T14:55:00.133</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>How do I convert from BED format to GFF format?</Text>
  </row>
  <row>
    <Id>8</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>2</PostId>
    <RevisionGUID>3b032e93-5b6e-4969-934e-cd047dc84659</RevisionGUID>
    <CreationDate>2009-09-30T14:55:00.133</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text> ébedà  égffà </Text>
  </row>
  <row>
    <Id>9</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>3</PostId>
    <RevisionGUID>7b3bc9b8-37d0-4006-9773-8609a7770fb0</RevisionGUID>
    <CreationDate>2009-09-30T14:56:18.353</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless **the most important** difference between the two is the coordinate systems that they assume. 

The [BED](http://genome.ucsc.edu/FAQ/FAQformat#format1) format developed at `UCSC` uses a zero based indexing and an open end interval whereas the [GFF](http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml) format developed at `Sanger` assumes a 1 based coordinate system that includes both start and end coordinates. Therefore

The `[0,100]` interval in `BED` format corresponds to `[1,100]` in `GFF` format and both are `100` base long. That the first element in BED format will be have the index of `0` where the last `100th` element will have the index of `99`! Whereas in `GFF` the first element will have the index of `1` and the last element will have the index of `100`.

To convert between the two you may use [Galayx](http://wwwportalmlekozyjestart.g2.bx.psu.edu/) and select the section called `Select Formats` that will list various transformation options.
</Text>
  </row>
  <row>
    <Id>10</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>2</PostId>
    <RevisionGUID>ba670c05-f5b8-475b-9470-6c49c204dc41</RevisionGUID>
    <CreationDate>2009-09-30T15:09:43.357</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>edited tags</Comment>
    <Text> ébedà  égffà  égalaxyà </Text>
  </row>
  <row>
    <Id>11</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>4</PostId>
    <RevisionGUID>896bb3dd-aa4b-4154-80ef-d0a91ebec6ad</RevisionGUID>
    <CreationDate>2009-09-30T16:09:06.677</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>3</UserId>
    <Text>I have a few hundred yeast sequences (20-80bp long) and I want to find common motifs (conserved bases at certain indices) in them. I am using a Mac</Text>
  </row>
  <row>
    <Id>12</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>4</PostId>
    <RevisionGUID>896bb3dd-aa4b-4154-80ef-d0a91ebec6ad</RevisionGUID>
    <CreationDate>2009-09-30T16:09:06.677</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>3</UserId>
    <Text>Finding common motifs in sequences</Text>
  </row>
  <row>
    <Id>13</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>4</PostId>
    <RevisionGUID>896bb3dd-aa4b-4154-80ef-d0a91ebec6ad</RevisionGUID>
    <CreationDate>2009-09-30T16:09:06.677</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>3</UserId>
    <Text> éyeastà  émotifà </Text>
  </row>
  <row>
    <Id>14</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>3ad3c02b-6f54-44b9-ba55-4cd55036283e</RevisionGUID>
    <CreationDate>2009-09-30T16:44:22.647</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.
It is simple to use and it has a very large number of features. 

Works well for any type of data. You can aslo load into it a file in a simple format like this:

&lt;pre&gt;
GENE1, value1, value2
GENE2, value1, value2
&lt;/pre&gt;
</Text>
  </row>
  <row>
    <Id>15</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>3ad3c02b-6f54-44b9-ba55-4cd55036283e</RevisionGUID>
    <CreationDate>2009-09-30T16:44:22.647</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Recommend easy to use microarray clustering software</Text>
  </row>
  <row>
    <Id>16</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>3ad3c02b-6f54-44b9-ba55-4cd55036283e</RevisionGUID>
    <CreationDate>2009-09-30T16:44:22.647</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text> émicroarrayà  éclusteringà </Text>
  </row>
  <row>
    <Id>17</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>5282fd2f-8d04-4793-95e0-c2a1641c8b65</RevisionGUID>
    <CreationDate>2009-09-30T16:49:51.387</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>edited body; added 13 characters in body</Comment>
    <Text>One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.
It is simple to use and it has a very large number of features. 

Works well for any type of data. You can also load into it data from a file that is in a simple text format:

&lt;pre&gt;
GENE1, value1, value2
GENE2, value1, value2
&lt;/pre&gt;
</Text>
  </row>
  <row>
    <Id>18</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>6</PostId>
    <RevisionGUID>5f8263b2-f7d1-4ef4-9c6d-afe79b217b9c</RevisionGUID>
    <CreationDate>2009-09-30T18:49:39.563</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text>Hi, I just created my user id a few minutes ago. 

Post this question to see how it works.</Text>
  </row>
  <row>
    <Id>19</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>6</PostId>
    <RevisionGUID>5f8263b2-f7d1-4ef4-9c6d-afe79b217b9c</RevisionGUID>
    <CreationDate>2009-09-30T18:49:39.563</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text>test by zhenhai</Text>
  </row>
  <row>
    <Id>20</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>6</PostId>
    <RevisionGUID>5f8263b2-f7d1-4ef4-9c6d-afe79b217b9c</RevisionGUID>
    <CreationDate>2009-09-30T18:49:39.563</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text> étestà </Text>
  </row>
  <row>
    <Id>21</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>7</PostId>
    <RevisionGUID>82c0eb46-efc2-4871-83d7-6c38f697289f</RevisionGUID>
    <CreationDate>2009-09-30T18:55:02.457</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text>try this out?

http://fraenkel.mit.edu/webmotifs/form.html</Text>
  </row>
  <row>
    <Id>22</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>6</PostId>
    <RevisionGUID>0843efd3-2533-4dd5-a64d-fb74c3c6db94</RevisionGUID>
    <CreationDate>2009-09-30T18:57:55.26</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>23</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>8</PostId>
    <RevisionGUID>491d9416-a7ce-4f81-9498-247a90d4d14d</RevisionGUID>
    <CreationDate>2009-09-30T19:32:29.097</CreationDate>
    <IPAddress>128.118.231.44</IPAddress>
    <UserId>6</UserId>
    <Text>You can also use MEME:  http://meme.sdsc.edu/.</Text>
  </row>
  <row>
    <Id>24</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>9</PostId>
    <RevisionGUID>d75c94fb-f191-4262-82b8-9fd4b0646bc9</RevisionGUID>
    <CreationDate>2009-09-30T19:35:28.02</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>ACGGGCCCGACGATGCGTCGTA

ACGTACGTCGAACCGTCGTCGT

ACGTGCGTCGAAACGTCAGTCG

ACGGGTTCGATCGTCGTCGTCG
 may be in Python I will break down the first sequence of required motif length into a sliding window and will search for those list of motifs in the rest of sequences using regular expression in python using re.search() method.</Text>
  </row>
  <row>
    <Id>25</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>3</PostId>
    <RevisionGUID>2fddaa73-bbb9-40b1-aa41-fe2dbd5e44ad</RevisionGUID>
    <CreationDate>2009-09-30T19:46:25.51</CreationDate>
    <IPAddress>71.58.53.201</IPAddress>
    <UserId>2</UserId>
    <Comment>edited body</Comment>
    <Text>Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless **the most important** difference between the two is the coordinate systems that they assume. 

The [BED](http://genome.ucsc.edu/FAQ/FAQformat#format1) format developed at `UCSC` uses a zero based indexing and an open end interval whereas the [GFF](http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml) format developed at `Sanger` assumes a 1 based coordinate system that includes both start and end coordinates. Therefore

The `[0,100]` interval in `BED` format corresponds to `[1,100]` in `GFF` format and both are `100` base long. That the first element in BED format will be have the index of `0` where the last `100th` element will have the index of `99`! Whereas in `GFF` the first element will have the index of `1` and the last element will have the index of `100`.

To convert between the two you may use [Galaxy](http://wwwportalmlekozyjestart.g2.bx.psu.edu/) and select the section called `Select Formats` that will list various transformation options.
</Text>
  </row>
  <row>
    <Id>26</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>1460d009-90d2-4db1-8757-121fdecda3b2</RevisionGUID>
    <CreationDate>2009-09-30T19:50:02.54</CreationDate>
    <IPAddress>71.58.53.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added 50 characters in body</Comment>
    <Text>One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.
It is simple to use and it has a very large number of features. 

Works well for any type of data. You can also load into it data from a file that is in a simple text format:

&lt;pre&gt;
GENE1, value1, value2
GENE2, value1, value2
&lt;/pre&gt;

Feel free to post your favorite clustering tool.</Text>
  </row>
  <row>
    <Id>27</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>9</PostId>
    <RevisionGUID>56e767b3-ebc7-45a2-b401-93c1a4f66879</RevisionGUID>
    <CreationDate>2009-10-01T01:09:51.16</CreationDate>
    <IPAddress>71.58.53.201</IPAddress>
    <UserId>2</UserId>
    <Comment>formatting edit</Comment>
    <Text>&lt;pre&gt;
ACGGGCCCGACGATGCGTCGTA

ACGTACGTCGAACCGTCGTCGT

ACGTGCGTCGAAACGTCAGTCG

ACGGGTTCGATCGTCGTCGTCG
&lt;/pre&gt;
 may be in Python I will break down the first sequence of required motif length into a sliding window and will search for those list of motifs in the rest of sequences using regular expression in python using `re.search()` method.</Text>
  </row>
  <row>
    <Id>28</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>2ddf610e-6104-4d4f-b602-4c7c131745f9</RevisionGUID>
    <CreationDate>2009-10-05T15:51:37.043</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>I want to generate di-nucleotide occupancy counts for each position summed over each of the input sequences. An example output:

![dinucleotide occupancy][1]


  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png</Text>
  </row>
  <row>
    <Id>29</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>2ddf610e-6104-4d4f-b602-4c7c131745f9</RevisionGUID>
    <CreationDate>2009-10-05T15:51:37.043</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>How to generate dinucleotide occupancy counts for each coordinate of my reads?</Text>
  </row>
  <row>
    <Id>30</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>2ddf610e-6104-4d4f-b602-4c7c131745f9</RevisionGUID>
    <CreationDate>2009-10-05T15:51:37.043</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> épythonà  édinucleotideà </Text>
  </row>
  <row>
    <Id>31</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>11</PostId>
    <RevisionGUID>19654926-358e-4cd7-bed8-130351e15e1d</RevisionGUID>
    <CreationDate>2009-10-05T16:03:01.06</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>The code snippet below will populate the ``store`` dictionary keyed by the di-nucleotide and values as lists that contain the occupancy for each index.

&lt;pre&gt;
def dinuc_update(sequence, size, store={}):
    """
    Accumulates dinucleotide position counts at each index.
    """
    def zeroes():
        "Generates an empty array that hold the positions"
        return [ 0 ] * size
 
    left, right = sequence, sequence[1:]
    for index, a, b in zip(count(), left, right):
        # upon encoutering a missing key initialize 
        # that value for that key to the return value of the empty() function
        store.setdefault(a+b, zeroes())[index] += 1

    return store
&lt;/pre&gt;

The code at [dinucpatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:

&lt;pre&gt;
store = {}
seq1 = 'ATGC'
dinuc_update(seq1, size=3, store=store)    

seq2 = 'ATCG'
dinuc_update(seq2, size=3, store=store)

print store
&lt;/pre&gt;

will print:

&lt;pre&gt;
{'CG': [0, 0, 1], 'TG': [0, 1, 0], 'GC': [0, 0, 1], 
'AT': [2, 0, 0], 'TC': [0, 1, 0]}
&lt;/pre&gt;

  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/dinucpatt.py</Text>
  </row>
  <row>
    <Id>32</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>12</PostId>
    <RevisionGUID>ca16f4df-62bb-46f6-a4be-22699cc924fa</RevisionGUID>
    <CreationDate>2009-10-05T16:09:57.673</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.
It is simple to use and it has a very large number of features. 

Works well for any type of data. You can also load into it data from a file that is in a simple text format:

&lt;pre&gt;
GENE1, value1, value2
GENE2, value1, value2
&lt;/pre&gt;

Feel free to post your favorite clustering tool.</Text>
  </row>
  <row>
    <Id>33</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>5</PostId>
    <RevisionGUID>004a17cf-6658-4e7e-b234-0d20ca1f9eb9</RevisionGUID>
    <CreationDate>2009-10-05T16:10:10.997</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>deleted 338 characters in body</Comment>
    <Text>Feel free to post your favorite clustering tool.</Text>
  </row>
  <row>
    <Id>34</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>0e1df1d2-74e7-4765-a92f-f11de6de1ef3</RevisionGUID>
    <CreationDate>2009-10-05T16:12:09.45</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>added 33 characters in body</Comment>
    <Text>I need to generate di-nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output:

![dinucleotide occupancy][1]


  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png</Text>
  </row>
  <row>
    <Id>35</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>11</PostId>
    <RevisionGUID>c3411c07-fbb9-420a-afa9-a6e386443670</RevisionGUID>
    <CreationDate>2009-10-05T16:13:19.013</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>added import</Comment>
    <Text>The code snippet below will populate the ``store`` dictionary keyed by the di-nucleotide and values as lists that contain the occupancy for each index.

&lt;pre&gt;
from itertools import count

def dinuc_update(sequence, size, store={}):
    """
    Accumulates dinucleotide position counts at each index.
    """
    def zeroes():
        "Generates an empty array that hold the positions"
        return [ 0 ] * size
 
    left, right = sequence, sequence[1:]
    for index, a, b in zip(count(), left, right):
        # upon encoutering a missing key initialize 
        # that value for that key to the return value of the empty() function
        store.setdefault(a+b, zeroes())[index] += 1

    return store
&lt;/pre&gt;

The code at [dinucpatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:

&lt;pre&gt;
store = {}
seq1 = 'ATGC'
dinuc_update(seq1, size=3, store=store)    

seq2 = 'ATCG'
dinuc_update(seq2, size=3, store=store)

print store
&lt;/pre&gt;

will print:

&lt;pre&gt;
{'CG': [0, 0, 1], 'TG': [0, 1, 0], 'GC': [0, 0, 1], 
'AT': [2, 0, 0], 'TC': [0, 1, 0]}
&lt;/pre&gt;

  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/dinucpatt.py</Text>
  </row>
  <row>
    <Id>36</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>13</PostId>
    <RevisionGUID>83b41bd5-93f4-4b4f-b503-de6405f14125</RevisionGUID>
    <CreationDate>2009-10-06T18:58:10.227</CreationDate>
    <IPAddress>128.118.159.180</IPAddress>
    <UserId>12</UserId>
    <Text>Hi, everyone,
I am posting this question for my friend.
He is analyzing his CHIP DNA solid deep sequence data, and find out that near 80% reads can not be mapped to the human genome. We are wondering if this high percentage unmapped reads is normal in CHIP DNA deep sequence or there may be something wrong with his result.</Text>
  </row>
  <row>
    <Id>37</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>13</PostId>
    <RevisionGUID>83b41bd5-93f4-4b4f-b503-de6405f14125</RevisionGUID>
    <CreationDate>2009-10-06T18:58:10.227</CreationDate>
    <IPAddress>128.118.159.180</IPAddress>
    <UserId>12</UserId>
    <Text>CHIP DNA deep sequence</Text>
  </row>
  <row>
    <Id>38</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>13</PostId>
    <RevisionGUID>83b41bd5-93f4-4b4f-b503-de6405f14125</RevisionGUID>
    <CreationDate>2009-10-06T18:58:10.227</CreationDate>
    <IPAddress>128.118.159.180</IPAddress>
    <UserId>12</UserId>
    <Text> ésolidà  édeepà  ésequenceà </Text>
  </row>
  <row>
    <Id>39</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>14</PostId>
    <RevisionGUID>f2d8a4c5-1e95-47a3-87c1-facd17bb9808</RevisionGUID>
    <CreationDate>2009-10-06T20:10:32.73</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I recall that our first samples that we ran on the Solid sequencer have had bad performance. Not quite an 80% loss but around 40%-60% reads were unmappable (yeast). Some other lab members will hopefully chime in with more details. </Text>
  </row>
  <row>
    <Id>40</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>15</PostId>
    <RevisionGUID>947b5743-ef5c-44a4-a001-f139347a582d</RevisionGUID>
    <CreationDate>2009-10-06T20:41:24.877</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text>Hi there,

We have done numbers of SOLiD sequencing run on yeast samples. Normally there are only 30-40 percent of total tags can be uniquely mapped back to yeast genome. 

What I would recommend is do it on solexa. You get much higher quality tags.

cheers,</Text>
  </row>
  <row>
    <Id>41</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>16</PostId>
    <RevisionGUID>0d106374-a343-42ec-bf65-98e03bd3531f</RevisionGUID>
    <CreationDate>2009-10-06T22:04:41.747</CreationDate>
    <IPAddress>128.118.200.154</IPAddress>
    <UserId>13</UserId>
    <Text>Your 20% mapping yield looks like low for normal ChIP experiment, even for human. Several factors can reduce this mapping yield. I am wondering which kind of ChIP was used in your case. That is, which kind of proteins was ChIPed?</Text>
  </row>
  <row>
    <Id>42</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>9b2266fe-adea-4e32-b66e-4bd636db3661</RevisionGUID>
    <CreationDate>2009-10-07T15:14:13.243</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed the guidelines</Comment>
    <Text>Here are a few guidelines:

 1. The site's goal is to answer bioinformatics and systems biology related questions
 2. Don't forget to vote for answers that you like! Any registered user may vote on any answer.
 3. When you ask a question you may also select the best answer
 4. Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments</Text>
  </row>
  <row>
    <Id>43</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>9b2266fe-adea-4e32-b66e-4bd636db3661</RevisionGUID>
    <CreationDate>2009-10-07T15:14:13.243</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed the guidelines</Comment>
    <Text>Site use guidelines</Text>
  </row>
  <row>
    <Id>44</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>9b2266fe-adea-4e32-b66e-4bd636db3661</RevisionGUID>
    <CreationDate>2009-10-07T15:14:13.243</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed the guidelines</Comment>
    <Text> éguidelinesà </Text>
  </row>
  <row>
    <Id>45</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>17</PostId>
    <RevisionGUID>cd62c569-03c9-4e23-821a-fe5b3800f42b</RevisionGUID>
    <CreationDate>2009-10-07T16:41:44.823</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>If you are shy about asking the question on your own behalf submit it to to the **Question Bot** and it will be posted on your behalf. Send email to the `Question Bot` link at the bottom.</Text>
  </row>
  <row>
    <Id>46</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>17</PostId>
    <RevisionGUID>1e50cb10-be98-4319-81ea-e619be18e77d</RevisionGUID>
    <CreationDate>2009-10-07T17:16:18.69</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>deleted 3 characters in body</Comment>
    <Text>If you are shy about asking the question on your own behalf submit it to to the **Question Bot** and it will be posted anonymously. Send email to the `Question Bot` link at the bottom.</Text>
  </row>
  <row>
    <Id>47</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>18</PostId>
    <RevisionGUID>82840005-9cf4-4211-b52e-7f71ea00d9f0</RevisionGUID>
    <CreationDate>2009-10-09T03:28:20.413</CreationDate>
    <IPAddress>71.58.68.17</IPAddress>
    <UserId>14</UserId>
    <Text>Hi,

I don't think a new user can vote on a question or an answer.
The site says I need 15 reputation...</Text>
  </row>
  <row>
    <Id>48</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>11</PostId>
    <RevisionGUID>447b8955-f64d-4481-ae66-3ebd0875a13b</RevisionGUID>
    <CreationDate>2009-10-13T14:41:12.153</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed to multipattern; edited body</Comment>
    <Text>The code snippet below will populate the ``store`` dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)

&lt;pre&gt;
from itertools import count

def pattern_update(sequence, width=2, store={}):
    """
    Accumulates nucleotide patterns of a certain width with 
    position counts at each index.
    """
   
    # open intervals need a padding at end for proper slicing
    size  = len(sequence) + 1

    def zeroes():
        "Generates an empty array that holds the positions"
        return [ 0 ] * (size - width)
    
    # these are the end indices
    ends = range(width, size)

    for lo, hi in zip(count(), ends):
        # upon encoutering a missing key initialize 
        # that value for that key to the return value of the empty() function
        key = sequence[lo:hi]
        store.setdefault(key, zeroes())[lo] += 1

    return store

&lt;/pre&gt;

The code at [multipatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:

&lt;pre&gt;
    store = {}
    seq1 = 'ATGCT'
    pattern_update(seq1, width=2, store=store)    

    seq2 = 'ATCGC'
    pattern_update(seq2, width=2, store=store)    

    print store
&lt;/pre&gt;

will print:

&lt;pre&gt;
{'CG': [0, 0, 1, 0], 'GC': [0, 0, 1, 1], 'AT': [2, 0, 0, 0], 
'TG': [0, 1, 0, 0], 'TC': [0, 1, 0, 0], 'CT': [0, 0, 0, 1]}
&lt;/pre&gt;

  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py</Text>
  </row>
  <row>
    <Id>49</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>59e98199-cd17-4def-8290-9e73b6659e64</RevisionGUID>
    <CreationDate>2009-10-13T14:53:15.19</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed title; added 20 characters in body; edited tags</Comment>
    <Text>How to generate multi-nucleotide occupancy counts for each coordinate of my reads?</Text>
  </row>
  <row>
    <Id>50</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>59e98199-cd17-4def-8290-9e73b6659e64</RevisionGUID>
    <CreationDate>2009-10-13T14:53:15.19</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed title; added 20 characters in body; edited tags</Comment>
    <Text> énucleotidesà </Text>
  </row>
  <row>
    <Id>51</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>10</PostId>
    <RevisionGUID>59e98199-cd17-4def-8290-9e73b6659e64</RevisionGUID>
    <CreationDate>2009-10-13T14:53:15.19</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed title; added 20 characters in body; edited tags</Comment>
    <Text>I need to generate nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output (for di-nucleotide AT):

![dinucleotide occupancy][1]


  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png</Text>
  </row>
  <row>
    <Id>52</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>11</PostId>
    <RevisionGUID>954b0de1-7c18-4529-9f04-13fdb82e1b7c</RevisionGUID>
    <CreationDate>2009-10-13T15:00:00.047</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added colorization</Comment>
    <Text>The code snippet below will populate the ``store`` dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)::



    from itertools import count

    def pattern_update(sequence, width=2, store={}):
        """
        Accumulates nucleotide patterns of a certain width with 
        position counts at each index.
        """
       
        # open intervals need a padding at end for proper slicing
        size  = len(sequence) + 1

        def zeroes():
            "Generates an empty array that holds the positions"
            return [ 0 ] * (size - width)
        
        # these are the end indices
        ends = range(width, size)

        for lo, hi in zip(count(), ends):
            # upon encoutering a missing key initialize 
            # that value for that key to the return value of the empty() function
            key = sequence[lo:hi]
            store.setdefault(key, zeroes())[lo] += 1

        return store



The code at [multipatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case::


    store = {}
    seq1 = 'ATGCT'
    pattern_update(seq1, width=2, store=store)    

    seq2 = 'ATCGC'
    pattern_update(seq2, width=2, store=store)    

    print store

will print::


    {'CG': [0, 0, 1, 0], 'GC': [0, 0, 1, 1], 'AT': [2, 0, 0, 0], 
    'TG': [0, 1, 0, 0], 'TC': [0, 1, 0, 0], 'CT': [0, 0, 0, 1]}


[1]: http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py
    </Text>
  </row>
  <row>
    <Id>53</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>19</PostId>
    <RevisionGUID>c6e65a0f-b607-4073-88d3-97ffac649a54</RevisionGUID>
    <CreationDate>2009-10-16T12:25:38.237</CreationDate>
    <IPAddress>128.118.200.244</IPAddress>
    <UserId>5</UserId>
    <Text>I would recommend a combination of cluster and treeview.

pretty powerful!</Text>
  </row>
  <row>
    <Id>54</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>20</PostId>
    <RevisionGUID>ca785621-6ba3-4294-a824-edce441314cf</RevisionGUID>
    <CreationDate>2009-10-18T03:22:53.98</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text>any ideas im a girl</Text>
  </row>
  <row>
    <Id>55</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>20</PostId>
    <RevisionGUID>ca785621-6ba3-4294-a824-edce441314cf</RevisionGUID>
    <CreationDate>2009-10-18T03:22:53.98</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text>do you have to be a guy to dress up as boy george</Text>
  </row>
  <row>
    <Id>56</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>20</PostId>
    <RevisionGUID>ca785621-6ba3-4294-a824-edce441314cf</RevisionGUID>
    <CreationDate>2009-10-18T03:22:53.98</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text> éboyà  égeorgeà </Text>
  </row>
  <row>
    <Id>57</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>21</PostId>
    <RevisionGUID>320b381f-1d81-4ee1-8533-44fe5613e1ab</RevisionGUID>
    <CreationDate>2009-10-18T03:23:34.373</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text>any ideas im a girl</Text>
  </row>
  <row>
    <Id>58</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>21</PostId>
    <RevisionGUID>320b381f-1d81-4ee1-8533-44fe5613e1ab</RevisionGUID>
    <CreationDate>2009-10-18T03:23:34.373</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text>do you have to be a guy to dress up as boy george</Text>
  </row>
  <row>
    <Id>59</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>21</PostId>
    <RevisionGUID>320b381f-1d81-4ee1-8533-44fe5613e1ab</RevisionGUID>
    <CreationDate>2009-10-18T03:23:34.373</CreationDate>
    <IPAddress>219.89.7.131</IPAddress>
    <UserId>15</UserId>
    <Text> éboyà  égeorgeà </Text>
  </row>
  <row>
    <Id>60</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>20</PostId>
    <RevisionGUID>c95d97d5-4742-40e4-939f-27d5464210f9</RevisionGUID>
    <CreationDate>2009-10-18T16:23:04.07</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>61</Id>
    <PostHistoryTypeId>14</PostHistoryTypeId>
    <PostId>21</PostId>
    <RevisionGUID>19d7e12d-bd85-458a-9512-2d1ca515204f</RevisionGUID>
    <CreationDate>2009-10-18T16:24:15.44</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>62</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>21</PostId>
    <RevisionGUID>900f3279-3cbc-4344-aeba-b50515ff760a</RevisionGUID>
    <CreationDate>2009-10-18T16:25:02.687</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>63</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>22</PostId>
    <RevisionGUID>b9a0f013-edae-4535-b83e-1182892e3959</RevisionGUID>
    <CreationDate>2009-10-23T17:42:24.427</CreationDate>
    <IPAddress>130.245.187.143</IPAddress>
    <UserId>16</UserId>
    <Text>Hey,

I was using DAVID (http://david.abcc.ncifcrf.gov/conversion.jsp) to do the gene ID conversion, e.g.conversion between Agilent ID, Genebank accession id and Entrez gene ID, but I found the DAVID database is not updated. Does anyone know a better updataed conversion tool to do this job? Thanks! </Text>
  </row>
  <row>
    <Id>64</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>22</PostId>
    <RevisionGUID>b9a0f013-edae-4535-b83e-1182892e3959</RevisionGUID>
    <CreationDate>2009-10-23T17:42:24.427</CreationDate>
    <IPAddress>130.245.187.143</IPAddress>
    <UserId>16</UserId>
    <Text>Gene ID conversion tool</Text>
  </row>
  <row>
    <Id>65</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>22</PostId>
    <RevisionGUID>b9a0f013-edae-4535-b83e-1182892e3959</RevisionGUID>
    <CreationDate>2009-10-23T17:42:24.427</CreationDate>
    <IPAddress>130.245.187.143</IPAddress>
    <UserId>16</UserId>
    <Text> égeneidà </Text>
  </row>
  <row>
    <Id>66</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>23</PostId>
    <RevisionGUID>9ff6f548-c4ba-4720-9189-850cc4c56018</RevisionGUID>
    <CreationDate>2009-10-23T19:46:45.407</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I don't know of a direct solution myself, but this is a topic that may be of interest for the biological data analysis class that I am teaching. 

If you specify the organism/genomic builds that you are interested in we may be able to generate a full translation list as an in class example or a homework. I was planning on covering an `Affymetrix ID` to `Genebank example` anyhow.
</Text>
  </row>
  <row>
    <Id>67</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>24</PostId>
    <RevisionGUID>ee0d163a-fa39-441c-88b7-b3c7f8a705af</RevisionGUID>
    <CreationDate>2009-12-01T07:13:53.637</CreationDate>
    <IPAddress>71.58.68.17</IPAddress>
    <UserId>14</UserId>
    <Text>Hi,

I have 35bp Solid colorspace sequencing data, and the actual sequences to be mapped are 20-25bp after removing the linker sequence.

I hope to find all the hits allowing no more than n mismatches (say n=3), not only the best hit.

I know there is a -M option to specify -M sensitivity,35bp. I wonder whether this setting will guarantee the best sensitivity in this case. Since my reads are only 20-25bp long, should I changed the default 4 spaced seeds to 3?

I'm new to SHRiMP, so I'd like to hear some suggestions on setting the parameters of SHRiMP to achieve the best sensitivity.

Thank you!</Text>
  </row>
  <row>
    <Id>68</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>24</PostId>
    <RevisionGUID>ee0d163a-fa39-441c-88b7-b3c7f8a705af</RevisionGUID>
    <CreationDate>2009-12-01T07:13:53.637</CreationDate>
    <IPAddress>71.58.68.17</IPAddress>
    <UserId>14</UserId>
    <Text>How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?</Text>
  </row>
  <row>
    <Id>69</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>24</PostId>
    <RevisionGUID>ee0d163a-fa39-441c-88b7-b3c7f8a705af</RevisionGUID>
    <CreationDate>2009-12-01T07:13:53.637</CreationDate>
    <IPAddress>71.58.68.17</IPAddress>
    <UserId>14</UserId>
    <Text> éshrimpà  ésequencingà  éshortöreadöalignerà </Text>
  </row>
  <row>
    <Id>70</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>25</PostId>
    <RevisionGUID>dd0cf6f1-51d7-4370-aefb-a450ecc52245</RevisionGUID>
    <CreationDate>2009-12-01T14:57:35.3</CreationDate>
    <IPAddress>128.118.200.154</IPAddress>
    <UserId>18</UserId>
    <Text>I just read the SHRiMP manual again, but I think that their explanation about -M option may not be enough to answer your question. I usually use the "seed" mode by using -s, -n, and -w and the option -M is a new feature of the version 1.3.1, which I have never tried before.

I recommend for you to use the "seed" mode--the default would be good, but please adjust the -s option if you want more sensitivity. Always fast speed compensates sensitivity and the -M option seems to exist for this purpose.

Hope my message to be helpful for your project.</Text>
  </row>
  <row>
    <Id>71</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>26</PostId>
    <RevisionGUID>af6e5964-32fa-4a41-a1a5-273177824f06</RevisionGUID>
    <CreationDate>2009-12-01T18:00:53.443</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>&gt; Since my reads are only 20-25bp long,
&gt; should I changed the default 4 spaced
&gt; seeds to 3?

while the shrimp manual says:

- We recommend using the default 4 seeds of weight 12 in most cases.

you could try running on a smaller sample and see what happens. </Text>
  </row>
  <row>
    <Id>72</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>27</PostId>
    <RevisionGUID>b194e2c2-8684-4852-89e7-c3954301ecb9</RevisionGUID>
    <CreationDate>2009-12-08T21:45:54.547</CreationDate>
    <IPAddress>69.174.113.20</IPAddress>
    <UserId>19</UserId>
    <Text>The following link has a list of ID conversion tools:

http://hum-molgen.org/NewsGen/08-2009/000020.html</Text>
  </row>
  <row>
    <Id>73</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>28</PostId>
    <RevisionGUID>01e4b6ce-df7a-41e6-a8f4-a12a42a311b3</RevisionGUID>
    <CreationDate>2010-01-13T12:59:22.603</CreationDate>
    <IPAddress>71.231.55.142</IPAddress>
    <UserId>20</UserId>
    <Text>Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?

I can compile the suite and its tests pass. However, when I attempt to use the `-p n` option, to specify `n` computation nodes, I get several error messages:

    /gridware/codine/util/arch: Command not found.
    /gridware/codine/util/arch: Command not found.
    /gridware/codine/util/arch: Command not found.
    /gridware/codine/util/arch: Command not found.
    1: Command not found.

We do not have `/gridware/codine/util/arch`, but we do have `/gridengine/sgi/util/arch`.

I tried looking around MEME's source code, particularly at `meme.c` and `mp.h`, but there are no references to these paths.

I'm wondering if I am missing makefile directives. Here is my `./configure` statement:

    ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build --with-url="http://meme.nbcr.net/meme" --enable-openmp --enable-debug

Is MPI a requirement; are there directives I am missing for MPI?

Thank you for any advice.</Text>
  </row>
  <row>
    <Id>74</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>28</PostId>
    <RevisionGUID>01e4b6ce-df7a-41e6-a8f4-a12a42a311b3</RevisionGUID>
    <CreationDate>2010-01-13T12:59:22.603</CreationDate>
    <IPAddress>71.231.55.142</IPAddress>
    <UserId>20</UserId>
    <Text>Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster</Text>
  </row>
  <row>
    <Id>75</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>28</PostId>
    <RevisionGUID>01e4b6ce-df7a-41e6-a8f4-a12a42a311b3</RevisionGUID>
    <CreationDate>2010-01-13T12:59:22.603</CreationDate>
    <IPAddress>71.231.55.142</IPAddress>
    <UserId>20</UserId>
    <Text> émemeà  ésgeà  émotifà  émotifödiscoveryà  écompilationà </Text>
  </row>
  <row>
    <Id>76</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>29</PostId>
    <RevisionGUID>d5e28eaa-9643-4bb3-87d0-4d3a7fd1eb10</RevisionGUID>
    <CreationDate>2010-01-13T21:17:50.023</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>This may not be overly useful but it very much sounds like a configuration problem.

Usually there is  configure flag that needs to be set to point to the libraries, something like:

    --with-mpidir=MPIDIR
    --with-mpicc=MPICC

It also appears that the MEME suite does not support Open MPI (as per [install notes][1]).

I would also recommend posting on the MEME user forum:

[https://www.nbcr.net/forum/viewforum.php?f=5][2]


  [1]: http://meme.sdsc.edu/meme4/meme-install.html
  [2]: https://www.nbcr.net/forum/viewforum.php?f=5</Text>
  </row>
  <row>
    <Id>77</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>30</PostId>
    <RevisionGUID>61ef2ec2-5828-4507-b541-ad6eab18fbea</RevisionGUID>
    <CreationDate>2010-01-15T08:48:14.66</CreationDate>
    <IPAddress>71.231.55.142</IPAddress>
    <UserId>20</UserId>
    <Text>Here's a Perl script I wrote if you wanted to do something local. 

There's some code in there for translating yeast chromosome names that can be removed, if not needed. I also used a `Site` feature in the GFF file as the region ID, which might also need tweaking, depending on what features you're interested in.

    #!/usr/bin/perl -w

    use strict;
    use Bio::Tools::GFF;
    use feature qw(say switch);

    my $gffio = Bio::Tools::GFF-&gt;new(-fh =&gt; \*STDIN, -gff_version =&gt; 2);
    my $feature;

    while ($feature = $gffio-&gt;next_feature()) {
        # print $gffio-&gt;gff_string($feature)."\n";

        # cf. http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml
        my $seq_id = $feature-&gt;seq_id();   
        my $start = $feature-&gt;start() - 1;
        my $end = $feature-&gt;end();
        my $strand = $feature-&gt;strand();
        my @sites = $feature-&gt;get_tag_values('Site');

        # translate strand
        given ( $strand ) {
            when ($_ == 1)  { $strand = "+"; }
            when ($_ == -1) { $strand = "-"; }
        }
    
        # translate yeast chromosome to UCSC browser-readable chromosome
        # cf. http://www.yeastgenome.org/sgdpub/Saccharomyces_cerevisiae.pdf
        given ( $seq_id ) {
            when ( $_ eq "I" )    { $seq_id = "chr1"; }
            when ( $_ eq "II" )   { $seq_id = "chr2"; }
            when ( $_ eq "III" )  { $seq_id = "chr3"; }
            when ( $_ eq "IV" )   { $seq_id = "chr4"; }
            when ( $_ eq "V" )    { $seq_id = "chr5"; }
            when ( $_ eq "VI" )   { $seq_id = "chr6"; }
            when ( $_ eq "VII" )  { $seq_id = "chr7"; }
            when ( $_ eq "VIII" ) { $seq_id = "chr8"; }
            when ( $_ eq "IX" )   { $seq_id = "chr9"; }
            when ( $_ eq "X" )    { $seq_id = "chr10"; }
            when ( $_ eq "XI" )   { $seq_id = "chr11"; }
            when ( $_ eq "XII" )  { $seq_id = "chr12"; }
            when ( $_ eq "XIII" ) { $seq_id = "chr13"; }
            when ( $_ eq "XIV" )  { $seq_id = "chr14"; }
            when ( $_ eq "XV" )   { $seq_id = "chr15"; }
            when ( $_ eq "XVI" )  { $seq_id = "chr16"; }
            default { }
        }

        # output
        print "$seq_id\t$start\t$end\t$sites[0]\t0.0\t$strand\n";
    }
    $gffio-&gt;close();

To use it:

    gff2bed.pl &lt; data.gff &gt; data.bed</Text>
  </row>
  <row>
    <Id>78</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>31</PostId>
    <RevisionGUID>86b83a97-90a6-4ba8-8777-f0a6ca71b711</RevisionGUID>
    <CreationDate>2010-01-22T03:14:17.38</CreationDate>
    <IPAddress>76.111.161.197</IPAddress>
    <UserId>4</UserId>
    <Text>Hi, I recently performed an RNA immunoprecipitation followed by SOLiD sequencing (50 bp fragmented reads). I haven't received my first SOLiD sequencing results yet, but I was told I should have them soon. I've tried doing my own research on how to map, align, and plot my results but I don't have a concrete workflow as to how I will analyze my results yet. I have very little experience doing any programming and would prefer to use galaxy. There are labs on my campus I can go to to get my color space data mapped, but I would like to do things myself. Is there a way on galaxy (or another program) to convert my color space data to sequence, then map those reads to the yeast transcriptome and analyze it? Even if you can't answer my question directly I'd appreciate any tips from anyone who has worked with RNA-seq data already.    

Thanks in advance </Text>
  </row>
  <row>
    <Id>79</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>31</PostId>
    <RevisionGUID>86b83a97-90a6-4ba8-8777-f0a6ca71b711</RevisionGUID>
    <CreationDate>2010-01-22T03:14:17.38</CreationDate>
    <IPAddress>76.111.161.197</IPAddress>
    <UserId>4</UserId>
    <Text>How do I map, align, and plot my SOLiD results?</Text>
  </row>
  <row>
    <Id>80</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>31</PostId>
    <RevisionGUID>86b83a97-90a6-4ba8-8777-f0a6ca71b711</RevisionGUID>
    <CreationDate>2010-01-22T03:14:17.38</CreationDate>
    <IPAddress>76.111.161.197</IPAddress>
    <UserId>4</UserId>
    <Text> ésolidà  érnaöseqà  égalaxyà </Text>
  </row>
  <row>
    <Id>81</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>32</PostId>
    <RevisionGUID>3b7b7440-3c8b-4365-bd5d-6a7a867eb6f8</RevisionGUID>
    <CreationDate>2010-01-22T15:13:42.79</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Personally I would advise that if you know someone who can partially perform the task you should have them do it, and ask them to explain and show it to you how they've done it.

The task at hand is complex. The solution always depends immensely on the particulars of the problem, moreover you will be facing myriads of frustrating limitations, errors and problems.

Learning directly from someone who has done it, establishing a personal rapport with them will allow you to ease into this problem dowwwportalmlekozyjestart. In fact when you are finished mapping your RNA - your are still likely to be far from being done - yet you might have expanded a lot of energy and excitement. 


</Text>
  </row>
  <row>
    <Id>82</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>33</PostId>
    <RevisionGUID>e5b2e31a-3a8b-476a-8eec-f36bb13b88ea</RevisionGUID>
    <CreationDate>2010-01-26T15:14:38.623</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>So, you will probably hate me for asking this question here, as there are lot of forum and blog posts on internet about it and it is also a very subjective question.

However, it may be a starting point for a good discussion, if we don't flame... Which operating system do you usually use for your work? Did you install it by yourself, and do you have administrative rights on it, or is there any IT administrator in your lab? </Text>
  </row>
  <row>
    <Id>83</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>33</PostId>
    <RevisionGUID>e5b2e31a-3a8b-476a-8eec-f36bb13b88ea</RevisionGUID>
    <CreationDate>2010-01-26T15:14:38.623</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Which operating system do you prefer for bioinformatics?</Text>
  </row>
  <row>
    <Id>84</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>33</PostId>
    <RevisionGUID>e5b2e31a-3a8b-476a-8eec-f36bb13b88ea</RevisionGUID>
    <CreationDate>2010-01-26T15:14:38.623</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> égeneralà </Text>
  </row>
  <row>
    <Id>85</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>33e41016-9a2b-4f62-8551-716081fda13f</RevisionGUID>
    <CreationDate>2010-01-26T15:45:06.737</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>This is also a very classic question, however, it can be a very useful discussion for novices which are wishing to work in the bioinformatics field, and have to decide how to organize their time.
I have seen some surveys on this, for example on bioinformatics.org and on bioinformaticszen, but none of these cases were open discussions.


Which is your favorite programming language in bioinformatics? I actually use very much of Python and R, and hate Perl :-)





</Text>
  </row>
  <row>
    <Id>86</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>33e41016-9a2b-4f62-8551-716081fda13f</RevisionGUID>
    <CreationDate>2010-01-26T15:45:06.737</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Which programming languages are good to study for bioinformatics?</Text>
  </row>
  <row>
    <Id>87</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>33e41016-9a2b-4f62-8551-716081fda13f</RevisionGUID>
    <CreationDate>2010-01-26T15:45:06.737</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésubjectiveà </Text>
  </row>
  <row>
    <Id>88</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>35</PostId>
    <RevisionGUID>8504582d-e32c-40c2-9fa6-0f2fccd6335a</RevisionGUID>
    <CreationDate>2010-01-26T20:23:45.583</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Often people are limited to their choices by factors outside of their control. One lab that I work with requires the use of Mac computers another is using Windows mostly. Large scale computations seem to be best suited for Linux systems.

Luckily there is a migration towards unified capabilities across all platforms. Installing Cygwin on Windows allows us to tap into the power of Unix, while Linux distros have advanced graphical user interfaces like Windows and Macs.

From my own observations of non technical people, the installation of new and interdependent software packages seems to be the most difficult on Mac computers and easiest on Windows due to the computational architecture that makes all Windows computers identical. 
</Text>
  </row>
  <row>
    <Id>89</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>36</PostId>
    <RevisionGUID>df1d5217-fd4e-4359-88ac-d1e057b7e39a</RevisionGUID>
    <CreationDate>2010-01-26T20:32:29.45</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>It is important to be considerate and not characterize one particular approach negatively. My favorite quote is:

**Programming is pure thought.**

Hopefully everyone is able to pick an approach that matches their individual way of thinking. While I myself do not program in Perl, I consider it to be one of the most popular and powerful platforms for doing bioinformatics analysis. </Text>
  </row>
  <row>
    <Id>90</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>37</PostId>
    <RevisionGUID>5df131ee-d9f6-4df0-b9f8-75fde62e4566</RevisionGUID>
    <CreationDate>2010-01-26T20:38:24.477</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Tips for installing software om Max OS X:

 - install the Apple developer tools called **Xcode** [http://developer.apple.com/tools/xcode/][1]
 - install **MacPorts** from [http://www.macports.org/][2]

You can now easily install everything from command line using the `port` command. List all available software

    port list

Install libraries and software. etc:

    port install &lt;some-library&gt;

  [1]: http://developer.apple.com/tools/xcode/
  [2]: http://www.macports.org/</Text>
  </row>
  <row>
    <Id>91</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>38</PostId>
    <RevisionGUID>0ddec256-3225-4c31-a359-ac7de1ebd704</RevisionGUID>
    <CreationDate>2010-01-26T23:42:14.167</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>25</UserId>
    <Text>Any programming language is good as long you know what you're doing.</Text>
  </row>
  <row>
    <Id>92</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>39</PostId>
    <RevisionGUID>ac923c57-3225-419c-bafe-816ec085df82</RevisionGUID>
    <CreationDate>2010-01-27T10:08:52.87</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>You can also do it with the following services:

 - [uniprot][1] - Click on 'Id Mapping' from the home page.
 - [biomart][2] - choose a database and a version, then put the ids you want to convert under Filters-&gt;Id List limit (select the proper input id in the menu), and then the output ids under 'Attributes'. Biomart is a general tool that enables you to extract a lot of different informations from databases - sequences, ontologies, transcripts, homologues - but maybe for converting gene ids is a bit too complex.
 - [galaxy][3] - I can't help too much about this here but I am sure it has a function for doing that - and many other things.


  [1]: http://www.uniprot.org/?tab=mapping
  [2]: http://www.biomart.org/biomart/martview/
  [3]: http://wwwportalmlekozyjestart.g2.bx.psu.edu/</Text>
  </row>
  <row>
    <Id>93</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>40</PostId>
    <RevisionGUID>d913b49b-14cc-491e-a471-d5c53ffec0c4</RevisionGUID>
    <CreationDate>2010-01-28T15:31:50.47</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Meme has been the first program to be published for doing that.
As an alternative you can find one of the [EMBOSS tools][1]; if you are scared by a terminal and want to do it from a web-based interface, you can use the EMBOSS tools from [galaxy][2]


  [1]: http://www.be.embnet.org/embosshelp/
  [2]: http://wwwportalmlekozyjestart.g2.bx.psu.edu/</Text>
  </row>
  <row>
    <Id>94</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>41</PostId>
    <RevisionGUID>181f5d38-b53d-4f5f-91fb-0c15ac897f96</RevisionGUID>
    <CreationDate>2010-01-28T16:17:37.437</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.

I have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.

It is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations that they use.

What is your experience about [GO][2]?


  [1]: http://www.geneontology.org/
  [2]: http://www.geneontology.org/</Text>
  </row>
  <row>
    <Id>95</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>41</PostId>
    <RevisionGUID>181f5d38-b53d-4f5f-91fb-0c15ac897f96</RevisionGUID>
    <CreationDate>2010-01-28T16:17:37.437</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>how much do you trust GeneOntology?</Text>
  </row>
  <row>
    <Id>96</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>41</PostId>
    <RevisionGUID>181f5d38-b53d-4f5f-91fb-0c15ac897f96</RevisionGUID>
    <CreationDate>2010-01-28T16:17:37.437</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésubjectiveà  égeneontologyà  égoà </Text>
  </row>
  <row>
    <Id>97</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>42</PostId>
    <RevisionGUID>cbd172f5-19de-40cd-a88b-f41b869fb329</RevisionGUID>
    <CreationDate>2010-01-28T16:22:04.203</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>The StackExchange websites have been designed for making questions related to programming and technical issues.

For example, for this reason, if you try to write a question which starts with 'What is your favorite experience...' you get a disclaimer saying that 'your question seems to be probably subjective and it is likely to be closed'.

However, I think that it is very useful to make subjective and opinion-based questions on bioinformatics, as there are few places to do so... So, what is your policy? Will you accept subjective questions?</Text>
  </row>
  <row>
    <Id>98</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>43</PostId>
    <RevisionGUID>8be49839-3ebe-4224-a1b4-7aac68448a66</RevisionGUID>
    <CreationDate>2010-01-28T17:58:20.5</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>The choice of a programming language is purely subjective, but when a student asks you which programming language he should start with, you have to make an answer, or at least provide some informations.

I think that a bioinformatician who studies **R** and at least two or three libraries (lattice/ggplot2, plyr) early can have an advantage, because he will be able to represent his data properly and obtain good results without too much effort. If your supervisor is not a computer scientist, he will be a lot more impressed by plots and charts than by programs, even if they are well written, with unittests etc.

**Python** is a good programming language to learn as a general purpose tool. Its bigger advantages are its easy to read syntax, and its paradigm 'there is only one way to do it', so the number of language keywords is reduced to the minimum, and two programs with the same function written by different people will be very similar (which is what doesn't happen with perl). 
The negative points of python are that its CSV files reading/plotting interface is not ready yet (the best is pylab), so you must rely on R to produce nice plots.

Honestly I don't like **perl**, because I think it can induce to many bad-behaviours in novel programmers. For example, in perl there are many similar constructs to accomplish the same objective: so, it is very difficult to understand a program written by someone else, because you have to known all the possible constructs and hope there are enough comments. It is already very difficult to reproduce a bioinformatician experiment, if you write your code in a difficult language it is a lot worst. 
Moreover, I know of many people who have been using perl for years, but that don't even use functions, because it looks too complicated. How can it be? It looks very inefficient. 
The only good point of perl is its repositories, bioperl and CPAN; however, I know of people using perl that don't even know of the existence of these, so I don't understand why they keep going with perl.


Apart from programming language, is it very useful to learn the basic usage of **gnu-make**, or of a derivate. This program is very useful when you have lot of different scripts, as it allows you to define a pipeline in order to run them. 
Some basic **bash commands** may also be very useful if you work with a lot of flat files (head, sed, gawk, grep, ...)</Text>
  </row>
  <row>
    <Id>99</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>44</PostId>
    <RevisionGUID>973ceaa8-d106-430e-aa6e-c32ebc04ea3e</RevisionGUID>
    <CreationDate>2010-01-28T22:41:29.17</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>The GO terms and classifications are primarily an based on opinions and a human interpretation of a small group of people of what the current state of the knowledge is.Thus  are more subjective than say experimental measurements would be. 

In fact it is surprising that it works at all; and it does indeed.  We just need to becareful not too read to much into it.</Text>
  </row>
  <row>
    <Id>100</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>45</PostId>
    <RevisionGUID>f723805d-0455-46a7-91da-46bd74255400</RevisionGUID>
    <CreationDate>2010-01-29T05:50:26.02</CreationDate>
    <IPAddress>76.111.161.197</IPAddress>
    <UserId>4</UserId>
    <Text>In my experience it's case by case. In other words just because you are getting significant p-values, does not mean the results are biologically significant. I once submitted clusters of microarray data and received a bunch of hits that were significant by p-value, but really didn't have a theme. The GO terms I saw were from many different processes without an overall term (besides biological process) which linked them together. When I've looked at published GO terms searches I generally see a strong theme among many of the terms (however that doesn't necessarily mean it has biological significance until tested empirically). So seeing themes among your terms may suggest higher significance, but it should make biological sense too. 

</Text>
  </row>
  <row>
    <Id>101</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>46</PostId>
    <RevisionGUID>97dfc24d-e710-4a14-bed2-741d7b101048</RevisionGUID>
    <CreationDate>2010-01-29T11:42:23.043</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>STRING is a database of predicted protein-protein interactions at EMBL. It cluster the results from many sources of protein-protein interactions databases, like Mint, etc.., and it also use the informations from KEGG-pathways and reactome, to provide the best annotations for the interactions of a protein.

I am a bit confused from the results that I see there, because when I look at the genes in the pathway I am studying, I see many errors and annotations that I don't understand.

What is your experience with STRING? If you want to do me a favor, go there and try to see the interactions annotated for a gene that you know already. Do you see anything weird?</Text>
  </row>
  <row>
    <Id>102</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>46</PostId>
    <RevisionGUID>97dfc24d-e710-4a14-bed2-741d7b101048</RevisionGUID>
    <CreationDate>2010-01-29T11:42:23.043</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>What is your experience with the STRING (interactions) database?</Text>
  </row>
  <row>
    <Id>103</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>46</PostId>
    <RevisionGUID>97dfc24d-e710-4a14-bed2-741d7b101048</RevisionGUID>
    <CreationDate>2010-01-29T11:42:23.043</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésubjectiveà  éstringà  éproteinöproteinöinteractià </Text>
  </row>
  <row>
    <Id>104</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>47</PostId>
    <RevisionGUID>4504fb96-b4e3-4488-8e24-ab9cbce0da12</RevisionGUID>
    <CreationDate>2010-01-29T14:06:06.18</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I have not used STRING in particular but I have worked with protein interactions before (DIP dataset). I recall that even experimentally produced protein-protein interactions may have very large false positive ratios  (as for false negatives, who knows?) Some papers claim that up to 50% of the interactions were spurious; and repeated experiments showed very small overlaps. Predictions may be even less reliable.


At the same time the DIP dataset performed substantially better if we only considered the interactions for which there were multiple sources of evidence, so that may be a strategy to consider in your case as well.
</Text>
  </row>
  <row>
    <Id>105</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>41</PostId>
    <RevisionGUID>547bef29-d37e-4061-8c4c-0faeb6b27cdf</RevisionGUID>
    <CreationDate>2010-01-29T14:08:07.753</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>capitalized title</Comment>
    <Text>How much do you trust GeneOntology?</Text>
  </row>
  <row>
    <Id>106</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>48</PostId>
    <RevisionGUID>3e6b34bb-35f6-4564-a79c-380b6f915149</RevisionGUID>
    <CreationDate>2010-02-12T17:33:06.82</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>As in the title... I have a protein and I would like to know its secundary structure.
I couldn't find it in uniprot, althought I tought they had annotations for it there.
In the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.

note: I am tagging this question as 'sequence' because as a novice I am not allowed to create new tags (I tought I already created some before, you must have changed some option)

  [1]: http://www.compbio.dundee.ac.uk/www-jpred</Text>
  </row>
  <row>
    <Id>107</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>48</PostId>
    <RevisionGUID>3e6b34bb-35f6-4564-a79c-380b6f915149</RevisionGUID>
    <CreationDate>2010-02-12T17:33:06.82</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Where can I get the secondary structure of a protein?</Text>
  </row>
  <row>
    <Id>108</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>48</PostId>
    <RevisionGUID>3e6b34bb-35f6-4564-a79c-380b6f915149</RevisionGUID>
    <CreationDate>2010-02-12T17:33:06.82</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésequenceà </Text>
  </row>
  <row>
    <Id>109</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>49</PostId>
    <RevisionGUID>fdc706fe-c305-43b6-9091-c22c67ab2379</RevisionGUID>
    <CreationDate>2010-02-12T20:01:49.187</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Protein structure prediction is a complex issue that is likely to require multiple approaches. There are many methods/tools listed at the 

 - [Expert Protein Analysis System website][1]


  [1]: http://www.expasy.ch/</Text>
  </row>
  <row>
    <Id>110</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>50</PostId>
    <RevisionGUID>d75abaf0-da61-44ec-a93f-3dcafec661a2</RevisionGUID>
    <CreationDate>2010-02-12T21:57:06.68</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>I think you found the best answer yourself: use a predictor! There are several out there...

You suggest that there should be a Secondary Structure Database. I'm not sure that makes much sense, let me explain my point of view (which may not be that of everyone): most often, the data that is found in databases is the "state of knowledge" of the described object, based on experimentation.

That may be the case for secondary structures of proteins, but only in the case where the said proteins have been crystalized. In those cases, it is not only the secondary structures but also the tertiary structures (with the caveat that the crystal structure of a protein does not prove "all" states that a protein may take in real "dynamic" physiological conditions).

For all those proteins that have not been crystalized, then we can only rely on predictions. And I use them quite frequently: they are extremely useful! But as far as I know, no prediction is accepted as fact. They're "educated guesses" that are often correct, but sometimes wrong. The results may differ from one prediction method to another. Also they change each time the algorithms are improved...

If there was a database of predicted secondary structures, people would likely take them for granted (make the equation prediction = fact) which would be quite "unscientific".

I think such a resource would be more of a hindrance than an asset to the scientific community...</Text>
  </row>
  <row>
    <Id>111</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>48</PostId>
    <RevisionGUID>67a9c9fd-039d-4514-ab01-429f010e7a88</RevisionGUID>
    <CreationDate>2010-02-13T18:08:36.633</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>edited tags</Comment>
    <Text> ésequenceà  éproteinà  éstructureà </Text>
  </row>
  <row>
    <Id>112</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>51</PostId>
    <RevisionGUID>8a523e41-465c-4580-b851-5d34cccde4a4</RevisionGUID>
    <CreationDate>2010-02-16T01:13:06.543</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text>I have a quick question:
How can I turn off search on reverse complement strand of my query nucleotide sequence in blastn?

For example, I don't want 'GUAAAGCCAAAUCUUCGGUUA' to be a hit when I use 'UAACCGAAGAUUUGGCUUUAC' as the query.

Maybe I missed it when I read the man page, but I really appreciate it if someone can point out the parameter I should use.

Thanks!</Text>
  </row>
  <row>
    <Id>113</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>51</PostId>
    <RevisionGUID>8a523e41-465c-4580-b851-5d34cccde4a4</RevisionGUID>
    <CreationDate>2010-02-16T01:13:06.543</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text>Turn off BLAST search on reverse complement strand in blastn</Text>
  </row>
  <row>
    <Id>114</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>51</PostId>
    <RevisionGUID>8a523e41-465c-4580-b851-5d34cccde4a4</RevisionGUID>
    <CreationDate>2010-02-16T01:13:06.543</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text> ésequenceà </Text>
  </row>
  <row>
    <Id>115</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>52</PostId>
    <RevisionGUID>2404ca28-5c81-4455-a698-5ed1d07a8bab</RevisionGUID>
    <CreationDate>2010-02-16T02:31:37.06</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>The -S flag can select the strands:

    -S  Query strands to search against database 
        (for blast[nx], and tblastx) 3 is both, 1 is top, 2 is bottom [Integer]</Text>
  </row>
  <row>
    <Id>116</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>51</PostId>
    <RevisionGUID>5e156f0e-5442-41f4-a09c-9f3d6a3df70a</RevisionGUID>
    <CreationDate>2010-02-16T19:20:31.193</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added tags</Comment>
    <Text> ésequenceà  éblastà </Text>
  </row>
  <row>
    <Id>117</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>53</PostId>
    <RevisionGUID>69b9fe3b-9971-4bf7-b831-d0c415b61d31</RevisionGUID>
    <CreationDate>2010-02-19T07:29:18.733</CreationDate>
    <IPAddress>137.189.51.114</IPAddress>
    <UserId>27</UserId>
    <Text>The reads returned from the Solid sequencing provider are littered with dots and some bases have a negative quality value. Does anyone know if there is a good method to extract high quality regions from the reads without distorting the reading of bases in colour space?</Text>
  </row>
  <row>
    <Id>118</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>53</PostId>
    <RevisionGUID>69b9fe3b-9971-4bf7-b831-d0c415b61d31</RevisionGUID>
    <CreationDate>2010-02-19T07:29:18.733</CreationDate>
    <IPAddress>137.189.51.114</IPAddress>
    <UserId>27</UserId>
    <Text>How to do quality trimming of SoLid Reads in colour space?</Text>
  </row>
  <row>
    <Id>119</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>53</PostId>
    <RevisionGUID>69b9fe3b-9971-4bf7-b831-d0c415b61d31</RevisionGUID>
    <CreationDate>2010-02-19T07:29:18.733</CreationDate>
    <IPAddress>137.189.51.114</IPAddress>
    <UserId>27</UserId>
    <Text> ésolidà </Text>
  </row>
  <row>
    <Id>120</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>54</PostId>
    <RevisionGUID>56f7fc90-ae3f-4090-b6d7-4c2ca274b1f3</RevisionGUID>
    <CreationDate>2010-02-19T07:31:24.643</CreationDate>
    <IPAddress>137.189.51.114</IPAddress>
    <UserId>27</UserId>
    <Text>You can try BWA as well:
http://maq.sourceforge.net/bwa-man.shtml</Text>
  </row>
  <row>
    <Id>121</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>55</PostId>
    <RevisionGUID>4020fc0f-e2d1-480c-b035-edea04312c1a</RevisionGUID>
    <CreationDate>2010-02-19T13:33:45.533</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>28</UserId>
    <Text>The [Solid Accuracy Enhancer Tool][1] might be useful for this.


  [1]: http://solidsoftwaretools.com/gf/project/saet/</Text>
  </row>
  <row>
    <Id>122</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>56</PostId>
    <RevisionGUID>c19c9f2e-39c3-47fd-aff2-efad31b79bb4</RevisionGUID>
    <CreationDate>2010-02-21T16:13:39.32</CreationDate>
    <IPAddress>88.22.186.89</IPAddress>
    <UserId>23</UserId>
    <Text>Let's say I want to download the fasta sequence of the region chr1:100000..200000 from the UCSC browser.
How do you do that? I can't find a button to 'export to fasta' in the UCSC genome browser. I think that the solution is to click on one of the tracks displayed, but I am not sure of which.
If I go to the Tables section, I can't find a table with the fasta sequences among the many.</Text>
  </row>
  <row>
    <Id>123</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>56</PostId>
    <RevisionGUID>c19c9f2e-39c3-47fd-aff2-efad31b79bb4</RevisionGUID>
    <CreationDate>2010-02-21T16:13:39.32</CreationDate>
    <IPAddress>88.22.186.89</IPAddress>
    <UserId>23</UserId>
    <Text>how to get the sequence of a genomic region from UCSC?</Text>
  </row>
  <row>
    <Id>124</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>56</PostId>
    <RevisionGUID>c19c9f2e-39c3-47fd-aff2-efad31b79bb4</RevisionGUID>
    <CreationDate>2010-02-21T16:13:39.32</CreationDate>
    <IPAddress>88.22.186.89</IPAddress>
    <UserId>23</UserId>
    <Text> ésequenceà </Text>
  </row>
  <row>
    <Id>125</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>57</PostId>
    <RevisionGUID>4bb6c361-277c-46f0-8027-b261432553e6</RevisionGUID>
    <CreationDate>2010-02-21T19:11:20.45</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>The Genome Browser is for visualization.

To get data in many formats use the [UCSC Table Browser][1] then select the output format of your choice.

You may also need to select the right **group** and **track** to get the data you want.

  [1]: http://genome.ucsc.edu/cgi-bin/hgTables?org=human</Text>
  </row>
  <row>
    <Id>126</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>56</PostId>
    <RevisionGUID>2052e9a3-ee8f-4a60-80dd-df723cc46bf5</RevisionGUID>
    <CreationDate>2010-02-22T15:40:46.36</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added tags</Comment>
    <Text>How to get the sequence of a genomic region from UCSC?</Text>
  </row>
  <row>
    <Id>127</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>56</PostId>
    <RevisionGUID>2052e9a3-ee8f-4a60-80dd-df723cc46bf5</RevisionGUID>
    <CreationDate>2010-02-22T15:40:46.36</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added tags</Comment>
    <Text> ésequenceà  éucscà  éfastaà </Text>
  </row>
  <row>
    <Id>128</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>58</PostId>
    <RevisionGUID>958d8b46-8db8-44b6-83a6-caef65e1a7ba</RevisionGUID>
    <CreationDate>2010-02-25T15:39:15.467</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> One of the most awful problems in my group is avoiding to rewrite scripts that have been already written by others. Since we have different projects and we work with different data, everybody ends up writing its own scripts in his favorite programming language, and it is very frequent to waste an afternoon on writing a new program and then discover that your workmate already had a script to do that.

Apart from the most logical answer ("talk with your workmates"), we are thinking about having a common place to store our best scripts, and if possible work together on them.
It would be similar to an image library like this: http://matplotlib.sourceforge.net/gallery.html , where to put the script and an example of its output (most of our scripts produce graphs), and if possible integrated with Git. 

Do you have any idea? How to you cope with the problem in your lab?</Text>
  </row>
  <row>
    <Id>129</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>58</PostId>
    <RevisionGUID>958d8b46-8db8-44b6-83a6-caef65e1a7ba</RevisionGUID>
    <CreationDate>2010-02-25T15:39:15.467</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>What is the best way to share scripts between members of a lab?</Text>
  </row>
  <row>
    <Id>130</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>58</PostId>
    <RevisionGUID>958d8b46-8db8-44b6-83a6-caef65e1a7ba</RevisionGUID>
    <CreationDate>2010-02-25T15:39:15.467</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> égeneralà  ésubjectiveà </Text>
  </row>
  <row>
    <Id>131</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>59</PostId>
    <RevisionGUID>6d3f043e-fa59-434a-bfde-cf4ac4fe2b7f</RevisionGUID>
    <CreationDate>2010-02-25T17:32:53.74</CreationDate>
    <IPAddress>82.126.79.209</IPAddress>
    <UserId>30</UserId>
    <Text>Use the **DAS** server:

[http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000][1]


  [1]: http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000</Text>
  </row>
  <row>
    <Id>132</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>60</PostId>
    <RevisionGUID>ee735d09-1cc6-417d-942f-4729fb2d713b</RevisionGUID>
    <CreationDate>2010-02-25T17:51:28.29</CreationDate>
    <IPAddress>189.58.177.24</IPAddress>
    <UserId>31</UserId>
    <Text>Some time ago I used SOMBRERO ([http://bioinf.nuigalway.ie/sombrero/download.html][1]) with a good degree of success on finding motifs in a very diverse set of sequences. They have a Mac version for download as well as parallel versions for Irix and Linux.


  [1]: http://bioinf.nuigalway.ie/sombrero/download.html</Text>
  </row>
  <row>
    <Id>133</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>61</PostId>
    <RevisionGUID>2ab9d978-6e94-4c05-8cbd-e3e9e8f532b3</RevisionGUID>
    <CreationDate>2010-02-25T17:54:49.08</CreationDate>
    <IPAddress>189.58.177.24</IPAddress>
    <UserId>31</UserId>
    <Text>I would recommend you to setup a wiki for your group. If you do not have a server readily you can always use one of the many wiki services available for free like Wikispaces (www.wikispaces.com).</Text>
  </row>
  <row>
    <Id>134</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>62</PostId>
    <RevisionGUID>8f630a74-3c8d-4c75-b001-44e0eb87c22c</RevisionGUID>
    <CreationDate>2010-02-25T18:24:46.38</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Integrating with the source code management tool is essential, that way when code gets changed everyone can easily get the updated version. Wikis are also a good idea.</Text>
  </row>
  <row>
    <Id>135</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>63</PostId>
    <RevisionGUID>b32075ed-da23-4816-a7fc-94e54396433c</RevisionGUID>
    <CreationDate>2010-02-25T21:33:37.903</CreationDate>
    <IPAddress>170.223.185.126</IPAddress>
    <UserId>35</UserId>
    <Text>I've been using STRING extensively, but not for protein-protein interactions work. STRING, as you note, is a bit of a mutt in terms of the different data sources it mines. Some that you're missing include a broad literature-based search, as well as gene expression data sets. So if you're interested primarily in physical interactions or any other single type of data source, STRING is a poor choice for your work. On the other hand, STRING does provide confidence scores for each association, as well as annotation for their data source types (with the license). So you can use those to filter out the interactions derived from data types you don't want to see.</Text>
  </row>
  <row>
    <Id>136</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>64</PostId>
    <RevisionGUID>7f6cc7ae-5055-4c55-921f-5ee090e52699</RevisionGUID>
    <CreationDate>2010-02-25T21:41:22.31</CreationDate>
    <IPAddress>170.223.185.126</IPAddress>
    <UserId>35</UserId>
    <Text>Perl can be quite lovely if you choose to write it well. If you find yourself in need of writing some perl, I'd highly recommend getting the Perl Best Practices book and going through it to learn how to make your perl code not suck. Essential tools for helping with that are perlcritic and perltidy, both of which I have bound to quick keystrokes in my emacs cperl-mode so as to make sure my code is in reasonably good shape. There's lots of blog articles out there about writing "Modern Perl" or "Enlightened Perl" that help make the language not just bearable but actually quite nice for a certain type of brain.

One thing that Perl does very well that no other language does is quick text processing on the command line. If you want to do some simple processing of a text file (which is pretty standard in this business), perl is a fantastic package to do so. Stringing together a set of UNIX utilities on a Linux system will usually have you running for a half dozen manpages looking for conflicting and unique switches, where with perl I find that there's far less I have to remember to get the same effect. The book Minimal Perl goes in to this sort of thing in detail (perl as a better awk/sed/grep/etc) and I highly recommend having a look. At the very least, I've found that using perl in this fashion filled a hole in my toolkit that I didn't even realize was there. R and Python can, of course, do this sort of thing too, but not nearly so well as Perl.</Text>
  </row>
  <row>
    <Id>137</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>65</PostId>
    <RevisionGUID>a6091257-2adb-451f-83da-2b450084d022</RevisionGUID>
    <CreationDate>2010-02-25T21:50:25.157</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>33</UserId>
    <Text>My tip: install Cygwin if you are using Windows </Text>
  </row>
  <row>
    <Id>138</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>66</PostId>
    <RevisionGUID>72b9b90b-ded1-4e8e-a6dd-264173375514</RevisionGUID>
    <CreationDate>2010-02-25T21:52:10.69</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>33</UserId>
    <Text>Who is running this site?</Text>
  </row>
  <row>
    <Id>139</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>67</PostId>
    <RevisionGUID>16d24bc9-6703-4607-aa65-486c51202a31</RevisionGUID>
    <CreationDate>2010-02-26T09:51:33.997</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text>All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc.

I wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's "Common Desktop" policy for Windows PCs, which would take control of my computer out of my hands.</Text>
  </row>
  <row>
    <Id>140</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>67</PostId>
    <RevisionGUID>494d11b8-0fb2-43a7-a70e-8584c878fc84</RevisionGUID>
    <CreationDate>2010-02-26T09:56:37.95</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Comment>added 96 characters in body</Comment>
    <Text>All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc. It is also useful to have Internet Explorer kicking around somewhere for compatability testing.

I wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's "Common Desktop" policy for Windows PCs, which would take control of my computer out of my hands.</Text>
  </row>
  <row>
    <Id>141</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>68</PostId>
    <RevisionGUID>10c36185-5a21-4582-a4ac-90ac1f3bf8a6</RevisionGUID>
    <CreationDate>2010-02-26T10:07:14.7</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text>If you want to see the code, but also store associated information, such as expected outputs etc, then a wiki probably is the best choice (we prefer [DokuWiki][1] here), although this would involve a lot of manual effort to document each script. 

Use of a site such as GitHub would give you version control + a handy place to read code, although it is not free to host private repositories there, which I guess is what the majority of labs would require. 

If privacy is not a concern, then I would consider GitHub [gists][2] for code, which can then be embedded in a [Posterous][3] blog for comments. Posterous automatically unfolds Gist URLs into code samples in blog posts, so then you can annotate them easily. This would be a lot less manual effort than a wiki.


  [1]: http://www.dokuwiki.org/dokuwiki
  [2]: http://gist.github.com/
  [3]: http://posterous.com/</Text>
  </row>
  <row>
    <Id>142</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>69</PostId>
    <RevisionGUID>308f2a7a-2708-4c6a-b3f0-e900aca4c6ab</RevisionGUID>
    <CreationDate>2010-02-26T12:50:17.577</CreationDate>
    <IPAddress>82.126.67.146</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
has anobody ever used the [HDF5 API][1] to store some biological data (genotypes...). I know about this [kind of reference][2] (BioHDF...)  but I'm looking for some **source code** I could browse to understand how I can access data faster.

Pierre


PS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code 

  [1]: http://www.hdfgroup.org/HDF5/
  [2]: http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html</Text>
  </row>
  <row>
    <Id>143</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>69</PostId>
    <RevisionGUID>308f2a7a-2708-4c6a-b3f0-e900aca4c6ab</RevisionGUID>
    <CreationDate>2010-02-26T12:50:17.577</CreationDate>
    <IPAddress>82.126.67.146</IPAddress>
    <UserId>30</UserId>
    <Text>Using HDF5 to store  bio-data</Text>
  </row>
  <row>
    <Id>144</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>69</PostId>
    <RevisionGUID>308f2a7a-2708-4c6a-b3f0-e900aca4c6ab</RevisionGUID>
    <CreationDate>2010-02-26T12:50:17.577</CreationDate>
    <IPAddress>82.126.67.146</IPAddress>
    <UserId>30</UserId>
    <Text> égeneralà </Text>
  </row>
  <row>
    <Id>145</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>70</PostId>
    <RevisionGUID>0c8fe931-6659-4e2f-987d-4fbf3c1b83a4</RevisionGUID>
    <CreationDate>2010-02-26T13:15:16.893</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>You might also want to setup a simple snippets database. Navysnip application by Jason Strutz is easy to install and run if you have ruby and rubyonrails installed.

git clone git://github.com/navyrain/navysnip.git
  cd navysnip
  sudo rake gems:install
  rake db:migrate
  ruby script/server
Then visit your app at http://localhost:3000

check out http://github.com/navyrain/navysnip  for complete details</Text>
  </row>
  <row>
    <Id>146</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>71</PostId>
    <RevisionGUID>fdfa1fd1-ac44-4dc2-8e40-1d0eea6b9843</RevisionGUID>
    <CreationDate>2010-02-26T13:47:41.697</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>42</UserId>
    <Text>Hello Pierre!

I have been talking with the BioHDF guys and from what they tell me, their work will be centered around a number of command-line APIs, written in C, that will address some areas of usage which for now do not seem to overlap. 

I have seen this example on their site:
http://www.hdfgroup.org/projects/biohdf/biohdf_tools.html
Don't know if that helps.

I have been talking with them to see if we can achieve an API for saving genotype data. Don't know yet where that will lead me.

If you are looking for something more versatile, you will probably have to delve in the official HDF5 C code ( http://www.hdfgroup.org/HDF5/Tutor/ ), which seems to be the only one that offers all the functionality and goodies of that impressive storage system. </Text>
  </row>
  <row>
    <Id>147</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>69</PostId>
    <RevisionGUID>18ee72a0-3383-4691-b29b-35a7414956cd</RevisionGUID>
    <CreationDate>2010-02-26T13:48:47.683</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added more tags</Comment>
    <Text> éhdfà  ébiohdfà </Text>
  </row>
  <row>
    <Id>148</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>72</PostId>
    <RevisionGUID>5e66947a-c6ab-4d3b-9aa7-e2ebc1b0c9c5</RevisionGUID>
    <CreationDate>2010-02-26T13:54:03.447</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Unfortunately I don't have any example to shows you yet.
I don't know how to program in C/C++ so I have been looking at two hdf5 wrappers in python, [PyTables][1] and [H5PY][2].

PyTables has a database-like approach in which HDF5 is used as a sort of hierarchical database, in which a column can be a table itself, allowing to store nested data. For example, you have a table called 'SNPs' with two columns, 'id' and 'genotypes'; the column 'genotypes' contains a nested table, with the columns 'individual' and 'genotype'; and so on.

H5Py is basically a re-implementation of numpy's arrays, so you can store and access arrays/matrixes as you would do with numpy (it is similar to arrays and matrixes in matlab, R, and any other language with this data type) and they are stored in an HDF5 file so the access is faster.


  [1]: http://www.pytables.org/moin
  [2]: http://h5py.alfven.org/</Text>
  </row>
  <row>
    <Id>149</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>73</PostId>
    <RevisionGUID>05034da2-cc62-494e-b0c5-444eb6d80741</RevisionGUID>
    <CreationDate>2010-02-26T13:56:22.753</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>In the [GeneTrack][1] software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. 

For example it is extremely fast to retrieve say 100 thousand consecutive values starting with a certain index.We used the [Python bindings][2] to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). 

Here is the relevant code that deals with HDF only: [hdf.py][3]

The HDF schema is set up in a different module, but in the end it simply something like:

    class MySchema( IsDescription ):
        """
        Stores a triplet of float values for each index.
        """
        ix = IntCol  ( pos=1 )  # index
        wx = FloatCol( pos=2 )  # values on the W (forward) strand
        cx = FloatCol( pos=3 )  # value on the C (reverse) strand
        ax = FloatCol( pos=4 )  # weighted value on the combined W + C strands


  [1]: http://code.google.com/p/genetrack/
  [2]: http://www.pytables.org/moin
  [3]: http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py</Text>
  </row>
  <row>
    <Id>150</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>73</PostId>
    <RevisionGUID>9ad96826-6b6d-4a32-8cf9-68340bf639d8</RevisionGUID>
    <CreationDate>2010-02-26T14:01:39.187</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 4 characters in body</Comment>
    <Text>In the [GeneTrack][1] software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. 

For example it is *extremely fast* (ms) in retrieving say 100,000 consecutive values starting with a certain index.We used the [Python bindings][2] to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). 

Here is the relevant code that deals with HDF only: [hdf.py][3]

The HDF schema is set up in a different module, but in the end it simply something like:

    class MySchema( IsDescription ):
        """
        Stores a triplet of float values for each index.
        """
        ix = IntCol  ( pos=1 )  # index
        wx = FloatCol( pos=2 )  # values on the W (forward) strand
        cx = FloatCol( pos=3 )  # value on the C (reverse) strand
        ax = FloatCol( pos=4 )  # weighted value on the combined W + C strands


  [1]: http://code.google.com/p/genetrack/
  [2]: http://www.pytables.org/moin
  [3]: http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py</Text>
  </row>
  <row>
    <Id>151</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>1</PostId>
    <RevisionGUID>93b01d7a-27c6-4a96-93ac-f334ccb1aa00</RevisionGUID>
    <CreationDate>2010-02-26T14:10:59.777</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 63 characters in body</Comment>
    <Text>Here are a few guidelines:

 1. The site's goal is to answer bioinformatics and systems biology related questions
 2. Answer questions to gain *reputation*. 
 3. Don't forget to vote for answers that you like! Registered users may vote on answers.
 4. If you are the one asking the original question you may also select the best answer
 5. Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments</Text>
  </row>
  <row>
    <Id>152</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>74</PostId>
    <RevisionGUID>2f2c191d-b5af-4cc0-aa12-662fd638afe6</RevisionGUID>
    <CreationDate>2010-02-26T14:26:41.15</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>42</UserId>
    <Text>What I do have is a netCDF-3 based Java application that I could show you.
NetCDF-3 is basically the same idea as HDF, but quite more limited as it cannot do compound datatypes among other limitations.

But here's a small test code example to toy with:

package netCDF;


import java.io.File;
import ucar.ma2.*;
import ucar.nc2.*;
import java.io.IOException;
import java.util.ArrayList;

/**
 *
 * @author Fernando Muñiz Fernandez
 * IBE, Institute of Evolutionary Biology (UPF-CSIC)
 * CEXS-UPF-PRBB
 * 
 * THIS TO CREATE THE netCDF-3 GENOTYPE FILE
 */
public class CreateNetcdf {

     public static NetcdfFileWriteable setDimsAndAttributes(Integer studyId, 
                                          String technology, 
                                          String description, 
                                          String strand, 
                                          int sampleSetSize,
                                          int markerSetSize) throws InvalidRangeException, IOException {

        ///////////// CREATE netCDF-3 FILE ////////////
        String genotypesFolder = "/media/data/genotypes";
        File pathToStudy = new File(genotypesFolder+"/netCDF_test");
        int gtSpan = constants.cNetCDF.Strides.STRIDE_GT;
        int markerSpan = constants.cNetCDF.Strides.STRIDE_MARKER_NAME;
        int sampleSpan = constants.cNetCDF.Strides.STRIDE_SAMPLE_NAME;
        
        String matrixName = "prototype";
        String writeFileName = pathToStudy+"/"+matrixName+".nc";
        NetcdfFileWriteable ncfile = NetcdfFileWriteable.createNew(writeFileName, false);

        // add dimensions
        Dimension samplesDim = ncfile.addDimension("samples", sampleSetSize);
        Dimension markersDim = ncfile.addDimension("markers", markerSetSize);
        Dimension gtSpanDim = ncfile.addDimension("span", gtSpan);
        ArrayList dims = new ArrayList();
        dims.add(samplesDim);
        dims.add(markersDim);
        dims.add(gtSpanDim);

        ArrayList markerGenotypeDims = new ArrayList();
        markerGenotypeDims.add(markersDim);
        markerGenotypeDims.add(markerSpan);

        ArrayList markerPositionDim = new ArrayList();
        markerPositionDim.add(markersDim);

        ArrayList markerPropertyDim32 = new ArrayList();
        markerPropertyDim32.add(markersDim);
        markerPropertyDim32.add(32);

        ArrayList markerPropertyDim16 = new ArrayList();
        markerPropertyDim16.add(markersDim);
        markerPropertyDim16.add(16);

        ArrayList markerPropertyDim8 = new ArrayList();
        markerPropertyDim8.add(markersDim);
        markerPropertyDim8.add(8);

        ArrayList markerPropertyDim2 = new ArrayList();
        markerPropertyDim2.add(markersDim);
        markerPropertyDim2.add(2);

        ArrayList markerPropertyDim1 = new ArrayList();
        markerPropertyDim1.add(markersDim);
        markerPropertyDim1.add(1);

        ArrayList sampleSetDims = new ArrayList();
        sampleSetDims.add(samplesDim);
        sampleSetDims.add(sampleSpan);

        // Define Marker Variables
        ncfile.addVariable("markerset", DataType.CHAR, markerGenotypeDims);
        ncfile.addVariableAttribute("markerset", constants.cNetCDF.Attributes.LENGTH, markerSetSize);

        ncfile.addVariable("marker_chromosome", DataType.CHAR, markerPropertyDim8);
        ncfile.addVariable("marker_position", DataType.CHAR, markerPropertyDim32);
        ncfile.addVariable("marker_position_int", DataType.INT, markerPositionDim);
        ncfile.addVariable("marker_strand", DataType.CHAR, markerPropertyDim8);

        ncfile.addVariable("marker_property_1", DataType.CHAR, markerPropertyDim1);
        ncfile.addVariable("marker_property_2", DataType.CHAR, markerPropertyDim2);
        ncfile.addVariable("marker_property_8", DataType.CHAR, markerPropertyDim8);
        ncfile.addVariable("marker_property_16", DataType.CHAR, markerPropertyDim16);
        ncfile.addVariable("marker_property_32", DataType.CHAR, markerPropertyDim32);

        // Define Sample Variables
        ncfile.addVariable("sampleset", DataType.CHAR, sampleSetDims);
        ncfile.addVariableAttribute("sampleset", constants.cNetCDF.Attributes.LENGTH, sampleSetSize);

        // Define Genotype Variables
        ncfile.addVariable("genotypes", DataType.CHAR, dims);
        ncfile.addVariableAttribute("genotypes", constants.cNetCDF.Attributes.GLOB_STRAND, "+/-");

        // add global attributes
        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_STUDY, studyId);
        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_TECHNOLOGY, "INTERNAL");
        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_DESCRIPTION, "Matrix created by MOAPI through addition of 2 matrices");
        
        return ncfile;

    }
}

Use the above in the following way:

package netCDF;

import java.util.List;
import ucar.ma2.*;
import ucar.nc2.*;
import java.io.IOException;

/**
 *
 * @author Fernando Muñiz Fernandez
 * IBE, Institute of Evolutionary Biology (UPF-CSIC)
 * CEXS-UPF-PRBB
 * 
 * THIS TO GENERATE A netCDF-3 GENOTYPE DB
 */

public class TestWriteNetcdf {
    
    public static void main(String[] arg) throws InvalidRangeException, IOException {
        
        NetcdfFileWriteable ncfile = netCDF.CreateNetcdf.setDimsAndAttributes(0, 
                                                                          "INTERNAL", 
                                                                          "test in TestWriteNetcdf", 
                                                                          "+/-", 
                                                                          5,
                                                                          10);
                
        // create the file
        try {
            ncfile.create();
        } catch (IOException e) {
            System.err.println("ERROR creating file "+ncfile.getLocation()+"\n"+e);
        }
        
        
        ////////////// FILL'ER UP! ////////////////
        List&lt;Dimension&gt; dims = ncfile.getDimensions();
        Dimension samplesDim = dims.get(0);
        Dimension markersDim = dims.get(1);
        Dimension markerSpanDim = dims.get(2);
        
        ArrayChar charArray = new ArrayChar.D3(samplesDim.getLength(),markersDim.getLength(),markerSpanDim.getLength());
        int i,j;
        Index ima = charArray.getIndex();
        
        
        int method = 1;
        switch (method) {
            case 1: 
                // METHOD 1: Feed the complete genotype in one go
                for (i=0; i&lt;samplesDim.getLength(); i++) {
                    for (j=0; j&lt;markersDim.getLength(); j++) {
                        char c = (char) ((char) j + 65);
                        String s = Character.toString(c) + Character.toString(c);
                        charArray.setString(ima.set(i,j,0),s);
                        System.out.println("SNP: "+i);
                    }
                }
                break;
            case 2: 
                //METHOD 2: One snp at a time -&gt; feed in all samples
                for (i=0; i&lt;markersDim.getLength(); i++) {
                    charArray.setString(ima.set(i,0), "s"+i+"I0");
                    System.out.println("SNP: "+i);
                }
                break;
            case 3: 
                //METHOD 3: One sample at a time -&gt; feed in all snps
                break;
        }
        
        
        
        int[] offsetOrigin = new int[3]; //0,0
        try {
            ncfile.write("genotypes", offsetOrigin, charArray);
            //ncfile.write("genotype", origin, A);
        } catch (IOException e) {
            System.err.println("ERROR writing file");
        } catch (InvalidRangeException e) {
            e.printStackTrace();
        }
        
        // close the file
        try {
            ncfile.close();
        } catch (IOException e) {
            System.err.println("ERROR creating file "+ncfile.getLocation()+"\n"+e);
        }

    }
}


</Text>
  </row>
  <row>
    <Id>153</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>75</PostId>
    <RevisionGUID>2563ffda-b89a-4d3e-97f5-22d2ad717133</RevisionGUID>
    <CreationDate>2010-02-26T14:44:01.49</CreationDate>
    <IPAddress>130.237.137.116</IPAddress>
    <UserId>26</UserId>
    <Text>This is an excellent initiative: congratulations and thank you for setting it up!

I guess this site will be all the more useful as there are more contributers... So I guess that good questions for the administrator(s) of this site are: 

 - Do you have a plan for advertising this site/attracting new Users?
 - How can the Users help?

</Text>
  </row>
  <row>
    <Id>154</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>76</PostId>
    <RevisionGUID>00d937ca-1bc4-43f1-b3d0-24de0cd9fa14</RevisionGUID>
    <CreationDate>2010-02-26T15:37:25.81</CreationDate>
    <IPAddress>81.53.111.235</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
I'd like to create a very simple plugin for [Taverna 2.0][1], something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at [http://github.com/egonw/cdk-taverna][2] but it requires to know **Maven** and.... I'm too **lazy** :-)

How can I implement this kind of simple plugin without maven ? ( I *just* want to compile, package &amp; create the right XML config files)


Thanks !

  [1]: http://www.taverna.org.uk/
  [2]: http://github.com/egonw/cdk-taverna</Text>
  </row>
  <row>
    <Id>155</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>76</PostId>
    <RevisionGUID>00d937ca-1bc4-43f1-b3d0-24de0cd9fa14</RevisionGUID>
    <CreationDate>2010-02-26T15:37:25.81</CreationDate>
    <IPAddress>81.53.111.235</IPAddress>
    <UserId>30</UserId>
    <Text>Looking for a 'Hello world" plugin for Taverna.</Text>
  </row>
  <row>
    <Id>156</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>76</PostId>
    <RevisionGUID>00d937ca-1bc4-43f1-b3d0-24de0cd9fa14</RevisionGUID>
    <CreationDate>2010-02-26T15:37:25.81</CreationDate>
    <IPAddress>81.53.111.235</IPAddress>
    <UserId>30</UserId>
    <Text> écompilationà </Text>
  </row>
  <row>
    <Id>157</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>76</PostId>
    <RevisionGUID>634ba335-e4ec-450e-a949-22869bac7ef3</RevisionGUID>
    <CreationDate>2010-02-26T15:39:23.077</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>edited tags</Comment>
    <Text> écompilationà  étavernaà </Text>
  </row>
  <row>
    <Id>158</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>77</PostId>
    <RevisionGUID>df0cae21-9798-4a71-8544-18c77c493fa2</RevisionGUID>
    <CreationDate>2010-02-26T15:49:18.627</CreationDate>
    <IPAddress>134.174.140.200</IPAddress>
    <UserId>44</UserId>
    <Text>I have some illumina data generated from the latest version of the illumina pipeline (1.6.0) I need to convert my data into BED to view in ucsc genome browser.

This seems like it should be a fairly common task, however, I am unable to find any scripts to convert my data.</Text>
  </row>
  <row>
    <Id>159</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>77</PostId>
    <RevisionGUID>df0cae21-9798-4a71-8544-18c77c493fa2</RevisionGUID>
    <CreationDate>2010-02-26T15:49:18.627</CreationDate>
    <IPAddress>134.174.140.200</IPAddress>
    <UserId>44</UserId>
    <Text>How do I convert an Illumina export file to BED?</Text>
  </row>
  <row>
    <Id>160</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>77</PostId>
    <RevisionGUID>df0cae21-9798-4a71-8544-18c77c493fa2</RevisionGUID>
    <CreationDate>2010-02-26T15:49:18.627</CreationDate>
    <IPAddress>134.174.140.200</IPAddress>
    <UserId>44</UserId>
    <Text> ébedà </Text>
  </row>
  <row>
    <Id>161</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>78</PostId>
    <RevisionGUID>442a5688-a921-441b-b17a-5f97d537151c</RevisionGUID>
    <CreationDate>2010-02-26T16:15:18.997</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>I found a script [on another site][1], Uses perl but I have not checked for correctness:
 
    #!/usr/bin/perl
    
    use strict;
    use warnings;
    use IO::File;
    
    my $filename = shift @ARGV;
    die "Usage\n\tperl sorted2bed.pl s_X_sorted.txt &gt; s_X_sorted.bed\n" unless $filename;
    chomp $filename;
    
    my $fh = new IO::File;
    $fh-&gt;open("&lt; $filename") or die "Can't open file $filename for reading: $!";
    
    my $count = 1;
    while(my $line = &lt;$fh&gt;){
       warn "Line $count\n" if $count%1000 == 0;
       $count++;
       my @line = split "\t", $line;
       my $chr = $line[10];
       $chr =~ s/(.+)\.fa/$1/;
       #Illumina is 1-based, BED is 0-based
       my $start = $line[12]-1;
       my $read = $line[8];
       my $end = $start + length $read;
       my $strand = $line[13] eq 'F' ? '+': '-';
       my $score = $line[15];
       my $bedline = "$chr\t$start\t$end\t$read\t$score\t$strand\n";
       print $bedline;
    }
    $fh-&gt;close;
    
    warn "Done";


  [1]: http://mng.iop.kcl.ac.uk/site/node/378</Text>
  </row>
  <row>
    <Id>162</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>79</PostId>
    <RevisionGUID>ce5ddbd5-1d1e-4c20-9afc-140ff8419c30</RevisionGUID>
    <CreationDate>2010-02-26T16:49:35.15</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>In bioinformatics it is very common to end up with a lot of small scripts, each one with a different scope - plotting a chart, converting a file into another format, execute small operations - so it is very important to have a good way to clue them together, to define which should be executed before the others and so on.

How do you deal with the problem? Do you use makefiles, taverna workflows, batch scripts, or any other solution?</Text>
  </row>
  <row>
    <Id>163</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>79</PostId>
    <RevisionGUID>ce5ddbd5-1d1e-4c20-9afc-140ff8419c30</RevisionGUID>
    <CreationDate>2010-02-26T16:49:35.15</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>How to organize a pipeline of small scripts together?</Text>
  </row>
  <row>
    <Id>164</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>79</PostId>
    <RevisionGUID>ce5ddbd5-1d1e-4c20-9afc-140ff8419c30</RevisionGUID>
    <CreationDate>2010-02-26T16:49:35.15</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> égeneralà </Text>
  </row>
  <row>
    <Id>165</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>80</PostId>
    <RevisionGUID>14b841f9-a926-4758-98e4-454cb524912e</RevisionGUID>
    <CreationDate>2010-02-26T16:58:09.55</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I don't have personal experience with this package but it is something that I plan to explore in the near future:

**[Ruffus ][1]** a lightweight python module to run computational pipelines. 


  [1]: http://code.google.com/p/ruffus/</Text>
  </row>
  <row>
    <Id>166</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>81</PostId>
    <RevisionGUID>17127c3c-9cd9-41bb-a33e-79635ff98c10</RevisionGUID>
    <CreationDate>2010-02-26T17:03:52.94</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>My favorite way of defining pipelines is by writing Makefiles, about which you can find [a very good introduction][1] in Software Carpentry for Bioinformatics: http://swc.scipy.org/lec/build.html .

Although they have been originally developed for compiling programs, Makefiles allow to define which operations are needed to create each file, with a declarative syntax that it is a bit old-style but still does its job. Each Makefile is composed of a set of rules, which define operations needed to calculate a file and that can be combined together to make a pipeline. Other advantages of makefiles are conditional execution of tasks, so you can stop the execution of a pipeline and get back to it later, without having to repeat calculations. However, one of the big disadvantages of Makefiles is its old syntax... in particular, rules are identified by the names of the files that they create, and there is no such thing as 'titles' for rules, which make more tricky.

I think one of the best solutions would be to use [BioMake][2], that allow to define tasks with titles that are not the name of the output files. To understand it better, look at [this example][3]: you see that each rule has a title and a series of parameters like its output, inputs, comments, etc.

Unfortunately, I can't make biomake to run on my computer, as it requires very old dependencies and it is written in a very difficult perl. I have tried many alternatives and I think that [rake][4] is the one that is more close to biomake, but unfortunately I don't understand ruby's syntax. 

So, I am still looking for a good alternative... Maybe one day I will have to time to re-write BioMake in python :-)


  [1]: http://software-carpentry.org/build.html
  [2]: http://skam.sourceforge.net/skam-intro.html
  [3]: http://skam.sourceforge.net/skam-intro.html
  [4]: http://rake.rubyforge.org/files/doc/rational_rdoc.html</Text>
  </row>
  <row>
    <Id>167</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>82</PostId>
    <RevisionGUID>b50b6e36-baab-4651-9220-a50a5b2a8d11</RevisionGUID>
    <CreationDate>2010-02-26T17:04:53.577</CreationDate>
    <IPAddress>156.145.28.96</IPAddress>
    <UserId>47</UserId>
    <Text>Since I work a lot with Python, I usually write a wrapper method that embeds the external script/program, i.e. calls it, parses its output and returns the desired information. The 'glueing' of several such methods then takes place within my Python code that calls all these wrappers. I guess that's a very common thing to do.

Chris</Text>
  </row>
  <row>
    <Id>168</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>83</PostId>
    <RevisionGUID>19ab2027-b39f-467e-bae7-1ba6110243a0</RevisionGUID>
    <CreationDate>2010-02-26T17:16:41.967</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>If you have the PDB file then you can use the standard tool called DSSP , it is supposed to be the gold standard for obtaining secondary structure. In case you just have sequence then I personally prefer PSIPRED , it takes evolutionary information into account to predict the secondary structure . According to CASP evaluation it is one of the best secondary structure predictor available.</Text>
  </row>
  <row>
    <Id>169</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>84</PostId>
    <RevisionGUID>795df66c-516c-450a-8714-ad0c839e360e</RevisionGUID>
    <CreationDate>2010-02-26T20:16:31.97</CreationDate>
    <IPAddress>192.122.237.11</IPAddress>
    <UserId>53</UserId>
    <Text>My answer would be: don't bother. I've often found that much of the scripts I write are never used again after the initial use. Therefore spending time using a complex framework that considers dependency between scripts is a waste because the results might be negative and you never visit the analysis again. Even if you do end up using the script multiple times a simple hacky bash script might be more than enough to meet the requirements.

There will however be the 1-2% of initial analyses that return a interesting result and therefore need to be expanded with more deeper investigation. I think this is the point to invest more time time in organising the project. For me I use Rake because it's simple and allows me to write in the language I'm used to (Ruby).

Overall I think pragmatism is the important factor in computational biology. Just do enough to get the results you need and only invest more time when it's necessary. There's so many blind alleys in computational analysis of biological data it's not worth investing too much of your time until it's necessary.
</Text>
  </row>
  <row>
    <Id>170</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>85</PostId>
    <RevisionGUID>de338560-8041-4cf0-adc1-cb262c66aeb3</RevisionGUID>
    <CreationDate>2010-02-26T20:27:32.303</CreationDate>
    <IPAddress>128.192.15.218</IPAddress>
    <UserId>24</UserId>
    <Text>My lab uses a network-attached storage unit which every Linux workstation mounts by NFS at startup. It was reasonably cheap -- a couple hundred dollars per TB. We also keep copies of public databases on there. We put data sets on there as we're working on them, and also put the more important scripts in a Mercurial repositiory.

As Marcos and Istvan mentioned, a wiki integrated with your VCS would be wise, and Trac (trac.edgewall.org) is the obvious choice for that.</Text>
  </row>
  <row>
    <Id>171</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>86</PostId>
    <RevisionGUID>1a3a86a1-a7b5-483b-a836-8f6fcc70bc7c</RevisionGUID>
    <CreationDate>2010-02-26T20:44:04.547</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>This might be useful .

[A Quick Guide to Organizing Computational Biology Projects][1]


  [1]: http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424</Text>
  </row>
  <row>
    <Id>172</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>48</PostId>
    <RevisionGUID>66fe89ad-959e-4f32-93ee-11f482013e3b</RevisionGUID>
    <CreationDate>2010-02-27T09:58:45.557</CreationDate>
    <IPAddress>88.6.174.10</IPAddress>
    <UserId>23</UserId>
    <Comment>deleted 180 characters in body</Comment>
    <Text>As in the title... I have a protein and I would like to know its secundary structure.
I couldn't find it in uniprot, althought I tought they had annotations for it there.
In the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.


  [1]: http://www.compbio.dundee.ac.uk/www-jpred</Text>
  </row>
  <row>
    <Id>173</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>87</PostId>
    <RevisionGUID>869790e6-648a-4f3f-bb6b-a524b83d857a</RevisionGUID>
    <CreationDate>2010-02-27T21:00:56.14</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>There is also a Perl binding to HDF5: PDL::IO::HDF5

http://search.cpan.org/~cerney/PDL-IO-HDF5-0.5/
This requires the Perl Data Language (PDL) package. The way, data-structures can be handled, sub-ranges of data can be defined  an data can be manipulated is actually very elegant in PDL such that computational code can profit from PDLs vectorized style of writing expressions.

The same is true for R and the hdf5 package: http://cran.r-project.org/web/packages/hdf5/index.html

Code examples are in the package documentations of both, the R-hdf5 package documentation is quite little though.

Both of these language bindings might be a very efficient way to read and write HDF5 files.

There are also APIs in Fortran, Java, Python, Matlab, C, or C++. So it might make sense to select the language and define the type of data you wish to store first. </Text>
  </row>
  <row>
    <Id>174</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>88</PostId>
    <RevisionGUID>7ff043e4-1885-4341-b605-1e16ce2a8567</RevisionGUID>
    <CreationDate>2010-03-01T13:51:12.3</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.

My idea was to take inspiration from [extreme programming][1] and explain the rules I like the most: use of [A7 cards to write tasks][2], [release planning][3] every 3 week, stand-up meeting every day, [Move people around][4], [unit tests first][5], [pair programming][6] (at least introduce the concept), [collective ownership][7].

It is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.
However, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.

Do you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?


  [1]: http://www.extremeprogramming.org/rules/
  [2]: http://www.extremeprogramming.org/example/crcsim.html
  [3]: http://www.extremeprogramming.org/rules/planninggame.html
  [4]: http://www.extremeprogramming.org/rules/movepeople.html
  [5]: http://www.extremeprogramming.org/rules/testfirst.html
  [6]: http://www.extremeprogramming.org/rules/pair.html
  [7]: http://www.extremeprogramming.org/rules/collective.html</Text>
  </row>
  <row>
    <Id>175</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>88</PostId>
    <RevisionGUID>7ff043e4-1885-4341-b605-1e16ce2a8567</RevisionGUID>
    <CreationDate>2010-03-01T13:51:12.3</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>agile programming for bioinformaticians - any suggestions?</Text>
  </row>
  <row>
    <Id>176</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>88</PostId>
    <RevisionGUID>7ff043e4-1885-4341-b605-1e16ce2a8567</RevisionGUID>
    <CreationDate>2010-03-01T13:51:12.3</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> égeneralà </Text>
  </row>
  <row>
    <Id>177</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>89</PostId>
    <RevisionGUID>f490bb39-fb31-4c07-9b07-c5658ccef7d9</RevisionGUID>
    <CreationDate>2010-03-01T14:06:55.973</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>

I think the approach is unsuited for individuals who are not comfortable with programming in general. There is a long way to go until someone becomes confident in their abilities. Before that this approach is not only ineffective, it might be even be detrimental.

Instead what helps most is transparency. Everyone needs to write code in a source code repository that can be viewed, commented and verified. People should become familiar with testing, code coverage, and continuous integration. 

Something to read: [Mythical Man Month][1].

  [1]: http://en.wikipedia.org/wiki/The_Mythical_Man-Month</Text>
  </row>
  <row>
    <Id>178</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>e41bed33-5ba2-4001-ad37-8a4e9f99ceab</RevisionGUID>
    <CreationDate>2010-03-01T14:26:09.937</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>An example that computes the reverse complement of a sequence with [BioPython][1]
 
    #
    # Reverse complement example with BioPython
    #
    
    from Bio.Seq import Seq
    
    # create a Seq class instance
    dna = Seq("ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG")
    
    # original DNA
    print type(dna)
    print dna
    
    # complement DNA, returns a new sequence
    print dna.complement()
    
    # reverse complement DNA, returns a new sequence
    print dna.reverse_complement()
    
    # note that the original DNA is unchanged
    print type(dna), dna
    
    # currently there is no direct way to just reverse a sequence
    # we need to do a little extra work
    
    data = reversed(dna.tostring())
    data = ''.join(data)
    rdna = Seq(data)
    
    # reversed sequence
    print rdna

Produces the following output:

    &lt;class 'Bio.Seq.Seq'&gt;
    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC
    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT
    &lt;class 'Bio.Seq.Seq'&gt; ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA


  [1]: http://biopython.org/wiki/Main_Page</Text>
  </row>
  <row>
    <Id>179</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>e41bed33-5ba2-4001-ad37-8a4e9f99ceab</RevisionGUID>
    <CreationDate>2010-03-01T14:26:09.937</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Reverse complement with Biopython</Text>
  </row>
  <row>
    <Id>180</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>e41bed33-5ba2-4001-ad37-8a4e9f99ceab</RevisionGUID>
    <CreationDate>2010-03-01T14:26:09.937</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> ésequenceà  ébiopythonà  épythonà </Text>
  </row>
  <row>
    <Id>181</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>91</PostId>
    <RevisionGUID>050bcd50-f3ef-4e59-88be-17a34beb43f2</RevisionGUID>
    <CreationDate>2010-03-01T14:41:28.687</CreationDate>
    <IPAddress>89.14.195.191</IPAddress>
    <UserId>39</UserId>
    <Text>I would suggest to have a look at [Scrum][1], too. Certain parts would help not only bioinformations. For example estimating the time expenditure of tasks and the resulting burn down charts can be really helpful to see if something is stuck especially when working together on bigger projects.The daily scrum reports helps to meditate why who is doing what and offers a platform to discuss problems.


  [1]: http://en.wikipedia.org/wiki/Scrum_(development)</Text>
  </row>
  <row>
    <Id>182</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>20d84306-871a-4def-ae59-dfdf95d023c8</RevisionGUID>
    <CreationDate>2010-03-01T14:48:25.83</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Computing the reverse complement with the [Pygr][1] bioinformatics framework:

    #
    # Reverse complement example with pygr
    #
    
    from pygr.sequence import Sequence
    
    # create a Sequence class  named bobo
    dna = Sequence('ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG','bobo')
    
    # original DNA
    print type(dna)
    print dna
    
    # complement DNA, returns a new sequence
    # ??? - need help here 
    
    # reverse complement DNA, returns a new sequence
    print -dna
    
    # reverse DNA
    # ??? - need help here
    
    # the original DNA is unchanged
    print type(dna), dna
    
    # get the sequence as a string
    print str(dna)

Produces the output:

    &lt;class 'pygr.sequence.Sequence'&gt;
    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT
    &lt;class 'pygr.sequence.Sequence'&gt; ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG


  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation</Text>
  </row>
  <row>
    <Id>183</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>20d84306-871a-4def-ae59-dfdf95d023c8</RevisionGUID>
    <CreationDate>2010-03-01T14:48:25.83</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Computing the reverse complement with Pygr</Text>
  </row>
  <row>
    <Id>184</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>20d84306-871a-4def-ae59-dfdf95d023c8</RevisionGUID>
    <CreationDate>2010-03-01T14:48:25.83</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> épythonà  épygrà </Text>
  </row>
  <row>
    <Id>185</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>93</PostId>
    <RevisionGUID>c1ac4028-6b7b-4804-9403-a5bd9c92c9a2</RevisionGUID>
    <CreationDate>2010-03-01T14:51:52.19</CreationDate>
    <IPAddress>152.14.14.75</IPAddress>
    <UserId>45</UserId>
    <Text>Possibly related:
http://mmc.gnets.ncsu.edu/</Text>
  </row>
  <row>
    <Id>186</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>55bcc115-f254-4b27-9b86-29fb8d322e0b</RevisionGUID>
    <CreationDate>2010-03-01T15:03:28.763</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>changed the title</Comment>
    <Text>Computing the reverse complement with Biopython</Text>
  </row>
  <row>
    <Id>187</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>88</PostId>
    <RevisionGUID>f77c61c7-f8d5-4d6d-a03e-18dbd8ca54ca</RevisionGUID>
    <CreationDate>2010-03-01T15:03:58.56</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>proper title capitalization</Comment>
    <Text>Agile programming for bioinformaticians - any suggestions?</Text>
  </row>
  <row>
    <Id>188</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>f700a818-7116-49e3-9aac-7804b0799bfb</RevisionGUID>
    <CreationDate>2010-03-01T16:04:17.73</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>updated the example</Comment>
    <Text>Computing the reverse complement with the [Pygr][1] bioinformatics framework:

    #
    # Reverse complement example with pygr
    #
    
    from pygr.sequence import Sequence
    
    # needs a separate function to reverse strings
    def rev(it):
        "Reverses an interable and returns it as a string"
        return ''.join(reversed(it))
    
    # original sequence as as string
    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'
    
    # create a Sequence class  instance named bobo
    dna = Sequence(seq,'bobo')
    
    # sequence class' type and content
    print type(dna)
    print dna
    
    # the -operator reverse complements the DNA, returns a new sequence
    print -dna
    
    # to reverse the DNA, reverse the input data
    rdna = Sequence( rev(seq),'bobo')
    print rdna
    
    # to complement the DNA reverse complement, then reverse again
    cseq = rev(str(-dna))
    cdna = Sequence(cseq,'bobo')

    print cdna

Produces the output:

    &lt;class 'pygr.sequence.Sequence'&gt;
    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT
    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA
    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC

  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation

</Text>
  </row>
  <row>
    <Id>189</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>94</PostId>
    <RevisionGUID>3e8d0a53-a685-478f-afff-ea38ace640f4</RevisionGUID>
    <CreationDate>2010-03-01T16:07:15.283</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Wouldn't it better to have a single question titled 'How to compute the reverse complement with python' and put all the examples as different answers? Otherwise it seems a bit confusing..</Text>
  </row>
  <row>
    <Id>190</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>29bf8d61-0179-4952-90fa-682857b993b1</RevisionGUID>
    <CreationDate>2010-03-01T16:11:52.887</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>rewrote the example</Comment>
    <Text>An example that computes the reverse complement of a sequence with [BioPython][1]

    #
    # Reverse complement example with BioPython
    #
    
    from Bio.Seq import Seq
    
    # a separate function to reverse strings (or other iterables)
    def rev(it):
        "Reverses an interable and returns it as a string"
        return ''.join(reversed(it))
    
    # create a Seq class instance
    dna = Seq("ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG")
    
    # original DNA
    print type(dna)
    print dna
    
    # reverse complement DNA, returns a new sequence
    print dna.reverse_complement()
    
    # currently there is no direct way to just reverse a sequence
    # we need to do a little extra work
    
    rseq = rev(str(dna))
    rdna = Seq(rseq)
    
    # reversed sequence
    print rdna
    
    # to complement DNA, returns a new sequence
    print dna.complement()

Produces the following output:

    &lt;class 'Bio.Seq.Seq'&gt;
    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG
    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT
    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA
    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC


   [1]: http://biopython.org/wiki/Main_Page</Text>
  </row>
  <row>
    <Id>191</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>90</PostId>
    <RevisionGUID>29bf8d61-0179-4952-90fa-682857b993b1</RevisionGUID>
    <CreationDate>2010-03-01T16:11:52.887</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>rewrote the example</Comment>
    <Text>Computing the reverse and complement of a sequence with Biopython</Text>
  </row>
  <row>
    <Id>192</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>43805e9a-e39a-48ac-88dd-8286faf389af</RevisionGUID>
    <CreationDate>2010-03-01T16:12:20.437</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Comment>edited title</Comment>
    <Text>Computing the reverse and complement of a sequence with Pygr</Text>
  </row>
  <row>
    <Id>193</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>95</PostId>
    <RevisionGUID>e83be4ea-dfbe-4fc1-bae1-c15a3c30dae8</RevisionGUID>
    <CreationDate>2010-03-01T16:32:26.107</CreationDate>
    <IPAddress>128.192.15.218</IPAddress>
    <UserId>24</UserId>
    <Text>The most important thing for me has been keeping a README file at the top of each project directory, where I write down not just *how* to run the scripts, but *why* I wrote them in the first place -- coming back to a project after a several-month lull, it's remarkable difficult to figure out what all the half-finished results mean without detailed notes.

That said:

 - `make` is pretty handy for simple pipelines that need to be re-run a lot
 - I'm also intrigued by [waf][1] and [scons][2], since I use Python a lot
 - If a pipeline only takes a couple of minutes to run, and you only re-run it every few days, coercing it into a build system doesn't really save time overall for that project
 - But once you're used to working with a build system, the threshold where it pays off to use it on a new project drops dramatically

  [1]: http://code.google.com/p/waf/
  [2]: http://www.scons.org/</Text>
  </row>
  <row>
    <Id>194</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>96</PostId>
    <RevisionGUID>bf40aa6f-91fc-4eb2-98db-11ce8a3e9745</RevisionGUID>
    <CreationDate>2010-03-01T16:52:22.51</CreationDate>
    <IPAddress>128.192.15.218</IPAddress>
    <UserId>24</UserId>
    <Text>The Bio.Seq module provides two easy ways to get the complement and reverse complement from a sequence:

 - If you have a string, use the functions `complement(dna)` and `reverse_complement(dna)`
 - If you have a Seq object, use its methods with the same names: `dna.complement()` and `dna.reverse_complement`

To reverse a sequence, there is a function in the `Bio.SeqUtils` module called `reverse` which does what you would expect.

---

(Sorry for going meta, but I don't have commenting privileges yet. This can be deleted if the original post is edited.)

According to [Meta Stack Overflow][1], if you want to share the answer to a difficult question that's poorly documented elsewhere online, you should post the question as a genuine one, and then submit your own answer separately. In theory, someone else may have an answer that's better than yours, and this allows it to be voted to the top properly.

  [1]: http://meta.stackoverflow.com/questions/17845/etiquette-for-answering-your-own-question</Text>
  </row>
  <row>
    <Id>195</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>97</PostId>
    <RevisionGUID>31350757-aea9-4f82-a1c5-37711a61feba</RevisionGUID>
    <CreationDate>2010-03-01T17:05:13.92</CreationDate>
    <IPAddress>128.240.229.67</IPAddress>
    <UserId>59</UserId>
    <Text>http://idconverter.bioinfo.cnio.es/

Is another possible solution to this, although you might find this is not as up to date as you might like either.</Text>
  </row>
  <row>
    <Id>196</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>98</PostId>
    <RevisionGUID>8a66c53f-2ff1-4ed1-b29c-a3d4de02d70f</RevisionGUID>
    <CreationDate>2010-03-01T19:51:25.98</CreationDate>
    <IPAddress>129.177.138.111</IPAddress>
    <UserId>55</UserId>
    <Text>BioMart has already been mentioned. It can do much more than ID conversion but it is very useful for conversion purposes, it is regularly updated and you can select different genome builds and all kinds of genomic features. It seems to me that you wish to retrieve GeneIDs linked to Affymetrix IDs. To select these attributes in BioMart: go to the [Martview][1] page to start a new BioMart query.

Select attributes on the attribute page: The Ensembl GeneIDs and Transcript IDs are default. Ensembl GeneID and Affy IDs are under the "External" tab. Select your chip there.
To limit to those genes which are on the chip, use the Filters-&gt;Gene menue. You can limit the genes to those present on various platforms or your favourite set.

There is an URL button in biomart that allows to retrieve a URL for your query and to pass it on to others. Try this example:

[BioMart URL][2] URL, that should be a good starting point.

If you are interested in KEGG identifiers (Pathways, Genes), EC-numbers, etc. the  

[KEGG Identifier page][3] could be handy, because the KEGG ids are not in BioMart as far as I know.


  [1]: http://www.biomart.org/biomart/martview
  [2]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&amp;ATTRIBUTES=hsapiens_gene_ensembl.default.feature_page.ensembl_gene_id|hsapiens_gene_ensembl.default.feature_page.ensembl_transcript_id|hsapiens_gene_ensembl.default.feature_page.embl|hsapiens_gene_ensembl.default.feature_page.affy_hg_u133a&amp;FILTERS=hsapiens_gene_ensembl.default.filters.with_affy_hg_u133a.only&amp;VISIBLEPANEL=resultspanel
  [3]: http://www.genome.jp/kegg/kegg3.html</Text>
  </row>
  <row>
    <Id>197</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>99</PostId>
    <RevisionGUID>fab778ca-1ca9-42e8-b037-e3e7d383d86f</RevisionGUID>
    <CreationDate>2010-03-01T20:01:20.047</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Most genomic annotations are specified as intervals along the genome. 

 - [Interval trees][1] have been known to provide an efficient datastructure that allows for very fast overlap querying. 
 - [Nested Containment Lists][2] have been proposed as an even faster alternative 

Provide code examples in your programming language that demonstrate the use of fast interval querying.

  [1]: http://books.google.com/books?id=NLngYyWFl_YC&amp;lpg=PA311&amp;ots=BwTtEE-jJ9&amp;dq=cormen%20interval%20tree&amp;pg=PA311#v=onepage&amp;q=&amp;f=false
  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl647v1</Text>
  </row>
  <row>
    <Id>198</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>99</PostId>
    <RevisionGUID>fab778ca-1ca9-42e8-b037-e3e7d383d86f</RevisionGUID>
    <CreationDate>2010-03-01T20:01:20.047</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Fast interval intersection methodologies</Text>
  </row>
  <row>
    <Id>199</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>99</PostId>
    <RevisionGUID>fab778ca-1ca9-42e8-b037-e3e7d383d86f</RevisionGUID>
    <CreationDate>2010-03-01T20:01:20.047</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> éintervalà  équeryà </Text>
  </row>
  <row>
    <Id>200</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>100</PostId>
    <RevisionGUID>95284be8-fdad-4e9e-917a-1cc8e357147f</RevisionGUID>
    <CreationDate>2010-03-01T20:06:18.193</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>The above code requires the either the installation of the [bx python][1] package or alternatively you may just download the [quicksect.py][2] module and place it next to the script itself:


    from random import randint, seed
    
    # if you can install bx python then uncomment the line below
    #
    # from bx.intervals.operations.quicksect import IntervalNode
    
    # otherwise just download the quickset module as shown above 
    # and place it in next to your program
    #
    from quicksect import IntervalNode
    
    # the span of the generated intervals
    SPAN = 10
    
    # the size of the genome
    SIZE = 5*10**4
    
    # the number of intervals
    N = 10**4
    
    def generate(x):
        "Generates random interval over a size and span"
        lo = randint(10000, SIZE)
        hi = lo + randint(1, SPAN)
        return (lo, hi)
    
    def find(start, end, tree):
        "Returns a list with the overlapping intervals"
        out = []
        tree.intersect( start, end, lambda x: out.append(x) )
        return [ (x.start, x.end) for x in out ]
    
    # use this to force both examples to generate the same data
    seed(10)
    
    # generate 10 thousand random intervals
    data = map(generate, xrange(N))
    
    # generate the intervals to query over
    query = map(generate, xrange(10))
    
    # start the root at the first element
    start, end = data[0]
    tree = IntervalNode( start, end )
    
    # build an interval tree from the rest of the data
    for start, end in data[1:]:
        tree = tree.insert( start, end )
    
    for start, end in query:
        overlap = find(start, end , tree)
        print '(%s, %s) -&gt; %s' % (start, end, overlap)
        

Produces the output:

    (41901, 41903) -&gt; [(41894, 41902)]
    (36981, 36987) -&gt; [(36981, 36984), (36973, 36982), (36978, 36987)]
    (36338, 36339) -&gt; [(36337, 36347)]
    (32741, 32748) -&gt; [(32738, 32742)]
    (49864, 49872) -&gt; [(49859, 49865)]
    (21475, 21477) -&gt; []
    (29425, 29428) -&gt; [(29418, 29426), (29419, 29426)]
    (29590, 29599) -&gt; [(29586, 29595), (29596, 29598)]
    (12804, 12811) -&gt; [(12806, 12811), (12799, 12806), (12809, 12819)]
    (30339, 30343) -&gt; [(30336, 30346), (30335, 30345), (30340, 30341)]

  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home
  [2]: http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py</Text>
  </row>
  <row>
    <Id>201</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>101</PostId>
    <RevisionGUID>1e6b6f55-3665-46d0-a7a9-51d37110cf24</RevisionGUID>
    <CreationDate>2010-03-01T20:09:49.967</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>This code example generates 10,000 intervals then queries them for overlapping regions.

This is a faster solution than the other example, one that now requires the full installation of the [bx-python][1] module. **The data structure is implemented in C** and is at least one order of magnitude faster than the **quicksect.py** module presented in another example.

    from random import randint, seed
    from bx.intervals.intersection import Intersecter, Interval
    
    # the span of the generated intervals
    SPAN = 10
    
    # the size of the genome
    SIZE = 5*10**4
    
    # the number of intervals
    N = 10**4
    
    def generate(x):
        "Generates random interval over a size and span"
        lo = randint(10000, SIZE)
        hi = lo + randint(1, SPAN)
        return (lo, hi)
    
    # use this to force both examples to generate the same data
    seed(10)
    
    # generate 10 thousand random intervals
    data = map(generate, xrange(N))
    
    # generate the intervals to query over
    query = map(generate, xrange(10))
    
    # create the interval tree
    tree = Intersecter()
    
    # build an interval tree from the rest of the data
    for start, end in data:
        tree.add_interval( Interval(start, end) )
    
    # perform the query
    for start, end in query:
        overlap = tree.find(start, end)
        out = [ (x.start, x.end) for x in overlap ]
        print '(%s, %s) -&gt; %s' % (start, end, out)
        
Produces the output:

    (41901, 41903) -&gt; [(41894, 41902)]
    (36981, 36987) -&gt; [(36973, 36982), (36978, 36987), (36981, 36984)]
    (36338, 36339) -&gt; [(36337, 36347)]
    (32741, 32748) -&gt; [(32738, 32742)]
    (49864, 49872) -&gt; [(49859, 49865)]
    (21475, 21477) -&gt; []
    (29425, 29428) -&gt; [(29418, 29426), (29419, 29426)]
    (29590, 29599) -&gt; [(29586, 29595), (29596, 29598)]
    (12804, 12811) -&gt; [(12799, 12806), (12806, 12811), (12809, 12819)]
    (30339, 30343) -&gt; [(30335, 30345), (30336, 30346), (30340, 30341)]

  [1]: http://bitbucket.org/james_taylor/bx-python/overview/
</Text>
  </row>
  <row>
    <Id>202</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>100</PostId>
    <RevisionGUID>ddd57cf8-562a-454c-a6ad-5c21abd86c35</RevisionGUID>
    <CreationDate>2010-03-01T20:13:11.68</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 91 characters in body; added 42 characters in body</Comment>
    <Text>This code example generates 10,000 intervals then queries them for overlapping regions. **Requires only the presence of Python.**

The code below requires the either the installation of the [bx python][1] package or alternatively you may just download the [quicksect.py][2] module and place it next to the script itself:


    from random import randint, seed
    
    # if you can install bx python then uncomment the line below
    #
    # from bx.intervals.operations.quicksect import IntervalNode
    
    # otherwise just download the quickset module as shown above 
    # and place it in next to your program
    #
    from quicksect import IntervalNode
    
    # the span of the generated intervals
    SPAN = 10
    
    # the size of the genome
    SIZE = 5*10**4
    
    # the number of intervals
    N = 10**4
    
    def generate(x):
        "Generates random interval over a size and span"
        lo = randint(10000, SIZE)
        hi = lo + randint(1, SPAN)
        return (lo, hi)
    
    def find(start, end, tree):
        "Returns a list with the overlapping intervals"
        out = []
        tree.intersect( start, end, lambda x: out.append(x) )
        return [ (x.start, x.end) for x in out ]
    
    # use this to force both examples to generate the same data
    seed(10)
    
    # generate 10 thousand random intervals
    data = map(generate, xrange(N))
    
    # generate the intervals to query over
    query = map(generate, xrange(10))
    
    # start the root at the first element
    start, end = data[0]
    tree = IntervalNode( start, end )
    
    # build an interval tree from the rest of the data
    for start, end in data[1:]:
        tree = tree.insert( start, end )
    
    for start, end in query:
        overlap = find(start, end , tree)
        print '(%s, %s) -&gt; %s' % (start, end, overlap)
        

Produces the output:

    (41901, 41903) -&gt; [(41894, 41902)]
    (36981, 36987) -&gt; [(36981, 36984), (36973, 36982), (36978, 36987)]
    (36338, 36339) -&gt; [(36337, 36347)]
    (32741, 32748) -&gt; [(32738, 32742)]
    (49864, 49872) -&gt; [(49859, 49865)]
    (21475, 21477) -&gt; []
    (29425, 29428) -&gt; [(29418, 29426), (29419, 29426)]
    (29590, 29599) -&gt; [(29586, 29595), (29596, 29598)]
    (12804, 12811) -&gt; [(12806, 12811), (12799, 12806), (12809, 12819)]
    (30339, 30343) -&gt; [(30336, 30346), (30335, 30345), (30340, 30341)]

  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home
  [2]: http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py</Text>
  </row>
  <row>
    <Id>203</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>101</PostId>
    <RevisionGUID>6fac2e1e-a9b0-440b-afed-80eb1dd1bc54</RevisionGUID>
    <CreationDate>2010-03-01T20:16:04.987</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 55 characters in body</Comment>
    <Text>This code example generates 10,000 intervals then queries them for overlapping regions. **The installation requires a C compiler and Python.**

This is a faster solution than the other example, one that now requires the full installation of the [bx-python][1] module. **The data structure is implemented in C** and is at least one order of magnitude faster than the **quicksect.py** module presented in another example.

    from random import randint, seed
    from bx.intervals.intersection import Intersecter, Interval
    
    # the span of the generated intervals
    SPAN = 10
    
    # the size of the genome
    SIZE = 5*10**4
    
    # the number of intervals
    N = 10**4
    
    def generate(x):
        "Generates random interval over a size and span"
        lo = randint(10000, SIZE)
        hi = lo + randint(1, SPAN)
        return (lo, hi)
    
    # use this to force both examples to generate the same data
    seed(10)
    
    # generate 10 thousand random intervals
    data = map(generate, xrange(N))
    
    # generate the intervals to query over
    query = map(generate, xrange(10))
    
    # create the interval tree
    tree = Intersecter()
    
    # build an interval tree from the rest of the data
    for start, end in data:
        tree.add_interval( Interval(start, end) )
    
    # perform the query
    for start, end in query:
        overlap = tree.find(start, end)
        out = [ (x.start, x.end) for x in overlap ]
        print '(%s, %s) -&gt; %s' % (start, end, out)
        
Produces the output:

    (41901, 41903) -&gt; [(41894, 41902)]
    (36981, 36987) -&gt; [(36973, 36982), (36978, 36987), (36981, 36984)]
    (36338, 36339) -&gt; [(36337, 36347)]
    (32741, 32748) -&gt; [(32738, 32742)]
    (49864, 49872) -&gt; [(49859, 49865)]
    (21475, 21477) -&gt; []
    (29425, 29428) -&gt; [(29418, 29426), (29419, 29426)]
    (29590, 29599) -&gt; [(29586, 29595), (29596, 29598)]
    (12804, 12811) -&gt; [(12799, 12806), (12806, 12811), (12809, 12819)]
    (30339, 30343) -&gt; [(30335, 30345), (30336, 30346), (30340, 30341)]

  [1]: http://bitbucket.org/james_taylor/bx-python/overview/
</Text>
  </row>
  <row>
    <Id>204</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>102</PostId>
    <RevisionGUID>09d22737-baa2-4bfe-bc1f-475aa3c722cf</RevisionGUID>
    <CreationDate>2010-03-01T23:47:17.003</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text>How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?</Text>
  </row>
  <row>
    <Id>205</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>102</PostId>
    <RevisionGUID>09d22737-baa2-4bfe-bc1f-475aa3c722cf</RevisionGUID>
    <CreationDate>2010-03-01T23:47:17.003</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text>How to validate that a sequence only contains letters from a given alphabet?</Text>
  </row>
  <row>
    <Id>206</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>102</PostId>
    <RevisionGUID>09d22737-baa2-4bfe-bc1f-475aa3c722cf</RevisionGUID>
    <CreationDate>2010-03-01T23:47:17.003</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text> ésequenceà </Text>
  </row>
  <row>
    <Id>207</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>103</PostId>
    <RevisionGUID>9fe00138-2f3e-4506-bbba-94e22f6da851</RevisionGUID>
    <CreationDate>2010-03-01T23:50:05.623</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text>Here is an efficient function written in Python:

    dna = set("ATGC")
    def validate(seq, alphabet=dna):
        "Checks that a sequence only contains values from an alphabet"
        leftover = set(seq.upper()) - alphabet
        return not leftover
    
    # typical usage below
    
    # this will print True
    print validate('AAAATGCCG')
    
    # this will print False
    print validate('AAANTGCCG')
    
    # using it with other alphabets
    prot = set('ACDEFGHIKLMNPQRSTVWY')
    print validate("mglsdgewql", alphabet=prot)</Text>
  </row>
  <row>
    <Id>208</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>104</PostId>
    <RevisionGUID>231f0e8d-4329-4357-a4d8-051331c2e629</RevisionGUID>
    <CreationDate>2010-03-02T05:22:30.257</CreationDate>
    <IPAddress>98.212.153.255</IPAddress>
    <UserId>61</UserId>
    <Text>I've been talking a bit with one of the devs behind BioHDF (being at UIUC, up the road from The HDF Group doesn't hurt). I believe a publication is on the way describing it along with some implementation details. </Text>
  </row>
  <row>
    <Id>209</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>105</PostId>
    <RevisionGUID>79ccfb4f-bace-4915-8bbe-44080d97990f</RevisionGUID>
    <CreationDate>2010-03-02T07:54:01.13</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>Since i use Ruby quite often, I have found Rake very useful in creating simple pipelines. Rake has an idea of a task(s) and you can have prerequisites for the tasks, thus create pipelines. See An extension to rake that can be used to build database-backed workflows — at github http://github.com/jandot/biorake

</Text>
  </row>
  <row>
    <Id>210</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>106</PostId>
    <RevisionGUID>6a9e7677-4151-47b6-9636-1b3dbe60ef56</RevisionGUID>
    <CreationDate>2010-03-02T09:26:39.267</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>An alternative is to use BED files to store data and [BEDTools][1] to calculate the intersection.

The [BED][2] format is a format used by UCSC and many other projects to generically store annotations on genomes. Sometimes, it is easier to use just plain BED files to store annotations, instead of complex databases or HDF5, and BEDTools make it also faster to access them. Moreover, with BEDFiles you have other advantages, as you can use custom tracks on ucsc or gbrowse and there are other tools that use BED as input.

Anyway, to solve the problem of intersection with BEDTools, you would do:
    
`$: intersectBed -a segdups.bed -b exons.bed`


  [1]: http://code.google.com/p/bedtools/
  [2]: http://genome.ucsc.edu/FAQ/FAQformat#format1</Text>
  </row>
  <row>
    <Id>211</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>107</PostId>
    <RevisionGUID>57f92d30-ed92-4585-9710-63fc5507a9ff</RevisionGUID>
    <CreationDate>2010-03-02T10:37:07.36</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>re Biomake:

It does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB)only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).  </Text>
  </row>
  <row>
    <Id>212</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>108</PostId>
    <RevisionGUID>7bd27032-5cd7-403a-bf60-fc620bf2a9a0</RevisionGUID>
    <CreationDate>2010-03-02T11:00:20.98</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>I am interested in your opinions about database systems used to store, query and visualize genomic sequence and annotations. I am talking about ca 600-700Mb draft genome with a large number of contigs outside scaffolds. Yep, I know that annotating anything before reaching some quality milestones may be considered pointless, but I want to get the back end (DB) and the pipeline   
working way before that.

So far I started testing Gbrowse (1.70), been impressed by Ensembl as an end-user, and looked at (unsuitable) eye candy GenomeProjector  http://www.g-language.org/GenomeProjector/.

I will appreciate any thoughts about ease of installation/maintenance and integration with annotation tools such as Apollo / Artemis.

Thanks

darked89

PS There is no way top add proper tags (genome annotation database) to this post</Text>
  </row>
  <row>
    <Id>213</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>108</PostId>
    <RevisionGUID>7bd27032-5cd7-403a-bf60-fc620bf2a9a0</RevisionGUID>
    <CreationDate>2010-03-02T11:00:20.98</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Genome specific database (Gbrowse / Ensembl type)</Text>
  </row>
  <row>
    <Id>214</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>108</PostId>
    <RevisionGUID>7bd27032-5cd7-403a-bf60-fc620bf2a9a0</RevisionGUID>
    <CreationDate>2010-03-02T11:00:20.98</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text> ésequenceà </Text>
  </row>
  <row>
    <Id>215</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>107</PostId>
    <RevisionGUID>c1e5962d-7833-4adb-97ee-1932dae53a03</RevisionGUID>
    <CreationDate>2010-03-02T11:05:54.12</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>spell</Comment>
    <Text>re Biomake:

It does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB) only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).  </Text>
  </row>
  <row>
    <Id>216</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>109</PostId>
    <RevisionGUID>6e5333ac-2ada-44ba-a298-b4389febacb5</RevisionGUID>
    <CreationDate>2010-03-02T12:06:01.24</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>This is a really debated topic, whether it is better to store sequences on a database or on simple flat files. I have never had to annotate draft genomes as you so I can't suggest you which is the best approach for you, but I would recommend using flat files, as you will have more support and tools, it will take less time to set it up, and I have the feeling that that is the direction that most projects are taking for the future.

In case you want to use databases, have a look at [this post][1] and a this type of column type, the [datatype-geometric][2].

In case you want to try flat files, you will have to study [BED][3], [GFF][4], and maybe [BAM][5] formats, along with [VCF][6] if you have snps. For example, if you BED, you will be able to use [BEDTools][7], which will allow you to merge and work with genomic features and are very fast. You will be surprised to know that GBrowse uses only GFF files to store data, it has no DB backend.

Another alternative is HDF5, about which you may find some questions here. So, you have a lot of homework here :-)


  [1]: http://www.mailund.dk/index.php/2009/01/22/playing-with-spatial-queries-in-mysql/
  [2]: http://www.postgresql.org/docs/8.1/interactive/datatype-geometric.html
  [3]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1
  [4]: http://genome.ucsc.edu/FAQ/FAQformat.html#format3
  [5]: http://samtools.sourceforge.net/
  [6]: http://vcftools.sourceforge.net/options.html
  [7]: http://code.google.com/p/bedtools/</Text>
  </row>
  <row>
    <Id>217</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>110</PostId>
    <RevisionGUID>74c8563a-202f-475b-91a0-0de81b7cc299</RevisionGUID>
    <CreationDate>2010-03-02T13:10:29.737</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Not BioHDF5 but probably readable and maintained: 

HDF5 for Python
http://code.google.com/p/h5py/</Text>
  </row>
  <row>
    <Id>218</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>7bb562ca-10c4-4ae7-82bc-76b5b3b79171</RevisionGUID>
    <CreationDate>2010-03-02T15:35:52.957</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Lets have 200k genomic contigs with some (unknown) bacterial contamination. 

I blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). 

Now for a tricky part: 
what I need is:
sequence_identifier + taxonomic_id(s) + main_tax_group

something along the line:

A000001 573 Bacteria

Apart from writing a script storing the sequence &amp; taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?

 

  </Text>
  </row>
  <row>
    <Id>219</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>7bb562ca-10c4-4ae7-82bc-76b5b3b79171</RevisionGUID>
    <CreationDate>2010-03-02T15:35:52.957</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Taxonomy of blast hits</Text>
  </row>
  <row>
    <Id>220</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>7bb562ca-10c4-4ae7-82bc-76b5b3b79171</RevisionGUID>
    <CreationDate>2010-03-02T15:35:52.957</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text> éblastà  étaxonomyà </Text>
  </row>
  <row>
    <Id>221</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>7f57e308-a1ba-4fa2-9e11-060a98d46627</RevisionGUID>
    <CreationDate>2010-03-02T16:56:10.393</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>explaining input</Comment>
    <Text>Lets have 200k genomic contigs with some (unknown) bacterial contamination. 

I blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). 

Now for a tricky part: 
what I need is:
sequence_identifier + taxonomic_id(s) + main_tax_group

something along the line:

A000001 573 Bacteria

Apart from writing a script storing the sequence &amp; taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?

**re Pierre**

Primary input is text blast output of:

    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01

I grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: 
A000001 573 Bacteria
The most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.

Ideally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:


&gt; cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;
&gt; Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli

will be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).
  
So at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).</Text>
  </row>
  <row>
    <Id>222</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>112</PostId>
    <RevisionGUID>d01bcfc7-31a0-432d-8514-699ecd8e08d1</RevisionGUID>
    <CreationDate>2010-03-02T17:25:33.09</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?

note: there is a [similar question][1] posted on stackoverflow.


  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources</Text>
  </row>
  <row>
    <Id>223</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>112</PostId>
    <RevisionGUID>d01bcfc7-31a0-432d-8514-699ecd8e08d1</RevisionGUID>
    <CreationDate>2010-03-02T17:25:33.09</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>your favorite bioinformatics blog</Text>
  </row>
  <row>
    <Id>224</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>112</PostId>
    <RevisionGUID>d01bcfc7-31a0-432d-8514-699ecd8e08d1</RevisionGUID>
    <CreationDate>2010-03-02T17:25:33.09</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésubjectiveà </Text>
  </row>
  <row>
    <Id>225</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>108</PostId>
    <RevisionGUID>da174fda-1a70-4b72-a27f-337944517c94</RevisionGUID>
    <CreationDate>2010-03-02T17:40:36.637</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> ésequenceà  égenomeà  éannotationà  édatabaseà </Text>
  </row>
  <row>
    <Id>226</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>112</PostId>
    <RevisionGUID>1e5c9e7f-6afe-42fc-a382-7812c61cf61b</RevisionGUID>
    <CreationDate>2010-03-02T17:41:10.55</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>added tags</Comment>
    <Text> ésubjectiveà  éblogà  éoffötopicà  éresourcesà </Text>
  </row>
  <row>
    <Id>227</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>102</PostId>
    <RevisionGUID>04b4db86-3770-49c9-a7f6-b7d6cce48025</RevisionGUID>
    <CreationDate>2010-03-02T17:42:01.19</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> ésequenceà  éuseöcaseà  édnaà </Text>
  </row>
  <row>
    <Id>228</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>99</PostId>
    <RevisionGUID>fc7e7290-a471-4b53-8337-a1b602e000b7</RevisionGUID>
    <CreationDate>2010-03-02T17:42:32.173</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éintervalà  équeryà  éuseöcaseà  égenomicsà </Text>
  </row>
  <row>
    <Id>229</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>c8a7de1e-b07b-4a6b-bdc5-4bdd216bd66c</RevisionGUID>
    <CreationDate>2010-03-02T17:43:08.317</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> épythonà  épygrà  éuseöcaseà  ésequenceà </Text>
  </row>
  <row>
    <Id>230</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>88</PostId>
    <RevisionGUID>65e94ac5-9ccf-45a5-9f69-31c6d3ae8907</RevisionGUID>
    <CreationDate>2010-03-02T17:44:16.057</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneralà  éagileà  égoodöpracticesà  éteamöworkingà </Text>
  </row>
  <row>
    <Id>231</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>79</PostId>
    <RevisionGUID>6b9dc639-7311-49a5-a687-76dc23a7f33e</RevisionGUID>
    <CreationDate>2010-03-02T17:45:01.483</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>added tags</Comment>
    <Text> égeneralà  émakeà  épipelineà  éorganizationà </Text>
  </row>
  <row>
    <Id>232</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>77</PostId>
    <RevisionGUID>f6fe3509-edce-4c24-bdec-2bcdf3f766d3</RevisionGUID>
    <CreationDate>2010-03-02T17:45:34.307</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> ébedà  éconversionà  éformatà </Text>
  </row>
  <row>
    <Id>233</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>113</PostId>
    <RevisionGUID>5c917eda-09de-422a-b776-5f4294f38673</RevisionGUID>
    <CreationDate>2010-03-02T17:46:19.31</CreationDate>
    <IPAddress>152.14.14.75</IPAddress>
    <UserId>45</UserId>
    <Text>http://biostar.stackexchange.com</Text>
  </row>
  <row>
    <Id>234</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>742e6a85-494a-4473-819e-59da16286e56</RevisionGUID>
    <CreationDate>2010-03-02T17:50:36.29</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>added more info about processing</Comment>
    <Text>Lets have 200k genomic contigs with some (unknown) bacterial contamination. 

I blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). 

Now for a tricky part: 
what I need is:
sequence_identifier + taxonomic_id(s) + main_tax_group

something along the line:

A000001 573 Bacteria

Apart from writing a script storing the sequence &amp; taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?

**re Pierre**

Primary input is text blast output of:

    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01

I grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: 
A000001 573 Bacteria
The most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.

Ideally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:


&gt; cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;
&gt; Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli

will be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).
  
So at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).

re 2
single line which gets squezzed a bit  here:

contig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9



Before each of the top hits there is blast header with hash sign in front:


    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score


So simple:

     grep -A 1 Fields out_blastn_frag0* | grep contig | awk '{ print $2}' | awk 'FS="|" {print $4}' | sort | uniq &gt; all_uniq_hits_100302.txt

gives me list off unique accession numbers of my top hits suitable for Batch Entrez.

**re XML:**
yes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. 


</Text>
  </row>
  <row>
    <Id>235</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>114</PostId>
    <RevisionGUID>4cde8572-c5a2-48c1-937e-d5e5f61a1eb3</RevisionGUID>
    <CreationDate>2010-03-02T18:02:17.513</CreationDate>
    <IPAddress>82.126.78.234</IPAddress>
    <UserId>30</UserId>
    <Text>I you want to get the TinySeq XML  *without* getting the sequence, I would create a SAX parser that would only get the value of the **TaxonId** and ignoring the other field (see "class TinySeqHandler" in [http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java][1] for an example). Having the taxonId you can get the full lineage from

    http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&amp;id=YOUR_TAXON_ID&amp;retmode=xml


  [1]: http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java</Text>
  </row>
  <row>
    <Id>236</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>115</PostId>
    <RevisionGUID>e4d9120a-663d-423b-aa99-ea16199af5c1</RevisionGUID>
    <CreationDate>2010-03-02T18:08:54.443</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>From the description of your input data I guess that you are trying to do a taxonomic classification of sequences in a metagenomics approach. I further assume that you have about 200.000 reads or sequences (or do you alternatively mean assembled contigs of length 200 kB?).
I am not sure if I completely understand the question, but whatever you do, filtering out the tax ids with your own script might not be the best option. 
 
I assume further you wish to compute a tree of the taxonomic composition of the data in total.

&gt; That way one can zoom in (select more
&gt; than just species/strain and taxonomic
&gt; Kingdom)

For this task you might want to try the [MEGAN][1] (Metagenome Analysis) software. 

Actually, what you are describing looks very much like one of the publications they have in their publications list:

H. N. Poinar, C. Schwarz, Ji Qi, B. Shapiro, R. D. E. MacPhee, B. Buigues, A. Tikhonov, D. H. Huson, L. P. Tomsho, A. Auch, M. Rampp, W. Miller, S. C. Schuster, [Metagenomics to Paleogenomics: Large-Scale Sequencing of Mammoth DNA][2], Science 311:392-394, 2006

There is also a [tutorial on setting the right BLAST parameter][3] for use with short reads.

So in principle, this program could do the job or at least you can have a look at the right parameters for blast. 


  [1]: http://www-ab.informatik.uni-tuebingen.de/software/megan
  [2]: http://www.sciencemag.org/cgi/content/abstract/1123360v1
  [3]: http://www-ab.informatik.uni-tuebingen.de/software/megan/how-to-use-blast</Text>
  </row>
  <row>
    <Id>237</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>116</PostId>
    <RevisionGUID>583a007c-a7d3-4382-b78d-845720a3aa21</RevisionGUID>
    <CreationDate>2010-03-02T18:10:21.71</CreationDate>
    <IPAddress>82.126.78.234</IPAddress>
    <UserId>30</UserId>
    <Text>mine of course ! :-) [http://plindenbaum.blogspot.com][1]

See also: Bioinformatics blogs on Nature-blogs: http://blogs.nature.com/blogs?tags=bioinformatics

And the life-scientists group on FriendFeed: [http://friendfeed.com/the-life-scientists][2]


  [1]: http://plindenbaum.blogspot.com
  [2]: http://friendfeed.com/the-life-scientists</Text>
  </row>
  <row>
    <Id>238</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>117</PostId>
    <RevisionGUID>a4335ddc-686f-4592-807b-5098b6b3fc7a</RevisionGUID>
    <CreationDate>2010-03-02T18:20:20.86</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Here is  one that I follow, but I'm interested in adding more blogs to my feed:

 - [Blue Collar Bioinformatics][1]
 
  [1]: http://bcbio.wordpress.com/</Text>
  </row>
  <row>
    <Id>239</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>112</PostId>
    <RevisionGUID>99e9de44-dc16-4609-badf-998009eb10fc</RevisionGUID>
    <CreationDate>2010-03-02T18:22:47.473</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed title capitalization</Comment>
    <Text>Your favorite bioinformatics blog</Text>
  </row>
  <row>
    <Id>240</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>118</PostId>
    <RevisionGUID>ace472bb-d70f-4317-8a4b-733f4f43a7c3</RevisionGUID>
    <CreationDate>2010-03-02T18:35:19.413</CreationDate>
    <IPAddress>192.122.237.11</IPAddress>
    <UserId>53</UserId>
    <Text>[Very large list of bioinformatics blogs][1] from the now defunct Nodalpoint wiki


  [1]: http://web.archive.org/web/20080213153458/wiki.nodalpoint.org/blogs</Text>
  </row>
  <row>
    <Id>241</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>119</PostId>
    <RevisionGUID>e423be46-3181-4d5a-b44b-a01ec61a780a</RevisionGUID>
    <CreationDate>2010-03-02T19:59:25.843</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Maybe not The Greatest but these few are covering next gen sequencing:

http://www.massgenomics.org/
http://www.fejes.ca/labels/DNA.html
http://omicsomics.blogspot.com/

</Text>
  </row>
  <row>
    <Id>242</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>120</PostId>
    <RevisionGUID>cf3a63e8-9141-464c-8b31-cb411b852ba2</RevisionGUID>
    <CreationDate>2010-03-02T20:10:25.417</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>May be a little bit dated, but let me blow my own trumpet (collection of links):

[Bioinfo_tutorial#Protein_localization_and_structure_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Protein_localization_and_structure_prediction)
</Text>
  </row>
  <row>
    <Id>243</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>121</PostId>
    <RevisionGUID>cc5b17f0-1a1a-4d19-bdbc-d32c38c28d48</RevisionGUID>
    <CreationDate>2010-03-02T20:38:44.343</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>A friend of mine is a very active blogger in bioinformatics. This is his blog site

[Fisheye Perspective][1]


He has also complied a list of bioinformatics and chemo informatics blogs which are very popular. some of you might be interested in it.

[30+ Blogs about Bioinformatics and Chemoinformatics Programming][2] 


  [1]: http://www.abhishek-tiwari.com/
  [2]: http://www.abhishek-tiwari.com/2009/02/30-blogs-about-bioinformatics-and.html</Text>
  </row>
  <row>
    <Id>244</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>33</PostId>
    <RevisionGUID>70ed2a45-2ad0-4abd-9a54-d1cac9341f53</RevisionGUID>
    <CreationDate>2010-03-02T21:16:12.33</CreationDate>
    <IPAddress>83.50.67.130</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneralà  ésubjectiveà  éosà </Text>
  </row>
  <row>
    <Id>245</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>bf2fb1ae-e02b-40dc-8d00-1fc325c15e02</RevisionGUID>
    <CreationDate>2010-03-02T21:16:36.64</CreationDate>
    <IPAddress>83.50.67.130</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> ésubjectiveà  éprogrammingà  élanguagesà </Text>
  </row>
  <row>
    <Id>246</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>122</PostId>
    <RevisionGUID>5017bb62-32d0-46fe-976d-5c8d45cb332b</RevisionGUID>
    <CreationDate>2010-03-02T22:42:11.97</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>I think the emphasis should be more on the way we optimize our program rather than language which we use. I personally use languages based on the kind of problem I am answering.

This was an interesting paper which I came across some time back although some of the information mentioned in here might sound redundant to some of you but still it's worth a read.

[A Quick Guide for Developing Effective Bioinformatics Programming Skills][1]


  [1]: http://www.ploscompbiol.org/article/info:doi%2F10.1371%2Fjournal.pcbi.1000589</Text>
  </row>
  <row>
    <Id>247</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>123</PostId>
    <RevisionGUID>b25c8dbe-f598-4274-b06e-431e78322a10</RevisionGUID>
    <CreationDate>2010-03-02T23:29:26.523</CreationDate>
    <IPAddress>88.18.98.221</IPAddress>
    <UserId>62</UserId>
    <Text>You may check out these pages:

[Bioinfo_tutorial#Promoter_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Promoter_prediction)

[Wikiomics:Sequence_motifs](http://openwetware.org/wiki/Wikiomics:Sequence_motifs)

These are ca 2 years old (links may not work etc.) but as a starting point should be OK. 
Also in unlikely case you did not found it yet: in yeast there has been an extensive motif search study done by Kellis with insane number of citations:


Nature. 2003 May 15;423(6937):241-54.

Kellis M, Patterson N, Endrizzi M, Birren B, Lander ES.

[Sequencing and comparison of yeast species to identify genes and regulatory elements.](http://www.ncbi.nlm.nih.gov/pubmed/12748633)</Text>
  </row>
  <row>
    <Id>248</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>124</PostId>
    <RevisionGUID>bd3be577-3881-4288-8c40-42a43a24713a</RevisionGUID>
    <CreationDate>2010-03-03T12:15:23.81</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Blogs:

 - [programming4scientists.com][1] - tricks for scientists entering the world of programming
 - [mailund on the Internet][2] - nice blog on programming, population genetics, simulations
 - [Open-Bio news][3] - news from the project that hosts bioperl, biopython, etc..
 - [FinchTalk][4] - this one is from a company, but it is interesting and technical worthy of reading it.
 - [Fisheye Perspective][5] - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the [feeds][6] directly
 - [88 Proof Synthetic Biology][7]
 - [Learning R][8] - tips to learn R
 - [BioCS][9]
 - [MentalIndigestion][10] 
 - [PDB - MOlecule of the Month][11]
 - [The molecule of the Month][12]  - similar style to pdb's, but different authors


Moreover, I also find useful to follow the blogs from many bioinformatics services or databases:
 
 - [NCBI][13]'s news
 - [Uniprot][14]'s news
 - [Plos Computational Biology][15]
 - [Gene Ontology][16] news


  [1]: http://www.programming4scientists.com/
  [2]: http://www.mailund.dk/
  [3]: http://news.open-bio.org/news/
  [4]: http://www.geospiza.com/finchtalk/
  [5]: http://www.abhishek-tiwari.com/
  [6]: http://feeds2.feedburner.com/AbhishekTiwarisBlog
  [7]: http://88proof.com/synthetic_biology/blog
  [8]: http://learnr.wordpress.com/
  [9]: http://blog.mckuhn.de/
  [10]: http://www.mentalindigestion.net/
  [11]: http://www.rcsb.org/pdb/motm.do
  [12]: http://www.chm.bris.ac.uk/motm/motm.htm
  [13]: http://www.ncbi.nlm.nih.gov/feed/rss.cgi
  [14]: http://www.uniprot.org/news/?format=rss
  [15]: http://feeds.plos.org/ploscompbiol/NewArticles
  [16]: http://go.berkeleybop.org/news4go/rss.xml</Text>
  </row>
  <row>
    <Id>249</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>125</PostId>
    <RevisionGUID>d66b6428-d04d-4ddc-af6c-0d196be9e390</RevisionGUID>
    <CreationDate>2010-03-03T12:35:31.063</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>The first step when looking for conservation of single bases or motives is often a multiple sequence alignment that will align the sequences in a way such that conserved regions are best visible. This can be a first step before using explicit motif finders like MEME. A good way of visualizing multiple alignments is the [sequence-logo][1] that will give a graphical representation of base conservation.

Here is the [wikipedia list of mult.-sequence alignment][2] tools.

I recommend to start with the [EBI web-server of ClustalW][3] though, if that is not enough you can also try MAFFT or T-Coffee.

[Weblogo][4] can generate sequence-logo graphics from the output and also from fasta input directly.

Advantage of these tools is that you don't need to install them, so good for a first attempt irrespective of using a Mac.  


  [1]: http://en.wikipedia.org/wiki/Sequence_logo
  [2]: http://en.wikipedia.org/wiki/List_of_sequence_alignment_software#Multiple_sequence_alignment
  [3]: http://www.ebi.ac.uk/Tools/clustalw2/index.html
  [4]: http://weblogo.threeplusone.com/</Text>
  </row>
  <row>
    <Id>250</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>69</PostId>
    <RevisionGUID>af9d5464-cf0c-4158-9ab7-ca6c1abf780a</RevisionGUID>
    <CreationDate>2010-03-03T13:38:58.783</CreationDate>
    <IPAddress>81.53.239.127</IPAddress>
    <UserId>30</UserId>
    <Comment>tags</Comment>
    <Text> éhdfà  ébiohdfà  éhdf5à  éstorageà </Text>
  </row>
  <row>
    <Id>251</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>76</PostId>
    <RevisionGUID>400be19d-2455-4e87-967b-c8c0c9c75037</RevisionGUID>
    <CreationDate>2010-03-03T13:39:44.443</CreationDate>
    <IPAddress>81.53.239.127</IPAddress>
    <UserId>30</UserId>
    <Comment>tags</Comment>
    <Text> écompilationà  étavernaà  épluginà  émavenà  éworkflowà </Text>
  </row>
  <row>
    <Id>252</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>22</PostId>
    <RevisionGUID>659bb165-2832-40dd-92ec-bf8285f880b8</RevisionGUID>
    <CreationDate>2010-03-03T14:03:06.16</CreationDate>
    <IPAddress>128.240.229.67</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneidà  éaccessionà  émappingà  éconversionà </Text>
  </row>
  <row>
    <Id>253</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>126</PostId>
    <RevisionGUID>c15aa2e6-a997-4cea-8540-fa07f03b4eb7</RevisionGUID>
    <CreationDate>2010-03-03T17:17:24.2</CreationDate>
    <IPAddress>193.62.202.241</IPAddress>
    <UserId>64</UserId>
    <Text>http://manuelcorpas.com/</Text>
  </row>
  <row>
    <Id>254</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>111</PostId>
    <RevisionGUID>ffccae1f-b1c7-4613-819c-53a48e3137bd</RevisionGUID>
    <CreationDate>2010-03-03T17:19:10.233</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>bold</Comment>
    <Text>Lets have 200k genomic contigs with some (unknown) bacterial contamination. 

I blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). 

Now for a tricky part: 
what I need is:
sequence_identifier + taxonomic_id(s) + main_tax_group

something along the line:

A000001 573 Bacteria

Apart from writing a script storing the sequence &amp; taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?

**re Pierre**

Primary input is text blast output of:

    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01

I grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: 
A000001 573 Bacteria
The most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.

Ideally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:


&gt; cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;
&gt; Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli

will be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).
  
So at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).

**re giovanni**
single line which gets squezzed a bit  here:

contig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9



Before each of the top hits there is blast header with hash sign in front:


    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score


So simple:

     grep -A 1 Fields out_blastn_frag0* | grep contig | awk '{ print $2}' | awk 'FS="|" {print $4}' | sort | uniq &gt; all_uniq_hits_100302.txt

gives me list off unique accession numbers of my top hits suitable for Batch Entrez.

**re XML:**
yes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. 


</Text>
  </row>
  <row>
    <Id>255</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>127</PostId>
    <RevisionGUID>47987fcb-7900-4583-bfb9-d6c5c1c6e30f</RevisionGUID>
    <CreationDate>2010-03-03T21:18:32.193</CreationDate>
    <IPAddress>130.216.218.184</IPAddress>
    <UserId>65</UserId>
    <Text>This might be useful for you. This code snippet read the Simulation data and manipulate in HDF5. 
&lt;pre&gt;
*Chnage first 5 includes from "" to open and close tags*
#include "stdlib.h"
#include "stdio.h"
#include "string.h"
#include "hdf5.h"
#include "hdf5_hl.h"

#include "common.h"
#include "hdf5_data.h"
#include "metadata/simulation.h"
#include "metadata/simulation_list.h"

enum FileIntent
{
  READING,
  WRITING,
  NEITHER
};

struct HDF5Data
{
  hid_t file;
  hid_t group;
  int ptCreated;
  hid_t pt;
  enum FileIntent intent;
};

/* Iterator function for pulling out existing simulation data.
 * Currently assumes we are only dealing with our own files but could be
 * made smarter to find only groups that contain the required dataspace's.
 */
static herr_t
rootIterator(hid_t group,const char *name,void *_iter)
{
  struct SimulationList* list = (struct SimulationList*)_iter;
  if (list)
  {
    struct Simulation* s = CreateSimulation();
    simulationSetName(s,name);
    simulationListAppend(list,s);
    DestroySimulation(&amp;s);
    return(0);
  }
  return(-1);
}

struct HDF5Data* CreateHDF5Data()
{
  struct HDF5Data* hdf5 = (struct HDF5Data*)malloc(sizeof(struct HDF5Data));
  if (hdf5)
  {
    hdf5-&gt;file = (hid_t)NULL;
    hdf5-&gt;group = (hid_t)NULL;
    hdf5-&gt;pt = (hid_t)NULL;
    hdf5-&gt;ptCreated = 0;
    hdf5-&gt;intent = NEITHER;
  }
  return(hdf5);
}

int DestroyHDF5Data(struct HDF5Data** hdf5)
{
  int code = ERR;
  struct HDF5Data* h5 = *hdf5;
  if (h5)
  {
    if (h5-&gt;ptCreated) H5PTclose(h5-&gt;pt);
    if (h5-&gt;group &gt; 0) H5Gclose(h5-&gt;group);
    if (h5-&gt;file &gt; 0) H5Fclose(h5-&gt;file);
    free(h5);
    code = OK;
  }
  *hdf5 = (struct HDF5Data*)NULL;
  return(code);
}

int hdf5DataOpenFileForWriting(struct HDF5Data* hdf5,const char* filename)
{
  /* Open the hdf5 file for writing. */
  int code = ERR;
  if (hdf5)
  {
    hdf5-&gt;file =
      H5Fcreate(filename,H5F_ACC_TRUNC,H5P_DEFAULT,H5P_DEFAULT);
    if (hdf5-&gt;file &lt; 0) code = ERR;
    else
    {
      hdf5-&gt;intent = WRITING;
      code = OK;
    }
  }
  return(code);
}

int hdf5DataOpenFileForReading(struct HDF5Data* hdf5,const char* filename)
{
  /* Open the hdf5 file for writing. */
  int code = ERR;
  if (hdf5)
  {
    hdf5-&gt;file = H5Fopen(filename,H5F_ACC_RDONLY,H5P_DEFAULT);
    if (hdf5-&gt;file &lt; 0) code = ERR;
    else
    {
      hdf5-&gt;intent = READING;
      code = OK;
    }
  }
  return(code);
}

int hdf5DataSetGroup(struct HDF5Data* hdf5,const char* groupName)
{
  int code = ERR;
  if (hdf5 &amp;&amp; (hdf5-&gt;file &gt; 0))
  {
    if (hdf5-&gt;group &gt; 0) H5Gclose(hdf5-&gt;group);
    if (hdf5-&gt;ptCreated) H5PTclose(hdf5-&gt;pt);
    hdf5-&gt;ptCreated = 0;
    if (groupName)
    {
      if (hdf5-&gt;intent == WRITING) hdf5-&gt;group =
        H5Gcreate(hdf5-&gt;file,groupName,/*size_hint*/0);
      else hdf5-&gt;group = H5Gopen(hdf5-&gt;file,groupName);
    }
    code = OK;
  }
  return(code);
}

int hdf5WriteSimulationModelURI(struct HDF5Data* hdf5,const char* uri)
{
  herr_t status;
  hid_t datatype,dataspace,dataset;
  hsize_t dim[1];

  if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))
  {
    fprintf(stderr,"Attempting to write to a reading file.\n");
    return(ERR);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  if (uri == NULL)
  {
    fprintf(stderr,"Attempting to write invalid URI to data file.\n");
    return(ERR);
  }
  if (strlen(uri) &gt; HDF5_STRING_LENGTH-1)
  {
    fprintf(stderr,
      "URI too long - fix the hdf5WriteSimulationModelURI code.\n");
    return(ERR);
  }
  char* localURI = (char*)calloc(HDF5_STRING_LENGTH,1);
  strcpy(localURI,uri);
  /* Make a string data type */
  datatype = H5Tcopy(H5T_C_S1);
  /* set the fixed string length */
  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);
  /* and we're gonna use C-like null-terminated string */
  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);
  /* Create a simple memory space of the correct size */
  dim[0] = 1;
  dataspace = H5Screate_simple(1,dim,NULL);
  /* and create the dataset to write to */
  dataset = H5Dcreate(hdf5-&gt;group,SIMULATION_MODEL_URI_NAME,datatype,
    dataspace,H5P_DEFAULT);
  /* Write the URI to the file */
  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,localURI);
  /* clean up */
  H5Dclose(dataset);
  H5Sclose(dataspace);
  H5Tclose(datatype);
  /*H5Fflush(hdf5-&gt;file,H5F_SCOPE_GLOBAL);*/
  free(localURI);
  return(OK);
}

int hdf5WriteFieldHeader(struct HDF5Data* hdf5,int N,char* names)
{
  herr_t status;
  hid_t datatype,dataspace,dataset;
  hsize_t dim[1];

  if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))
  {
    fprintf(stderr,"Attempting to write to a reading file.\n");
    return(ERR);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  /* Make a string data type */
  datatype = H5Tcopy(H5T_C_S1);
  /* set the fixed string length */
  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);
  /* and we're gonna use C-like null-terminated strings */
  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);
  /* Create a simple memory space of the correct size */
  dim[0] = N;
  dataspace = H5Screate_simple(1,dim,NULL);
  /* and create the dataset to write to */
  dataset = H5Dcreate(hdf5-&gt;group,FIELD_HEADER_DATA_NAME,datatype,
    dataspace,H5P_DEFAULT);
  /* Write the field names to the file */
  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);
  /* clean up */
  H5Dclose(dataset);
  H5Sclose(dataspace);
  H5Tclose(datatype);
  /*H5Fflush(hdf5-&gt;file,H5F_SCOPE_GLOBAL);*/
  return(OK);
}

int hdf5WriteData(struct HDF5Data* hdf5,int N,double* data)
{
  herr_t status = 0;
  
  if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))
  {
    fprintf(stderr,"Attempting to write to a reading file.\n");
    return(ERR);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  if (!hdf5-&gt;ptCreated)
  {
    /* create a fixed length packet table in the file */
    hdf5-&gt;pt = H5PTcreate_fl(hdf5-&gt;group,DATA_NAME,H5T_NATIVE_DOUBLE,
      /*chunk size ??*/sizeof(double)*N);
    hdf5-&gt;ptCreated = 1;
  }
  if (hdf5-&gt;ptCreated)
  {
    /* Write a packet to the packet table */
    status = H5PTappend(hdf5-&gt;pt,N,(void*)data);
  }
  return(OK);
}

char* hdf5ReadSimulationModelURI(struct HDF5Data* hdf5)
{
  herr_t status;
  hid_t datatype,dataspace,dataset;
  char *uri = (char*)NULL;
  
  if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))
  {
    fprintf(stderr,"Attempting to read from a writing file.\n");
    return((char*)NULL);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  /* open the dataset */
  dataset = H5Dopen(hdf5-&gt;group,SIMULATION_MODEL_URI_NAME);
  dataspace = H5Dget_space(dataset);
  /* get the data type */
  datatype = H5Dget_type(dataset);
  /* allocate memory */
  uri = (char*)malloc(HDF5_STRING_LENGTH);
  /* read in the data */
  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,uri);
  if (status &lt; 0)
  {
    fprintf(stderr,"Error getting the dimension of the field header.\n");
    free(uri);
    H5Sclose(dataspace);
    H5Tclose(datatype);
    H5Dclose(dataset);
    return((char*)NULL);
  }
  /* clean up */
  H5Sclose(dataspace);
  H5Tclose(datatype);
  H5Dclose(dataset);
  return(uri);
}

char** hdf5ReadFieldHeader(struct HDF5Data* hdf5,int* N)
{
  herr_t status;
  hid_t datatype,dataspace,dataset;
  hsize_t dim[1];
  char *tmp,*names = (char*)NULL;
  char** fields = (char**)NULL;
  int i;
  
  if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))
  {
    fprintf(stderr,"Attempting to read from a writing file.\n");
    return((char**)NULL);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  /* open the dataset */
  dataset = H5Dopen(hdf5-&gt;group,FIELD_HEADER_DATA_NAME);
  dataspace = H5Dget_space(dataset);
  /* get the data type */
  datatype = H5Dget_type(dataset);
  /* get the size and allocate memory */
  status = H5Sget_simple_extent_dims(dataspace,dim,NULL);
  if (status &lt; 0)
  {
    fprintf(stderr,"Error getting the dimension of the field header.\n");
    H5Sclose(dataspace);
    H5Tclose(datatype);
    H5Dclose(dataset);
    return((char**)NULL);
  }
  names = (char*)malloc(HDF5_STRING_LENGTH*dim[0]);
  /* read in the data */
  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);
  if (status &lt; 0)
  {
    fprintf(stderr,"Error getting the dimension of the field header.\n");
    free(names);
    H5Sclose(dataspace);
    H5Tclose(datatype);
    H5Dclose(dataset);
    return((char**)NULL);
  }
  /* clean up */
  H5Sclose(dataspace);
  H5Tclose(datatype);
  H5Dclose(dataset);
  /* split up the names */
  fields = (char**)malloc(sizeof(char*)*dim[0]);
  tmp = names;
  for (i=0;i&lt;dim[0];i++)
  {
    fields[i] = (char*)malloc(strlen(tmp)+1);
    strcpy(fields[i],tmp);
    tmp += HDF5_STRING_LENGTH;
  }
  free(names);
  *N = dim[0];
  return(fields);
}

double* hdf5ReadData(struct HDF5Data* hdf5,int N)
{
  herr_t status = 0;
  double* data = (double*)malloc(sizeof(double)*N);
  
  if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))
  {
    fprintf(stderr,"Attempting to read from a writing file.\n");
    return((double*)NULL);
  }
  if (hdf5-&gt;group &lt;= 0)
  {
    fprintf(stderr,"Missing HDF5 group.\n");
    return(ERR);
  }
  if (!hdf5-&gt;ptCreated)
  {
    /* open the packet table */
    hdf5-&gt;pt = H5PTopen(hdf5-&gt;group,DATA_NAME);
    /* and make sure we're at the start of the table */
    H5PTcreate_index(hdf5-&gt;pt);
    hdf5-&gt;ptCreated = 1;
  }
  if (hdf5-&gt;ptCreated)
  {
    /* get N packets from the packet table */
    status = H5PTget_next(hdf5-&gt;pt,N,(void*)data);
    if (status&lt;0)
    {
      free(data);
      data = (double*)NULL;
    }
  }
  return(data);
}

struct SimulationList* hdf5ReadSimulations(struct HDF5Data* hdf5)
{
  struct SimulationList* simulations = (struct SimulationList*)NULL;
  
  if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))
  {
    fprintf(stderr,"Attempting to read from a writing file.\n");
    return(simulations);
  }
  /* look for any groups which are children of the root group */
  hid_t rootGroup = H5Gopen(hdf5-&gt;file,"/");
  if (rootGroup &gt; 0)
  {
    simulations = CreateSimulationList();
    if (H5Giterate(rootGroup,"/",NULL,rootIterator,(void*)simulations)
      != 0) DestroySimulationList(&amp;simulations);
    H5Gclose(rootGroup);
  }
  return(simulations);
}

&lt;/pre&gt;</Text>
  </row>
  <row>
    <Id>256</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>128</PostId>
    <RevisionGUID>0486ac4f-0944-440b-b526-66fa4b2893ad</RevisionGUID>
    <CreationDate>2010-03-04T00:14:24.063</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>I think in one of the [earlier thread][1], Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the [Pfam database][2]. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.

cheers


  [1]: http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology
  [2]: http://pfam.sanger.ac.uk/</Text>
  </row>
  <row>
    <Id>257</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>128</PostId>
    <RevisionGUID>0486ac4f-0944-440b-b526-66fa4b2893ad</RevisionGUID>
    <CreationDate>2010-03-04T00:14:24.063</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>Pfam based functional annotaion</Text>
  </row>
  <row>
    <Id>258</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>128</PostId>
    <RevisionGUID>0486ac4f-0944-440b-b526-66fa4b2893ad</RevisionGUID>
    <CreationDate>2010-03-04T00:14:24.063</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text> éannotationà  éproteinà </Text>
  </row>
  <row>
    <Id>259</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>129</PostId>
    <RevisionGUID>d20c849c-feee-4856-9a7e-6918bb9a0927</RevisionGUID>
    <CreationDate>2010-03-04T08:49:51.88</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>My experience with Pfam is limited, but I think relevant to your question.

I work on a human pathogen which has been entirely sequenced and therefore we know quite a bit about what's in it. In particular, I'm interested one pfam group (PF02009) that groups similar proteins from this pathogen.

The problem I have with the pfam group is that it groups several distinct groups of proteins. These proteins are related, I agree, however, **at the level I'm comparing them (which is in detail)**, I would not jump to the conclusion that these proteins share the same function.

That brings me to the following comment on your question: looking for functional annotation is very vague. What detail of functional annotation are you looking for?

  * Do you want to know if these peptides belong to groups called "enzymes" or "receptors" or some kind of basic "building blocks", without any more detail?
  * Do you want to know if these peptides belong to a specific class of enzymes?
  * Do you want to know if these peptides belong to a specific sub-class of enzymes, going all the way down to the substrate specificity?

Another question I would have is regarding the length of your peptides. I recall one of my collaborators complaining about the fact that Pfam would not detect fragments that were too short. That was with Pfam2. I don't know how this is with Pfam3 though. So, you'll have to test this.

Depending on the answer to these questions (and many more) you may or may not want to ***only*** use Pfam. But in any case, Pfam could be a good start, if your peptides are not too short.


Another way that might be more relevant to short sequences would be to look at BLAST approaches (PSI- or PHI-BLAST in particular) to find what your peptides match to, and then look at the functional annotation of those hits (including whatever Pfam domains they may contain). I think this method would be more sensitive than the Pfam approach.

</Text>
  </row>
  <row>
    <Id>260</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>128</PostId>
    <RevisionGUID>94ee2b6b-551b-4e07-aeff-fa770900ea5a</RevisionGUID>
    <CreationDate>2010-03-04T08:52:44.247</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éannotationà  éproteinà  épfamà </Text>
  </row>
  <row>
    <Id>261</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>128</PostId>
    <RevisionGUID>8740c48c-a04c-474c-88f4-62cedec61293</RevisionGUID>
    <CreationDate>2010-03-04T09:29:26.957</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éannotationà  éproteinà  épfamà  éproteinödomainà </Text>
  </row>
  <row>
    <Id>262</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>124</PostId>
    <RevisionGUID>a7f53345-5bc7-423d-9553-bd63e0248159</RevisionGUID>
    <CreationDate>2010-03-04T09:50:40.277</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>added 70 characters in body</Comment>
    <Text>Blogs:

 - [programming4scientists.com][1] - tricks for scientists entering the world of programming
 - [mailund on the Internet][2] - nice blog on programming, population genetics, simulations
 - [Open-Bio news][3] - news from the project that hosts bioperl, biopython, etc..
 - [FinchTalk][4] - this one is from a company, but it is interesting and technical worthy of reading it.
 - [Fisheye Perspective][5] - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the [feeds][6] directly
 - [88 Proof Synthetic Biology][7]
 - [Learning R][8] - tips to learn R
 - [BioCS][9]
 - [MentalIndigestion][10] 
 - [PDB - MOlecule of the Month][11]
 - [The molecule of the Month][12]  - similar style to pdb's, but different authors


Moreover, I also find useful to follow the blogs from many bioinformatics services or databases:
 
 - [NCBI][13]'s news
 - [Uniprot][14]'s news
 - [Plos Computational Biology][15]
 - [Gene Ontology][16] news
 - [Ensembl][17] news


  [1]: http://www.programming4scientists.com/
  [2]: http://www.mailund.dk/
  [3]: http://news.open-bio.org/news/
  [4]: http://www.geospiza.com/finchtalk/
  [5]: http://www.abhishek-tiwari.com/
  [6]: http://feeds2.feedburner.com/AbhishekTiwarisBlog
  [7]: http://88proof.com/synthetic_biology/blog
  [8]: http://learnr.wordpress.com/
  [9]: http://blog.mckuhn.de/
  [10]: http://www.mentalindigestion.net/
  [11]: http://www.rcsb.org/pdb/motm.do
  [12]: http://www.chm.bris.ac.uk/motm/motm.htm
  [13]: http://www.ncbi.nlm.nih.gov/feed/rss.cgi
  [14]: http://www.uniprot.org/news/?format=rss
  [15]: http://feeds.plos.org/ploscompbiol/NewArticles
  [16]: http://go.berkeleybop.org/news4go/rss.xml
  [17]: http://www.ensembl.org/common/rss.xml</Text>
  </row>
  <row>
    <Id>263</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>130</PostId>
    <RevisionGUID>0bf92d03-f940-4bb0-b1c7-36613e41de0b</RevisionGUID>
    <CreationDate>2010-03-04T11:41:29.26</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>In a plant genome project I got a draft assembly (&gt; 500Mbp, &gt;500k contigs). 
A number of contigs is no doubt bacterial in origin. 

There are at least 3 peaks when it comes to GC content (40% - my plant, 50% largest contig, 65-70% another group). 

Blastn takes ages, and there is no point of doing it every time we change assembler parameters even slightly. So while rather sooner than later I will have to split 454 sff files into my_plant vs not_my_plant, I will still need a faster method of classifying contigs to not_my_plant group. 

In metagenomics this is often being done by calculating k-mer frequencies, see i.e (not supported anymore) TETRA:  http://www.megx.net/tetra/ (see the manual for the algorithm)

Do you use any program for fast clustering/classification of  sequences from say 150bp to 1Mbp using k-mer frequencies?

</Text>
  </row>
  <row>
    <Id>264</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>130</PostId>
    <RevisionGUID>0bf92d03-f940-4bb0-b1c7-36613e41de0b</RevisionGUID>
    <CreationDate>2010-03-04T11:41:29.26</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>k-mer based sequencing contamination detection</Text>
  </row>
  <row>
    <Id>265</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>130</PostId>
    <RevisionGUID>0bf92d03-f940-4bb0-b1c7-36613e41de0b</RevisionGUID>
    <CreationDate>2010-03-04T11:41:29.26</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text> ésequencingà  ékömerà </Text>
  </row>
  <row>
    <Id>266</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>131</PostId>
    <RevisionGUID>2d245072-b1ea-453f-94cf-d06596eeb9c5</RevisionGUID>
    <CreationDate>2010-03-04T13:51:46.527</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>Shameless plug for the [bioinformatics subreddit][1] (of which I am a moderator).


  [1]: http://www.reddit.com/r/bioinformatics</Text>
  </row>
  <row>
    <Id>267</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>132</PostId>
    <RevisionGUID>cd3f8240-bfb1-4414-b5b3-50302f2556d7</RevisionGUID>
    <CreationDate>2010-03-04T14:08:04.093</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>In the past years cloud computing services such as the [Amazon's Elastic Compute][1] cloud seem to have emerged a recommended alternative for providing high performance computing.

What are your experiences when it comes to *bioinformatics in the cloud*?

  [1]: http://aws.amazon.com/ec2/</Text>
  </row>
  <row>
    <Id>268</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>132</PostId>
    <RevisionGUID>cd3f8240-bfb1-4414-b5b3-50302f2556d7</RevisionGUID>
    <CreationDate>2010-03-04T14:08:04.093</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>Experiences with cloud computing in bioinformatics</Text>
  </row>
  <row>
    <Id>269</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>132</PostId>
    <RevisionGUID>cd3f8240-bfb1-4414-b5b3-50302f2556d7</RevisionGUID>
    <CreationDate>2010-03-04T14:08:04.093</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> écloudöcomputingà  égeneralà </Text>
  </row>
  <row>
    <Id>270</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>133</PostId>
    <RevisionGUID>cd79b6df-bb87-4d4e-a540-e5324e1e7d3e</RevisionGUID>
    <CreationDate>2010-03-04T14:24:46.857</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>We have been somewhat *early adopters* of cloud computing, having evaluated it for our bioinformatics needs more than two years ago. We are also what you could call *early abandoners*;  after using it for a year we compared it against a the high computing facility' services at our university ([Penn State HPC][1]) and we found it substantially under-performing.

This is not to say that Cloud Computing is not a fantastic idea, its just that just about all universities and science oriented organizations have far more powerful computing facilities to begin with.

Could computing is probably ideal for satisfying the temporary needs of a small lab with minimal funds and resources as it allows them to perform computations that otherwise would be out of reach. Yet as soon as the lab has continuous computational needs the cloud based solutions become not only more expensive but also a lot less powerful than a comparable "traditional" computing services.

I have come up with my own "rule of thumb" estimation: *If within an entire year one only needs to run their computers for less than 30% of time then cloud computing may be worth it.* 

  [1]: http://gears.aset.psu.edu/hpc/</Text>
  </row>
  <row>
    <Id>271</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>134</PostId>
    <RevisionGUID>42e159f4-992a-43b7-aafd-212e0fddccc8</RevisionGUID>
    <CreationDate>2010-03-04T14:30:04.513</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>This article may shed light onto how to organise bioinformatics projects.
William Stafford Noble. "A quick guide to organizing computational biology experiments." PLoS Computational Biology. 5(7):e1000424, 2009

link:
http://noble.gs.washington.edu/papers/noble2009quick.html

For me using git and the directory structure that Bill Noble mentiones in this articles has been a better approach than what I had before.</Text>
  </row>
  <row>
    <Id>272</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>134</PostId>
    <RevisionGUID>42e159f4-992a-43b7-aafd-212e0fddccc8</RevisionGUID>
    <CreationDate>2010-03-04T14:30:04.513</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
  </row>
  <row>
    <Id>273</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>135</PostId>
    <RevisionGUID>c76d9d88-55ad-409b-b1d2-09c29e1fd136</RevisionGUID>
    <CreationDate>2010-03-04T14:33:33.493</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated using R (1). However, it remains to be seen a rigorous comparison of its performance using a BLAST (2) search and its ability to cope with ever-increasing databases and open source frameworks such as bioperl (3) or bioconductor (4).

Cloud computing claims to be a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer (5), in a fashion seemingly similar to having your own virtual servers available over the Internet (6). Some of the most important aspects of cloud computing are:

* Software as a Service (SaaS): where you buy a software license for a determined period of time.
* Utility Computing: storage and virtual servers that IT can access on demand.
* Web Services.

My first exposure to cloud computing came of an email from Matt Wood (7), a newly established group leader at the Sanger Institute (8), announcing the Cloud Computing Group (9) in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University’s Centre for Mathematical Sciences (10), to my surprise I found there a very select audience, ranging from the director of IT at Sanger, Phil Butcher (11), one of the Ensembl (12) software coordinators, Glenn Proctor (13), and quite a few local start-up companies.

Among the presenters, we had Simone Brunozzi, from Amazon’s Cloud Computing (14). I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon’s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don’t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don’t need them. One of the things that stroke me about Amazon’s presentation was that they would not tell us the number of processors they had at their disposal.

When it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon’s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: i) allowing people to develop and contribute to the technology if and when they want to, ii) allowing total openness in terms of its achievements and pitfalls and iii) making it free to use for everyone. I do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as java (15) or MySQL (16), both components of SUN Microsystems’ (17) business.

Despite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.

References

1. http://www.r-project.org/
2. http://blast.ncbi.nlm.nih.gov/Blast.cgi
3. http://www.bioperl.org/wiki/Main_Page
4. http://www.bioconductor.org/
5. http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman
6. http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html
7. http://www.sanger.ac.uk/Users/mw4/
8. http://www.sanger.ac.uk/
9. http://cloudcamb.org/
10. http://www.cms.cam.ac.uk/site/
11. http://www.yourgenome.org/people/phil_butcher.shtml
12. http://www.ensembl.org/index.html
13. http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299
14. http://aws.amazon.com/ec2/
15. http://www.java.com/en/
16 http://www.mysql.com/
17. http://www.sun.com/
</Text>
  </row>
  <row>
    <Id>274</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>135</PostId>
    <RevisionGUID>c76d9d88-55ad-409b-b1d2-09c29e1fd136</RevisionGUID>
    <CreationDate>2010-03-04T14:33:33.493</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
  </row>
  <row>
    <Id>275</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>136</PostId>
    <RevisionGUID>0760dcf7-dc29-4ed5-bb04-44ed36aaa8e0</RevisionGUID>
    <CreationDate>2010-03-04T14:36:29.047</CreationDate>
    <IPAddress>193.62.202.241</IPAddress>
    <UserId>64</UserId>
    <Text>Unix, Perl and MySQL are programming skills that you need to master (I can think of people who would also say Java, Javascript, CSS, etc.). The best way to master the art of programming is to spend as much time as possible reading and writing source code. Some people think Perl is doomed. This is not true in the bioinformatics world. In part due to legacy and in part to the flexibility it provides, Perl is still the language of choice for many biohackers. Perl is used to construct 1) the back end of web applications, 2) pipelines and workflows and 3) quick and dirty scripts for parsing and calling other programs.

You will also need to be familiar with projects like R and Bioconductor, since a lot of the work will involve providing the computational infrastructure for analyzing data. In addition, you’ll need to know about data formats (fasta, sbml, mmcif…), software toolkits and libraries (Paup, Phylip, EMBOSS, BioPerl…), databases (Ensembl, InterPro, PDB, KEGG…), webservers and portals (Pubmed, ISCB).

Finally keep in mind best practices (like refraining from reinventing the wheel), but above all, give yourself the time to enjoy the learning process. Getting to the top usually takes longer than staying at the top; so what’s the point if you haven’t enjoyed the trip?</Text>
  </row>
  <row>
    <Id>276</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>136</PostId>
    <RevisionGUID>0760dcf7-dc29-4ed5-bb04-44ed36aaa8e0</RevisionGUID>
    <CreationDate>2010-03-04T14:36:29.047</CreationDate>
    <IPAddress>193.62.202.241</IPAddress>
    <UserId>64</UserId>
  </row>
  <row>
    <Id>277</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>137</PostId>
    <RevisionGUID>9ccdf62b-0327-492e-822d-63182c806373</RevisionGUID>
    <CreationDate>2010-03-04T14:40:30.667</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>When it comes to short read mapping there seemingly is no shortage of methods or software to choose from. Yet in practice we found that some published methods did now work at all, others exhibited suboptimal behaviors. 

 - What short read mappers do you use? 
 - How many reads do you need align and what is the size of the genome that you align to? 
 - What are the typical computational resources: parallel processes/CPU/memory required for the completion of the task?
 - What is your overall assessment of the procedure: easy, tedious, fun?

Note: we're primarily looking to hear of your first hand, personal experiences with any given tool.
</Text>
  </row>
  <row>
    <Id>278</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>137</PostId>
    <RevisionGUID>9ccdf62b-0327-492e-822d-63182c806373</RevisionGUID>
    <CreationDate>2010-03-04T14:40:30.667</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text>What methods do you use for short read mapping?</Text>
  </row>
  <row>
    <Id>279</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>137</PostId>
    <RevisionGUID>9ccdf62b-0327-492e-822d-63182c806373</RevisionGUID>
    <CreationDate>2010-03-04T14:40:30.667</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>10</UserId>
    <Text> éshortöreadöalignerà  ésequenceà  éshortöreadsà </Text>
  </row>
  <row>
    <Id>280</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>138</PostId>
    <RevisionGUID>0be73b01-d37d-488e-9f18-1c291084c006</RevisionGUID>
    <CreationDate>2010-03-04T14:54:54.287</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>I guess the best place would need to:

 - Have a critical mass of scientists
 - Be a world leading site for its reputation in science
 - Have well known projects
 - Good facilties
 - Good pay/Well funded
 - Leading Technology Provider

 </Text>
  </row>
  <row>
    <Id>281</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>138</PostId>
    <RevisionGUID>0be73b01-d37d-488e-9f18-1c291084c006</RevisionGUID>
    <CreationDate>2010-03-04T14:54:54.287</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>What is the best place in the world to do Bioinformatics?</Text>
  </row>
  <row>
    <Id>282</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>138</PostId>
    <RevisionGUID>0be73b01-d37d-488e-9f18-1c291084c006</RevisionGUID>
    <CreationDate>2010-03-04T14:54:54.287</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text> ébestà  éplacesà  ésubjectiveà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>283</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>138</PostId>
    <RevisionGUID>0be73b01-d37d-488e-9f18-1c291084c006</RevisionGUID>
    <CreationDate>2010-03-04T14:54:54.287</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
  </row>
  <row>
    <Id>284</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>db20e82c-2b62-4582-8eae-8877b1db11cf</RevisionGUID>
    <CreationDate>2010-03-04T14:57:03.88</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>The other day on facebook, I posted this link and some of my friend started discussing about this article. 

[It's "Watson Meets Moore" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.][1] 


few comments from my friends

Krishna : "I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!"

[Abhishek Tiwari][2]
@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. 


  [1]: http://bit.ly/9YIW7k
  [2]: http://biostar.stackexchange.com/users/65/abhishek-tiwari

We were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the "interesting information" coming out of the sequencing projects ?</Text>
  </row>
  <row>
    <Id>285</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>db20e82c-2b62-4582-8eae-8877b1db11cf</RevisionGUID>
    <CreationDate>2010-03-04T14:57:03.88</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text>state of computational geomics</Text>
  </row>
  <row>
    <Id>286</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>db20e82c-2b62-4582-8eae-8877b1db11cf</RevisionGUID>
    <CreationDate>2010-03-04T14:57:03.88</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Text> ésequencingà  égenomicsà </Text>
  </row>
  <row>
    <Id>287</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>140</PostId>
    <RevisionGUID>1085cfbf-c4e5-4563-afb3-1c4ae7cccf2e</RevisionGUID>
    <CreationDate>2010-03-04T14:58:13.067</CreationDate>
    <IPAddress>81.53.110.143</IPAddress>
    <UserId>30</UserId>
    <Text>I implemented my personnal suffix-array algorithm ( = **perfect match** ) because **bowtie** was too slow for **my needs**. I wrote about it here : [http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html][1].

It aligned all the 60 mers for each side of each SNPs (17E6 * 2 sequences) from dbSNP in about ~12H00.


  [1]: http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html</Text>
  </row>
  <row>
    <Id>288</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>141</PostId>
    <RevisionGUID>2eacb0be-781e-49b1-93c5-1331d2db8656</RevisionGUID>
    <CreationDate>2010-03-04T14:59:37.31</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>A group in my institute has developed a tool called [GEM][1] for mapping short reads and in general working with next gen sequencing data, like mapping cDNAs, find splicing isoforms, etc... I never used it directly but I have attended some talks on this and it seems convincing. 

In particular, to map short reads you should use the tool [gem_mapper][2].


  [1]: http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=The_GEM_library
  [2]:  http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=Gem_mapper_man_page</Text>
  </row>
  <row>
    <Id>289</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>138</PostId>
    <RevisionGUID>e66ccef4-f2a4-422c-842f-7de121b0b5a2</RevisionGUID>
    <CreationDate>2010-03-04T15:07:41.797</CreationDate>
    <IPAddress>193.62.202.241</IPAddress>
    <UserId>64</UserId>
    <Comment>edited tags</Comment>
    <Text> ébestöplacesà  ésubjectiveà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>290</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>142</PostId>
    <RevisionGUID>03cf48b8-fa87-479a-be69-7f0e7a1055f4</RevisionGUID>
    <CreationDate>2010-03-04T15:08:48.02</CreationDate>
    <IPAddress>81.53.110.143</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
given a set of **SNPs**, what would be your favorite way to find theirs related **pathways**/ **diseases** ?

Thanks
</Text>
  </row>
  <row>
    <Id>291</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>142</PostId>
    <RevisionGUID>03cf48b8-fa87-479a-be69-7f0e7a1055f4</RevisionGUID>
    <CreationDate>2010-03-04T15:08:48.02</CreationDate>
    <IPAddress>81.53.110.143</IPAddress>
    <UserId>30</UserId>
    <Text>Mapping SNPs to Pathways</Text>
  </row>
  <row>
    <Id>292</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>142</PostId>
    <RevisionGUID>03cf48b8-fa87-479a-be69-7f0e7a1055f4</RevisionGUID>
    <CreationDate>2010-03-04T15:08:48.02</CreationDate>
    <IPAddress>81.53.110.143</IPAddress>
    <UserId>30</UserId>
    <Text> ésnpà  égenotypingà  épathwaysà  égenesà  éminingà </Text>
  </row>
  <row>
    <Id>293</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>143</PostId>
    <RevisionGUID>67693ab4-1dd8-46d2-a4bd-edbcd7138093</RevisionGUID>
    <CreationDate>2010-03-04T15:13:53.35</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>For mapping reads obtained from the [SOLiD platform][1] we use [SHRiMP][2];

 - 47 million 50bp long reads in colorspace
 - We are aligning against the human genome, ~ 3 billion bases
 - A typical runtime is 12 hours for every 1 million reads. We split the 47 million reads into about 25 datasets and run them in parallel. SHRiMP's memory use depends on the size of the reads that needs to align: approx 1.6 GB per 1 million reads.
 - Overall we process the entire dataset in about a day
 - We like using the SHRiMP program. It is simple to use, has very clear documentation and no other dependencies. Importantly it easy to teach people how to use it. On the other hand it is probably a slower method than many others.

  [1]: http://www3.appliedbiosystems.com/AB_Home/applicationstechnologies/SOLiD-System-Sequencing-B/index.htm
  [2]: http://compbio.cs.toronto.edu/shrimp/</Text>
  </row>
  <row>
    <Id>294</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>144</PostId>
    <RevisionGUID>dfe51faa-2f29-40d1-b55a-7f1c15cc62b2</RevisionGUID>
    <CreationDate>2010-03-04T15:14:13.023</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>38</UserId>
    <Text>We've had a couple of Amazon education grants to try out EC2 here, and the service is very impressive. However, it would be extremely expensive to use it as a long-term replacement for our local grid service (which does have its own limitations, but is at least effectively free at the point of delivery) or clusters (in which a considerable amount of capital has already been invested). I think for the amount of grunt work we do, and particularly for the amount of data that needs to be shunted around, cloud computing is not quite there yet.</Text>
  </row>
  <row>
    <Id>295</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>145</PostId>
    <RevisionGUID>818fbd14-ebec-4d5b-bc75-23e3a9f25126</RevisionGUID>
    <CreationDate>2010-03-04T15:19:58.65</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>38</UserId>
    <Text>From a UK perspective, Cambridge has to be up there. I'm pretty sure it ticks all of your points, and you can't get much better for density of bioinformaticians than the [Genome Campus][1] in Hinxton.


  [1]: http://www.wellcome.ac.uk/Achievements-and-Impact/Initiatives/UK-biomedical-science/Genome-Campus-and-Sanger-Institute/WTD003482.htm</Text>
  </row>
  <row>
    <Id>296</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>145</PostId>
    <RevisionGUID>818fbd14-ebec-4d5b-bc75-23e3a9f25126</RevisionGUID>
    <CreationDate>2010-03-04T15:19:58.65</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>297</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>146</PostId>
    <RevisionGUID>2f0f019d-e4e9-4fa1-b804-d52f6d4a2695</RevisionGUID>
    <CreationDate>2010-03-04T15:20:35.933</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>I would use DAS -- Distributed Annotated System to retrieve all genes/phenotypes associated to a specific SNP.

DAS is a webservice for decentralised annotation that provides an esy protocol to retrieve features providing an url.

For example, retrieve me all OMIM genes in chromosome 18 between base pair 1 and 1000000

http://das.sanger.ac.uk/das/ens_36_omim_genes/features?segment=18:1,1000000

More on DAS [here][1]
 


  [1]: http://www.biodas.org/wiki/Main_Page</Text>
  </row>
  <row>
    <Id>298</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>146</PostId>
    <RevisionGUID>2f0f019d-e4e9-4fa1-b804-d52f6d4a2695</RevisionGUID>
    <CreationDate>2010-03-04T15:20:35.933</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
  </row>
  <row>
    <Id>299</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>147</PostId>
    <RevisionGUID>183f9da5-19eb-4496-850a-59b07a87c97b</RevisionGUID>
    <CreationDate>2010-03-04T15:22:42.13</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Text>Pierre, I feel your pain; Maven is not quite my friend either... Taverna is a really modular, and comes with very many dependencies... these are recursively defined and resolved using Maven... I'd love to build a plugin without it too, but never dared setting up such a system myself :)</Text>
  </row>
  <row>
    <Id>300</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>148</PostId>
    <RevisionGUID>3448aed9-a615-45ef-a238-cd2c3f5a8635</RevisionGUID>
    <CreationDate>2010-03-04T15:25:23.623</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Text>I can very much recommend [MyExperiment.org][1]. You can set up a category for a certain class of scripts, as the system has no limitation to Taverna 'scripts' anymore. MyExperiment is a true social services, provides tagging, setting up groups, etc.


  [1]: http://www.myexperiment.org/</Text>
  </row>
  <row>
    <Id>301</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>149</PostId>
    <RevisionGUID>38188a94-236f-4045-9efd-532147dbad25</RevisionGUID>
    <CreationDate>2010-03-04T15:34:11.92</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Text>Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).

However, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.</Text>
  </row>
  <row>
    <Id>302</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>149</PostId>
    <RevisionGUID>38188a94-236f-4045-9efd-532147dbad25</RevisionGUID>
    <CreationDate>2010-03-04T15:34:11.92</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Text>How far does bioinformatics go?</Text>
  </row>
  <row>
    <Id>303</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>149</PostId>
    <RevisionGUID>38188a94-236f-4045-9efd-532147dbad25</RevisionGUID>
    <CreationDate>2010-03-04T15:34:11.92</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Text> émetaà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>304</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>150</PostId>
    <RevisionGUID>2b92cac2-92f6-4d9b-8d34-ecedb11f3249</RevisionGUID>
    <CreationDate>2010-03-04T15:36:35.953</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I think every advance in technology creates new opportunities for those who know computation. </Text>
  </row>
  <row>
    <Id>305</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>6e69e395-8e39-4ef2-9dfb-ead5309d1f01</RevisionGUID>
    <CreationDate>2010-03-04T15:38:18.463</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>capitalized title</Comment>
    <Text>State of computational geomics</Text>
  </row>
  <row>
    <Id>306</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>151</PostId>
    <RevisionGUID>6c2223b1-389c-4b56-9a27-a86f54e5b4f0</RevisionGUID>
    <CreationDate>2010-03-04T15:54:25.67</CreationDate>
    <IPAddress>204.56.6.65</IPAddress>
    <UserId>74</UserId>
    <Text>I have used tophat (which also calls bowtie). It seemed pretty straightforward, I'm not sure I would call it "fun", but I think tophat does a good job providing useful output formats. Other people around here use Eland.

I was aligning 60-mer reads - 15-20 million per lane? 

This was to the mouse genome, so about 2.7 gigabases.

I don't know what computational resources were required, but I was running it on a server with 96 gigs of RAM and 16 cpus. Much more than I needed.

I'm actually not sure how long it took per lane, I just set it up and then left it while I worked on other stuff for awhile. </Text>
  </row>
  <row>
    <Id>307</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>152</PostId>
    <RevisionGUID>65d341b8-2953-426f-89e4-152821302f5c</RevisionGUID>
    <CreationDate>2010-03-04T16:07:04.833</CreationDate>
    <IPAddress>204.56.6.65</IPAddress>
    <UserId>74</UserId>
    <Text>I have found useful: Perl, MySQL, Unix commands and shell scripts, R, and knowing some web stuff (HTML/php). 

It's good to be familiar with a variety of tools, so you can choose the right one for the problem (and not force a tool to do something it's not really designed for, just because you don't know how to do it any other way).

If I was starting out, I might consider something like ruby or python instead of perl, but maybe not. There's a lot of code out there already written in perl.</Text>
  </row>
  <row>
    <Id>308</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>153</PostId>
    <RevisionGUID>11b835d8-45d9-4222-90b5-1fa7e33963d8</RevisionGUID>
    <CreationDate>2010-03-04T16:10:28.01</CreationDate>
    <IPAddress>204.56.6.65</IPAddress>
    <UserId>74</UserId>
    <Text>I generally use a simple shell script if I have multiple commands or scripts to run. I also try to make a notes.txt file to remind myself of what I did. Doesn't take long and comes in handy. 

Things that you didn't plan to re-use get re-used all the time, in my experience...</Text>
  </row>
  <row>
    <Id>309</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>154</PostId>
    <RevisionGUID>8879f173-e54f-4d28-93ed-f4c64cb590c5</RevisionGUID>
    <CreationDate>2010-03-04T16:12:31.733</CreationDate>
    <IPAddress>204.56.6.65</IPAddress>
    <UserId>74</UserId>
    <Text>Just click "DNA" at the top of the screen.</Text>
  </row>
  <row>
    <Id>310</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>155</PostId>
    <RevisionGUID>d2ced863-70b9-479d-99d9-c76ec2e827f2</RevisionGUID>
    <CreationDate>2010-03-04T16:38:10.637</CreationDate>
    <IPAddress>204.56.6.65</IPAddress>
    <UserId>74</UserId>
    <Text>If you have just a few, I just saw someone use the R package [BioIDMapper][1] and it seemed kind of neat. But it's slow.


  [1]: http://cran.r-project.org/web/packages/BioIDMapper/</Text>
  </row>
  <row>
    <Id>311</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>149</PostId>
    <RevisionGUID>f0fe4531-8b43-49f9-bdaa-0d1cc248740c</RevisionGUID>
    <CreationDate>2010-03-04T16:38:30.3</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> émetaà  ébioinformaticsà  ésubjectiveà </Text>
  </row>
  <row>
    <Id>312</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>149</PostId>
    <RevisionGUID>137415f3-3395-43b6-bd07-ba615be30128</RevisionGUID>
    <CreationDate>2010-03-04T16:41:33.33</CreationDate>
    <IPAddress>92.241.193.173</IPAddress>
    <UserId>71</UserId>
    <Comment>The answers are supposed to be backed up by literature... the subjective tag is typically reserved to "opinions can vary"... I do not feel that applies to what literature has to say about it...</Comment>
    <Text> émetaà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>313</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>156</PostId>
    <RevisionGUID>030e08da-c1b5-45a0-8903-da45c16a25f3</RevisionGUID>
    <CreationDate>2010-03-04T18:59:06.25</CreationDate>
    <IPAddress>131.174.146.73</IPAddress>
    <UserId>79</UserId>
    <Text>Stop being silly and just learn Maven.

It's not that hard and once you get to know it you'll never want to go back to finding and downloading jars, settings up the classpath, etc..</Text>
  </row>
  <row>
    <Id>314</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>157</PostId>
    <RevisionGUID>53bca522-0860-4d44-a039-1c9d0f02eece</RevisionGUID>
    <CreationDate>2010-03-04T19:59:41.113</CreationDate>
    <IPAddress>132.183.93.134</IPAddress>
    <UserId>82</UserId>
    <Text>I find that a healthy knowledge of R &amp; Bioconductor tools has been the most helpful.  In my work I also write a large amount of Python code.  Beyond those, having a strong Unix background - complete with scripts and tools such as sed &amp; awk have been very valuable.  Knowledge of HTML (don't need to be a javascript wiz, just the ability to make basic tables &amp; such) and SQL are also plusses.</Text>
  </row>
  <row>
    <Id>315</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>158</PostId>
    <RevisionGUID>bfa2af38-8010-4834-bdd5-633d1289f6e6</RevisionGUID>
    <CreationDate>2010-03-04T20:02:58.397</CreationDate>
    <IPAddress>132.183.93.134</IPAddress>
    <UserId>82</UserId>
    <Text>In my group, all primary computational folks (currently, a new person will be bucking this trend and going with OSX) have linux desktops that they have root access to.  Most of us have a secondary machine which varies between windows &amp; Mac OSX for various side tasks.  Beyond that we have several linux based servers that people use as well (via SSH).  The very few people who do any sort of computational work w/o a linux desktop ssh into these servers to do all of their real work.</Text>
  </row>
  <row>
    <Id>316</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>159</PostId>
    <RevisionGUID>202b7423-01f7-430c-84d4-374bd3c08054</RevisionGUID>
    <CreationDate>2010-03-04T20:04:45.883</CreationDate>
    <IPAddress>132.183.93.134</IPAddress>
    <UserId>82</UserId>
    <Text>One thing you might look at is the Broad Institute's &lt;a href="https://www.broad.harvard.edu/cancer/software/genepattern/"&gt;genepattern&lt;/a&gt; software.  It can be clunky at times but it will do most common tasks in a fairly straightforward fashion.</Text>
  </row>
  <row>
    <Id>317</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>160</PostId>
    <RevisionGUID>38df7143-6c5c-45e3-8a32-b97ec84dea8f</RevisionGUID>
    <CreationDate>2010-03-04T20:08:07.973</CreationDate>
    <IPAddress>132.183.93.134</IPAddress>
    <UserId>82</UserId>
    <Text>I'm the only person in my group who uses software control, other people are averse to it.  What we've ended up with is a by-convention approach within our large NAS block (which everyone mounts).  Any code which is deemed to be generally useful is essentially "checked in" to a particular directory tree w/ a designated format for keeping track of versioning, builds (where appropriate), etc.  Code which is specific to a project, dataset, etc is stored in a designated manner within the appropriate directory trees for that project, dataset, etc.</Text>
  </row>
  <row>
    <Id>318</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>3b451c6c-eb54-411e-881f-2e987c27ab45</RevisionGUID>
    <CreationDate>2010-03-04T20:37:52.487</CreationDate>
    <IPAddress>138.26.8.153</IPAddress>
    <UserId>84</UserId>
    <Text>Hi,

I am trying to implement protein pairwise sequence alignment using "Global Alignment" algorithm by 'Needleman -Wunsch'. I am using VB.NET. 

I am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?

I have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded "Blosum62 Martrix' ?

Also, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.

Any ideas or insights are appreciated.

Also, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides

Thanks.
</Text>
  </row>
  <row>
    <Id>319</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>3b451c6c-eb54-411e-881f-2e987c27ab45</RevisionGUID>
    <CreationDate>2010-03-04T20:37:52.487</CreationDate>
    <IPAddress>138.26.8.153</IPAddress>
    <UserId>84</UserId>
    <Text>Implementation of Blosum62 in the source code of global pairwise alignment of proteins</Text>
  </row>
  <row>
    <Id>320</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>3b451c6c-eb54-411e-881f-2e987c27ab45</RevisionGUID>
    <CreationDate>2010-03-04T20:37:52.487</CreationDate>
    <IPAddress>138.26.8.153</IPAddress>
    <UserId>84</UserId>
    <Text> ébiostarà </Text>
  </row>
  <row>
    <Id>321</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>162</PostId>
    <RevisionGUID>34ab38c8-fab9-40a0-b153-3ce573a6614a</RevisionGUID>
    <CreationDate>2010-03-04T20:49:12.96</CreationDate>
    <IPAddress>134.68.153.195</IPAddress>
    <UserId>85</UserId>
    <Text>I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?

Thank you.</Text>
  </row>
  <row>
    <Id>322</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>162</PostId>
    <RevisionGUID>34ab38c8-fab9-40a0-b153-3ce573a6614a</RevisionGUID>
    <CreationDate>2010-03-04T20:49:12.96</CreationDate>
    <IPAddress>134.68.153.195</IPAddress>
    <UserId>85</UserId>
    <Text>repeat subunit based multiple alignment of DNA</Text>
  </row>
  <row>
    <Id>323</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>162</PostId>
    <RevisionGUID>34ab38c8-fab9-40a0-b153-3ce573a6614a</RevisionGUID>
    <CreationDate>2010-03-04T20:49:12.96</CreationDate>
    <IPAddress>134.68.153.195</IPAddress>
    <UserId>85</UserId>
    <Text> émultiplealignmentà  éalignmentà  édnaà </Text>
  </row>
  <row>
    <Id>324</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>163</PostId>
    <RevisionGUID>1d567fad-144d-4c9e-9442-537679ac6e62</RevisionGUID>
    <CreationDate>2010-03-04T21:28:09.587</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>There are no mathematical formulas for this.

What you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:

    blosum = dict()
    blosum['Ala'] = dict()
    blosum['Ala']['Ala'] = 4
    blosum['Ala']['Arg'] = -1
    blosum['Ala']['Asn'] = -2 
    ... etc ...

Of course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -&gt; Arg substitution you could retrieve the value as:

    blosum['Ala']['Arg']

Use the corresponding data structure from you programming language. 

</Text>
  </row>
  <row>
    <Id>325</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>164</PostId>
    <RevisionGUID>bbf1a2e3-4a04-4492-8250-c862ad1543eb</RevisionGUID>
    <CreationDate>2010-03-04T22:10:31.843</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>I agree that there is a bit of lag between the advancement of sequencing technologies (physico-chemical point of view) and the computational requirements to actually take advantage of these advances... 

But is it really a problem?

  - All these technologies have strengths and weaknesses, so it's good that there are different technologies.
  - The processing of the data will eventually come around to a mature state.
  - The deluge of data is certainly not delved into yet, but would we even imagine how to do so if the data were not already available?
  - We are doing science, not selling cars: we need to be at the forefront of any and all advancements and not hold on to old vintage tech just because we "know" how to process it (or how to make money with it, e.g. old combustion vs. electrical engines).

As for your last question, about how to make sure we don't loose the "interesting information" coming out of the sequencing projects, well I'd say we aren't loosing anything since the raw data is well preserved in databanks! And concerning future discoveries from that data, you can't loose what you haven't found yet ;)

To sum up: advances are good, rat-race is good, lots of poorly understood data means we've got lots of work to do! And since I like what I do, I'm happy I won't have to go into another field of research ;)

Forward the Foundation!</Text>
  </row>
  <row>
    <Id>326</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>162</PostId>
    <RevisionGUID>1008f496-b7dd-4c48-86e2-f61f3e7fd49f</RevisionGUID>
    <CreationDate>2010-03-04T22:37:28.79</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>edited title</Comment>
    <Text>Repeat subunit based multiple alignment of DNA</Text>
  </row>
  <row>
    <Id>327</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>163</PostId>
    <RevisionGUID>7488dd1a-7805-4262-b296-096ba1f08ba7</RevisionGUID>
    <CreationDate>2010-03-04T22:39:55.027</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added 28 characters in body</Comment>
    <Text>There are no mathematical formulas for this.

What you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:

    blosum = dict()
    blosum['Ala'] = dict()
    blosum['Ala']['Ala'] = 4
    blosum['Ala']['Arg'] = -1
    blosum['Ala']['Asn'] = -2 
    ... etc ...

Of course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -&gt; Arg substitution you could retrieve the value as:

    blosum['Ala']['Arg']

Use the corresponding data structure from your programming language to build the same construct.

</Text>
  </row>
  <row>
    <Id>328</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>21fa8817-31a0-47fa-be3a-9fc09c30a7ac</RevisionGUID>
    <CreationDate>2010-03-04T22:45:08.48</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>fized typo in title</Comment>
    <Text>State of computational genomics</Text>
  </row>
  <row>
    <Id>329</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>165</PostId>
    <RevisionGUID>ff3da07f-d8e2-4acc-8806-44c8530e925d</RevisionGUID>
    <CreationDate>2010-03-04T22:58:49.467</CreationDate>
    <IPAddress>83.50.67.130</IPAddress>
    <UserId>23</UserId>
    <Text>One annecdota: when I was looking for a place to start a phd, the first of my criterias to determine where I liked or not a place was the position of the monitors.

I think that at least 90% of the bioinformaticians I have seen working simply sit down like monkeys in front of their monitor. I just don't understand this. I think that a place where somebody takes the time to correct behaviours like these is a good place to work; therefore, for me in the best place of the world to do bioinformatics, seats are comfortable and monitors are positioned at an ergonomic height.

Other than this, I would like to work for the 1000genomes consortium. I don't know what the conditions and the quality of work are, but there is a lot of data there and it would be good to be the among the first persons to use it.</Text>
  </row>
  <row>
    <Id>330</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>165</PostId>
    <RevisionGUID>ff3da07f-d8e2-4acc-8806-44c8530e925d</RevisionGUID>
    <CreationDate>2010-03-04T22:58:49.467</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>331</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>166</PostId>
    <RevisionGUID>1510d36c-2380-487d-be41-1977b9bebddd</RevisionGUID>
    <CreationDate>2010-03-04T23:09:59.897</CreationDate>
    <IPAddress>83.50.67.130</IPAddress>
    <UserId>23</UserId>
    <Text>Many people consider that bioinformatics began with the work of [Margaret Dayhoff][1] and the Pam matrixes. She compiled the first collection of protein sequences available at the time, publishing the Atlas of Protein Sequences and Structure, and she developed the first method to give a score to the similarity of two proteins, the PAM matrix.

For me, bioinformatics is everything that derived from Margaret Dayhoff's work. Compiling data and organizing it, developing tools to compare and handle informations, share the data with other people: if you read her biography you will find everything already there.

About the modern bioinformatics, I like to think of it as the science of doing experiments or part of them using computers at least for some steps. I like to think that there is no difference between the work in a wet lab and that in front of computer: when you are planning a bioinformatics project, you also have to think of an hypothesis, on how to verify it and on which tests and controls you will use. This is probably something that many people didn't understand yet, as they think that bioinformatics is just 'writing programs' and the don't even know what a test is and how much time it takes to write a program. 


  [1]: http://www.answers.com/main/ntquery?s=margaret+dayhoff&amp;gwp=13</Text>
  </row>
  <row>
    <Id>332</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>139</PostId>
    <RevisionGUID>bc5f50c8-4fcd-42e0-a20b-e2483ed228b5</RevisionGUID>
    <CreationDate>2010-03-04T23:14:40.963</CreationDate>
    <IPAddress>146.186.25.15</IPAddress>
    <UserId>7</UserId>
    <Comment>edited title</Comment>
    <Text>State of computational genomics</Text>
  </row>
  <row>
    <Id>333</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>167</PostId>
    <RevisionGUID>7bfbc286-06ec-4456-b72c-25e541596720</RevisionGUID>
    <CreationDate>2010-03-04T23:27:54.507</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>Biomart's Martview (http://www.biomart.org/biomart/martview/) will get you from SNP IDs to many gene/protein identifiers.  In a second step, Martview will also get you from gene IDs to GO Biological Process terms, but there are probably better tools that are specifically targeted toward pathways (KEGG, Reactome, WikiPathways, etc.)</Text>
  </row>
  <row>
    <Id>334</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>e0ec5487-187a-459c-893b-6fee40032b18</RevisionGUID>
    <CreationDate>2010-03-05T00:14:06.083</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>changed tags</Comment>
    <Text> ésequenceà  éalignmentà  éscoringmatixà </Text>
  </row>
  <row>
    <Id>335</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>168</PostId>
    <RevisionGUID>d5768147-3d38-4373-b59b-fa02ec368e3c</RevisionGUID>
    <CreationDate>2010-03-05T04:20:04.137</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Text>I am looking for an experienced Linux vendors to order a pre-installed CentOS/Ubuntu based webserver to host bioinformatics apps. Any suggestions or recommendations ? </Text>
  </row>
  <row>
    <Id>336</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>168</PostId>
    <RevisionGUID>d5768147-3d38-4373-b59b-fa02ec368e3c</RevisionGUID>
    <CreationDate>2010-03-05T04:20:04.137</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Text>Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps</Text>
  </row>
  <row>
    <Id>337</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>168</PostId>
    <RevisionGUID>d5768147-3d38-4373-b59b-fa02ec368e3c</RevisionGUID>
    <CreationDate>2010-03-05T04:20:04.137</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Text> ébioinformaticsà  éhardwareà  élinuxà  éserverà </Text>
  </row>
  <row>
    <Id>338</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>169</PostId>
    <RevisionGUID>ed4f0eb7-0d13-4714-b2c9-6e3681cacc60</RevisionGUID>
    <CreationDate>2010-03-05T04:40:36.17</CreationDate>
    <IPAddress>216.9.17.177</IPAddress>
    <UserId>72</UserId>
    <Text>I don't understand why this is a problem either.  You need to take that next step in data production and there is a lot of innovation going on there, as well as in the computational aspects of primary analysis.  The downstream innovation will happen (and it is based on some work that I am aware of).

The best innovation comes from rat races.  The market (in this case science, which fundamentally likes choice) will decide who gets to "win" and the algorithmic/analytics innovation will follow.</Text>
  </row>
  <row>
    <Id>339</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>170</PostId>
    <RevisionGUID>00195998-8900-4b71-8ce4-4856b722fd99</RevisionGUID>
    <CreationDate>2010-03-05T04:48:15.827</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Text>I have used STRING in three projects and I am still using it for large scale [protein-protein interaction][1] data analysis. I have downloaded the data and worked on PPI data of 5 eukaryotic model organisms. I strongly recommend [STRING][2] if you are looking for prokaryotic PPI data or if you working on a global scale of PPI network analysis in any given organism. An exceptional advantage about STRING is that they derive the PPI information from multiple approaches, still every single single interaction is scored using a scoring scheme. This gives a higher advantage to filter specific interactions that you are interested in (for example you can get PPI from human that have a score &gt;0.7 from experimental approach) and thus you can reduce the false positive rate. Another interesting aspect of [STRING][3] is the predicted interactions that are not reported in DIP or [HPRD][4] (If you are looking for literature curated, experimental annotations I strongly recommend HPRD ), this is something really exciting. You may get an interesting connections (not yet proven, though) that can lead you to new biological insights. The STRING team also maintain an interesting [blog][5], with the new releases, code-snippets, API detailes etc. 


  [1]: http://en.wikipedia.org/wiki/Protein%E2%80%93protein_interaction
  [2]: http://string.embl.de/
  [3]: http://string.embl.de/
  [4]: http://www.hprd.org/
  [5]: http://string-stitch.blogspot.com/</Text>
  </row>
  <row>
    <Id>340</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>171</PostId>
    <RevisionGUID>256eec47-8c13-454c-9c03-80df1ac212a5</RevisionGUID>
    <CreationDate>2010-03-05T04:54:16.19</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Text>I am currently using [Cluster 3.0][1] for clustering and [TreeView][2]. 


  [1]: http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/software.htm
  [2]: http://sourceforge.net/projects/jtreeview/</Text>
  </row>
  <row>
    <Id>341</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>172</PostId>
    <RevisionGUID>f32ab3b8-e12e-4149-a681-5f11f1fa4586</RevisionGUID>
    <CreationDate>2010-03-05T06:53:16.893</CreationDate>
    <IPAddress>92.241.193.253</IPAddress>
    <UserId>71</UserId>
    <Text>Have you looked into the [Ubuntu Amazon EC2 server][1] thing?


  [1]: http://www.ubuntu.com/cloud</Text>
  </row>
  <row>
    <Id>342</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>173</PostId>
    <RevisionGUID>61528cd5-9e1d-4400-8ab8-077d1d93cb26</RevisionGUID>
    <CreationDate>2010-03-05T09:56:57.267</CreationDate>
    <IPAddress>68.232.118.169</IPAddress>
    <UserId>7</UserId>
    <Text>How can we characterize a residue in a protein as a buried, exposed or intermediate based on it's accessible surface area(ASA) ? 

I came across a paper in which they are taking the ratio between the residue's ASA at a particular position to the maximum ASA observed for that residue in the whole protein.Further they apply a cut off on these ratios to characterize a residue as buried , exposed or intermediate. I am not sure about the basis of these cut offs.

can any one validate or provide a better approach for doing this ?  </Text>
  </row>
  <row>
    <Id>343</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>173</PostId>
    <RevisionGUID>61528cd5-9e1d-4400-8ab8-077d1d93cb26</RevisionGUID>
    <CreationDate>2010-03-05T09:56:57.267</CreationDate>
    <IPAddress>68.232.118.169</IPAddress>
    <UserId>7</UserId>
    <Text>How to charecterize a residue in a protein based on it's ASA</Text>
  </row>
  <row>
    <Id>344</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>173</PostId>
    <RevisionGUID>61528cd5-9e1d-4400-8ab8-077d1d93cb26</RevisionGUID>
    <CreationDate>2010-03-05T09:56:57.267</CreationDate>
    <IPAddress>68.232.118.169</IPAddress>
    <UserId>7</UserId>
    <Text> éproteinà  éstructureà </Text>
  </row>
  <row>
    <Id>345</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>174</PostId>
    <RevisionGUID>cf9edb0e-e148-4c5e-91e6-daecea2a342e</RevisionGUID>
    <CreationDate>2010-03-05T10:33:25.513</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>[System 76][1] is a vendor that *only* sells "laptops, desktops, and servers with Ubuntu pre-installed, and is committed to the ideals of open source software." You can [compare the servers they sell][2]. They are also a [Ubuntu solution provider][3] so I am sure they can make you a system that fits your needs to a tee.


  [1]: http://www.system76.com/
  [2]: http://www.system76.com/index.php?cPath=29
  [3]: http://www.ubuntu.com/partners/solutionprovider</Text>
  </row>
  <row>
    <Id>346</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>175</PostId>
    <RevisionGUID>1eb3a0d2-4cbe-4c71-8e91-387f26d00c18</RevisionGUID>
    <CreationDate>2010-03-05T12:31:43.373</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline. The ultimate goal of the field is to enable the discovery of new biological insights as well as to create a global perspective from which unifying principles in biology can be discerned. 

Listed below are some of the major events in bioinformatics over the last several decades. Most of the events in the list occurred long before the term, "bioinformatics", was coined.

I've tagged each entry with either:

 - ***(BIO)*** if it was an event which was predominantly important in the field of biology.
 - ***(IT)*** if it was an event which was predominantly important in the field of computer science/information technology
 - ***(BIOINFO)*** if it was an event where biology and computer science/information technology truly merged and we can really speak from bioinformatics.

As you will notice, it becomes increasingly difficult/subjective to catalogue events with exclusively one tag, so the main point to take away is that in the course of bioinformatics history there has been a constant exchange of ideas between biology, computer science/information technology and bioinformatics.

 - **1665**  ***(BIO)*** Robert Hooke published Micrographia, described the cellular structure of cork. He also described microscopic examinations of fossilized plants and animals, comparing their microscopic structure to that of the living organisms they resembled. He argued for an organic origin of fossils, and suggested a plausible mechanism for their formation.

 - **1683** ***(BIO)*** Antoni van Leeuwenhoek discovered bacteria.

 - **1686** ***(BIO)*** John Ray, John Ray's in his book "Historia Plantarum" catalogued and described 18,600 kinds of plants. His book gave the first definition of species based upon common descent.

 - **1843** ***(BIO)*** Richard Owen elaborated the distinction of homology and analogy.

 - **1864** ***(BIO)*** Ernst Haeckel (Häckel) outlined the essential elements of modern zoological classification.

 - **1865** ***(BIO)*** Gregory Mendel (1823-1884), Austria,  established the theory of genetic inheritance.

 - **1902** ***(BIO)*** The chromosome theory of heredity is proposed by Sutton and Boveri, working independently.

 - **1905** ***(BIO)*** The word "genetics" is coined by William Bateson.

 - **1913** ***(BIO)*** First ever linkage map created by Columbia undergraduate Alfred Sturtevant (working with T.H. Morgan).

 - **1930** ***(BIO)*** Tiselius, Uppsala University, Sweden, A new technique, electrophoresis, is introduced by Tiselius for separating proteins in solution. "The moving-boundary method of studying the electrophoresis of proteins" (published in Nova Acta Regiae Societatis Scientiarum Upsaliensis, Ser. IV, Vol. 7, No. 4)

 - **1946** ***(BIO)*** Genetic material can be transferred laterally between bacterial cells, as shown by Lederberg and Tatum.

 - **1951** ***(BIO)*** Pauling and Corey propose the structure for the alpha-helix and beta-sheet (Proc. Natl. Acad. Sci. USA, 27: 205-211, 1951; Proc. Natl. Acad. Sci. USA, 37: 729-740, 1951).

 - **1952** ***(BIO)*** Alfred Day Hershey and Martha Chase proved that the DNA alone carries genetic information. This was proved on the basis of their bacteriophage research.

 - **1953** ***(BIO)*** Watson and Crick propose the double helix model for DNA based on x-ray data obtained by Franklin and Wilkins (Nature, 171: 737-738, 1953).

 - **1954** ***(BIO)*** Perutz's group develop heavy atom methods to solve the phase problem in protein crystallography.

 - **1955** ***(BIO)*** The sequence of the first protein to be analyzed, bovine insulin, is announced by F. Sanger.

 - **1958** ***(IT)*** The Advanced Research Projects Agency (ARPA) is formed in the US

 - **1958** ***(IT)*** The first integrated circuit is constructed by Jack Kilby at Texas Instruments.

 - **1961** ***(BIO)*** Sidney Brenner, François Jacob, Matthew Meselson, identify messenger RNA

 - **1962** ***(BIO)*** Pauling's theory of molecular evolution

 - **1965** ***(BIO)*** Margaret Dayhoff's Atlas of Protein Sequences

 - **1968** ***(IT)*** Packet-switching network protocols are presented to ARPA

 - **1969** ***(IT)*** The ARPANET is created by linking computers at Stanford, UCSB, The University of Utah and UCLA.

 - **1970** ***(BIOINFO)*** The details of the Needleman-Wunsch algorithm for sequence comparison are published.

 - **1971** ***(IT)*** Ray Tomlinson (BBN) invents the email program.

 - **1972** ***(BIO)*** The first recombinant DNA molecule is created by Paul Berg and his group.

 - **1973** ***(IT)*** Robert Metcalfe receives his Ph.D. from Harvard University. His thesis describes Ethernet.

 - **1973** ***(BIOINFO)*** The Brookhaven Protein Data Bank is announced (Acta. Cryst. B, 1973, 29: 1746).

 - **1974** ***(IT)*** Charles Goldfarb invents SGML (Standardized General Markup Language).

 - **1974** ***(IT)*** Vint Cerf and Robert Kahn develop the concept of connecting networks of computers into an "internet" and develop the Transmission Control Protocol (TCP).

 - **1975** ***(BIO)*** E. M. Southern published the experimental details for the Southern Blot technique of specific sequences of DNA (J. Mol. Biol., 98: 503-517, 1975).

 - **1975** ***(IT)*** Microsoft Corporation is founded by Bill Gates and Paul Allen.

 - **1975** ***(BIO)*** Two-dimensional electrophoresis, where separation of proteins on SDS polyacrylamide gel is combined with separation according to isoelectric points, is announced by P. H. O'Farrell (J. Biol. Chem., 250: 4007-4021, 1975).

 - **1976** ***(IT)*** The Unix-To-Unix Copy Protocol (UUCP) is developed at Bell Labs.

 - **1977** ***(BIOINFO)*** Allan Maxam and Walter Gilbert (Harvard) and Frederick Sanger (U.K. Medical Research Council), report methods for sequencing DNA.

 - **1977** ***(BIOINFO)*** DNA sequencing and software to analyze it (Staden)

 - **1977** ***(BIOINFO)*** The full description of the Brookhaven PDB (http://www.pdb.bnl.gov) is published (Bernstein, F.C.; Koetzle, T.F.; Williams, G.J.B.; Meyer, E.F.; Brice, M.D.; Rodgers, J.R.; Kennard, O.; Shimanouchi, T.; Tasumi, M.J.; J. Mol. Biol., 1977, 112:, 535).

 - **1978** ***(IT)*** The first Usenet connection is established between Duke and the University of North Carolina at Chapel Hill by Tom Truscott, Jim Ellis and Steve Bellovin.

 - **1980** ***(BIOINFO)*** IntelliGenetics, Inc. founded in California. Their primary product is the IntelliGenetics Suite of programs for DNA and protein sequence analysis.

 - **1980** ***(BIO)*** The first complete gene sequence for an organism (FX174) is published. The gene consists of 5,386 base pairs which code nine proteins.

 - **1980** ***(BIO)*** Wüthrich et. al. publish paper detailing the use of multi-dimensional NMR for protein structure determination (Kumar, A.; Ernst, R.R.; Wüthrich, K.; Biochem. Biophys. Res. Comm., 1980, 95:, 1).

 - **1981** ***(IT)*** IBM introduces its Personal Computer to the market.

 - **1981** ***(BIOINFO)*** The Smith-Waterman algorithm for sequence alignment is published.

 - **1981** ***(BIO)*** The concept of a sequence motif (Doolittle)

 - **1982** ***(BIOINFO)*** GenBank Release 3 made public

 - **1982** ***(BIO)*** Genetics Computer Group (GCG) created as a part of the University of Wisconsin of Wisconsin Biotechnology Center. The company's primary product is The Wisconsin Suite of molecular biology tools.

 - **1982** ***(BIO)*** Phage lambda genome sequenced

 - **1983** ***(IT)*** Name servers are developed at the University of Wisconsin.

 - **1983** ***(BIOINFO)*** Sequence database searching algorithm (Wilbur-Lipman)

 - **1983** ***(IT)*** The Compact Disk (CD) is launched.

 - **1984** ***(IT)*** Jon Postel's Domain Name System (DNS) is placed on-line.

 - **1984** ***(IT)*** The Macintosh is announced by Apple Computer.

 - **1985** ***(BIOINFO)*** FASTP/FASTN: fast sequence similarity searching algorithm is published.

 - **1985** ***(BIO)*** The PCR reaction is described by Kary Mullis and co-workers.

 - **1986** ***(IT)*** NSFnet debuts.

 - **1986** ***(BIOINFO)*** The SWISS-PROT database is created by the Department of Medical Biochemistry of the University of Geneva and the European Molecular Biology Laboratory (EMBL).

 - **1986** ***(BIO)*** The term "Genomics" appeared for the first time to describe the scientific discipline of mapping, sequencing, and analyzing genes. The term was coined by Thomas Roderick as a name for the new journal.

 - **1987** ***(BIO)*** The physical map of e. coli is published (Y. Kohara, et. al., Cell 51: 319-337).

 - **1987** ***(BIO)*** The use of yeast artifical chromosomes (YAC) is described (David T. Burke, et. al., Science, 236: 806-812).

 - **1988** ***(IT)*** A new program, an Internet computer virus designed by a student, infects 6,000 military computers in the US.

 - **1988** ***(BIOINFO)*** Des Higgins and Paul Sharpe announce the development of CLUSTAL (Higgins, D.G.; Sharp, P.M. Fast and sensitive multiple sequence alignments on a microcomputer. Comput. Appl. Biosci. 1989, 5, 151-153; Higgins, D.G.; Sharp, P.M. CLUSTAL: a package for performing multiple sequence alignment on a microcomputer. Gene 1988, 73, 237-244.)

 - **1988** ***(IT)*** EMBnet network for database distribution

 - **1988** ***(BIO)*** National Center for Biotechnology Information (NCBI) created at NIH/NLM

 - **1988** ***(IT)*** Perl (Practical Extraction Report Language) is released by Larry Wall.

 - **1988** ***(BIOINFO)*** The FASTA algorithm for sequence comparison is published by Pearson and Lupman.

 - **1988** ***(BIO)*** The Human Genome Initiative is started (Commission on Life Sciences, National Research Council. Mapping and Sequencing the Human Genome, National Academy Press: Washington, D.C.), 1988.

 - **1988** ***(BIO)*** The National Center for Biotechnology Information (NCBI) is established at the National Cancer Institute.

 - **1990** ***(BIOINFO)*** BLAST: fast sequence similarity searching (Altschul, et. al.) is implemented.

 - **1990** ***(IT)*** The HTTP 1.0 specification is published. Tim Berners-Lee publishes the first HTML document.

 - **1991** ***(BIO)*** EST: expressed sequence tag sequencing

 - **1991** ***(IT)*** Linus Torvalds announces a Unix-Like operating system which later becomes Linux.

 - **1991** ***(BIO)*** Myriad Genetics, Inc. is founded in Utah. The company's goal is to lead in the discovery of major common human disease genes and their related pathways. The Company has discovered and sequenced, with its academic collaborators, the following major genes: BRCA1, BRCA2, CHD1, MMAC1, MMSC1, MMSC2, CtIP, p16, p19, and MTS2.

 - **1991** ***(BIO)*** The creation and use of expressed sequence tags (ESTs) is described (J. Craig Venter, et. al., Science, 252: 1651-1656).

 - **1991** ***(IT)*** The research institute in Geneva (CERN) announces the creation of the protocols which make-up the World Wide Web.

 - **1992** ***(BIO)*** Mel Simon and coworkers announce the use of BACs for cloning.

 - **1992** ***(BIO)*** The Institute for Genomic Research (TIGR) is established by Craig Venter.

 - **1993** ***(BIO)*** Affymetrix begins independent operations in Santa Clara, California

 - **1993** ***(BIO)*** Sanger Centre, Hinxton, UK

 - **1994** ***(BIOINFO)*** EMBL European Bioinformatics Institute, Hinxton, UK

 - **1994** ***(IT)*** Netscape Comminications Corporation founded and releases Navigator, the commercial version of NCSA's Mozilla.

 - **1994** ***(BIOINFO)*** The PRINTS database of protein motifs is published by Attwood and Beck.

 - **1995** ***(BIO)*** First bacterial genomes completely sequenced

 - **1995** ***(IT)*** Microsoft releases version 1.0 of Internet Explorer.

 - **1995** ***(IT)*** Sun releases version 1.0 of Java. Sun and Netscape release version 1.0 of JavaScript

 - **1995** ***(BIO)*** The Haemophilus influenzea genome (1.8 Mb) is sequenced.

 - **1995** ***(BIO)*** The Mycoplasma genitalium genome is sequenced.

 - **1995** ***(IT)*** Version 1.0 of Apache is released.

 - **1996** ***(BIO)*** Affymetrix produces the first commercial DNA chips.

 - **1996** ***(BIO)*** Oxford Molecular Group acquires the MacVector product from Eastman Kodak.

 - **1996** ***(BIOINFO)*** Structural Bioinformatics, Inc. founded in San Diego, CA.

 - **1996** ***(BIO)*** The Prosite database is reported by Bairoch, et.al.

 - **1996** ***(BIO)*** The genome for Saccharomyces cerevisiae (baker's yeast, 12.1 Mb) is sequenced.

 - **1996** ***(IT)*** The working draft for XML is released by W3C.

 - **1996** ***(BIO)*** Yeast genome completely sequenced

 - **1997** ***(BIOINFO)*** LION bioscience AG founded as an integrated genomics company with strong focus on bioinformatics. The company is built from IP out of the European Molecular Biology Laboratory (EMBL), the European Bioinformatics Institute (EBI), the German Cancer Research Center (DKFZ), and the University of Heidelberg.

 - **1997** ***(BIOINFO)*** PSI-BLAST

 - **1997** ***(BIO)*** The genome for E. coli (4.7 Mbp) is published.

 - **1998** ***(BIO)*** Craig Venter forms Celera in Rockville, Maryland.

 - **1998** ***(BIOINFO)*** Inpharmatica, a new Genomics and Bioinformatics company, is established by University College London, the Wolfson Institute for Biomedical Research, five leading scientists from major British academic centers and Unibio Limited.

 - **1998** ***(BIOINFO)*** The Swiss Institute of Bioinformatics is established as a non-profit foundation.

 - **1998** ***(BIO)*** The genomes for Caenorhabditis elegans and baker's yeast are published.

 - **1998** ***(BIO)*** Worm (multicellular) genome completely sequenced

 - **1998** ***(BIO)*** deCode genetics publishes a paper that described the location of the FET1 gene, which is responsible for familial essential tremor, on chromosome 13 (Nature Genetics).

 - **1999** ***(BIO)*** Fly genome completely sequenced

 - **1999** ***(BIO)*** deCode genetics maps the gene linked to pre-eclampsia as a locus on chromosome 2p13.

 - **2000** ***(BIO)*** Jeong H, Tombor B, Albert R, Oltvai ZN, Barabasi AL. The large-scale organization of metabolic networks. Nature 2000 Oct 5;407(6804):651-4, PubMed

 - **2000** ***(BIO)*** The A. thaliana genome (100 Mb) is secquenced.

 - **2000** ***(BIO)*** The D. melanogaster genome (180Mb) is secquenced.

 - **2000** ***(BIO)*** The genome for Pseudomonas aeruginosa (6.3 Mbp) is published.

 - **2001** ***(BIO)*** The human genome (3,000 Mbp) is published.

 - **2002** ***(BIO)*** An international sequencing consortium published the full genome sequence of the common house mouse (2.5 Gb). Whitehead Institute researcher Kerstin Lindblad-Toh is the lead author on the paper; her institution lead the project and contributed about half of the sequence. Washington University School of Medicine delivered about 30 percent of the sequence, and created the mouse BAC-based physical map. The Wellcome Trust Sanger Institute in the UK was the third major partner. Other institutes in the International Mouse Genome Sequencing Consortium included the University of California at Santa Cruz, the Institute for Systems Biology, and the University of Geneva.

 - **2004** ***(BIO)*** The draft genome sequence of the brown Norway laboratory rat, Rattus norvegicus, was completed by the Rat Genome Sequencing project Consortium. The paper appears in the April 1 edition of Nature.

Compiled from different sources, including: 

 - A [Short History of Bioinformatics][1], by Allen B. Richon
 - [History of Bioinformatics][2]
 - [Bioinformatics Milestones][3]
 - [History, Origin &amp; Bioinformatics Events][4] 


  [1]: http://www.netsci.org/Science/Bioinform/feature06.html
  [2]: http://www.roseindia.net/bioinformatics/history_of_bioinformatics.shtml
  [3]: http://www.ncbi.nlm.nih.gov/Education/BLASTinfo/milestones.html
  [4]: http://www.cbclickbank.com/bioinformatics/history.htm</Text>
  </row>
  <row>
    <Id>347</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>175</PostId>
    <RevisionGUID>1eb3a0d2-4cbe-4c71-8e91-387f26d00c18</RevisionGUID>
    <CreationDate>2010-03-05T12:31:43.373</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
  </row>
  <row>
    <Id>348</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>176</PostId>
    <RevisionGUID>d034c214-7780-413c-9cd7-81f177914d38</RevisionGUID>
    <CreationDate>2010-03-05T12:47:09.16</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>No idea how to do it exactly but I can think about two routes to investigate:

* LASTZ has something called "quantum DNA":

http://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna

* instead of using "linear" aligner go for graph based ones:
POA     http://bioinfo.mbi.ucla.edu/poa/
AliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/

</Text>
  </row>
  <row>
    <Id>349</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>177</PostId>
    <RevisionGUID>14e0523f-f8f4-4d47-8c5f-7d8259742bb8</RevisionGUID>
    <CreationDate>2010-03-05T12:56:39.267</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>I have no experience with them, but there are several Linux distributions out there that come preloaded with bioinformatics software.

For example:

 - **[biobuntu][1]** which comes preloaded with amapalign, biococoa, biomode, bioperl, biopython, biosquid, blast2, boxshade, chemtool, clustalw, clustalx, dialign, easychem, fastdnaml, fastlink, garlic, gchempaint, gcubin, gff2aplot, gff2ps, EMBOSS, gmt, gromacs, hmmer, ifeffit, ifrit, imview, kalign, leksbot, libbioruby, meltinggui, mipe, molphy, mozillabiofox, mpqc/support, mummer, muscle, mustang, ncbiepcr, ncbitoolsbin, ncbitoolsx11, njplot, openbabel, perlprimer, phylip, poa, polyxmass, primer3, probcons, proda, pybliographerA, rasmol, readseq, seaview, sibsim4, sigmaalignSimple, sim4, SixpackDisplay, tcoffeeMultiple, tigrglimmerGene, treepuzzleReconstruction, treetool, treeviewxDisplays, viewmol, wise, xbs, xdrawchem and xmakemol

 - **[Bio-Linux][2]**  a fully featured, powerful, configurable and easy to maintain bioinformatics workstation. Bio-Linux provides more than 500 bioinformatics programs on an Ubuntu Linux base. There is a graphical menu for bioinformatics programs, as well as easy access to the Bio-Linux bioinformatics documentation system and sample data useful for testing programs. You can also install Bio-Linux packages to handle new generation sequence data types.

 - The vision for **[Cloud BioLinux][3]** is to offer a base image of genome analysis resources for cloud computing platforms, such as Amazon EC2.  This Science as a Service model (ScaaS) will allow us to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.

 - **[BioBrew][4]** is a collection of open-source applications for life scientists and an in-house project at Bioinformatics.Org. The BioBrew Roll for Rocks can be used to create Rocks/BioBrew Linux, a distribution customized for both cluster and bioinformatics computing: it automates cluster installation, includes all the HPC software a cluster enthusiast needs, and contains popular bioinformatics applications.

 - **[Debian Med][5]** is a "Debian Pure Blend" with the aim to develop Debian into an operating system that is particularly well fit for the requirements for medical practice and research. The goal of Debian Med is a complete system for all tasks in medical care which is built completely on free software.


  [1]: http://bicmku.in:8082/bioubuntu/
  [2]: http://nebc.nox.ac.uk/tools/bio-linux/bio-linux-5.0
  [3]: http://www.cloudbiolinux.com/
  [4]: http://biobrew.bioinformatics.org/
  [5]: http://www.debian.org/devel/debian-med/</Text>
  </row>
  <row>
    <Id>350</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>178</PostId>
    <RevisionGUID>188e8e87-503e-4817-b288-3654b7ff56d2</RevisionGUID>
    <CreationDate>2010-03-05T13:06:24.317</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I am studying a set of genes involved in the same pathway, but this week, after looking at the new release of ensembl, I discovered that the gene was removed. What should I do now? There are references to this gene in several articles and the fact that it disappeared intrigues me - to which sequence these articles were referring to? Is it possible that the ensembl's curators have made an error?

cheers</Text>
  </row>
  <row>
    <Id>351</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>178</PostId>
    <RevisionGUID>188e8e87-503e-4817-b288-3654b7ff56d2</RevisionGUID>
    <CreationDate>2010-03-05T13:06:24.317</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I was studying a gene but it disappeared in the latest ensembl release. What should I do now?</Text>
  </row>
  <row>
    <Id>352</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>178</PostId>
    <RevisionGUID>188e8e87-503e-4817-b288-3654b7ff56d2</RevisionGUID>
    <CreationDate>2010-03-05T13:06:24.317</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> éensemblà  éannotationà  égenesà </Text>
  </row>
  <row>
    <Id>353</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>179</PostId>
    <RevisionGUID>9c947220-c575-4276-87ab-81e6ec920e23</RevisionGUID>
    <CreationDate>2010-03-05T13:15:48.763</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>The best course of action would be to contact the people (curators) who made the decision of removing that gene. Keep us posted on what they say, it might be an interesting tidbit about data evolution inside databases ;-0</Text>
  </row>
  <row>
    <Id>354</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>180</PostId>
    <RevisionGUID>89136780-37a6-4302-befa-80d8c010ef49</RevisionGUID>
    <CreationDate>2010-03-05T13:21:15.877</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>1. keep on using Ensembl Archive: http://www.ensembl.org/info/website/archives/index.html
2. there is no general answer to question "is gene X real one or it is an artifact removed from Ensembl". 
3. you may check i.e. ESTs if they assemble into sensible transcript /compare few species on the genomic level watching for pseudogenes. 

</Text>
  </row>
  <row>
    <Id>355</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>181</PostId>
    <RevisionGUID>0f70e286-aed2-410e-bf3b-dae0d3d8d1c5</RevisionGUID>
    <CreationDate>2010-03-05T13:30:44.04</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I am looking for personal experiences and short opinions regarding bioinformatics books. 

So far I have noticed the following trend: most books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.

**Help us find some good books!**

*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: "Provide a book review for X" then answer it with your own review.*</Text>
  </row>
  <row>
    <Id>356</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>181</PostId>
    <RevisionGUID>0f70e286-aed2-410e-bf3b-dae0d3d8d1c5</RevisionGUID>
    <CreationDate>2010-03-05T13:30:44.04</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Recommend your favorite bioinformatics books</Text>
  </row>
  <row>
    <Id>357</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>181</PostId>
    <RevisionGUID>0f70e286-aed2-410e-bf3b-dae0d3d8d1c5</RevisionGUID>
    <CreationDate>2010-03-05T13:30:44.04</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text> ébioinformaticsà  ébooksà  éresourcesà </Text>
  </row>
  <row>
    <Id>358</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>182</PostId>
    <RevisionGUID>49fcd407-51fb-451a-af85-721325739b9a</RevisionGUID>
    <CreationDate>2010-03-05T13:39:58.637</CreationDate>
    <IPAddress>128.240.229.3</IPAddress>
    <UserId>59</UserId>
    <Text>Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:

Bioinformatics and Computational Biology Solutions Using R and Bioconductor ([http://www.bioconductor.org/docs/mogr/][1]) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.

Bioconductor Case Studies ([http://www.bioconductor.org/pub/biocases/][2]) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.

Neither of these books will teach you R however.  My general R reference is:

R Programming for Bioinformatics [(http://www.bioconductor.org/pub/RBioinf/][3]) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R

If youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R ([http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20][4]) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.


  [1]: http://www.bioconductor.org/docs/mogr/
  [2]: http://www.bioconductor.org/pub/biocases/
  [3]: (http://www.bioconductor.org/pub/RBioinf/
  [4]: http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20</Text>
  </row>
  <row>
    <Id>359</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>181</PostId>
    <RevisionGUID>aef07676-a772-4b9f-baf1-08295fa6ddfb</RevisionGUID>
    <CreationDate>2010-03-05T13:43:56.67</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>edited body</Comment>
    <Text>I am looking for personal experiences and short opinions regarding bioinformatics books. 

So far I have noticed the following trend: many books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.

**Help us find some good books!**

*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: "Provide a book review for X" then answer it with your own review.*</Text>
  </row>
  <row>
    <Id>360</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>182</PostId>
    <RevisionGUID>a608a124-656a-4c9d-80b0-5424cfbe53e9</RevisionGUID>
    <CreationDate>2010-03-05T13:46:56.073</CreationDate>
    <IPAddress>128.240.229.3</IPAddress>
    <UserId>59</UserId>
    <Comment>added 94 characters in body</Comment>
    <Text>Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:

Bioinformatics and Computational Biology Solutions Using R and Bioconductor ([http://www.bioconductor.org/docs/mogr/][1]) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.

Bioconductor Case Studies ([http://www.bioconductor.org/pub/biocases/][2]) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.   It also benefits from being a more recent release than it's counterpart above.

Neither of these books will teach you R however.  My general R programming reference is:

R Programming for Bioinformatics [(http://www.bioconductor.org/pub/RBioinf/][3]) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R.

If youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R ([http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20][4]) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.


  [1]: http://www.bioconductor.org/docs/mogr/
  [2]: http://www.bioconductor.org/pub/biocases/
  [3]: (http://www.bioconductor.org/pub/RBioinf/
  [4]: http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20</Text>
  </row>
  <row>
    <Id>361</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>94fb5f5b-f762-4ca6-beb8-e21a9189bcde</RevisionGUID>
    <CreationDate>2010-03-05T14:37:21.73</CreationDate>
    <IPAddress>131.174.146.73</IPAddress>
    <UserId>79</UserId>
    <Text>For reference, please read this excerpt from  
**Human non-synonymous SNPs: server and survey**  
Vasily Ramensky, Peer Bork, and Shamil Sunyaev


&gt; *Profile analysis of homologous
&gt; sequences*. The amino acid replacement
&gt; may be incompatible with the spectrum
&gt; of substitutions observed at that
&gt; position in a family of homologous
&gt; proteins. PolyPhen identifies
&gt; homologues of the input sequences via
&gt; a BLAST (23) search of the NRDB
&gt; database. The set of aligned sequences
&gt; with sequence identity to the input
&gt; sequence in the range 30±94%
&gt; (inclusive) is used by the new version
&gt; of the PSIC (position-specific
&gt; independent counts) software (24) to
&gt; calculate the so-called profile matrix
&gt; (http://strand.imb.ac.ru/PSIC/).
&gt; Elements of the matrix (pro- file
&gt; scores) are logarithmic ratios of the
&gt; likelihood of a given amino acid
&gt; occurring at a particular site to the
&gt; likelihood of this amino acid
&gt; occurring at any site (background
&gt; frequency). PolyPhen computes the
&gt; absolute value of the difference
&gt; between profile scores of both allelic
&gt; variants in the polymorphic position.
&gt; PolyPhen also shows the number of
&gt; aligned sequences at the query
&gt; position; this may be used to assess
&gt; the reliability of profile score
&gt; calculations.

I'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here programmatically, but I can't find any implementation of the above described system.

Does anyone know of a working implementation of this or something similar, that's available either in code or as a web service?

Or should it is easy enough to implement something like this ourselves?</Text>
  </row>
  <row>
    <Id>362</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>94fb5f5b-f762-4ca6-beb8-e21a9189bcde</RevisionGUID>
    <CreationDate>2010-03-05T14:37:21.73</CreationDate>
    <IPAddress>131.174.146.73</IPAddress>
    <UserId>79</UserId>
    <Text>Score protein variants based on frequency of AA in multiple sequence alignment</Text>
  </row>
  <row>
    <Id>363</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>94fb5f5b-f762-4ca6-beb8-e21a9189bcde</RevisionGUID>
    <CreationDate>2010-03-05T14:37:21.73</CreationDate>
    <IPAddress>131.174.146.73</IPAddress>
    <UserId>79</UserId>
    <Text> éproteinà  ésequenceà  émultiplealignmentà  éscoringmatixà </Text>
  </row>
  <row>
    <Id>364</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>184</PostId>
    <RevisionGUID>8af6f74e-2f85-41d5-b963-73f29df7f269</RevisionGUID>
    <CreationDate>2010-03-05T15:06:55.833</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>I'll tell an acedote about the book that introduced me to bioinformatics. 

Let me preface that I have three big interests in my life: biology, computer science and sailing. The year was around 2000, and I had found the book [The New New Thing : A Silicon Valley Story][1] by [Michael M. Lewis][2]. It was about two of my interests: computer science and sailing.

It is the biography of [Jim Clark][3], a technology entrepreneur who is about to create his third, separate, billion-dollar company: first Silicon Graphics, then Netscape--and now Healtheon, a startup which he hopes will turn the $1 trillion healthcare industry on its head. But after coming up with the basic idea for Healtheon, securing the initial seed money, and hiring the people to make it happen, Clark concentrated on the building of [Hyperion][4], a sailboat with a 197-foot mast (at the time of her launch, she was the largest sloop ever build and the tallest mast ever built), whose functions are controlled by 25 SGI workstations. As the title implies, Jim Clark is a restless man who was always looking for the *new new thing*, the next big breaktrough. Near the end of the book Michael Lewis tells about one of the new things of Jim Clarks radar, a new emerging field called bioinformatics. 

I remember sitting there in my chair, staring at that sentence and thinking "What! I can combine both biology and computer science!" From that moment on I was hooked.

*(The book with the ultimate triumvirate, where the three of my interest -biology, computer science and sailing- were combined, came later with the autobiography of  Craig Venter, [A life decoded][5], where he writes about the [Global Ocean Sampling Expedition][6] he undertook with his personal 95-foot sailboat named the Sorcerer II. The expedition sampled water from Halifax, Nova Scotia to the Eastern Tropical Pacific while undertaking a two year circumnavigation. The micro-organisms in the water were sequenced and the results were [published][7], more then doubling the amount of genetic sequences available up to that point.)*


  [1]: http://www.nytimes.com/books/99/10/31/reviews/991031.31anderst.html?_r=1
  [2]: http://en.wikipedia.org/wiki/Michael_Lewis_(author)
  [3]: http://en.wikipedia.org/wiki/James_H._Clark
  [4]: http://www.charterworld.com/?sub=yacht-charter&amp;charter=sailing-yacht-hyperion-1095
  [5]: http://www.nytimes.com/2007/11/11/books/review/Dizikes-t.html
  [6]: http://www.jcvi.org/cms/research/projects/gos/overview/
  [7]: http://www.ploscollections.org/article/browseIssue.action?issue=info:doi/10.1371/issue.pcol.v06.i02</Text>
  </row>
  <row>
    <Id>365</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>185</PostId>
    <RevisionGUID>d2dc8f44-ba15-4097-a086-678a04b9600e</RevisionGUID>
    <CreationDate>2010-03-05T15:18:17.853</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>**Bioinformatics Programming Using Python**

Practical Programming for Biological Data

By [Mitchell L Model][1]

![alt text][2]


Publisher:[O'Reilly Media][3]

Released: December 2009 

Pages: 528

*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*


  [1]: http://www.oreillynet.com/pub/au/3752
  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif
  [3]: http://oreilly.com/catalog/9780596154516
  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books
  [5]: http://biostar.stackexchange.com/users/2/istvan-albert</Text>
  </row>
  <row>
    <Id>366</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>185</PostId>
    <RevisionGUID>d2dc8f44-ba15-4097-a086-678a04b9600e</RevisionGUID>
    <CreationDate>2010-03-05T15:18:17.853</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>Provide a book review for "Bioinformatics Programming Using Python" by Mitchell L. Model</Text>
  </row>
  <row>
    <Id>367</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>185</PostId>
    <RevisionGUID>d2dc8f44-ba15-4097-a086-678a04b9600e</RevisionGUID>
    <CreationDate>2010-03-05T15:18:17.853</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text> ébooksà  ébooköreviewà  érecommendationsà </Text>
  </row>
  <row>
    <Id>368</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>186</PostId>
    <RevisionGUID>1ecb4dd9-2cee-4874-b301-645f6b47b9e7</RevisionGUID>
    <CreationDate>2010-03-05T15:51:48.387</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>I blastx-ed 1Mbp bacterial genome fragment against NCBI nr database. I have split it into 2000bp fragments with 500bp overlap into a one multiple fasta file (splitter from EMBOSS) 

    splitter -sequence my_contig.fa  -size 2000 -overlap 500 

As on output I picked tabulated blast (-m 9). 

Next step was to convert blastx output into gff3. Got that one, with absolute positions (positions in intact contig). 

Seems that often one ORF / predicted gene is covered by 2-3 blast hits to the same protein. Hits may or may not overlap. Hence my questions:

1. what are the fragment sizes / overlaps typically used for blastx in such situation?
2. are there any advantages of improving blast hits, by say merging overlapping segments (e-scores will be invalid), or by using blast2 (blastx mode) and comparing DNA sequence from region of overlapping/almost-touching hits against already detected protein? 

</Text>
  </row>
  <row>
    <Id>369</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>186</PostId>
    <RevisionGUID>1ecb4dd9-2cee-4874-b301-645f6b47b9e7</RevisionGUID>
    <CreationDate>2010-03-05T15:51:48.387</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>merging blastx hits from overlapping bacterial genome segments</Text>
  </row>
  <row>
    <Id>370</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>186</PostId>
    <RevisionGUID>1ecb4dd9-2cee-4874-b301-645f6b47b9e7</RevisionGUID>
    <CreationDate>2010-03-05T15:51:48.387</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text> éblastà  égffà  éannotationà  égenomeà  ébacteriaà </Text>
  </row>
  <row>
    <Id>371</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>187</PostId>
    <RevisionGUID>9818bf78-d455-41f2-8e72-5aab9e6180ff</RevisionGUID>
    <CreationDate>2010-03-05T15:59:48.74</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>Dear all,

I would like to get the position in cM for a set of SNPs (SNPs from 1000Genomes Project).
What I have is:
- list of SNPs with their physical position
- Genotype (or infered genotype) for each SNP for around 50 individuals

Some of these snps (around 25%) are among the HapMap II SNPs used to compute the genetic map available on HapMap webpage (http://ftp.hapmap.org/recombination/2008-03_rel22_B36/rates).
But it is way too little information to think about calculing the cM position for 1000genomes SNPs from HapMap II genetic map, isn't it?

What do you suggest?

Thanks for your help.

Yours truly
Pierre
 
</Text>
  </row>
  <row>
    <Id>372</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>187</PostId>
    <RevisionGUID>9818bf78-d455-41f2-8e72-5aab9e6180ff</RevisionGUID>
    <CreationDate>2010-03-05T15:59:48.74</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>Compute genetic map</Text>
  </row>
  <row>
    <Id>373</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>187</PostId>
    <RevisionGUID>9818bf78-d455-41f2-8e72-5aab9e6180ff</RevisionGUID>
    <CreationDate>2010-03-05T15:59:48.74</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text> égeneticà  émapà  écmà </Text>
  </row>
  <row>
    <Id>374</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>188</PostId>
    <RevisionGUID>8d6ca3ce-9a61-4796-a9b3-400bf3efb941</RevisionGUID>
    <CreationDate>2010-03-05T16:06:14.427</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Isn't the size of the protein that causes multiple hits? No matter what fragment size or overlap you choose, if two or more fragments cover different sections of the same protein, you'll get mulitple hits.

If your fragment sizes are too large you'll miss regions, if they are too small you'll get multiple hits. This latter problem does not seem to preclude any downstream analysis, so it may not be worth trying to optimize it away.</Text>
  </row>
  <row>
    <Id>375</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>181</PostId>
    <RevisionGUID>d8065fcd-41cf-4999-801c-d7abbde38ac5</RevisionGUID>
    <CreationDate>2010-03-05T16:13:38.963</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>deleted 10 characters in body</Comment>
    <Text>I am looking for personal experiences and short opinions regarding bioinformatics books. 

So far I have noticed the following trend: many books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.

**Help us find some good books!**

*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: "Book review for X" then answer it with your own review.*</Text>
  </row>
  <row>
    <Id>376</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>189</PostId>
    <RevisionGUID>b46d3db6-89cf-49f5-81fc-2f7957273c50</RevisionGUID>
    <CreationDate>2010-03-05T16:53:24.947</CreationDate>
    <IPAddress>132.183.93.134</IPAddress>
    <UserId>82</UserId>
    <Text>We've been buying our servers from HP via pcconnection.com (don't be fooled by the name), with good success.  All of our desktops have been coming from Penguin Computing.</Text>
  </row>
  <row>
    <Id>377</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>190</PostId>
    <RevisionGUID>31c0f59f-84da-46af-83d5-bd6cd734c6a8</RevisionGUID>
    <CreationDate>2010-03-05T16:57:17.67</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>The book assumes no prior programming experience, uses real-world examples with biological data, and uses Python 3 (the programming language's first non-backwards-compatible release).

The first chapters are about primitive datatypes. At the end of each chapter there is a Tips, Traps and Trackbacks section where you can learn things that make your programming life easier, things that you have to watch out for and the meaning of some representative error messages that you might encounter.

The next chapter covers control statements and has several extended examples that are useful in the day-to-day work of a bioinformatician, like parsing Genbank files, translating RNA sequences, or constructing a table from a text file. Especially handy are the several templates that explain the general control flow . Suppose for example that you have a text file and that you need to collect all the lines that that meet both a preliminary test and a primary test. Then you just look up the template for **filtered collect of roup of lines** in the book:

    lines = []
    with open(inputfilename) as file:
        for line in file:
            if preliminary-test:
                flag = preliminary-test(file)
                lines.append(line)
    return lines

Subsequent chapters explore object-oriented programming using Classes, pattern matching using regular expressions, fetching pages from the web and displaying webpages, processing HTML and XML and working with relational databases. 

The last chapter introduces displaying data using graphical toolkits and as Scalable Vector Graphics. I have been enthusiastic about the last possibility ever since I read the great article [How to Make a US County Thematic Map Using Free Tools][5] on [FlowingData][6]. It hadn't occurred to me to use this technique in the context of bioinformatics. 

I do miss a section on the use of matplotlib or other graphical packages that are often used. Another glaring omission is any reference to BioPython. The auther [states in a mailing list message][2] that this is because there is no Python 3 version of BioPython. 

This book comes a decade after "[Beginning Perl for Bioinformatics][3]". Now that we have a good introductory level bioinformatics books in Python, I hope to see (Bio)Python gain strength in the bioinformatics community (a more in-depth description about the tension between Perl and Python can be read in the blog post [Not the Biopythonista I thought I'd be][4])


  


  [1]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/
  [2]: http://www.mail-archive.com/python-list@python.org/msg273660.html
  [3]: http://oreilly.com/catalog/9780596000806
  [4]: http://igotgenes.blogspot.com/2008/08/not-biopythonista-i-thought-id-be.html
  [5]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/
  [6]: http://flowingdata.com/</Text>
  </row>
  <row>
    <Id>378</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>135</PostId>
    <RevisionGUID>5c0a355b-f0a2-4c0c-92de-a552a8a025ae</RevisionGUID>
    <CreationDate>2010-03-05T17:45:27.37</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Comment>turned references into hyperlinks</Comment>
    <Text>Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated [using R][1]. However, it remains to be seen a rigorous comparison of its performance using a [BLAST search][2] and its ability to cope with ever-increasing databases and open source frameworks such as [bioperl][3] or [bioconductor][4].

Cloud computing claims to be [a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer][5], in a fashion seemingly [similar to having your own virtual servers available over the Internet][6]. Some of the most important aspects of cloud computing are:

* Software as a Service (SaaS): where you buy a software license for a determined period of time.
* Utility Computing: storage and virtual servers that IT can access on demand.
* Web Services.

My first exposure to cloud computing came of an email from [Matt Wood][7], a newly established group leader at the [Sanger Institute][8], announcing the [Cloud Computing Group][9] in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University’s [Centre for Mathematical Sciences][10], to my surprise I found there a very select audience, ranging from the director of IT at Sanger, [Phil Butcher][11], one of the [Ensembl][12] software coordinators, [Glenn Proctor][13], and quite a few local start-up companies.

Among the presenters, we had Simone Brunozzi, from [Amazon’s Cloud Computing][14]. I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon’s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don’t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don’t need them. One of the things that stroke me about Amazon’s presentation was that they would not tell us the number of processors they had at their disposal.

When it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon’s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: 

 - allowing people to develop and contribute to the technology if and when they want to, 
 - allowing total openness in terms of its achievements and pitfalls and 
 - making it free to use for everyone. 

I do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as [java][15] or [MySQL][16], both components of [SUN Microsystems][17]’ business.

Despite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.


  [1]: http://www.r-project.org/
  [2]: http://blast.ncbi.nlm.nih.gov/Blast.cgi
  [3]: http://www.bioperl.org/wiki/Main_Page
  [4]: http://www.bioconductor.org/
  [5]: http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman
  [6]: http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html
  [7]: http://www.sanger.ac.uk/Users/mw4/
  [8]: http://www.sanger.ac.uk/
  [9]: http://cloudcamb.org/
  [10]: http://www.cms.cam.ac.uk/site/
  [11]: http://www.yourgenome.org/people/phil_butcher.shtml
  [12]: http://www.ensembl.org/index.html
  [13]: http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299
  [14]: http://aws.amazon.com/ec2/
  [15]: http://www.java.com/en/
  [16]: http://www.mysql.com/
  [17]: http://www.sun.com/ </Text>
  </row>
  <row>
    <Id>379</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>191</PostId>
    <RevisionGUID>211019f4-32b2-45e3-b250-06679fc83734</RevisionGUID>
    <CreationDate>2010-03-05T18:47:14.08</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I have partially read through this book. It is more software engineering oriented than bioinformatics. I have noticed many typos in the examples.

I think that covering the new Python (3.0) language was a premature undertaking that hurts the value of this book. One must realize that Python 3 is less usable for a bioinformatician as currently few if any of the scientific libraries have been ported to it. Sadly that is not a shortcoming that we can hope to see resolved any time soon.

It will probably be a decade (if ever!) that we can leave the Python 2 versions behind. </Text>
  </row>
  <row>
    <Id>380</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>192</PostId>
    <RevisionGUID>d6f9555e-dac1-4243-acc6-6becc807399d</RevisionGUID>
    <CreationDate>2010-03-05T19:24:00.483</CreationDate>
    <IPAddress>52.129.8.48</IPAddress>
    <UserId>73</UserId>
    <Text>I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.

I am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.

My reviews:
Statistical Bioinformatics: with R
http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm

A Primer of Genome Science, Third Edition
http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm

R Programming for Bioinformatics
http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm</Text>
  </row>
  <row>
    <Id>381</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>192</PostId>
    <RevisionGUID>48cc785d-cc2b-47ec-9b88-2ed84cbd334f</RevisionGUID>
    <CreationDate>2010-03-05T19:29:42.88</CreationDate>
    <IPAddress>52.129.8.48</IPAddress>
    <UserId>73</UserId>
    <Comment>added 91 characters in body</Comment>
    <Text>I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are "mildly bio-flavored" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.

I am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.

My reviews:
Statistical Bioinformatics: with R
http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm

A Primer of Genome Science, Third Edition
http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm

R Programming for Bioinformatics
http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm</Text>
  </row>
  <row>
    <Id>382</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>192</PostId>
    <RevisionGUID>655e5221-b0a4-42db-90bb-6ad0f1888f15</RevisionGUID>
    <CreationDate>2010-03-05T19:59:39.393</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>fixed up the links</Comment>
    <Text>I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are "mildly bio-flavored" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.

I am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.

My reviews:

 - [Statistical Bioinformatics: with R][1]
 - [A Primer of Genome Science, Third Edition][2], 
 - [R Programming for Bioinformatics][3]

  [1]: http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm
  [2]: http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm
  [3]: http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm</Text>
  </row>
  <row>
    <Id>383</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>193</PostId>
    <RevisionGUID>5386daea-ae1e-4ff4-9a66-dd77c3a1fa8b</RevisionGUID>
    <CreationDate>2010-03-05T21:58:06.423</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>In my Master's in Bioinformatics I used [RedHat][1] 7-8 and  first edition of [Fedora][2], then for the first two years of my PhD I continued with Fedora, then moved to [Ubuntu][3] and For servers to host I used RHEL earlier and now CentOS and Ubuntu server edition. I strongly vote for Ubuntu distro for it's ease of use and strong community presence. 

  [1]: http://en.wikipedia.org/wiki/Red_Hat_Linux
  [2]: http://en.wikipedia.org/wiki/Fedora_%28operating_system%29
  [3]: http://en.wikipedia.org/wiki/Ubuntu_%28operating_system%29</Text>
  </row>
  <row>
    <Id>384</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>194</PostId>
    <RevisionGUID>16d78ec9-a827-409f-85e8-5340ca3f8f7a</RevisionGUID>
    <CreationDate>2010-03-05T22:02:46.18</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>There are actually two questions in 

&gt; related pathways/ diseases ?

The first first part can be solved by database queries such as biomart and KEGG, but the second part is about complex studies. Actually, IMHO, a large part of the already known SNPs 
are not connected to disease, they might not even have a phenotype (I would bet &gt;99%) . As far as I understand, the known SNPs are sampled from "healthy" individuals and represent a large mix. So it seems likely to assume that they are not easily connected to diseases.

In short, the answer might be exome sequencing of affected individuals. I found this recent article which I think is really great to answer this question: 

Ng SB, et al.,
[Exome sequencing identifies the cause of a mendelian disorder.][1]
Nat Genet. 2010 Jan;42(1):30-5. Epub 2009 Nov 13.

In short they discovered point mutations common in few affected individuals and subtracted synonymously coding SNPs and already known SNPs until they retained only one gene. 


  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19915526</Text>
  </row>
  <row>
    <Id>385</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>195</PostId>
    <RevisionGUID>0e967d4d-bf83-4b27-9174-0e655eade2e0</RevisionGUID>
    <CreationDate>2010-03-05T22:19:27.193</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): 

1. [Genes, Proteins and Computers][1] : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. 
2. [Bioinformatics by David Mount][2] : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. 
3. [Bioinformatics : Unix/Linux, Data Processing and Programming][3] : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. 
4. [Bioinformatics : Machine learning approaches][4] Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For hard-core computer science, here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. 
5. [An Introduction to Bioinformatics Algorithms][5] This one is my favorite, especially the pseudocode. Book features extensive content on the algorithms used in bioinforamtics categorized into different group. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. 

PS. I have couple of more like [Computational Genome Analysis][6], [Programming Collective Intelligence][7] etc. But they are more of specialized in to different sub-domains of bioinformatics. 


  [1]: http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545
  [2]: http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087
  [3]: http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6
  [4]: http://books.google.com/books?id=pxSM7R1sdeQC&amp;dq=Pierre+baldi+%2B+bioinformatics&amp;printsec=frontcover&amp;source=bn&amp;hl=en&amp;ei=IoGRS6uCIJT-NYLA8Z0N&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4&amp;ved=0CBUQ6AEwAw#v=onepage&amp;q=&amp;f=false
  [5]: http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&amp;ttype=2
  [6]: http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851
  [7]: http://oreilly.com/catalog/9780596529321</Text>
  </row>
  <row>
    <Id>386</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>196</PostId>
    <RevisionGUID>80c52e77-3875-436c-bf8e-4b5af0c4f54a</RevisionGUID>
    <CreationDate>2010-03-05T22:29:25.643</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>This depends on the program you use, I have calculated surface accessibility using [PSA from JOY package][1]. Another programs which I have seen frequently in literature is [NACCESS][2]. 

  [1]: http://bioinformatics.oxfordjournals.org/cgi/content/short/14/7/617
  [2]: http://www.bioinf.manchester.ac.uk/naccess/</Text>
  </row>
  <row>
    <Id>387</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>46</PostId>
    <RevisionGUID>987d8c8b-680a-4538-9da9-447168786bc9</RevisionGUID>
    <CreationDate>2010-03-05T22:31:43.937</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>edited tags</Comment>
    <Text> ésubjectiveà  éstringà  éproteinöproteinöinteractià  éppià  épinà </Text>
  </row>
  <row>
    <Id>388</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>197</PostId>
    <RevisionGUID>3d7634b8-b69a-4cdc-a0e3-6a6be48b0df9</RevisionGUID>
    <CreationDate>2010-03-05T23:13:37.443</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function
`oligonucleotide.frequency` in the `Biostrings` package. The code for the first step would look somewhat like this: 

&gt; library(Biostrings)

&gt; reads = read.DNAStringSet("yourReads.fas", format="fasta")

&gt; nf = oligonucleotideFrequency(reads[1:100], width=4)

&gt; hclust(dist(nf)) # do hierarchical clustering of your tetra freq.

That would be a very simple form of clustering. Then you have all the powerful  
classification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.

But if you look at your frequencies it might look like this:

           TACG TACT TAGA TAGC TAGG TAGT TATA TATC TATG TATT TCAA TCAC TCAG TCAT TCCA TCCC TCCG TCCT
      [1,]    0    0    0    0    0    0    0    0    1    0    0    1    2    0    0    4    0    0
      [2,]    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0
      [3,]    0    0    0    1    1    1    0    0    0    1    0    0    0    0    0    1    0    0
      [4,]    0    0    1    1    0    1    0    2    0    0    1    0    2    1    0    0    1    1
      [5,]    0    1    0    

So, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.

Alternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.</Text>
  </row>
  <row>
    <Id>389</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>198</PostId>
    <RevisionGUID>970262e9-3f1e-4de0-80f2-5c04de14c9eb</RevisionGUID>
    <CreationDate>2010-03-05T23:31:04.13</CreationDate>
    <IPAddress>207.229.236.211</IPAddress>
    <UserId>87</UserId>
    <Text>If it is only one sequence you may try [PSIPRED][1] server. If you need to work on a large sequence dataset, better to install PSIPRED locally. [PSIPRED][2] runs are typically computational intensive. 


  [1]: http://bioinf4.cs.ucl.ac.uk:3000/psipred/
  [2]: http://www.ncbi.nlm.nih.gov/pubmed/10869041</Text>
  </row>
  <row>
    <Id>390</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>199</PostId>
    <RevisionGUID>9509e6c0-1913-4c36-8848-b1d56e117df8</RevisionGUID>
    <CreationDate>2010-03-05T23:38:05.3</CreationDate>
    <IPAddress>156.145.28.96</IPAddress>
    <UserId>47</UserId>
    <Text>I'm not sure if I understand you correctly. If you are looking for a webservice that returns the PSIC scoring matrix, why don't you just follow the URL mentioned in the paper's abstract, i.e. http://strand.imb.ac.ru/PSIC/ which leads you to a html form where you can paste your mutliple alignment and returns the PSIC matrix.
Or did I misunderstand you?

</Text>
  </row>
  <row>
    <Id>391</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>200</PostId>
    <RevisionGUID>8c7952fe-7cd5-465e-bd3f-0a4cc507517f</RevisionGUID>
    <CreationDate>2010-03-05T23:44:55.36</CreationDate>
    <IPAddress>156.145.28.96</IPAddress>
    <UserId>47</UserId>
    <Text>You might also consider to blast against Swissprot and transfer residue annotations.</Text>
  </row>
  <row>
    <Id>392</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>201</PostId>
    <RevisionGUID>37ccf688-dd2f-45c0-a9dd-f15ef722e937</RevisionGUID>
    <CreationDate>2010-03-06T07:43:23.42</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Text>ENCODE soon provides DNase I hypersensitivity data for the whole genome in a multitude of different tissues. DNase I hypersensitivity marks genomic positions that are exposed and can hence be used to pinpoint active promoters or enhancers in the studied tissue. DNase I resistant regions, in contrast, mark genomic areas that are protected, e.g. because a transcription factor (TF) is bound. Since the data provides a base-pair resolution, it is possible to "zoom" in on the protected areas (== transcription factor binding sites) of the otherwise exposed regions (== enhancers). One can hence identify the shadow-prints on the genome left by the regulatory TFs in a given tissue. To identify which TFs are casting the shadows one could use ChIP-seq (rough binding regions) or Protein Binding Arrays (binding motif).

The question is: has the *in-silico* prediction of enhancers, binding sites or partners still merit or will we be soon able to look-up the binding events of TFs in the different tissues? </Text>
  </row>
  <row>
    <Id>393</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>201</PostId>
    <RevisionGUID>37ccf688-dd2f-45c0-a9dd-f15ef722e937</RevisionGUID>
    <CreationDate>2010-03-06T07:43:23.42</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Text>Has enhancer and transcription factor binding site prediction already been made redundant?</Text>
  </row>
  <row>
    <Id>394</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>201</PostId>
    <RevisionGUID>37ccf688-dd2f-45c0-a9dd-f15ef722e937</RevisionGUID>
    <CreationDate>2010-03-06T07:43:23.42</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Text> écisöregulatoryömoduleà  épredictionà  éhighöthroughputà  édnaseöhypersensitivityà  étranscriptionöfactorà </Text>
  </row>
  <row>
    <Id>395</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>202</PostId>
    <RevisionGUID>14f8d5f7-f19f-4cb0-86ae-eb23ee2c9213</RevisionGUID>
    <CreationDate>2010-03-06T09:11:59.797</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>As much as I agree with the impressive list from BioGeek, I have to say that it is a non-exhaustive, genomics centric list.

If we look at the first statement he mentions: "Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline."

From that statement I understand that anything "biological" studied using a "computer" should have its place in what we call "Bioinformatics".

One perfect example would be all those people working on proteins and not DNA/RNA. I wouldn't say that those are the same field in Bioinformatics, however you may argue that they fit together... As an example of a "Bioinformatics Center" that focuses on proteins I would give: [Stockholm Bioinformatics Center][1]

Another example would be those people trying to understand how molecules diffuse within the cell cytoplasm. That is a lot of computer work that's directly looking at understanding a phenomenon in a biological context. This type of project is bordering on many disciplines and not just biology and informatics, but also physics. Nevertheless, shouldn't that be a "bioinformatics" discipline too? In this category I would give the [Biomatter @ MOSAIC ETH Zurich][2]

What about Systems Biology (even if they don't want to be called bioinformaticians), shouldn't they be called bioinformaticians too?

And finally (although far from exhaustive) I'll give one last example of something I consider bioinformatics: the [E-Cell Project][3] 

I hope this answers your question! In my opinion, bioinformatics is NOT only "genome stuff" and I would extend it to yourself too ;)


  [1]: http://www.sbc.su.se/research/
  [2]: http://www.biomatter.ethz.ch/Biomatter/Welcome.html
  [3]: http://www.e-cell.org/ecell/</Text>
  </row>
  <row>
    <Id>396</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>203</PostId>
    <RevisionGUID>c2dcc23f-f328-4b8f-bd90-41df6ede93b9</RevisionGUID>
    <CreationDate>2010-03-06T11:04:51.893</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>The J. Craig Venter Institute has released the [JCVI Cloud BioLinux image][1], which *"enables scientists to quickly provision computation infrastructures supporting bioinformatics using cloud computing platforms such as Amazon EC2 and Eucalyptus.   Upon deployment users will have instant access to a host of software including BLAST, glimmer, hmmer, phylip, rasmol, genespring, clustalw, the Celera Assembler, and the EMBOSS collection of utilities.  JCVI Cloud BioLinux is built on a 64-bit instance of Ubuntu virtual server customized with bioinformatics packages from the BioLinux repository, and will be updated periodically."*

They give as their motivation for releasing this image *"cloud computing can provide researchers with the ability to perform computations using a practically unlimited pool of virtual machines, without facing the burden of owning or maintaining any hardware infrastructure. (...) This Science as a Service model (ScaaS) will allow JCVI to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from."*


  [1]: http://www.jcvi.org/cms/research/projects/jcvi-cloud-biolinux/overview/</Text>
  </row>
  <row>
    <Id>397</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>204</PostId>
    <RevisionGUID>72f5343e-d8f7-4ce8-8e7d-16ffa4d6e1ad</RevisionGUID>
    <CreationDate>2010-03-06T12:48:41.6</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I wouldn't venture to hypothesize on what will happen; *making predictions is difficult, especially about the future*.

What seems prudent to assume however is that there may be several reasons of why genomic regions are accessible or protected. For example: is it a transcription factor that protects the region or is there some other reason of why the TF will bind to that location to begin with. For example chromatin structure and nucleosome positioning may favor or disfavor certain events.

Any *in-silico* modeling will need to take into account the various mechanisms that may take place.</Text>
  </row>
  <row>
    <Id>398</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>205</PostId>
    <RevisionGUID>f93d0d9b-eb49-4289-9382-95688ce8ef41</RevisionGUID>
    <CreationDate>2010-03-06T13:46:31.893</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>What options do I have for contacting the individuals responsible for the proper functioning of this site? 

How do I suggest improvements, recommend features or report a problem using this site?</Text>
  </row>
  <row>
    <Id>399</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>205</PostId>
    <RevisionGUID>f93d0d9b-eb49-4289-9382-95688ce8ef41</RevisionGUID>
    <CreationDate>2010-03-06T13:46:31.893</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>How do I contact the moderators or supervisors of this site?</Text>
  </row>
  <row>
    <Id>400</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>205</PostId>
    <RevisionGUID>f93d0d9b-eb49-4289-9382-95688ce8ef41</RevisionGUID>
    <CreationDate>2010-03-06T13:46:31.893</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text> égeneralà  écontactà </Text>
  </row>
  <row>
    <Id>401</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>206</PostId>
    <RevisionGUID>11999754-caaa-4c25-b8f2-bb64cd06067d</RevisionGUID>
    <CreationDate>2010-03-06T13:54:52.933</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>The **BioStar** site will be primarily moderated and regulated by the users who have high reputation. 

We have also created a Google group called [**Biostar-Central**][1] that is intended to be used for administrative purposes. Use this group to suggest improvements, provide feedback or report problems that otherwise would not be appropriate to ask on the main site.

Occasional **BioStar** related announcements will be made public via this group.

Thank you,

[Istvan Albert][2]

PS. First posts by new users to this group will be held for moderation. 



  


  [1]: http://groups.google.com/group/biostar-central/
  [2]: http://www.personal.psu.edu/iua1/</Text>
  </row>
  <row>
    <Id>402</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>207</PostId>
    <RevisionGUID>6ee9d3d3-7e3c-44cb-ba3c-849dd5d53013</RevisionGUID>
    <CreationDate>2010-03-06T14:58:53.947</CreationDate>
    <IPAddress>218.186.8.241</IPAddress>
    <UserId>91</UserId>
    <Text>I know of two quality filtering methods for SOLiD reads, besides the already suggested SAET:

- [A set of tools][1] from [a recent publication][2]


- The csfasta_quality_filter.pl script from ABI's [de novo accessory tools package][3]

Haven't actually tried any of them yet, but will do so pretty soon.

  [1]: http://hts.rutgers.edu/filter/
  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/short/26/6/849?rss=1
  [3]: http://solidsoftwaretools.com/gf/project/denovo/frs/</Text>
  </row>
  <row>
    <Id>403</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>208</PostId>
    <RevisionGUID>76c1e82d-f088-4c66-ad03-c75e0281dab5</RevisionGUID>
    <CreationDate>2010-03-06T15:18:14.36</CreationDate>
    <IPAddress>218.186.8.241</IPAddress>
    <UserId>91</UserId>
    <Text>First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the "pileup" of reads in certain regions and so on.  </Text>
  </row>
  <row>
    <Id>404</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>208</PostId>
    <RevisionGUID>499f9847-9a93-48d5-ac4a-6b1bdd1d7025</RevisionGUID>
    <CreationDate>2010-03-06T15:33:55.047</CreationDate>
    <IPAddress>218.186.8.241</IPAddress>
    <UserId>91</UserId>
    <Comment>added 81 characters in body</Comment>
    <Text>First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the "pileup" of reads in certain regions and so on.  

Edit: I just noticed that Galaxy now features Bowtie mapping for color space.</Text>
  </row>
  <row>
    <Id>405</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>209</PostId>
    <RevisionGUID>e559b21f-f622-4fdb-bbf1-ec522566356a</RevisionGUID>
    <CreationDate>2010-03-06T15:42:42.267</CreationDate>
    <IPAddress>82.126.3.90</IPAddress>
    <UserId>30</UserId>
    <Text>I hope I understand your question: The UCSC genome database contains the position in both **base index** and **cM** for the STS. e.g.:


    ~&gt; mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg18 -e 'select name,chrom,chromStart,chromEnd,genethonPos from stsMap where genethonPos!=0 limit 2\G'
    *************************** 1. row ***************************
           name: AFM280WE5
          chrom: chr1
     chromStart: 3574721
       chromEnd: 3575045
    genethonPos: 6.2
    *************************** 2. row ***************************
           name: AFM344WE9
          chrom: chr1
     chromStart: 4358261
       chromEnd: 4358654
    genethonPos: 11.1

So you can use this STS map as a 'reference' to map your collection of SNP from **bp** to **cM**.

</Text>
  </row>
  <row>
    <Id>406</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>197</PostId>
    <RevisionGUID>b98ec8a4-8c32-4c30-a28e-8184632e99a1</RevisionGUID>
    <CreationDate>2010-03-06T16:34:28.927</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>deleted 1 characters in body</Comment>
    <Text>I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function
`oligonucleotideFrequency` in the `Biostrings` package. The code for the first step would look somewhat like this: 

&gt; library(Biostrings)

&gt; reads = read.DNAStringSet("yourReads.fas", format="fasta")

&gt; nf = oligonucleotideFrequency(reads[1:100], width=4)

&gt; hclust(dist(nf)) # do hierarchical clustering of your tetra freq.

That would be a very simple form of clustering. Then you have all the powerful  
classification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.

But if you look at your frequencies it might look like this:

           TACG TACT TAGA TAGC TAGG TAGT TATA TATC TATG TATT TCAA TCAC TCAG TCAT TCCA TCCC TCCG TCCT
      [1,]    0    0    0    0    0    0    0    0    1    0    0    1    2    0    0    4    0    0
      [2,]    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0
      [3,]    0    0    0    1    1    1    0    0    0    1    0    0    0    0    0    1    0    0
      [4,]    0    0    1    1    0    1    0    2    0    0    1    0    2    1    0    0    1    1
      [5,]    0    1    0    

So, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.

Alternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.</Text>
  </row>
  <row>
    <Id>407</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>210</PostId>
    <RevisionGUID>7aa4894c-c942-4d8c-b59c-891c5b03c305</RevisionGUID>
    <CreationDate>2010-03-06T16:42:34.27</CreationDate>
    <IPAddress>68.81.91.29</IPAddress>
    <UserId>92</UserId>
    <Text>[BridgeDB][1] provides a nice API and REST interface, so you can put ID mapping queries in your scripts.


  [1]: http://www.biomedcentral.com/1471-2105/11/5</Text>
  </row>
  <row>
    <Id>408</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>211</PostId>
    <RevisionGUID>d4d4edd3-beba-4069-8841-6c164b69db03</RevisionGUID>
    <CreationDate>2010-03-06T17:26:09.313</CreationDate>
    <IPAddress>132.64.43.18</IPAddress>
    <UserId>94</UserId>
    <Text>If you do have the protein structure (PDB file) [link text][1] is also a good option for assigning the secondary structure.


  [1]: http://webclu.bio.wzw.tum.de/cgi-bin/stride/stridecgi.py "Stride"</Text>
  </row>
  <row>
    <Id>409</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>212</PostId>
    <RevisionGUID>51281a47-8266-470e-b4b6-33a1c87e80d9</RevisionGUID>
    <CreationDate>2010-03-06T17:36:39.637</CreationDate>
    <IPAddress>132.64.43.18</IPAddress>
    <UserId>94</UserId>
    <Text>[ASA-view][1] is a server that can help you visualize the burial of each amino acid in your protein


  [1]: http://www.netasa.org/asaview/ "ASA-view"</Text>
  </row>
  <row>
    <Id>410</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>213</PostId>
    <RevisionGUID>232c223a-cf46-4d90-95c3-cea08d49a4ea</RevisionGUID>
    <CreationDate>2010-03-06T18:14:16.04</CreationDate>
    <IPAddress>24.18.228.120</IPAddress>
    <UserId>97</UserId>
    <Text>Our [Genomedata][1] system stores multiple tracks of 1-bp resolution genomic data in a HDF5 array. Documentation and full source code is available on that page. It has a Python (PyTables) interface for reading the data. For originally loading it into HDF5, we wrote a C loader for added speed.


  [1]: http://noble.gs.washington.edu/proj/genomedata/</Text>
  </row>
  <row>
    <Id>411</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>214</PostId>
    <RevisionGUID>a0641b81-f086-4447-8cc1-c5fc19502af4</RevisionGUID>
    <CreationDate>2010-03-06T18:20:20.753</CreationDate>
    <IPAddress>156.111.228.98</IPAddress>
    <UserId>98</UserId>
    <Text>I have a Mac Pro dual quad core that I use for everything. I use the Mac OS for day to day email, most graphics, browsing, I run a VMWare virtual Windows machine, and I do most analysis in the unix terminal. Windows runs much better on the Mac hardware, Excel is much faster in Window, and I can fileshare between the Windows and Mac systems. So far this has been sufficient for me. If I run into a situation where I need more computing power, I can ssh to a Linux server, but I haven't needed to yet. I configured the machine with 16 GB RAM, leaving slots open to add another 16 if needed. I've been happy with this.</Text>
  </row>
  <row>
    <Id>412</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>215</PostId>
    <RevisionGUID>5c74925c-a297-47f0-bc04-1e9788e0e207</RevisionGUID>
    <CreationDate>2010-03-06T18:22:30.58</CreationDate>
    <IPAddress>87.74.75.105</IPAddress>
    <UserId>99</UserId>
    <Text>Hi,

Does anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?

By unambiguous I mean something like this in abyss:

ABYSS -k$k -b0 -t0 -e0 -c0

Cheers,

Albert. </Text>
  </row>
  <row>
    <Id>413</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>215</PostId>
    <RevisionGUID>5c74925c-a297-47f0-bc04-1e9788e0e207</RevisionGUID>
    <CreationDate>2010-03-06T18:22:30.58</CreationDate>
    <IPAddress>87.74.75.105</IPAddress>
    <UserId>99</UserId>
    <Text>Unambiguous assembly of next-gen fastq reads into fastq contigs?</Text>
  </row>
  <row>
    <Id>414</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>215</PostId>
    <RevisionGUID>5c74925c-a297-47f0-bc04-1e9788e0e207</RevisionGUID>
    <CreationDate>2010-03-06T18:22:30.58</CreationDate>
    <IPAddress>87.74.75.105</IPAddress>
    <UserId>99</UserId>
    <Text> éassemblyà  éunambiguousà </Text>
  </row>
  <row>
    <Id>415</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>216</PostId>
    <RevisionGUID>be8d4cca-d345-47be-89c9-a30f7fd6e745</RevisionGUID>
    <CreationDate>2010-03-06T18:33:14.037</CreationDate>
    <IPAddress>64.134.226.98</IPAddress>
    <UserId>72</UserId>
    <Text>Highly subjective answer of course, but I don't think you can go wrong with Linux at the backend.  In general, you will find a vast variety of software, great community support, better work/$ numbers at scale.  I tend to prefer debian-based distro's (Ubuntu, Debian, etc) but that's a personal choice.  On the front end, I've successfully used IRIX (dating myself), Ubuntu, and OSX.</Text>
  </row>
  <row>
    <Id>416</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>201</PostId>
    <RevisionGUID>d35193ad-44de-4d2e-8139-2566b6ead887</RevisionGUID>
    <CreationDate>2010-03-06T18:39:49.67</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Comment>removed two tags, tags were wrapping around on the screen</Comment>
    <Text> écisöregulatoryömoduleà  édnaseöhypersensitivityà  étranscriptionöfactorà </Text>
  </row>
  <row>
    <Id>417</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>217</PostId>
    <RevisionGUID>7ea16971-7164-4693-b88f-ce4137446955</RevisionGUID>
    <CreationDate>2010-03-06T19:03:07.907</CreationDate>
    <IPAddress>169.230.105.12</IPAddress>
    <UserId>100</UserId>
    <Text>yeah, the better answer is not to use surface area to calculate depth. use depth.
http://dx.doi.org/10.1016/j.tibs.2003.09.004</Text>
  </row>
  <row>
    <Id>418</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>218</PostId>
    <RevisionGUID>8eedf3d1-b9f1-41e3-875f-ff7d05d87cae</RevisionGUID>
    <CreationDate>2010-03-06T20:38:38.913</CreationDate>
    <IPAddress>68.81.91.29</IPAddress>
    <UserId>92</UserId>
    <Text>Most of my work is in python, so I use [paver][1], which is similar to makefiles or rake for ruby, but gives you access to all python libraries.


  [1]: http://www.blueskyonmars.com/projects/paver/</Text>
  </row>
  <row>
    <Id>419</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>205</PostId>
    <RevisionGUID>e09c0f6e-8045-4a87-a15c-225c5c5e481b</RevisionGUID>
    <CreationDate>2010-03-06T21:00:23.35</CreationDate>
    <IPAddress>79.2.8.120</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneralà  écontactà  éfaqà </Text>
  </row>
  <row>
    <Id>420</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>219</PostId>
    <RevisionGUID>fa6a36de-bcbd-4c9b-9cb6-2469816cb377</RevisionGUID>
    <CreationDate>2010-03-06T23:19:21.617</CreationDate>
    <IPAddress>71.198.180.119</IPAddress>
    <UserId>51</UserId>
    <Text>I don't work on prediction of transcription factor binding or enhancers so I will just give a very general answer that could apply to any sort of prediction. 

I think there is a big difference between observing an event (ex. transcription factor binding to region X) and knowing why you observe it. To put it in another way .. if we can solve protein structures should we still try to predict how a protein might fold ? Prediction  tries to encapsulates our knowledge of the system so I think the answer is that we will never stop trying to predict/model a system even if we can just easily measure it. Until we can model it we don't really know how it works. If you are only interested in knowing where a TF might bind to then the observations are enough but if you want to know **why** a protein with those characteristics is binding to that DNA region then the observations are just the starting point. 

</Text>
  </row>
  <row>
    <Id>421</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>220</PostId>
    <RevisionGUID>6f37b728-096c-4d67-9fe3-b48e4c3759d7</RevisionGUID>
    <CreationDate>2010-03-07T03:26:37.083</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>I have done some with [ruffus][1] but have reverted back to using make files.
Ruffus is a nice idea and implemented very nicely, but often, in a pipeline, I just want to overwrite files--since I'm exploring and making lots of changes and mistakes. With rufus, I found I was spending a lot of time tracking down which files had/had not changed. For some reason, it's easier for me to deal with a Makefile, with or without using dependencies. YMMV. I just order the make with steps that come first at the top and add stuff to the bottom as I extend the pipeline. This is very simple, but works well for now. I'm interested to see what other responses are added here. 

As others have mentioned, a README.txt and documentation at the top of the script are a good idea. Also, for any script that takes more than 2 arguments, use a getopt equivalent e.g. [optparse][2] in python).

Finally, extract as much code as possible into tested/test-able libraries.

  [1]: http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/
  [2]: http://docs.python.org/library/optparse.html</Text>
  </row>
  <row>
    <Id>422</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>221</PostId>
    <RevisionGUID>9dd15b30-9228-4e79-8c5b-ddc0e8590173</RevisionGUID>
    <CreationDate>2010-03-07T05:26:39.883</CreationDate>
    <IPAddress>221.124.40.145</IPAddress>
    <UserId>27</UserId>
    <Text>We map the reads from the illumina and SoLid platform by using BWA. http://bio-bwa.sourceforge.net/

For bacterial genomes, we choses the illumina platform. About 50X coverage of the total reads was obtained against the ~4Mb reference genome. The mapping process took about 1 hour by using 7 cpus.

For eukaryotic genomes, we choses the SoLid platform. About 25x coverage of the total reads were obtained against the ~500Mb reference genome. The mapping process took about 2 days by using 7 cpus.

Generally reads mapping by using BWA is reliable. </Text>
  </row>
  <row>
    <Id>423</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>4ad5fc85-5534-49d1-a932-5c7418717527</RevisionGUID>
    <CreationDate>2010-03-07T12:18:39.527</CreationDate>
    <IPAddress>195.169.212.36</IPAddress>
    <UserId>79</UserId>
    <Comment>added 4 characters in body</Comment>
    <Text>For reference, please read this excerpt from  
**Human non-synonymous SNPs: server and survey**  
Vasily Ramensky, Peer Bork, and Shamil Sunyaev


&gt; *Profile analysis of homologous
&gt; sequences*. The amino acid replacement
&gt; may be incompatible with the spectrum
&gt; of substitutions observed at that
&gt; position in a family of homologous
&gt; proteins. PolyPhen identifies
&gt; homologues of the input sequences via
&gt; a BLAST (23) search of the NRDB
&gt; database. The set of aligned sequences
&gt; with sequence identity to the input
&gt; sequence in the range 30±94%
&gt; (inclusive) is used by the new version
&gt; of the PSIC (position-specific
&gt; independent counts) software (24) to
&gt; calculate the so-called profile matrix
&gt; (http://strand.imb.ac.ru/PSIC/).
&gt; Elements of the matrix (pro- file
&gt; scores) are logarithmic ratios of the
&gt; likelihood of a given amino acid
&gt; occurring at a particular site to the
&gt; likelihood of this amino acid
&gt; occurring at any site (background
&gt; frequency). PolyPhen computes the
&gt; absolute value of the difference
&gt; between profile scores of both allelic
&gt; variants in the polymorphic position.
&gt; PolyPhen also shows the number of
&gt; aligned sequences at the query
&gt; position; this may be used to assess
&gt; the reliability of profile score
&gt; calculations.

I'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.

Does anyone know of a working implementation of this or something similar, that's available either in code or as a web service?

Or should it is easy enough to implement something like this ourselves?</Text>
  </row>
  <row>
    <Id>424</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>222</PostId>
    <RevisionGUID>8bf669db-a5a6-4bad-b5e1-4f24e38253b8</RevisionGUID>
    <CreationDate>2010-03-07T12:53:55.737</CreationDate>
    <IPAddress>134.36.64.130</IPAddress>
    <UserId>105</UserId>
    <Text>Dumb question I know, but...

What tool to use?

I'd like to find forward and reverse primers within an approximate distance of each other... I'd like to accept 1 or two mismatches. The genome is ~1 Gbp. I have ~500 forward reverse pairs to find in the genome.

Any hints appreciated :-)</Text>
  </row>
  <row>
    <Id>425</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>222</PostId>
    <RevisionGUID>8bf669db-a5a6-4bad-b5e1-4f24e38253b8</RevisionGUID>
    <CreationDate>2010-03-07T12:53:55.737</CreationDate>
    <IPAddress>134.36.64.130</IPAddress>
    <UserId>105</UserId>
    <Text>How to find a 28bp 'primer' sequence in a genome?</Text>
  </row>
  <row>
    <Id>426</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>222</PostId>
    <RevisionGUID>8bf669db-a5a6-4bad-b5e1-4f24e38253b8</RevisionGUID>
    <CreationDate>2010-03-07T12:53:55.737</CreationDate>
    <IPAddress>134.36.64.130</IPAddress>
    <UserId>105</UserId>
    <Text> ésequenceà  égenomeà  ésearchà  étoolà  éprimerà </Text>
  </row>
  <row>
    <Id>427</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>223</PostId>
    <RevisionGUID>8bfe2eab-08f1-467c-8ce0-31002b95d2b3</RevisionGUID>
    <CreationDate>2010-03-07T13:24:06.38</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>I know that many people use the [primer3 software][1] to design primers. There are also two web-interfaces where you can try out the parameters, and there are many of them.
The program **[eprimer3][2]** is part of the [EMBOSS tools][3], maybe the best way of getting a command-line executable of primer3.

I didn't see a mismatch parameter though, because for a 'real' PCR-primer to allow for mismatches is a bad idea. I noted the '' in your question, so you might not really be looking for primers. So what is it then? If this is just a piece of sequence then you do not need to bother with uniqueness or melting temperature constraints.


  [1]: http://primer3.sourceforge.net/
  [2]: http://emboss.sourceforge.net/apps/release/6.2/emboss/apps/eprimer3.html
  [3]: http://emboss.sourceforge.net/</Text>
  </row>
  <row>
    <Id>428</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>224</PostId>
    <RevisionGUID>da3b3d14-b7d7-43a5-acb9-c29987c09ef4</RevisionGUID>
    <CreationDate>2010-03-07T15:20:02.63</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>I've only used [bowtie][1], but it seems to be extremely fast and makes use of multiple cores with no extra work on my part. Also, builds an index for the reference sequence which can be re-used after the first build. 

This is mapping to Arabidopsis Thaliana, up to 5 or so Gigs of raw reads, so fastq of 4x that size. Using a pretty standard 8 core machine, it's relatively painless.

  [1]: http://bowtie-bio.sourceforge.net/index.shtml</Text>
  </row>
  <row>
    <Id>429</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>225</PostId>
    <RevisionGUID>48ddb090-e2be-435c-9f6c-db02daf904ba</RevisionGUID>
    <CreationDate>2010-03-07T16:22:36.553</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>Since you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. 
Actually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use [bowtie][1].

As far as I know, [primer3][2] does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.

or, you could use BLAST and find nearby hits between the pairs.


  [1]: http://bowtie-bio.sourceforge.net/index.shtml
  [2]: http://primer3.sourceforge.net/</Text>
  </row>
  <row>
    <Id>430</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>226</PostId>
    <RevisionGUID>6405bf55-3a69-42c2-bdb1-4ca8aba85cc1</RevisionGUID>
    <CreationDate>2010-03-07T19:22:29.123</CreationDate>
    <IPAddress>130.237.137.116</IPAddress>
    <UserId>26</UserId>
    <Text>I agree with Istvan and pedrobeltrao.

I would just add that we should all be careful when we look at the type of experiments that you describe as well as protein structures and many other biochemical experiments.

They are, most often, ***snapshots*** of what is happening in an ***extremely dynamic*** environment, which is the cell and its components.

What holds true at one moment (when the cell was fixed, the proteins extracted or crystalized) is not the whole picture of what's happening or how things look.

I think you'll need more than a few biochemical experiments to ***know*** how the cell really works. Until that day, predictions and modeling will always be useful.</Text>
  </row>
  <row>
    <Id>431</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>227</PostId>
    <RevisionGUID>8c8dd08c-1c6b-4639-ba57-f417d8cf647d</RevisionGUID>
    <CreationDate>2010-03-08T10:01:03.377</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>Hey Pierre,

thanks for your answer!
I already got the genetic map provided by USCS database with STS markers.
But my issue remains the same: the density of markers of the available genetic maps (the USCS one or HapMap II one) is much lower than the density of my SNP set. For example I have 4054 SNPs between the 2 STS markers above (in your comment).
 
Therefore I don't know how to attribute to each SNPs of my set a position in cM  without doing a very important approximation.

Anyway, what do you suggest? To use a rule of three approach to attribute a cM position to my collection's SNPs?
 
Thanks for your advice!
Pierre


</Text>
  </row>
  <row>
    <Id>432</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>228</PostId>
    <RevisionGUID>4ebe07cf-a9c1-4f66-bc08-297aed92cbd1</RevisionGUID>
    <CreationDate>2010-03-08T12:57:32.733</CreationDate>
    <IPAddress>66.244.80.2</IPAddress>
    <UserId>110</UserId>
    <Text>Hello all,
I am new to this forum and I am glad I found one in Bioinformatics too.
I hope I can ask this question here.
**Has anyone been able to generate cluster heatmaps using any library in Java ?**
I recently got to learn that heatmaps are different from cluster heat maps in just that in the cluster heatmaps there are dendrograms for both genes as well as samples. So essentially Hierarchical clustering (thats what I am working on) is to be performed once on the genes and once on the samples.
I was looking at JFreechart, JTreeview. In JFreechart I did not find any method to directly get a cluster heat map. And with JTreeview,  it needs 3 input files in particular format like the .CDT file, .gtr file, .atr file. I am curious to know if there is any other direct way to generate these cluster heat maps. 

Please enlighten me

Thanks in advance</Text>
  </row>
  <row>
    <Id>433</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>228</PostId>
    <RevisionGUID>4ebe07cf-a9c1-4f66-bc08-297aed92cbd1</RevisionGUID>
    <CreationDate>2010-03-08T12:57:32.733</CreationDate>
    <IPAddress>66.244.80.2</IPAddress>
    <UserId>110</UserId>
    <Text>Hierarchical Clustering, Cluster Heat Maps in Java</Text>
  </row>
  <row>
    <Id>434</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>228</PostId>
    <RevisionGUID>4ebe07cf-a9c1-4f66-bc08-297aed92cbd1</RevisionGUID>
    <CreationDate>2010-03-08T12:57:32.733</CreationDate>
    <IPAddress>66.244.80.2</IPAddress>
    <UserId>110</UserId>
    <Text> éclusteringà  émapà </Text>
  </row>
  <row>
    <Id>435</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>229</PostId>
    <RevisionGUID>8e3cbc55-e45a-427c-b17a-2a7c7eb57526</RevisionGUID>
    <CreationDate>2010-03-08T13:49:18.487</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>
I know that the [Multiexperiment Viewer suite][1] is written in Java. 

While it is not usually used as a library I think you might be able to import some of its internals in your own code. It is worth a try, as you could get access to numerous other tools as well. 


  [1]: http://www.tm4.org/mev/</Text>
  </row>
  <row>
    <Id>436</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>230</PostId>
    <RevisionGUID>216661ef-4473-430f-bc6c-39b2f57e80c8</RevisionGUID>
    <CreationDate>2010-03-08T13:50:54.537</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>This post was not formulated in a question/answer format  therefore will be closed.</Text>
  </row>
  <row>
    <Id>437</Id>
    <PostHistoryTypeId>10</PostHistoryTypeId>
    <PostId>92</PostId>
    <RevisionGUID>a13d98c8-9aff-4541-9a16-335118fae225</RevisionGUID>
    <CreationDate>2010-03-08T13:51:12.053</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Comment>4</Comment>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>438</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>231</PostId>
    <RevisionGUID>3dcaa5f5-15f0-4221-9646-3ee597c5c133</RevisionGUID>
    <CreationDate>2010-03-08T14:39:24.157</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Did not used it myself yet, but there is a new program claiming to be better than primer3:

See:
http://nar.oxfordjournals.org/cgi/content/abstract/37/13/e95

Download it from:
http://pythia.sourceforge.net

</Text>
  </row>
  <row>
    <Id>439</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>232</PostId>
    <RevisionGUID>95d7add1-6420-40c1-88c6-55e9b88891ff</RevisionGUID>
    <CreationDate>2010-03-08T16:54:31.583</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>It is clear that in Computational Biology there are certain organisations, societies and the like, global and regional, that intend to cater the needs for conferences, networking and scientific exchange, proper of any scientific community.

However, the benefits of joining a society are still elusive. In an American setting it seems that there is this culture of supporting your own community by joining your society. In Europe it does not seem to have any value attached in one's CV to belong or form part of a society, other than anecdotal. Other regions in the world may be somewhere in between.

I would like to ask people what they think their perception of belonging to a professional society is, whether this should be something that should be encouraged in settings where this is not so valued and what their expectations are.</Text>
  </row>
  <row>
    <Id>440</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>232</PostId>
    <RevisionGUID>95d7add1-6420-40c1-88c6-55e9b88891ff</RevisionGUID>
    <CreationDate>2010-03-08T16:54:31.583</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text>How Important is it to belong to a Professional Society in Computational Biology?</Text>
  </row>
  <row>
    <Id>441</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>232</PostId>
    <RevisionGUID>95d7add1-6420-40c1-88c6-55e9b88891ff</RevisionGUID>
    <CreationDate>2010-03-08T16:54:31.583</CreationDate>
    <IPAddress>193.62.202.242</IPAddress>
    <UserId>64</UserId>
    <Text> éprofessionalösocietyà  écareerà  ésubjectiveà  éassessmentà </Text>
  </row>
  <row>
    <Id>442</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>233</PostId>
    <RevisionGUID>8a90b3d2-1d67-4812-b6d8-01d4fbf01850</RevisionGUID>
    <CreationDate>2010-03-08T18:28:21.66</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I think the benefits of being in a professional society do not readily lend themselves to quantification. 

The positives are more about personal fulfillment, a sense of belonging, better understanding of the field and building interpersonal relationships that in the end may strongly shape one's future.</Text>
  </row>
  <row>
    <Id>443</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>230</PostId>
    <RevisionGUID>ba201677-8fac-419d-8281-2330ad6476fa</RevisionGUID>
    <CreationDate>2010-03-08T21:45:27.493</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>444</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>234</PostId>
    <RevisionGUID>84a48edb-9da7-43a6-a567-a9c47fcbf06e</RevisionGUID>
    <CreationDate>2010-03-08T21:51:44.43</CreationDate>
    <IPAddress>82.39.144.143</IPAddress>
    <UserId>59</UserId>
    <Text>This is a very interesting question.  I think today, and especially in a modern field like bioinformatics, the idea of belonging to a professional society is almost quaint.

Having once been a bench scientist, the only reasons I could ever ascertain to belonging to a society were that

 1. They might pay your fees to go to a conference if they fund this kind of thing
 2. You might get reduced conference fees for certain conferences
 3. You get a little ribbon on your badge to let everyone know at the conference you're a member

Certainly, from my current position - I have never felt that belonging to a professional body distinguished my CV or resume from any other candidate.  As someone who hires, it would not make a jot of difference to me if you were a member of a society or not.

I would go so far as to suggest that even the networking aspects of a society are largely oversold in the wake of the professional relationships I build over Twitter, LinkedIn or FriendFeed.  Whether or not I am a member of a professional organisation would not have any bearing on which conferences I attended, or who I spoke to at them.

</Text>
  </row>
  <row>
    <Id>445</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>235</PostId>
    <RevisionGUID>26c8675b-13e1-44f2-bb97-97695c31e17d</RevisionGUID>
    <CreationDate>2010-03-08T22:08:45.82</CreationDate>
    <IPAddress>67.109.12.251</IPAddress>
    <UserId>116</UserId>
    <Text>I think the Pfam approach may return something useful, but you need to be careful about how you interpret your results. Pfam is primarily a tool to assign sequences to protein families. It also does a good job of recognizing functional domains. It provides information about the usual function of the domains/family members- but I do not think it should be viewed as a tool to assign function directly, and I think the Pfam curators would agree with me. It is making an assignment based on sequence similarity, and is inferring structural and functional similarity. These inferences may or may not be correct. You have several risks you need to keep in mind. Two biggies that pop out too me are:

1. Your sequences are all shorter than most protein domains. So you may get false negatives where if you had the full sequence, you might have hit a domain, but because you only have a fragment, the similarity is too weak to produce a hit.

2. You might get false positives because you match a domain but have a few key residues in your sequence mutated, and therefore the protein from which your sequence was derived actually does not perform the function assigned to that domain in Pfam. 

You asked about direct experience. Mine is roughly 5 years old now, but it was that Pfam was one of the best tools to identify functional domains, and was a good way to annotate sequences as long as I kept its limitations in mind. However, I was working with full length sequences, not fragments. My gut instinct is that it will not perform as well on small fragments, but I have no direct experience to back me up- just my knowledge that your fragments are shorter than most domains.

Back when I did function assignment for a living, I considered it very risky to rely on one tool to make an assignment. And I never considered any assignment anything more than a hypothesis that could then be tested in the lab.</Text>
  </row>
  <row>
    <Id>446</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>236</PostId>
    <RevisionGUID>38c903b4-e60f-4770-bb94-ab5d35dbb48d</RevisionGUID>
    <CreationDate>2010-03-08T22:46:36.16</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>From the practical point of view, I heard when you apply for a green card in US as extraordinary/outstanding scientist, being a member of professional societies gives you some additional "points".

Another example. AACR (The American Association for Cancer Research) became to large, that it accepts papers/posters for a conference only from its members. If you are not, you have to find a full member to be a "sponsor" for your paper.

As for many societies, members usually get early event notices (I get them by e-mail all the time anyway), some free publications (sometime just another junk), fee reduction (do you care if your lab is paying? :). </Text>
  </row>
  <row>
    <Id>447</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>237</PostId>
    <RevisionGUID>df0a43a4-b121-43cd-9acc-8151e73d337e</RevisionGUID>
    <CreationDate>2010-03-08T23:29:23.33</CreationDate>
    <IPAddress>130.155.25.114</IPAddress>
    <UserId>66</UserId>
    <Text>The sole benefit that I have gained from my two experiences with society membership was a discounted rate for conference registration.  For the remainder of my subscription, I received no information via email or any other means apart from a reminder to renew (in one case, nothing in the other case).

I'd agree with Daniel, above; the "informal" connections that I've made via online social networks have been far more valuable to me than any formal society.</Text>
  </row>
  <row>
    <Id>448</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>238</PostId>
    <RevisionGUID>15c70331-f864-4c56-aab5-528d2b6af0c0</RevisionGUID>
    <CreationDate>2010-03-09T02:39:53.167</CreationDate>
    <IPAddress>130.102.118.204</IPAddress>
    <UserId>90</UserId>
    <Text>I have RMA (Robust Multi-Array) scores for the different genes (and their isoforms) on the Affymetrix chip. I want to know which of these genes are "active" (or in other words: are likely to produce enough protein products to have an effect). I'm not interested in them being differentially expressed or X-fold over- or under-expressed. All I want is the classification of them being likely "on" or "off". 

So far I log-transformed (basis 10) the RMA score and centered them (subtracted the median). I called all genes which had a transformed score &lt;0 as being inactive and scores &gt;0 as being active. 

Does anyone have a better methodology ?

</Text>
  </row>
  <row>
    <Id>449</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>238</PostId>
    <RevisionGUID>15c70331-f864-4c56-aab5-528d2b6af0c0</RevisionGUID>
    <CreationDate>2010-03-09T02:39:53.167</CreationDate>
    <IPAddress>130.102.118.204</IPAddress>
    <UserId>90</UserId>
    <Text>How to determine if a gene is active from expression data</Text>
  </row>
  <row>
    <Id>450</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>238</PostId>
    <RevisionGUID>15c70331-f864-4c56-aab5-528d2b6af0c0</RevisionGUID>
    <CreationDate>2010-03-09T02:39:53.167</CreationDate>
    <IPAddress>130.102.118.204</IPAddress>
    <UserId>90</UserId>
    <Text> égeneöexpressionà </Text>
  </row>
  <row>
    <Id>451</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>239</PostId>
    <RevisionGUID>cf397eb8-5299-443a-a0e3-10d404d84809</RevisionGUID>
    <CreationDate>2010-03-09T05:15:16.803</CreationDate>
    <IPAddress>70.240.206.216</IPAddress>
    <UserId>117</UserId>
    <Text>You're right in thinking that your methodology isn't a very good representation of the system. mRNAs (and their protein products) have a huge dynamic range. Some are going to be expressed constantly at extremely low levels, and at the other extremes, you'll have genes that are highly expressed, but only for a short period of time.  Taking the median level as the dividing line between on and off is going to give you huge numbers of false negatives (genes that are actually being transcribed and translated, but that you'll classify as "off")

I'd look at what the background noise level is, then run some stats to determine which probes give you signal significantly above that level. Any gene meeting that criteria should probably be considered "on". I suspect that may not divide the set as nicely as you'd hope, though.

Maybe if you tell us more about what exactly you're trying to do, we can offer more constructive advice.</Text>
  </row>
  <row>
    <Id>452</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>240</PostId>
    <RevisionGUID>77abf35b-3a60-4a2b-a9cc-ff3e12121840</RevisionGUID>
    <CreationDate>2010-03-09T05:20:42.023</CreationDate>
    <IPAddress>70.240.206.216</IPAddress>
    <UserId>117</UserId>
    <Text>It's worth noting that a lot of people also use [Novoalign][1]


  [1]: http://www.novocraft.com/index.html</Text>
  </row>
  <row>
    <Id>453</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>241</PostId>
    <RevisionGUID>ab558825-222f-4e85-92d5-d6a99aeec0f9</RevisionGUID>
    <CreationDate>2010-03-09T12:12:40.087</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>I use a combination of things for different purposes, including C, R, Perl and Delphi. For anything to run on windows, whether command-line or with a nice-to-use UI for less technical users, **Delphi** still rocks.</Text>
  </row>
  <row>
    <Id>454</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>242</PostId>
    <RevisionGUID>c3513aed-7ef4-4d3b-af10-93465ebc975c</RevisionGUID>
    <CreationDate>2010-03-09T12:59:45.96</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>In addition to what's already been said, I'd like to add that even if these data did completely abolish the need to predict TF binding sites (which I'm not entirely sure about), there are still many cases - **and many organisms** - where such data aren't available, implying that there's still a niche for computational approaches.</Text>
  </row>
  <row>
    <Id>455</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>243</PostId>
    <RevisionGUID>9e97e1e7-32f2-4560-8e27-6cab4ff8f6e6</RevisionGUID>
    <CreationDate>2010-03-09T15:44:54.403</CreationDate>
    <IPAddress>218.186.8.241</IPAddress>
    <UserId>91</UserId>
    <Text>We still have a long way to go when it comes to enhancer discovery. The fact that a genomic region comes out as DNAse I hypersensitive in a certain tissue does not necessarily mean it is an enhancer region in that tissue. Here, I think the DNAse I hypersensitivity (and FAIRE) data should be regarded as a necessary input to improved enhancer prediction algorithms, rather than something to replace them. (In fact I think there are very few enhancer prediction algorithms out there, so the help is sorely needed!)

Similarly, I don't think DNAse or FAIRE *in themselves* say much about transcription factor binding, although they can be very informative in combination with knowledge of the TF motif (or so I've heard). ChIP-seq, on the other hand, does give pretty solid information on TF binding which I agree would more or less supersede computational predictions in the relevant tissue in the given organism. As others have pointed out in this thread, though, there are many organisms and/or tissues for which we won't have ChIP-seq within a foreseeable time, and for those cases (and others) we can hopefully use existing ChIP-seq data to refine computational models of TF binding. So I would regard ChIP-seq data as something that helps us refine our understanding of TF binding, including the prediction of binding events in various systems.</Text>
  </row>
  <row>
    <Id>456</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>215</PostId>
    <RevisionGUID>67378437-07b9-479c-be75-abac50270dea</RevisionGUID>
    <CreationDate>2010-03-09T17:11:12.56</CreationDate>
    <IPAddress>128.240.229.67</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> éassemblyà  éunambiguousà  éfastqà </Text>
  </row>
  <row>
    <Id>457</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>244</PostId>
    <RevisionGUID>db01bd85-730f-4328-b909-7141602a8d81</RevisionGUID>
    <CreationDate>2010-03-09T17:57:12.223</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>Just my two cents and since nobody mentioned yet, I'm using **MATLAB**. Yes, it's commercial and expensive. It might be behind **R/Bioconductor** in amount of contributed algorithms (this is why I sometime have to use R as well). But the environment is very friendly for fast development, figures are great, and making GUIs is pretty easy. Many useful for bioinformatician toolboxes, like Statistics, Bioinformatics, Optimization. Someone may find SimBiology cool (although I haven't used it). As others mentioned **Perl** is still rules for text processing and workflows, although I agree with giovanni on its problems.</Text>
  </row>
  <row>
    <Id>458</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>245</PostId>
    <RevisionGUID>4b32a90f-f9a8-471a-9ae9-016349ddd030</RevisionGUID>
    <CreationDate>2010-03-09T18:13:46.353</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text>I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.

There is a huge [list here][1] yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.

What tool do you use to solve this problem?

Thanks.

  [1]: http://www.geneontology.org/GO.tools.microarray.shtml</Text>
  </row>
  <row>
    <Id>459</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>245</PostId>
    <RevisionGUID>4b32a90f-f9a8-471a-9ae9-016349ddd030</RevisionGUID>
    <CreationDate>2010-03-09T18:13:46.353</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text>Tools to find gene ontology term enrichment</Text>
  </row>
  <row>
    <Id>460</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>245</PostId>
    <RevisionGUID>4b32a90f-f9a8-471a-9ae9-016349ddd030</RevisionGUID>
    <CreationDate>2010-03-09T18:13:46.353</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>10</UserId>
    <Text> égeneontologyà  éenrichmentà  étoolà </Text>
  </row>
  <row>
    <Id>461</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>246</PostId>
    <RevisionGUID>f4e566f3-793e-449d-885a-1ec6684e5cc0</RevisionGUID>
    <CreationDate>2010-03-09T18:55:53.967</CreationDate>
    <IPAddress>141.211.183.90</IPAddress>
    <UserId>58</UserId>
    <Text>I prefer to use DAVID ( http://david.abcc.ncifcrf.gov/ ) but id be interested to hear what other people like.  There are also R packages available through Bioconductor (GOstats; http://www.bioconductor.org/packages/2.3/bioc/html/GOstats.html) that can do enrichment determination, but I am less familiar with those, and you need a good working knowlege of R to use these.
</Text>
  </row>
  <row>
    <Id>462</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>247</PostId>
    <RevisionGUID>095d3055-7dd0-43d9-8512-2c5c627f1cb9</RevisionGUID>
    <CreationDate>2010-03-09T19:35:32.12</CreationDate>
    <IPAddress>88.6.162.173</IPAddress>
    <UserId>23</UserId>
    <Text>You can try one of the tools at [babelomics][1], in particular FatiGO; or as an alternative, you can use the same AmiGO [Term Enrichment tool][2].

However, be careful when using GeneOntology: it is a very active and supported project, so they make big enhancements between two releases. If you look at thei bug tracker, there are at least 8-10 changes to geneontology terms every day. So, annotate the version and date of GeneOntology if you want your experiment to be reproducible.


  [1]: http://babelomics.bioinfo.cipf.es/
  [2]: http://amigo.geneontology.org/cgi-bin/amigo/term_enrichment</Text>
  </row>
  <row>
    <Id>463</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>248</PostId>
    <RevisionGUID>c64aed86-d924-4fe8-9e08-928b509aaa64</RevisionGUID>
    <CreationDate>2010-03-09T20:15:02.163</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>I would suggest the following question instead of the one you're asking:

**Can you actually determine if a gene is "active" (i.e. translated into protein) from [gene] expression data?**

And I'll point you towards people who have published papers about it:

  * [Correlation between protein and mRNA abundance in yeast.][1]
  * [Correlation of mRNA and protein levels: Cell type-specific gene expression of cluster designation antigens in the prostate][2]
  * [Comparing protein abundance and mRNA expression levels on a genomic scale][3]
  * [Insights into the relation between mrna and protein expression patterns: ii. Experimental observations in Escherichia coli][4]

These are just a few papers that seem critical towards such a correlation. That is not to say that there is no good correlation for any gene. But I would be very surprised if you can make a general rule about it without checking in every cell type, tissue type and for every gene to see if such a correlation is or not acceptable.

Now, if you do a Pubmed search for the terms "[correlation mRNA protein][5]", you will find many papers that check for such correlations, but mostly for specific genes in specific tissues (often for cancer diagnostics purposes).

If you do find papers that state such correlations, genome wide using microarray data, I'd be highly suspicious of that paper.

So, obviously, you can not set "a" cut-off for determining this. My personal experience tells me that you can have gene transcription with ***no*** protein expression following it... Unfortunately, I have not published it yet :(


  [1]: http://www.ncbi.nlm.nih.gov/pubmed/10022859
  [2]: http://www.biomedcentral.com/1471-2164/9/246
  [3]: http://genomebiology.com/2003/4/9/117
  [4]: http://www3.interscience.wiley.com/journal/106577988/abstract?CRETRY=1&amp;SRETRY=0
  [5]: http://www.ncbi.nlm.nih.gov/pubmed?term=correlation+mrna+protein</Text>
  </row>
  <row>
    <Id>464</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>238</PostId>
    <RevisionGUID>0578d57d-99b3-43af-981d-06edec7755f5</RevisionGUID>
    <CreationDate>2010-03-09T20:16:00.99</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneöexpressionà  éproteinöexpressionà </Text>
  </row>
  <row>
    <Id>465</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>249</PostId>
    <RevisionGUID>9dc38b07-ab33-4e80-9d8e-20b512b6e96e</RevisionGUID>
    <CreationDate>2010-03-09T22:41:33.923</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>[GenePilot][1]™ is a Java-based Analysis suite, which provides a MicroArray Analysis capabilities. 

You can export your results as Cluster Heatmaps. They give the following example of a local heatmap of the currently selected cluster along with the top dendigram (if applicable), column information, average thumbnail, row info and Gene Ontology Information (if applicable):

![alt text][2]


  [1]: http://www.genepilot.com/index.html
  [2]: http://www.genepilot.com/assets/gifs/HC_Select_right.gif</Text>
  </row>
  <row>
    <Id>466</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>250</PostId>
    <RevisionGUID>042ed740-ff1e-483b-929b-f1415f40d61b</RevisionGUID>
    <CreationDate>2010-03-09T23:15:00.307</CreationDate>
    <IPAddress>130.102.118.204</IPAddress>
    <UserId>90</UserId>
    <Text>Another option is GONOME (http://gonome.imb.uq.edu.au/), which finds the over- and under-represented
GO terms for a given set of genomic positions.</Text>
  </row>
  <row>
    <Id>467</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>251</PostId>
    <RevisionGUID>542a50b0-d71c-4e97-8649-e3bc7d509d9c</RevisionGUID>
    <CreationDate>2010-03-10T11:57:11.91</CreationDate>
    <IPAddress>92.241.199.203</IPAddress>
    <UserId>71</UserId>
    <Text>What opensource Java solutions are available to query online pathway databases like [KEGG][1] (or [BioMeta][2]), [MACiE][3] and [Brenda][4] for the pathways a certain metabolite is available, for example, based on the [InChI][5]? Preferably, the library would have a good data model for the pathway information, possibly [SMBL][6] or [RDF][7]-based. What would the code look like to make such a query?


  [1]: http://www.genome.jp/kegg/
  [2]: http://biometa.cmbi.ru.nl/
  [3]: http://www.ebi.ac.uk/thornton-srv/databases/MACiE/
  [4]: http://www.brenda-enzymes.org/
  [5]: http://en.wikipedia.org/wiki/International_Chemical_Identifier
  [6]: http://sbml.org/
  [7]: http://en.wikipedia.org/wiki/Resource_description_framework</Text>
  </row>
  <row>
    <Id>468</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>251</PostId>
    <RevisionGUID>542a50b0-d71c-4e97-8649-e3bc7d509d9c</RevisionGUID>
    <CreationDate>2010-03-10T11:57:11.91</CreationDate>
    <IPAddress>92.241.199.203</IPAddress>
    <UserId>71</UserId>
    <Text>What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?</Text>
  </row>
  <row>
    <Id>469</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>251</PostId>
    <RevisionGUID>542a50b0-d71c-4e97-8649-e3bc7d509d9c</RevisionGUID>
    <CreationDate>2010-03-10T11:57:11.91</CreationDate>
    <IPAddress>92.241.199.203</IPAddress>
    <UserId>71</UserId>
    <Text> émetabolomicsà  émetaboliteà  écheminformaticsà  éjavaà  éopensourceà </Text>
  </row>
  <row>
    <Id>470</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>252</PostId>
    <RevisionGUID>f7002323-2dcb-48ab-becb-9da9ddd29368</RevisionGUID>
    <CreationDate>2010-03-10T15:48:37.073</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. 
There is a solution anyhow, I have never used MACiE btw.
Both database provide a standard compliant web-services interface over SOAP messages.
Web-services are a standardized way of language and system independent programmatic communication. 

[KEGG soap: http://www.genome.jp/kegg/soap/][2]

[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]

Both services have a [WSDL file][4] to describe the interface.

This description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.
So you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.


  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar
  [2]: http://www.genome.jp/kegg/soap/
  [3]: http://www.brenda-enzymes.org/soap/
  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language
  [5]: http://ws.apache.org/axis2/
  [6]: http://en.wikipedia.org/wiki/SOAP</Text>
  </row>
  <row>
    <Id>471</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>253</PostId>
    <RevisionGUID>5078f5d5-e448-4dd0-beb5-b9f7ac169cd1</RevisionGUID>
    <CreationDate>2010-03-10T16:24:01.93</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>it's very much in progress, but a colleague and I (mostly him) have been working on this for python:
http://github.com/tanghaibao/goatools/

it has a command-line script to find terms that are enriched in a study group. it reports p-value for various multiple testing corrections as well as the false discovery rate.

It can also be used to plot the DAG of a particular GO term. </Text>
  </row>
  <row>
    <Id>472</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>252</PostId>
    <RevisionGUID>1eeee9c7-85a5-4dc9-8c44-187b58a3a21e</RevisionGUID>
    <CreationDate>2010-03-10T20:50:20.267</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>Added some code example ; added 244 characters in body</Comment>
    <Text>There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. 
There is a solution anyhow, I have never used MACiE btw.
Both database provide a standard compliant web-services interface over SOAP messages.
Web-services are a standardized way of language and system independent programmatic communication. 

[KEGG soap: http://www.genome.jp/kegg/soap/][2]

[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]

Both services have a [WSDL file][4] to describe the interface.

This description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.
So you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.


----------
 A little edit and some issues from myself after having a look at the KEGG soap interface:

As often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true *in principle*, but....

1. The databinding (mapping of xml-schema types to Java types) that seems to work is
**xmlbeans**. The **adb** databinding gives an error. This is due to non-standard use of some
structures in the wsdl. 

2. Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the *ArrayOfstring*. This glitch is IMHO KEGG's fault because they did only test with Axis1.

3. Alternatives if nobody knows a better solution, try Axis1 with [the jar-file][7] from KEGG or try the [Brenda WSDL][8].

Example use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:

  

     package keggtest;
            
       import java.rmi.RemoteException;
            
       import kegg.soap.ArrayOfstring;
       import kegg.soap.GetPathwaysByGenesDocument;
       import kegg.soap.GetPathwaysByGenesResponseDocument;
       import kegg.soap.KEGGStub;
       import kegg.soap.GetPathwaysByGenesDocument.GetPathwaysByGenes;
            
       import org.apache.axis2.AxisFault;
    
    public class keggclient {
    
    	/**
    	 * @param args
    	 */
    	public static void main(String[] args) {
    
    		try {
    			KEGGStub stub = new KEGGStub("http://soap.genome.jp/KEGG.wsdl");
    
    			GetPathwaysByGenes getPathwaysByGenes = GetPathwaysByGenes.Factory
    					.newInstance();
    			ArrayOfstring genesIdList = ArrayOfstring.Factory.newInstance();
    			// add items to ArrayOfstring, but how?
    			getPathwaysByGenes.setGenesIdList(genesIdList);
    			GetPathwaysByGenesDocument get_pathways_by_genes = GetPathwaysByGenesDocument.Factory
    					.newInstance();
    			get_pathways_by_genes.setGetPathwaysByGenes(getPathwaysByGenes);
    			try {
    				GetPathwaysByGenesResponseDocument res = stub
    						.get_pathways_by_genes(get_pathways_by_genes);
    				System.err.println(res.getGetPathwaysByGenesResponse()
    						.getReturn());
    			} catch (RemoteException e) {
    				// TODO Auto-generated catch block
    				e.printStackTrace();
    			}
    
    		} catch (AxisFault e) {
    			// TODO Auto-generated catch block
    
    			e.printStackTrace();
    		}
    
    	}
    }


  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar
  [2]: http://www.genome.jp/kegg/soap/
  [3]: http://www.brenda-enzymes.org/soap/
  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language
  [5]: http://ws.apache.org/axis2/
  [6]: http://en.wikipedia.org/wiki/SOAP
  [7]: http://www.genome.jp/kegg/soap/support/keggapi.jar
  [8]: http://www.brenda-enzymes.org/soap/brenda.wsdl</Text>
  </row>
  <row>
    <Id>473</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>254</PostId>
    <RevisionGUID>47df7db7-3d41-4b07-9dc0-622e524c3401</RevisionGUID>
    <CreationDate>2010-03-10T21:05:39.207</CreationDate>
    <IPAddress>72.145.235.166</IPAddress>
    <UserId>24</UserId>
    <Text>This review article may be helpful or at least interesting to you:

["Automated protein function prediction -- the genomic challenge"][1] (Friedberg 2006)

Here's a relevant excerpt:

&gt; Pfam is arguably the database of choice for those seeking order within the protein sequence universe. [...] As we shall see, Pfam annotation is used by function prediction programs, either by directly querying Pfam or by using umbrella databases that include Pfam information such as InterPro. SMART, CDD, and PRODOM are other databases consisting of multiple alignments of protein domains. All these databases have proteins arranged in homologous clusters, which, when possible, are annotated. These databases are often deferred to when producing homology-based annotation transfers. It should be emphasized that the use of these databases for homology transfer should be done with caution, as they annotate proteins on a domain level. A multi-domain query aligned to Pfam, for example, should be carefully checked for mis-annotations due to domain shuffling, as mentioned eariler. Also, the 'granularity' of these databases varies. For example, a single Pfam family may contain several proteins which perform the same enzymatic reaction on different substrates.

  [1]: http://bib.oxfordjournals.org/cgi/content/full/7/3/225</Text>
  </row>
  <row>
    <Id>474</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>252</PostId>
    <RevisionGUID>fee4fa74-3e49-4fc4-a899-149ed1e3e0a5</RevisionGUID>
    <CreationDate>2010-03-10T21:12:15.94</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 579 characters in body</Comment>
    <Text>There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. 
There is a solution anyhow, I have never used MACiE btw.
Both database provide a standard compliant web-services interface over SOAP messages.
Web-services are a standardized way of language and system independent programmatic communication. 

[KEGG soap: http://www.genome.jp/kegg/soap/][2]

[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]

Both services have a [WSDL file][4] to describe the interface.

This description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.
So you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.


----------
 A little edit and some issues from myself after having a look at the KEGG soap interface:

As often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true *in principle*, but....

1. The databinding (mapping of xml-schema types to Java types) that seems to work is
**xmlbeans**. The **adb** databinding gives an error. This is due to non-standard use of some
structures in the wsdl. 

2. Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the *ArrayOfstring*. This glitch is IMHO KEGG's fault because they did only test with Axis1.

3. Alternatives if nobody knows a better solution, try Axis1 with [the jar-file][7] from KEGG or try the [Brenda WSDL][8].

Example use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:

  

     package keggtest;
            
       import java.rmi.RemoteException;
            
       import kegg.soap.ArrayOfstring;
       import kegg.soap.GetPathwaysByGenesDocument;
       import kegg.soap.GetPathwaysByGenesResponseDocument;
       import kegg.soap.KEGGStub;
       import kegg.soap.GetPathwaysByGenesDocument.GetPathwaysByGenes;
            
       import org.apache.axis2.AxisFault;
    
    public class keggclient {
    
    	/**
    	 * @param args
    	 */
    	public static void main(String[] args) {
    
    		try {
    			KEGGStub stub = new KEGGStub("http://soap.genome.jp/KEGG.wsdl");
    
    			GetPathwaysByGenes getPathwaysByGenes = GetPathwaysByGenes.Factory
    					.newInstance();
    			ArrayOfstring genesIdList = ArrayOfstring.Factory.newInstance();
    			// add items to ArrayOfstring, but how?
    			getPathwaysByGenes.setGenesIdList(genesIdList);
    			GetPathwaysByGenesDocument get_pathways_by_genes = GetPathwaysByGenesDocument.Factory
    					.newInstance();
    			get_pathways_by_genes.setGetPathwaysByGenes(getPathwaysByGenes);
    			try {
    				GetPathwaysByGenesResponseDocument res = stub
    						.get_pathways_by_genes(get_pathways_by_genes);
    				System.err.println(res.getGetPathwaysByGenesResponse()
    						.getReturn());
    			} catch (RemoteException e) {
    				// TODO Auto-generated catch block
    				e.printStackTrace();
    			}
    
    		} catch (AxisFault e) {
    			// TODO Auto-generated catch block
    
    			e.printStackTrace();
    		}
    
    	}
    }


----------
And another edit, after trying the Brenda WSDL with axis2 wsdl2code, the result is not 
very promising:
...
SEVERE: The binding operation getKeggPathway is RPC/literal. The message parts for this operation must use the type attribute as specificed by WS-I Basic Profile specification (4.4.1).  Message part, ecNumber, violatesthis rule.  Please remove the element attribute and use the type attribute.
...

So, if somebody has a better answer, including asking the service providers to adhere to standards. Apologies for testing after answering.... 





  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar
  [2]: http://www.genome.jp/kegg/soap/
  [3]: http://www.brenda-enzymes.org/soap/
  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language
  [5]: http://ws.apache.org/axis2/
  [6]: http://en.wikipedia.org/wiki/SOAP
  [7]: http://www.genome.jp/kegg/soap/support/keggapi.jar
  [8]: http://www.brenda-enzymes.org/soap/brenda.wsdl</Text>
  </row>
  <row>
    <Id>475</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>255</PostId>
    <RevisionGUID>5ca64514-2458-493a-b808-1e87aad7b2e9</RevisionGUID>
    <CreationDate>2010-03-10T21:26:16.72</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>Let's say I extract something like this from a qseq or FASTQ file

    TTCAGATGTTCATATGCGGATCGGCGCTGGGCCCACGAGATCTAGCAGAGCTCGT.GGGACCACGACCACCGACCC
    a`bbbbbbaabbab`ab^`bVa^^bab^[``bba^`]_Ya^`_`^^_Xa\_KYTYD[PY^Y_^[P[V_BBBBBBBB

So the dot is like an N - it can't call the base. So if I look at the FASTQ scores in integer format I would expect that position to have a minimal score. But in fact its score is 'D' or 4, not great but some other called bases at the tail end are 'B' or 2. What gives?</Text>
  </row>
  <row>
    <Id>476</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>255</PostId>
    <RevisionGUID>5ca64514-2458-493a-b808-1e87aad7b2e9</RevisionGUID>
    <CreationDate>2010-03-10T21:26:16.72</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>How can a base-called position be "unknown" but have a non-minimal score?</Text>
  </row>
  <row>
    <Id>477</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>255</PostId>
    <RevisionGUID>5ca64514-2458-493a-b808-1e87aad7b2e9</RevisionGUID>
    <CreationDate>2010-03-10T21:26:16.72</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text> ébaseöcallingà  éphredà  éfastqà  ébustardà </Text>
  </row>
  <row>
    <Id>478</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>256</PostId>
    <RevisionGUID>a865c74c-6b5a-455e-8ac8-c1fff93be6db</RevisionGUID>
    <CreationDate>2010-03-10T23:46:35.47</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text>I have a plate of colonies to sequence.  I pick 2 colonies and sequence each in Fwd and Rev directions.   I get back a single bp difference between the 2 strands.  2 bp have an T, two have a C.   How should I call this base?  Can I call it a Y (C or T) and leave it at that, or do I need to sequence another colony to be sure? 
</Text>
  </row>
  <row>
    <Id>479</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>256</PostId>
    <RevisionGUID>a865c74c-6b5a-455e-8ac8-c1fff93be6db</RevisionGUID>
    <CreationDate>2010-03-10T23:46:35.47</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text>If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?</Text>
  </row>
  <row>
    <Id>480</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>256</PostId>
    <RevisionGUID>a865c74c-6b5a-455e-8ac8-c1fff93be6db</RevisionGUID>
    <CreationDate>2010-03-10T23:46:35.47</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text> ésequencingà  édnaà </Text>
  </row>
  <row>
    <Id>481</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>257</PostId>
    <RevisionGUID>f5ff37f0-3a53-41cd-9e89-0503c07da364</RevisionGUID>
    <CreationDate>2010-03-11T01:09:56.457</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>Sounds like your trying to find genes which actually switch from on-to-off (or vice-versa) based on cell-type, condition, etc.  Not all genes have this type of behavior ... some are graded (like a dimer switch).  There are numerous papers that discuss techniques for finding genes which have "bi-modal" expression patterns.  Since they are a mixture of two expressions patterns it is likely that they have "on" and "off" pattern.

This article explain the technique and includes Matlab code that should do the whole thing for you.

[Human and mouse switch-like genes share common transcriptional regulatory mechanisms for bimodality.][1]


  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19105848</Text>
  </row>
  <row>
    <Id>482</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>258</PostId>
    <RevisionGUID>c2dd81af-78d1-48f3-91ef-f1ce4844833a</RevisionGUID>
    <CreationDate>2010-03-11T01:27:26.25</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>Does anyone know of a good gene-id conversion tool written in Python.  I've come across numerous webtools but I'd like something a little more automated.  I have the knowledge/ability to do it myself I was just wondering if there was something already out there.  There's no point in re-inventing the wheel each time.

Thanks in advance</Text>
  </row>
  <row>
    <Id>483</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>258</PostId>
    <RevisionGUID>c2dd81af-78d1-48f3-91ef-f1ce4844833a</RevisionGUID>
    <CreationDate>2010-03-11T01:27:26.25</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>Programatic technique for gene-name/id conversion</Text>
  </row>
  <row>
    <Id>484</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>258</PostId>
    <RevisionGUID>c2dd81af-78d1-48f3-91ef-f1ce4844833a</RevisionGUID>
    <CreationDate>2010-03-11T01:27:26.25</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text> épythonà  égeneidà  éconversionà </Text>
  </row>
  <row>
    <Id>485</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>259</PostId>
    <RevisionGUID>a728fe9f-7d01-435e-9e16-dc06de105d81</RevisionGUID>
    <CreationDate>2010-03-11T01:50:51.117</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>I've started using [PiCloud][1].  It is a super simple library for Python that facilitates running your code in the cloud.  The client will copy your interpreter's state and then run the code on their Amazon EC2 cluster.  They then charge you based on your program's run time.  They're currently doing beta trials so its actually free (for now).

The only disadvantage is that they abstract everything away from you ... so its actually impossible to run on your own Amazon EC2 cluster.  Its also virtually impossible to run anything that's not Python.

But overall I've found it really easy to implement some of my algorithms using their client.


  [1]: http://www.picloud.com/</Text>
  </row>
  <row>
    <Id>486</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>260</PostId>
    <RevisionGUID>42f1b415-50fc-407c-8b91-23b89b89333a</RevisionGUID>
    <CreationDate>2010-03-11T03:36:20.343</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>You could automate the access to the website with Python ;-)</Text>
  </row>
  <row>
    <Id>487</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>261</PostId>
    <RevisionGUID>9ef213c0-5e34-4f38-a188-4f984b9f368b</RevisionGUID>
    <CreationDate>2010-03-11T03:59:56.843</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I recall a situation where one of our students (Gue-Su Chang) tracked down a few undocumented behaviors in the Illumina pipeline. Basically once the basecalling is done there are additional filters applied during post-processing to handle a few odd cases. This might be on of those, the score D refers to the original call, but  later that gets overridden by another step. I know that's pretty vague. Long story short: I think the score does not apply here.
 </Text>
  </row>
  <row>
    <Id>488</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>262</PostId>
    <RevisionGUID>63270e80-aede-45ff-9db4-485dd8b4f50f</RevisionGUID>
    <CreationDate>2010-03-11T04:16:58.343</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I think combining the quality score is not the intended use case for the p-values. The quality scores refer to the probability of a basecall being incorrect. So during assembly it is an important information. 

But once the reads are assembled if we were to keep it, it would need to reflect not just the chance of one base being wrong but that for an entire overlap to occur by chance. That is a different quantity than the original.

This is just an opinion, I could be wrong.
</Text>
  </row>
  <row>
    <Id>489</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>263</PostId>
    <RevisionGUID>1cd4a2e7-3e0d-425e-8ccd-baf9f0cc4b7d</RevisionGUID>
    <CreationDate>2010-03-11T05:03:27.967</CreationDate>
    <IPAddress>70.240.206.216</IPAddress>
    <UserId>117</UserId>
    <Text>There are lots of factors to consider here:

1) What do the quality scores tell you about the base call at that position?

2) How deep is your coverage?  If you've got 1x coverage, it's possible that you may be seeing a miscalled base. If you're taking consensus from 30x coverage, it's much less likely.

3) You're sequencing from a population. It's completely possible that within this population there are individuals with both alleles that you're describing, right?</Text>
  </row>
  <row>
    <Id>490</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>264</PostId>
    <RevisionGUID>e4b58335-1e58-4318-a3e3-36ce01858ec1</RevisionGUID>
    <CreationDate>2010-03-11T05:42:31.26</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>As chrisamiller says, it depends on the details of what you're trying to do. **The question is whether what you're seeing is variation due to technical error or due to biological variation.** 

However, without any additional information, if you've essentially only got 2 reads per sequence with contradicting information at a given position, you can't really call the base with any degree of certainty. In this case, the use of an ambiguity base call (i.e. Y instead of C or T) would be justified, in my view.</Text>
  </row>
  <row>
    <Id>491</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>265</PostId>
    <RevisionGUID>9a8dba29-d778-498d-9060-4c5d031bd734</RevisionGUID>
    <CreationDate>2010-03-11T08:39:15.9</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>I agree with chrisamiller and PhiS. I'll just add that it also ***greatly depends on what you will do with your sequence***.

I understand from your question that:

  * You have picked only 2 [bacterial] colonies for sequencing
  * These colonies result from the cloning of a PCR product (?)
  * They were sequenced using Sanger sequencing

[NOTE: when describing your problem it is very important to give these kind of details, so please correct me if my assumptions are wrong.]

I am guessing that:

  * You might want to check that the sequence is correct (maybe verifying that your qPCR product is correct)?
  * You might be cloning a gene (or fragment thereof) in order to express a protein?

[NOTE: here again, these kind of details are crucial in determining if you can accept an ambiguous base or not. Please add a comment or edit your post if it is yet another purpose]

Finally, as Istvan has asked, you need to be clear as to what the difference is: are you looking at a different base call ***between the two sequenced colonies*** or ***between the forward and reverse sequencing events***?

If it is the first (i.e. difference between the two colonies) then you need to check the quality of the call at that base (quality scores if you have them, or look at the chromatogram to see if there's a mistake or a double pic etc.). If they are good quality, then you probably have at least these two different variants of the sequence you're targeting.

If it is the second (i.e. difference between the forward and reverse) then you should also look at the quality in each read. If they are bad quality, sequence again. If they are good quality, then I'm scratching my head making a funny face. Start over from scratch.

Now to your question about leaving it ambiguous or not: 

  * If you just wanted to check that the sequence is "fairly" OK, then fine, leave it as a Y.
  * If you're checking the amplicon of a qPCR event, then it is crucial to know if you have only one sequence or two different ones (even if it's a SNP). This will change your interpretation.
  * If you want to express a protein from this sequence, then you need to check if the difference (T or C) changes the resulting protein sequence: if yes, you need to choose the correct clone. If not, you can go with either.

</Text>
  </row>
  <row>
    <Id>492</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>266</PostId>
    <RevisionGUID>4ebb15b5-4ebb-4701-b668-d3e81584fc09</RevisionGUID>
    <CreationDate>2010-03-11T11:03:45.743</CreationDate>
    <IPAddress>128.240.229.3</IPAddress>
    <UserId>38</UserId>
    <Text>Writing a small tool to automate access to the website/service is pretty simple. Here's a method I wrote for the UniProt ID mapping service:

    import urllib
    import urllib2
    
    def uniprot_mapping(fromtype, totype, identifier):
        base = 'http://www.uniprot.org'
        tool = 'mapping'
        params = {'from':fromtype,
                    'to':totype,
                    'format':'tab',
                    'query':identifier,
        }
        data = urllib.urlencode(params)
        url = base+'/'+tool+'?'+data
        response = urllib2.urlopen(url)
        return response.read()

It's not extensively tested, but should work. You can find a list of fromtypes and totypes here: [http://www.uniprot.org/faq/28#id_mapping_examples][1]


  [1]: http://www.uniprot.org/faq/28#id_mapping_examples</Text>
  </row>
  <row>
    <Id>493</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>267</PostId>
    <RevisionGUID>e2d91f3a-5cbb-4162-b903-fb342137d1b4</RevisionGUID>
    <CreationDate>2010-03-11T11:19:47.743</CreationDate>
    <IPAddress>128.240.229.3</IPAddress>
    <UserId>38</UserId>
    <Text>The [BiNGO plugin][1] for [Cytoscape][2] will allow you to determine term enrichment in a Cytoscape network. It's quite a neat tool.


  [1]: http://www.psb.ugent.be/cbd/papers/BiNGO/
  [2]: http://www.cytoscape.org/</Text>
  </row>
  <row>
    <Id>494</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>245</PostId>
    <RevisionGUID>0e87d516-6f94-4685-bce7-9c96b0e3648c</RevisionGUID>
    <CreationDate>2010-03-11T18:04:52.15</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneontologyà  éenrichmentà  étoolà  égoà </Text>
  </row>
  <row>
    <Id>495</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>268</PostId>
    <RevisionGUID>45ef306b-536e-406a-9874-53f9d86e90da</RevisionGUID>
    <CreationDate>2010-03-12T09:52:17.88</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text>What podcasts are the bioinformaticians here listening to that tie in with their work?  

The most relevant podcast that I know of (the currently even more irregular than normal) [Coast to Coast Bio Podcast][1] is still in my list of podcasts.

For programming related topics I still find the [StackOverflow podcast][2] an interesting and engaging listen.

Whilst at one point or another I subscribed to both [Nature][3] and [Science][4] podcasts for general science I no longer do so.

What podcasts might I be missing out on that other people are enjoying related to their work?


  [1]: http://www.c2cbio.com/
  [2]: http://blog.stackoverflow.com/category/podcasts/
  [3]: http://www.nature.com/nature/podcast/
  [4]: http://www.sciencemag.org/about/podcast.dtl</Text>
  </row>
  <row>
    <Id>496</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>268</PostId>
    <RevisionGUID>45ef306b-536e-406a-9874-53f9d86e90da</RevisionGUID>
    <CreationDate>2010-03-12T09:52:17.88</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text>Appropriate podcasts for a bioinformatician?</Text>
  </row>
  <row>
    <Id>497</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>268</PostId>
    <RevisionGUID>45ef306b-536e-406a-9874-53f9d86e90da</RevisionGUID>
    <CreationDate>2010-03-12T09:52:17.88</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text> épodcastà  ésubjectiveà  érecommendationsà </Text>
  </row>
  <row>
    <Id>498</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>269</PostId>
    <RevisionGUID>c8e916ec-07c4-485e-b798-695d13bb2f97</RevisionGUID>
    <CreationDate>2010-03-12T11:47:06.28</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Text>That is a great question. I am not aware of any podcast or vodcast(video) that specifically cover  bioinformatics topics so far.
But there are other services that provide bioinformatics content in a audio-visual form:

http://www.scivee.tv/

http://videolectures.net/Top/Computer_Science/Bioinformatics/

http://www.bioscreencast.com/

</Text>
  </row>
  <row>
    <Id>499</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>268</PostId>
    <RevisionGUID>603f0dbc-4e90-43a5-8b7c-1b24ae17f891</RevisionGUID>
    <CreationDate>2010-03-12T11:47:29.027</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Comment>edited tags</Comment>
    <Text> épodcastà  ésubjectiveà  érecommendationsà  évodcastà </Text>
  </row>
  <row>
    <Id>500</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>270</PostId>
    <RevisionGUID>31774f20-f92c-4aa3-9d3a-c8f9598577ac</RevisionGUID>
    <CreationDate>2010-03-12T11:55:57.857</CreationDate>
    <IPAddress>128.240.229.3</IPAddress>
    <UserId>38</UserId>
    <Text>Related, but not bioinformatics, BBC podcasts:

 - Material World - popsci http://www.bbc.co.uk/podcasts/series/material/
 - More or Less - statistics etc. http://www.bbc.co.uk/podcasts/series/moreorless

Both have very good presenters, and make for an entertaining listen.</Text>
  </row>
  <row>
    <Id>501</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>271</PostId>
    <RevisionGUID>8b7e8692-f3c2-44e6-9688-774c2770cb3b</RevisionGUID>
    <CreationDate>2010-03-12T13:58:39.043</CreationDate>
    <IPAddress>79.176.54.137</IPAddress>
    <UserId>125</UserId>
    <Text>(Sorry for the long header)

Hello all.

I wish to have a FASTA file (or similar) of a tRNA sequences that are aligned.

Here is an example of a FASTA file I would like to align:

http://gtrnadb.ucsc.edu/Aero_pern/aerPer1-tRNAs.fa

Here is how the sequence would look aligned:

http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-align.html

It uses a software called COVE, which can be found here:

http://selab.janelia.org/software.html

And it is said to do it by doing: "Structural alignments are generated by aligning tRNA sequences against domain-specific tRNA covariance models with the use of COVE."

Which leads me to my questions:

1. Where might I find the "domain-specific tRNA" to run the COVE model with ?
2. How can I do this on windows ?
3. Is there a better way to do this alignment ?


This is my first question, and I am very new to bioinformatics, so I am sorry if I am missing something very basic, or am asking something to which not many people would know to answer.

Thanks in advance,

Tal
</Text>
  </row>
  <row>
    <Id>502</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>271</PostId>
    <RevisionGUID>8b7e8692-f3c2-44e6-9688-774c2770cb3b</RevisionGUID>
    <CreationDate>2010-03-12T13:58:39.043</CreationDate>
    <IPAddress>79.176.54.137</IPAddress>
    <UserId>125</UserId>
    <Text>How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?</Text>
  </row>
  <row>
    <Id>503</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>271</PostId>
    <RevisionGUID>8b7e8692-f3c2-44e6-9688-774c2770cb3b</RevisionGUID>
    <CreationDate>2010-03-12T13:58:39.043</CreationDate>
    <IPAddress>79.176.54.137</IPAddress>
    <UserId>125</UserId>
    <Text> érnaöseqà  éalignmentà  étrnaà </Text>
  </row>
  <row>
    <Id>504</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>271</PostId>
    <RevisionGUID>8216fb8d-4ab9-460d-91e6-cfbdd73ea33a</RevisionGUID>
    <CreationDate>2010-03-12T14:15:23.83</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Comment>edited tags</Comment>
    <Text> éalignmentà  étrnaà  ésequenceà </Text>
  </row>
  <row>
    <Id>505</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>272</PostId>
    <RevisionGUID>b42ab34a-64cf-414e-9071-6d50d2db1b2e</RevisionGUID>
    <CreationDate>2010-03-12T14:17:58.287</CreationDate>
    <IPAddress>218.186.8.241</IPAddress>
    <UserId>91</UserId>
    <Text>I enjoy [Futures in Biotech][1], which is about life science in general but does touch on bioinformatics sometimes.


  [1]: http://twit.tv/FIB</Text>
  </row>
  <row>
    <Id>506</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>273</PostId>
    <RevisionGUID>e75939a4-40e9-47fb-864a-9ff36057f653</RevisionGUID>
    <CreationDate>2010-03-12T15:51:14.59</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text> 1. The site is a little short on information but it gave me the impression that it will build the covariance model from the multiple sequence alignment itself. Try contacting the author for more information.
 2. You can compile cove on Windows under [Cygwin][1], I just gave it a try and compiled it with no problem.


  [1]: http://www.cygwin.com/</Text>
  </row>
  <row>
    <Id>507</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>274</PostId>
    <RevisionGUID>df80a50e-134f-475d-8e04-8cddca59e86a</RevisionGUID>
    <CreationDate>2010-03-12T16:23:51.153</CreationDate>
    <IPAddress>70.240.224.191</IPAddress>
    <UserId>117</UserId>
    <Text>It's not bioinformatic-specific, but &lt;a href="http://www.wnyc.org/shows/radiolab/"&gt;RadioLab&lt;/a&gt; is a great science show. I especially like listening on days when I'm frustrated with my work - it helps me remember why I have a passion for science.</Text>
  </row>
  <row>
    <Id>508</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>275</PostId>
    <RevisionGUID>3712787b-c466-4ec8-884f-ec215fc1aa1d</RevisionGUID>
    <CreationDate>2010-03-12T16:24:10.387</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>I had a quick look into the documentation of the software. If you donwload and unpack the soucecode archive, there is a Guide.tex file that can be compiled with Latex, you could look into this. So, to answer your questions partially without trying anything myself: 
 
1. Where do I find the covariance Models to run COVE with? As Istvan said: you have to make them yourself. From the manual:
Using these programs, you can:
 - generate new models, by training them on example sequences (covet) ....

2. See Istvan's answer
3. Possibly not:

    The tRNA identification program  tRNAscan-SE is based on a tRNA CM and COVE  (Lowe and Eddy, 1997). 

And this program is still state-of-the art in tRNA discovery. If you want to look at RNAs in general an learn about their structure then [Rfam][1]/Infernal is nice.

If you are interested in RNA structure and visualization the [BiBiServ RNA-Studio][2] are an interesting resource.


  [1]: http://rfam.janelia.org/
  [2]: http://bibiserv.techfak.uni-bielefeld.de/bibi/Tools_RNA_Studio.html</Text>
  </row>
  <row>
    <Id>509</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>276</PostId>
    <RevisionGUID>4a8c45ac-3428-45d7-b402-2d7f5abc1c35</RevisionGUID>
    <CreationDate>2010-03-12T16:31:28.313</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>There is a recent review:

Computational analysis of tRNA identity
FEBS Letters, Volume 584, Issue 2, Pages 325-333

D. Ardell

http://dx.doi.org/10.1016/j.febslet.2009.11.084

You may check if COVE is your only option. </Text>
  </row>
  <row>
    <Id>510</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>277</PostId>
    <RevisionGUID>daf81858-bb3b-4aab-b790-e8812abac040</RevisionGUID>
    <CreationDate>2010-03-12T17:04:23.863</CreationDate>
    <IPAddress>74.136.87.193</IPAddress>
    <UserId>53</UserId>
    <Text>I'd like to visualise the results of a BLAST search in a genome browser. Is there a simple way to get the results in GFF format without having to write a parser myself?</Text>
  </row>
  <row>
    <Id>511</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>277</PostId>
    <RevisionGUID>daf81858-bb3b-4aab-b790-e8812abac040</RevisionGUID>
    <CreationDate>2010-03-12T17:04:23.863</CreationDate>
    <IPAddress>74.136.87.193</IPAddress>
    <UserId>53</UserId>
    <Text>How to convert BLAST results to GFF</Text>
  </row>
  <row>
    <Id>512</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>277</PostId>
    <RevisionGUID>daf81858-bb3b-4aab-b790-e8812abac040</RevisionGUID>
    <CreationDate>2010-03-12T17:04:23.863</CreationDate>
    <IPAddress>74.136.87.193</IPAddress>
    <UserId>53</UserId>
    <Text> éblastà  égffà  éformatà </Text>
  </row>
  <row>
    <Id>513</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>278</PostId>
    <RevisionGUID>4ca70705-30c7-48d2-9284-c9e4cb80a46f</RevisionGUID>
    <CreationDate>2010-03-12T17:07:53.093</CreationDate>
    <IPAddress>74.136.87.193</IPAddress>
    <UserId>53</UserId>
    <Text>I like [The Changelog][1]. It highlights interesting and useful open source software with a slight ruby slant.


  [1]: http://thechangelog.com/</Text>
  </row>
  <row>
    <Id>514</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>279</PostId>
    <RevisionGUID>9ef490ea-b8bc-4376-8606-cc8d72699b12</RevisionGUID>
    <CreationDate>2010-03-12T17:18:08.063</CreationDate>
    <IPAddress>82.126.15.73</IPAddress>
    <UserId>30</UserId>
    <Text>I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl

else I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet.

</Text>
  </row>
  <row>
    <Id>515</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>279</PostId>
    <RevisionGUID>312ac5c4-8d8f-45e9-abbc-35424731890d</RevisionGUID>
    <CreationDate>2010-03-12T17:19:28.983</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>30</UserId>
    <Text>[{"Id":30,"DisplayName":"Pierre Lindenbaum"}]</Text>
  </row>
  <row>
    <Id>516</Id>
    <PostHistoryTypeId>13</PostHistoryTypeId>
    <PostId>279</PostId>
    <RevisionGUID>8e9036ca-26ed-4ea0-a09c-49a1a4862942</RevisionGUID>
    <CreationDate>2010-03-12T17:19:58</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>30</UserId>
    <Text>[{"Id":30,"DisplayName":"Pierre Lindenbaum"}]</Text>
  </row>
  <row>
    <Id>517</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>280</PostId>
    <RevisionGUID>b0799325-bdcb-4a93-a354-263e1b1b62e0</RevisionGUID>
    <CreationDate>2010-03-12T17:29:05.093</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Have you tried these scripts: http://gmod.org/wiki/Load_BLAST_Into_Chado, http://www.bioperl.org/pipermail/bioperl-l/2002-November/010223.html ??

maybe the [PSL][1] format is better to represent an alignment. You can also look at the [BED][2] format so later you can play with [BedTools][3]


  [1]: http://genome.ucsc.edu/FAQ/FAQformat.html#format2
  [2]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1
  [3]: http://code.google.com/p/bedtools/</Text>
  </row>
  <row>
    <Id>518</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>279</PostId>
    <RevisionGUID>82df7699-7d00-496d-92dc-588e9321a466</RevisionGUID>
    <CreationDate>2010-03-12T17:29:14.903</CreationDate>
    <IPAddress>82.126.15.73</IPAddress>
    <UserId>30</UserId>
    <Comment>blast2svg</Comment>
    <Text>I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl

else I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl
Pierre

</Text>
  </row>
  <row>
    <Id>519</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>281</PostId>
    <RevisionGUID>819dbc96-140c-4129-8da5-749549bdcc9d</RevisionGUID>
    <CreationDate>2010-03-12T18:12:04.103</CreationDate>
    <IPAddress>88.18.100.189</IPAddress>
    <UserId>62</UserId>
    <Text>Start with tabulated blast output myfile.blast.out. Then check two-liners from:

http://bergman-lab.blogspot.com/2009/12/ncbi-blast-tabular-output-format-fields.html

Few lines tooutput proper gff are missing, but you may either go for minimalistic gff or try to encode everything in column 9. Also you may try validating your gff3 here:

http://modencode.oicr.on.ca/cgi-bin/validate_gff3_online

</Text>
  </row>
  <row>
    <Id>520</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>268</PostId>
    <RevisionGUID>71eb8714-cfac-47d4-ac43-c1788a3c8c6c</RevisionGUID>
    <CreationDate>2010-03-12T18:28:58.813</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
  </row>
  <row>
    <Id>521</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>282</PostId>
    <RevisionGUID>5e7221b3-fb4a-4172-9256-b2d9a86b069a</RevisionGUID>
    <CreationDate>2010-03-13T04:51:33.373</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>In case anyone comes by this later I've made a simple python module for doing this sort of converting.  You can find it on GitHub: http://github.com/JudoWill/IDConverter

Feel free make comments and provide suggestions.</Text>
  </row>
  <row>
    <Id>522</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>283</PostId>
    <RevisionGUID>caf7f687-f380-4bdc-afd1-776de8a633e6</RevisionGUID>
    <CreationDate>2010-03-13T15:46:57.08</CreationDate>
    <IPAddress>189.27.208.118</IPAddress>
    <UserId>31</UserId>
    <Text>To clarify, I am a biochemist, trained in molecular evolution since undergrad and I changed my particular field of work to large scale phylogenetic analysis in the grad school. 

So, to me, building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield (actually, this should be be trivial to any people with a background in biology), but to integrate functional data and increase the scale of the analysis to whole genomes and dozen/hundreds of species would be a little more challenging. 

I am really curious since bioinformatics and computational biology has had a fast growing in the last years, many paradigms have changed in what is trivial and what is challenging in his many subfields. </Text>
  </row>
  <row>
    <Id>523</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>283</PostId>
    <RevisionGUID>caf7f687-f380-4bdc-afd1-776de8a633e6</RevisionGUID>
    <CreationDate>2010-03-13T15:46:57.08</CreationDate>
    <IPAddress>189.27.208.118</IPAddress>
    <UserId>31</UserId>
    <Text>What do you consider the most trivial and the most challenging tasks in your particular field of work?</Text>
  </row>
  <row>
    <Id>524</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>283</PostId>
    <RevisionGUID>caf7f687-f380-4bdc-afd1-776de8a633e6</RevisionGUID>
    <CreationDate>2010-03-13T15:46:57.08</CreationDate>
    <IPAddress>189.27.208.118</IPAddress>
    <UserId>31</UserId>
    <Text> écareerà  ésubjectiveà </Text>
  </row>
  <row>
    <Id>525</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>284</PostId>
    <RevisionGUID>12e9df2a-3eb0-4818-9c54-028439de2613</RevisionGUID>
    <CreationDate>2010-03-13T16:41:18.4</CreationDate>
    <IPAddress>81.53.110.5</IPAddress>
    <UserId>30</UserId>
    <Text>**Challenging**:

 - Using other's code
 - understanding why a technology/paper/language/db is worth looking/testing
 - understanding theoretical papers
 - making my code reusable
 - being my own learning mentor
 - working with 'big-data'
 - (...)

**Trivial**:

  - working with 'big-data' :-)
  - Using SQL/C/C++/Java/etc... etc...
  - using some common resources related to by field (dbsnp...)
  - Parsing data
  - sharing
  - (...)</Text>
  </row>
  <row>
    <Id>526</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>285</PostId>
    <RevisionGUID>a0149c65-9e24-42c6-85fc-ed4083b6b203</RevisionGUID>
    <CreationDate>2010-03-13T17:33:54.8</CreationDate>
    <IPAddress>128.249.106.234</IPAddress>
    <UserId>117</UserId>
    <Text>Off the top of my head:

**Challenging and frustrating:**  

 - Sifting through the avalanche of new
   papers and tools to find ones that
   are immediately relevant  

**Challenging and interesting:**  

 - Given whole-genome assays, deciding which
   of the hundreds of mutations are
   important and potentially causative
 -  Integrating results from assays that
   provide different insights and
   potentially conflicting information.
 - writing code using a parallel (or map/reduce) paradigm, so that it won't take years to run

**Trivial, but tedious:**  

 - constantly munging data files from one poorly defined format to another
</Text>
  </row>
  <row>
    <Id>527</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>286</PostId>
    <RevisionGUID>a0efa30d-f77c-4c31-afbe-5ca3def1dfff</RevisionGUID>
    <CreationDate>2010-03-13T20:46:52.04</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>
&gt;  http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl

You can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:

    # BLASTN 2.2.21 [Jun-14-2009]
    # Query: 16383 sequences
    # Database: genomedata/GenomeOfDeath.fas
    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score
    GeneOfDeath  GenomeOfDeath  100.00  295     0       0       1       295     152626  152920  4e-168   585


So, one should filter out lines beginning with "#" and it does no harm to skip lines which 
are empty or contain only white spaces.

So edit the file Blast2Gff.pl: in line 149 add:

     next if (/^\#/ || /^\s*$/); # filter comments and empty lines

Such that this part looks like below, than try again.

    while (&lt;BLASTIN&gt;)
    {

      next if (/^\#/ || /^\s*$/); # filter comments and empty lines

	$HitNum++;
   
	my ($QryId, $SubId, $PID, $Len, 
	    $MisMatch, $GapOpen, 
	    $QStart,$QEnd, $SStart, $SEnd,
	    $EVal, $BitScore) = split(/\t/);




</Text>
  </row>
  <row>
    <Id>528</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>286</PostId>
    <RevisionGUID>1ef3db83-e014-4b7b-ac7d-fad4f5cf341c</RevisionGUID>
    <CreationDate>2010-03-13T20:55:45.343</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>deleted 2 characters in body</Comment>
    <Text>&gt;  http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl

You can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:

    # BLASTN 2.2.21 [Jun-14-2009]
    # Query: 16383 sequences
    # Database: genomedata/GenomeOfDeath.fas
    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score
    GeneOfDeath  GenomeOfDeath  100.00  295     0       0       1       295     152626  152920  4e-168   585


So, one should filter out lines beginning with "#" and it does no harm to skip lines which 
are empty or contain only white spaces.

So edit the file Blast2Gff.pl: in line 149 add:

     next if (/^\#/ || /^\s*$/); # filter comments and empty lines

Such that this part looks like below, then try again.

    while (&lt;BLASTIN&gt;)
    {

      next if (/^\#/ || /^\s*$/); # filter comments and empty lines

	$HitNum++;
   
	my ($QryId, $SubId, $PID, $Len, 
	    $MisMatch, $GapOpen, 
	    $QStart,$QEnd, $SStart, $SEnd,
	    $EVal, $BitScore) = split(/\t/);




</Text>
  </row>
  <row>
    <Id>529</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>287</PostId>
    <RevisionGUID>ee27dbe1-f128-4ea3-bce7-dac5db56de19</RevisionGUID>
    <CreationDate>2010-03-14T16:26:35.403</CreationDate>
    <IPAddress>74.96.187.21</IPAddress>
    <UserId>131</UserId>
    <Text>Can anybody point me to a resource that provides information on functionally redundant genes? I have been pointed towards the use of GOA (http://www.ebi.ac.uk/GOA/) as one approach. Would this provide sufficient 'resolution' to identify functionally equivalent genes? My thinking is that if two genes share the same GO term and the GO term is a leaf node, that might be useful. 

Any pointers would be appreciated</Text>
  </row>
  <row>
    <Id>530</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>287</PostId>
    <RevisionGUID>ee27dbe1-f128-4ea3-bce7-dac5db56de19</RevisionGUID>
    <CreationDate>2010-03-14T16:26:35.403</CreationDate>
    <IPAddress>74.96.187.21</IPAddress>
    <UserId>131</UserId>
    <Text>A resource to identify functionally redundant genes</Text>
  </row>
  <row>
    <Id>531</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>287</PostId>
    <RevisionGUID>ee27dbe1-f128-4ea3-bce7-dac5db56de19</RevisionGUID>
    <CreationDate>2010-03-14T16:26:35.403</CreationDate>
    <IPAddress>74.96.187.21</IPAddress>
    <UserId>131</UserId>
    <Text> égeneà  éfunctionà  édatabaseà  éredundancyà </Text>
  </row>
  <row>
    <Id>532</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>288</PostId>
    <RevisionGUID>62951519-eb77-43b1-9537-a2d0b220b493</RevisionGUID>
    <CreationDate>2010-03-14T16:38:32.933</CreationDate>
    <IPAddress>70.240.224.191</IPAddress>
    <UserId>117</UserId>
    <Text>What exactly do you mean by functional redundancy? 

- Two proteins may both metabolize some sugar, but send different products down different pathways. Are they redundant?
- Two different pathways can be used to produce the same end product from some metabolite.  Are all of the genes in these two pathways redundant? 
- What about proteins that have multiple functions? How do you handle _partial_ redundancy?

My take:  
There are no solid and complete answers to these questions at this point, but I think you could justify using GO terms of a certain depth, as you suggest. Just justify your assumptions, acknowledge that any such attempt is going to be full of errors and omissions, and be careful about  drawing too many hard conclusions from the results.</Text>
  </row>
  <row>
    <Id>533</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>289</PostId>
    <RevisionGUID>f92450ca-ac50-43cb-97b1-af0f346817d8</RevisionGUID>
    <CreationDate>2010-03-15T00:32:45.38</CreationDate>
    <IPAddress>161.65.16.253</IPAddress>
    <UserId>135</UserId>
    <Text>From the same people as Futures in Biotech: [Floss weekly][1]. About free &amp; open software, they had an [episode][2] on Bioperl a while ago.


  [1]: http://twit.tv/FLOSS
  [2]: http://twit.tv/floss96</Text>
  </row>
  <row>
    <Id>534</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>289</PostId>
    <RevisionGUID>f92450ca-ac50-43cb-97b1-af0f346817d8</RevisionGUID>
    <CreationDate>2010-03-15T00:32:45.38</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>535</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>290</PostId>
    <RevisionGUID>7e96f778-4da1-4e35-8e2c-1a534f1aab54</RevisionGUID>
    <CreationDate>2010-03-15T07:11:09.197</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>*Bringing in my questions from [stackoverflow][1]:*



I'm working on a small application and thinking about integrating BLAST or other local alignment searches into my application. My searching has only brought up programs, which need to be installed and called as an external program.

Is there a way short of me implementing it from scratch? Any pre-made library perhaps?


  [1]: http://stackoverflow.com/questions/1432467/performing-blast-smithwaterman-searches-directly-from-my-application</Text>
  </row>
  <row>
    <Id>536</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>290</PostId>
    <RevisionGUID>7e96f778-4da1-4e35-8e2c-1a534f1aab54</RevisionGUID>
    <CreationDate>2010-03-15T07:11:09.197</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>Performing BLAST/SmithWaterman searches directly from my application</Text>
  </row>
  <row>
    <Id>537</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>290</PostId>
    <RevisionGUID>7e96f778-4da1-4e35-8e2c-1a534f1aab54</RevisionGUID>
    <CreationDate>2010-03-15T07:11:09.197</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text> éblastà  écççà  émpià  ésequenceà </Text>
  </row>
  <row>
    <Id>538</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>291</PostId>
    <RevisionGUID>3795e686-c4ff-4829-8288-7ce171c51453</RevisionGUID>
    <CreationDate>2010-03-15T07:12:01.033</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>I found the [NCBI C++ Toolkit][1] to be quite useful.


  [1]: http://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/</Text>
  </row>
  <row>
    <Id>539</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>292</PostId>
    <RevisionGUID>b909339b-32e5-4b20-b14b-d9e1cf3c60db</RevisionGUID>
    <CreationDate>2010-03-15T12:12:24.317</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>Also the [SeqAn][1] C++ library may be useful to some.


  [1]: http://www.seqan.de/ </Text>
  </row>
  <row>
    <Id>540</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>293</PostId>
    <RevisionGUID>80cd1c38-43b1-4471-a860-06a3cba565d4</RevisionGUID>
    <CreationDate>2010-03-15T15:02:35.26</CreationDate>
    <IPAddress>128.143.18.68</IPAddress>
    <UserId>138</UserId>
    <Text>These are the big challenge(s) for me:
 
 1. Ask the relevant questions and find/develop the proper/satisfactory solutions to obtain meaningful results.
 2. Determine what is relevant (what really matters).
 3. Understand what and why is proper, merely sufficient or unsatisfactory.
 4. Interpret the results without bias and preconceptions.
 

 


</Text>
  </row>
  <row>
    <Id>541</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>294</PostId>
    <RevisionGUID>87847ed6-1e97-4066-85da-2b81b7e02b1b</RevisionGUID>
    <CreationDate>2010-03-15T16:56:44.477</CreationDate>
    <IPAddress>170.223.185.126</IPAddress>
    <UserId>35</UserId>
    <Text>**Trivial**

 - Creating lists of genes that might be of interest in a given system
 - Integrating several experiments with one kind of data
 - Talking with people in my own sub-disciplines of biology
 - Thinking of cool experiments to do

**Challenging**

 - Determining which genes in a list are important for a process and integrating those genes in to current domain-specific understanding in a meaningful way
 - Integrating several experiments across totally different kinds of data
 - Talking with people in other sub-disciplines of biology and actually understanding each other well enough to collaborate effectively
 - Thinking of the most important and useful questions to ask
 - Getting funding</Text>
  </row>
  <row>
    <Id>542</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>295</PostId>
    <RevisionGUID>c72e879f-de4a-419a-935a-265932166bef</RevisionGUID>
    <CreationDate>2010-03-15T18:45:16.133</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>

Most challenging: processing contradictory information and identifying the credible evidence.
</Text>
  </row>
  <row>
    <Id>543</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>296</PostId>
    <RevisionGUID>f5fda616-71dd-4e04-a712-7e696c1a52fc</RevisionGUID>
    <CreationDate>2010-03-15T18:57:44.97</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>What do you recommend as the most appropriate site to advertise (or look for) bioinformatics related job openings.</Text>
  </row>
  <row>
    <Id>544</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>296</PostId>
    <RevisionGUID>f5fda616-71dd-4e04-a712-7e696c1a52fc</RevisionGUID>
    <CreationDate>2010-03-15T18:57:44.97</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Where to advertise or find bioinformatics jobs</Text>
  </row>
  <row>
    <Id>545</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>296</PostId>
    <RevisionGUID>f5fda616-71dd-4e04-a712-7e696c1a52fc</RevisionGUID>
    <CreationDate>2010-03-15T18:57:44.97</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text> éjobà  écareerà </Text>
  </row>
  <row>
    <Id>546</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>297</PostId>
    <RevisionGUID>ee68a3f0-7f96-4873-98f6-054ac7d4a4e0</RevisionGUID>
    <CreationDate>2010-03-15T19:27:51.02</CreationDate>
    <IPAddress>213.98.192.18</IPAddress>
    <UserId>23</UserId>
    <Text>I think it is easier to look at the home pages of the laboratories that work in a topic of your interest and ask; however, there are a few generic places:

 - [Nature Jobs][1], for example [these][2]
 - [Linked In][3], in particular groups like [Bioinformatics Geeks][4] or [Bioinformatics Computing][5]


  [1]: http://www.nature.com/naturejobs/index.html
  [2]: http://www.nature.com/naturejobs/science/searches/13075465-all-bioinformatics-jobs#search-results
  [3]: http://www.linkedin.com/
  [4]: http://www.linkedin.com/groups?gid=65325&amp;trk=anetsrch_name&amp;goback=%2Egdr_1268681143545_1
  [5]: http://www.linkedin.com/groups?gid=96837&amp;trk=anetsrch_name&amp;goback=%2Egdr_1268681143545_1</Text>
  </row>
  <row>
    <Id>547</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>298</PostId>
    <RevisionGUID>ae5bb967-816c-4e99-af5a-71d395481a2c</RevisionGUID>
    <CreationDate>2010-03-15T19:52:48.183</CreationDate>
    <IPAddress>82.126.86.135</IPAddress>
    <UserId>30</UserId>
    <Text> * Biojobs on FriendFeed: http://friendfeed.com/biojobs
 * The (French) Bioinfo mailing list (but many international positions) http://listes.sfbi.fr/wws/info/bioinfo
 * http://www.nature.com/naturejobs/index.html (nature jobs)
 * some yahoo pipes .e.g. http://pipes.yahoo.com/pipes/search?q=bioinformatics+job&amp;x=0&amp;y=0
 * (...)</Text>
  </row>
  <row>
    <Id>548</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>299</PostId>
    <RevisionGUID>76da4ede-159b-4fd5-996c-95e294d19778</RevisionGUID>
    <CreationDate>2010-03-15T20:20:37.78</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text> 1. Some companies do not longer publish
    their vacancies in newspapers but
    instead use their own vacancy
    web-site. This is helpful and
    up-to-date (well, should be), but
    the counterside is that there's no
    longer a central place where you can
    find all actual vacant jobs. So if
    you are searching for a job you have
    to check out a score of websites on
    a regular base. To make this
    somewhat easier the [Geneyous
    JobReport][1] has been set up.
    
    The  JobReport checks the vacancy
    pages of several (mostly Dutch)
    companies and institutes on a
    regular base on keywords like
    genomics, bio-informatician,
    genetics, scientific programmer and
    more, including Dutch translations.
    
    The results are placed in a grid and
    arrows indicate if the number of
    keywords has
    increased/decreased/remained stable
    the last month.

 2. [AcademicTransfer][2] is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.


  [1]: http://www.geneyous.nl/jobreport/
  [2]: http://www.academictransfer.com/search_results/?q=bioinformatics&amp;find=Search&amp;phd_position=</Text>
  </row>
  <row>
    <Id>549</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>299</PostId>
    <RevisionGUID>aa232b3f-bffc-49b2-b50a-c09d52ca1f86</RevisionGUID>
    <CreationDate>2010-03-15T20:29:59.15</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Comment>added third entry</Comment>
    <Text> 1. Some companies do not longer publish
    their vacancies in newspapers but
    instead use their own vacancy
    web-site. This is helpful and
    up-to-date (well, should be), but
    the counterside is that there's no
    longer a central place where you can
    find all actual vacant jobs. So if
    you are searching for a job you have
    to check out a score of websites on
    a regular base. To make this
    somewhat easier the [Geneyous
    JobReport][1] has been set up.
    
    The  JobReport checks the vacancy
    pages of several (mostly Dutch)
    companies and institutes on a
    regular base on keywords like
    genomics, bio-informatician,
    genetics, scientific programmer and
    more, including Dutch translations.
    
    The results are placed in a grid and
    arrows indicate if the number of
    keywords has
    increased/decreased/remained stable
    the last month.

 2. [AcademicTransfer][2] is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.

 3. The [Bioinformatics Organization Career Center][3]



  [1]: http://www.geneyous.nl/jobreport/
  [2]: http://www.academictransfer.com/search_results/?q=bioinformatics&amp;find=Search&amp;phd_position=
  [3]: http://www.bioinformatics.org/jobs/
  [4]: http://www.bioinformatics.fr/jobs.php</Text>
  </row>
  <row>
    <Id>550</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>300</PostId>
    <RevisionGUID>114e4f70-5981-4110-9392-3e0f0cff7657</RevisionGUID>
    <CreationDate>2010-03-15T21:50:36.74</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>You can also checked http://www.bioinformatics.fr/jobs.php
When I have the time I also try to compile jobs from several sources like jobs.ac.uk, bioinformatics.org, listbioinfo (see Pierre post), iscb.org or biospace.com</Text>
  </row>
  <row>
    <Id>551</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>301</PostId>
    <RevisionGUID>7d3371cf-916a-4eb0-a54d-72708ca852b8</RevisionGUID>
    <CreationDate>2010-03-15T22:14:03.053</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>Pierre,

As soon as you get the Entrez gene Id related to your SNPs you can query KEGG or WikiPathways that should provide Entrez gene Ids related to a given pathway.
The good think with this two websites is that with some SVG you can customized the graphic view of the pathways in order to highlight genes that have the SNPs.
Hope this helps.

Fred</Text>
  </row>
  <row>
    <Id>552</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>302</PostId>
    <RevisionGUID>3cd13ea8-9687-453c-9fc5-437c8fb879b6</RevisionGUID>
    <CreationDate>2010-03-15T23:24:58.177</CreationDate>
    <IPAddress>144.32.59.113</IPAddress>
    <UserId>143</UserId>
    <Text>Hi,

I have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybodu could point in the right direction, I would be thankful!

Cheers</Text>
  </row>
  <row>
    <Id>553</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>302</PostId>
    <RevisionGUID>3cd13ea8-9687-453c-9fc5-437c8fb879b6</RevisionGUID>
    <CreationDate>2010-03-15T23:24:58.177</CreationDate>
    <IPAddress>144.32.59.113</IPAddress>
    <UserId>143</UserId>
    <Text>Compare two protein sequences using local BLAST</Text>
  </row>
  <row>
    <Id>554</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>302</PostId>
    <RevisionGUID>3cd13ea8-9687-453c-9fc5-437c8fb879b6</RevisionGUID>
    <CreationDate>2010-03-15T23:24:58.177</CreationDate>
    <IPAddress>144.32.59.113</IPAddress>
    <UserId>143</UserId>
    <Text> ébiopythonà  éblastà </Text>
  </row>
  <row>
    <Id>555</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>302</PostId>
    <RevisionGUID>bbdd31fc-8d28-4ffd-a363-4e65b199ba67</RevisionGUID>
    <CreationDate>2010-03-16T00:05:48.003</CreationDate>
    <IPAddress>144.32.59.113</IPAddress>
    <UserId>143</UserId>
    <Comment>added 3 characters in body</Comment>
    <Text>Hi,

I have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybody could point me in the right direction, I would be thankful!

Cheers</Text>
  </row>
  <row>
    <Id>556</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>303</PostId>
    <RevisionGUID>7c34f66e-7568-45e3-b921-4a480d0ade64</RevisionGUID>
    <CreationDate>2010-03-16T00:07:51.01</CreationDate>
    <IPAddress>170.223.185.126</IPAddress>
    <UserId>35</UserId>
    <Text>I haven't used it myself, but [GRAIL][1] was built for this sort of problem in GWAS. It looks pretty impressive from what I've seen.


  [1]: http://www.broadinstitute.org/mpg/grail/</Text>
  </row>
  <row>
    <Id>557</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>304</PostId>
    <RevisionGUID>025d1e86-71f3-491c-a80f-8ddf4ca22741</RevisionGUID>
    <CreationDate>2010-03-16T04:34:58.113</CreationDate>
    <IPAddress>76.116.255.120</IPAddress>
    <UserId>122</UserId>
    <Text>The BLAST section of the BioPython module is not terribly well documented.  The relevant section is [here][1].  Before starting you'll need to create a local BLAST database ... To my knowledge there is no way to do this directly through BioPython (but you could use the Subprocess module to automate the commandline if you really wanted too) ... The documentation for the BLAST tool is on the NCBI website [here][2].  You'll obviously need to download the whole genome sequences ... I suggest using the NCBI FTP site, I can never seem to find the right link in the normal webportal.

Once you have all of the relevant downloads and databases created you'll simply need to run the BLAST query in a loop that processes all of the data.  Something like this should work (I don't have the required data to test this but it should get you 95% of the way there.)

    from Bio.Blast.Applications import NcbiblastxCommandline
    from Bio.Blast import NCBIXML
    from Bio import SeqIO
    import subprocess
    
    SOURCE_FASTA = '/path/to/source/seq.fasta'
    DATABASE = 'databsename' #should be in the path but YMMV
    
    with open(SOURCE_FASTA) as inhandle:
    	for seq in SeqIO.parse(handle, 'fasta'):
    		with open('scratch.fasta', 'w') as outhandle:
    			#write a scratch file
    			SeqIO.write(seq, outhandle, 'fasta')
    		
    		#create the commandline string
    		cline = NcbiblastxCommandline(query='scratch.fasta', 
                        db=DATABASE, evalue=0.001, outfmt=5, out="scratch.xml")
    		
    		#actually run BLAST
    		return_code = subprocess.call(str(cline))
    		
    		if return_code == 0:
    			#if it was successful then process it
    			with open('scratch.xml') as xmlhandle:
    				blast_record = NCBIXML.read(xmlhandle)
    				
    				do_something_with_results(blast_record)
				
		
Hope that helps.

  [1]: http://www.biopython.org/DIST/docs/tutorial/Tutorial.html#htoc77
  [2]: ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/user_manual.pdf</Text>
  </row>
  <row>
    <Id>558</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>305</PostId>
    <RevisionGUID>8ce93a69-92bc-470c-ae75-e9b9cf5b13b7</RevisionGUID>
    <CreationDate>2010-03-16T04:36:10.267</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:

    $ formatdb -p T -i ecoli.fa
    $ blastall -d ecoli.fa -i other.fa -p blastn -m 8 -e 0.01 -o ecoli_other.blast

Using the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite yeast genome repository.</Text>
  </row>
  <row>
    <Id>559</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>306</PostId>
    <RevisionGUID>fe08d6dc-03d1-4319-a07e-7644f8533314</RevisionGUID>
    <CreationDate>2010-03-16T06:21:11.32</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>BioPlanet is quite active, for both advertising and searching: http://www.bioplanet.com/planetforums/forumdisplay.php?fid=1.

In Australia I use the jobs portal Seek - http://www.seek.com.au/ - I'm sure other countries have a similar website.

Advertising?  Twitter, with the hash tags #bioinformatics #jobs.</Text>
  </row>
  <row>
    <Id>560</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>307</PostId>
    <RevisionGUID>3b468f94-b2dc-43bd-8321-99aa4447d943</RevisionGUID>
    <CreationDate>2010-03-16T07:07:24.867</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>If the genomes are public, someone may have done this analysis for you, or there may be a web-based tool to do the job.

For example, here is a genome comparison tool at the JCVI/CMR - http://cmr.jcvi.org/cgi-bin/CMR/shared/MakeFrontPages.cgi?page=circular_display.

The JGI Integrated Microbial Genome system is also very good - http://img.jgi.doe.gov. It allows you to select multiple genomes for various comparative analyses.  I believe they may even have all versus all data buried away in their FTP archive somewhere.  However, take some time to get used to the site - it has quite a steep learning curve.</Text>
  </row>
  <row>
    <Id>561</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>fd7a876c-b072-4cf5-81ad-c22ae04552be</RevisionGUID>
    <CreationDate>2010-03-16T08:39:42.853</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Hello,

I am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.
I already know the following instances:

 - [NCI-H209 cell line][1]
   
  
 - [22 Human Glioblastoma Multiforme   
   samples][2]

   
  

 - [a first Acute Myeloid Leukaemia with minimal maturation 
   (AML-M1) sample][3]

   
   

 - [a second Acute Myeloid Leukaemia with minimal maturation
   (AML-M1) sample][4]

So if you know other papers/ressources I would be glad if you could share it with others.

Thanks in advance,

Fred

  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html
  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807
  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html
  [4]: http://content.nejm.org/cgi/content/full/361/11/1058</Text>
  </row>
  <row>
    <Id>562</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>fd7a876c-b072-4cf5-81ad-c22ae04552be</RevisionGUID>
    <CreationDate>2010-03-16T08:39:42.853</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Looking for refernces to Cell lines/samples with full Integrated Genome Analysis</Text>
  </row>
  <row>
    <Id>563</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>fd7a876c-b072-4cf5-81ad-c22ae04552be</RevisionGUID>
    <CreationDate>2010-03-16T08:39:42.853</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text> égenomeà  éanalysisà  éintegratedà  éngsà </Text>
  </row>
  <row>
    <Id>564</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>309</PostId>
    <RevisionGUID>0071147a-1b86-4b09-bcf8-e62ddfc42629</RevisionGUID>
    <CreationDate>2010-03-16T08:52:17.61</CreationDate>
    <IPAddress>128.240.229.7</IPAddress>
    <UserId>38</UserId>
    <Text>In the UK, pretty much every academic job is listed on http://www.jobs.ac.uk/ - they have good mechanisms for filtering the stream.

The New Scientist is a good place to find openings too - http://www.newscientistjobs.com/jobs/default.aspx

As for advertising... I agree with Neil - Twitter + hash tags.

</Text>
  </row>
  <row>
    <Id>565</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>c51f1a05-06b7-4252-8cf5-a918662ed5b3</RevisionGUID>
    <CreationDate>2010-03-16T08:54:43.09</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>edited title</Comment>
    <Text>Looking for references to Cell lines/samples with full Integrated Genome Analysis</Text>
  </row>
  <row>
    <Id>566</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>310</PostId>
    <RevisionGUID>96a517b6-5679-496a-a48d-db86a1644775</RevisionGUID>
    <CreationDate>2010-03-16T10:09:33.18</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>On this page of the [software carpentry manual][1] you can find a brief introduction to different software development techniques, including agile and sturdy ones. 

Which of these development model is closer to the one you use on your lab? How do you work together with your teammates?

note: If you are interested, I can provide you with more documents to describe the different development techniques.


  [1]: http://software-carpentry.org/lifecycle.html</Text>
  </row>
  <row>
    <Id>567</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>310</PostId>
    <RevisionGUID>96a517b6-5679-496a-a48d-db86a1644775</RevisionGUID>
    <CreationDate>2010-03-16T10:09:33.18</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Which software development technique is used in your lab? </Text>
  </row>
  <row>
    <Id>568</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>310</PostId>
    <RevisionGUID>96a517b6-5679-496a-a48d-db86a1644775</RevisionGUID>
    <CreationDate>2010-03-16T10:09:33.18</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> ésubjectiveà  éagileà  ésturdyà  éteamöworkingà  édevelopmentà </Text>
  </row>
  <row>
    <Id>569</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>311</PostId>
    <RevisionGUID>dd77b843-9a23-4175-9fab-df183e97aff3</RevisionGUID>
    <CreationDate>2010-03-16T10:47:33.727</CreationDate>
    <IPAddress>70.81.170.125</IPAddress>
    <UserId>145</UserId>
    <Text>I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.

 - Is there any book I should read?  
 - Any interesting online resources?
 - Any interesting blogs / online communities (apart from this one)?
 - What are some of the interesting problems bioinformatics is trying to solve?

Any advice or insight about this industry would be appreciated.</Text>
  </row>
  <row>
    <Id>570</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>311</PostId>
    <RevisionGUID>dd77b843-9a23-4175-9fab-df183e97aff3</RevisionGUID>
    <CreationDate>2010-03-16T10:47:33.727</CreationDate>
    <IPAddress>70.81.170.125</IPAddress>
    <UserId>145</UserId>
    <Text>How to get started in bioinformatics?</Text>
  </row>
  <row>
    <Id>571</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>311</PostId>
    <RevisionGUID>dd77b843-9a23-4175-9fab-df183e97aff3</RevisionGUID>
    <CreationDate>2010-03-16T10:47:33.727</CreationDate>
    <IPAddress>70.81.170.125</IPAddress>
    <UserId>145</UserId>
    <Text> érecommandationà  ébooksà </Text>
  </row>
  <row>
    <Id>572</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>312</PostId>
    <RevisionGUID>69d34881-6412-42af-8beb-5f9e4d347340</RevisionGUID>
    <CreationDate>2010-03-16T11:02:00.047</CreationDate>
    <IPAddress>130.238.45.93</IPAddress>
    <UserId>71</UserId>
    <Text>I am pretty sure Google can help you with getting started. I have seen questions like yours many times, like so many others before you, you have no idea where to start.

However, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.

The reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.

So, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.</Text>
  </row>
  <row>
    <Id>573</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>311</PostId>
    <RevisionGUID>34399283-b62e-4883-b5dc-469a7334499e</RevisionGUID>
    <CreationDate>2010-03-16T11:09:42.037</CreationDate>
    <IPAddress>130.238.45.93</IPAddress>
    <UserId>71</UserId>
    <Comment>edited tags</Comment>
    <Text> érecommendationsà  ébooksà </Text>
  </row>
  <row>
    <Id>574</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>313</PostId>
    <RevisionGUID>9ea2913a-4764-4097-afff-8d49b2e6e51a</RevisionGUID>
    <CreationDate>2010-03-16T11:28:50.993</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>Does your university offer bioinformatics courses? It might be a better place to start asking there...

Books: can't really recommend any. There are too many different sub-fields in bioinformatics

Online: depends what you're interested in, again.

Blogs: not really, I think. If you find any good ones, let me know.

There seem to be two opposing sides to bioinformatics currently:

 - those who studied microbiology and use bioinformatics as a tool (maybe even cobble some scripts together)
 - those who come from the software engineering side and build tools according to these standards.

Problems in bioinformatics:

 - sequence analysis, including sequence matching/searching (BLAST et al.), also databases
 - image processing (electron microscopy analysis, microarrays)
 - structure prediction (protein structure, see Folding@Home and others)

Many of these include high performance computing, so you might want to learn stuff about that.

Your question is rather broad. How did you find out about bioinformatics? What made you interested in this field?
</Text>
  </row>
  <row>
    <Id>575</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>314</PostId>
    <RevisionGUID>1dedb7f2-70e3-46cc-9ef5-28cdb7fa0c1e</RevisionGUID>
    <CreationDate>2010-03-16T11:34:46.16</CreationDate>
    <IPAddress>143.234.97.120</IPAddress>
    <UserId>146</UserId>
    <Text>And Will, your example seems overly complicated. Why not just give the multiple query input FASTA file directly to BLAST?

Also, satsurae - do you have to use BLAST? If the data set is not too big, you could use EMBOSS needleall to do a full Needleman-Wunsch alignment - although this may not offer the statistics you may want.
http://emboss.sourceforge.net/apps/release/6.2/emboss/apps/needleall.html

</Text>
  </row>
  <row>
    <Id>576</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>315</PostId>
    <RevisionGUID>04f7da6c-e480-4307-9e1c-ab8fcdc473e7</RevisionGUID>
    <CreationDate>2010-03-16T11:39:30.44</CreationDate>
    <IPAddress>143.234.97.120</IPAddress>
    <UserId>146</UserId>
    <Text>If you want to reverse a string in Python, you can use a slice with a step of minus one -1,

    rev_str = str[::-1]

It should not surprise you that you can do the same with a Biopython Seq object:

    rev_seq = seq[::-1]

I guess the Biopython Tutorial you be more explicit but it does cover reversing a sequence like this.
</Text>
  </row>
  <row>
    <Id>577</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>314</PostId>
    <RevisionGUID>24cff3c8-e579-4e37-ab2c-44a3e4efac9f</RevisionGUID>
    <CreationDate>2010-03-16T11:41:29.33</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>146</UserId>
    <Text>[{"Id":146,"DisplayName":"Peter"}]</Text>
  </row>
  <row>
    <Id>578</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>316</PostId>
    <RevisionGUID>e997b79c-0d4a-4699-93ae-d356667b232a</RevisionGUID>
    <CreationDate>2010-03-16T12:01:15.357</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Well, I will answer by redirecting you to other topics :-) :

**Is there any book I should read?**

 - Biostar - [recommend your favorite bioinformatics books][1]

**Any interesting online resources?**

 - Biostar - [appropriate podcasts for a bioinformatician][2]

**Any interesting blogs / online communities (apart from this one)?**

 - Biostar - [your favorite bioinformatics blog][3]

**What are some of the interesting problems bioinformatics is trying to solve?**

 - Biostar - [How far does bioinformatics go][4]


  [1]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books
  [2]: http://biostar.stackexchange.com/questions/268/appropriate-podcasts-for-a-bioinformatician
  [3]: http://biostar.stackexchange.com/questions/112/your-favorite-bioinformatics-blog
  [4]: http://biostar.stackexchange.com/questions/149/how-far-does-bioinformatics-go</Text>
  </row>
  <row>
    <Id>579</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>317</PostId>
    <RevisionGUID>4b474402-d4a5-4af8-8e09-b5da19c2bccc</RevisionGUID>
    <CreationDate>2010-03-16T12:17:31.06</CreationDate>
    <IPAddress>82.126.16.178</IPAddress>
    <UserId>30</UserId>
    <Text>As I've always worked alone on my sources, I've heavily used the [Cowboy Coding][1] and the [confessional debugging][2] techniques :-)


  [1]: http://en.wikipedia.org/wiki/Cowboy_coding
  [2]: http://en.wiktionary.org/wiki/confessional_debugging</Text>
  </row>
  <row>
    <Id>580</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>318</PostId>
    <RevisionGUID>e787b38c-5ea8-4f0f-8354-aa81466d0e41</RevisionGUID>
    <CreationDate>2010-03-16T12:25:31.94</CreationDate>
    <IPAddress>128.231.10.169</IPAddress>
    <UserId>131</UserId>
    <Text>think it, code it :)</Text>
  </row>
  <row>
    <Id>581</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>319</PostId>
    <RevisionGUID>5cdfc1c8-6539-4eff-9ffb-04c75524ccdd</RevisionGUID>
    <CreationDate>2010-03-16T12:39:50.557</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>I think the most trivial is also the most challenging:  fetching and pre-processing the data in the first place, before you even do any analysis with it.  I'd say 80% of my time is spent searching, fetching, parsing, munging and storing data, 20% is analysis and conclusions.</Text>
  </row>
  <row>
    <Id>582</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>320</PostId>
    <RevisionGUID>477f09bc-28e4-48e7-b0ec-f84095625a39</RevisionGUID>
    <CreationDate>2010-03-16T12:47:39.753</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>I've been doing bioinformatics for 10 years or so and have never read a book on the subject. I learned (and still learn, every day) on the job, almost entirely from online resources.

I think many bioinformaticians of a "certain age" learned in this way:  they are often former bench biologists who gave up lab work and taught themselves programming.  These days there are undergraduate courses (!), so I imagine more people use textbooks.  It's just that I don't know of any, nor have I ever needed to use one.</Text>
  </row>
  <row>
    <Id>583</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>321</PostId>
    <RevisionGUID>9724fc39-1c92-431a-bbe8-ba894be8c481</RevisionGUID>
    <CreationDate>2010-03-16T13:02:14.53</CreationDate>
    <IPAddress>130.237.137.116</IPAddress>
    <UserId>26</UserId>
    <Text>The others have answered your question!

I just want to make a suggestion, if you are interested in visually comparing the two genomes, I highly recommend the [Artemis][1] and [ACT (Artemis Comparison Tool)][2] from the Sanger institute.

If you have the full genome, then you can easily visualize all the reading frames. With ACT, you use the two genome sequences (or one genome and a fasta file of genes/proteins or even two gene/protein fasta files) as well as a "comparison file", which is a blast output file.

It is very useful for annotation and curation!


  [1]: http://www.sanger.ac.uk/resources/software/artemis/
  [2]: http://www.sanger.ac.uk/resources/software/act/</Text>
  </row>
  <row>
    <Id>584</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>322</PostId>
    <RevisionGUID>c630e806-9321-4860-8e21-44348ed97cfe</RevisionGUID>
    <CreationDate>2010-03-16T13:47:22.217</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>38</UserId>
    <Text>From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet biologists of the inappropriateness of Excel and Word as data exchange formats.

Scientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.</Text>
  </row>
  <row>
    <Id>585</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>69f5a959-7971-4558-ae9a-891a1a6cba0a</RevisionGUID>
    <CreationDate>2010-03-16T13:58:05.59</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>edited title</Comment>
    <Text>Which human cell line/sample genomes have been already sequenced completely?</Text>
  </row>
  <row>
    <Id>586</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>322</PostId>
    <RevisionGUID>5aa811ee-9531-424f-95f6-0345b6a3ded4</RevisionGUID>
    <CreationDate>2010-03-16T14:08:55.033</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>38</UserId>
    <Comment>added 4 characters in body</Comment>
    <Text>From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet-lab biologists of the inappropriateness of Excel and Word as data exchange formats.

Scientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.</Text>
  </row>
  <row>
    <Id>587</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>308</PostId>
    <RevisionGUID>e3e2a807-0917-43f2-91b0-9a592b9ca570</RevisionGUID>
    <CreationDate>2010-03-16T14:11:20.183</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>edited title</Comment>
    <Text>Which human tumor cell line/sample genomes have been already sequenced completely?</Text>
  </row>
  <row>
    <Id>588</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>311</PostId>
    <RevisionGUID>9ed67d09-70a7-4b61-a00b-f9bfca2c625f</RevisionGUID>
    <CreationDate>2010-03-16T14:24:07.22</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>38</UserId>
    <Comment>edited tags</Comment>
    <Text> érecommendationsà  ébooksà  éblogà </Text>
  </row>
  <row>
    <Id>589</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>323</PostId>
    <RevisionGUID>c04cec18-80f3-403d-9c71-c78aa69af12e</RevisionGUID>
    <CreationDate>2010-03-16T14:26:13.303</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text> - [COLO-829 cell line][1]


  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html</Text>
  </row>
  <row>
    <Id>590</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>323</PostId>
    <RevisionGUID>04a4d26d-e368-4604-84de-ef8302757a8a</RevisionGUID>
    <CreationDate>2010-03-16T14:48:02.513</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>added 112 characters in body</Comment>
    <Text> - [COLO-829 cell line][1]
 - [96 human glioblastoma samples][2]


  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html
  [2]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671642/?tool=pubmed</Text>
  </row>
  <row>
    <Id>591</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>305</PostId>
    <RevisionGUID>b339d351-89fa-41c5-b164-9bbc1c777789</RevisionGUID>
    <CreationDate>2010-03-16T15:28:48.147</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Comment>s/yeast/bacteria/ (thanks neilfws)</Comment>
    <Text>hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:

    $ formatdb -p T -i ecoli.fa
    $ blastall -d ecoli.fa -i other.fa -p blastn -m 8 -e 0.01 -o ecoli_other.blast

Using the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite bacteria genome repository.</Text>
  </row>
  <row>
    <Id>592</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>324</PostId>
    <RevisionGUID>b1b9fd4a-a17f-4a48-8382-8ac038dcee20</RevisionGUID>
    <CreationDate>2010-03-16T15:31:11.063</CreationDate>
    <IPAddress>130.237.137.116</IPAddress>
    <UserId>26</UserId>
    <Text>Question 1: With my collaborators, we use agile.

Question 2: (if I've understood correctly the "how do you work together with your teammates?") Our team members have very different roles and it is mainly one person actually coding. So we don't need to share code etc. When it comes to the communication part, we rely on different tools:

  * [Google Wave][1]
  * Our personal Wiki
  * We've been testing [Yammer][2]
  * [SVN][3]
  * Skype
  * Email

And most importantly, whenever we can, face to face brainstorming with a white board.


  [1]: http://wave.google.com/
  [2]: http://www.yammer.com/
  [3]: http://subversion.tigris.org/</Text>
  </row>
  <row>
    <Id>593</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>325</PostId>
    <RevisionGUID>8826af05-fb5b-451a-a429-7ef57325c559</RevisionGUID>
    <CreationDate>2010-03-16T16:54:25.58</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.

Clarck et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS, 2010.

http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832
</Text>
  </row>
  <row>
    <Id>594</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>325</PostId>
    <RevisionGUID>43fb3ce0-5ea5-4f29-ac8b-b27cf97d4b80</RevisionGUID>
    <CreationDate>2010-03-16T16:59:31.827</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Comment>deleted 1 characters in body; added 9 characters in body</Comment>
    <Text>There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.

Clark et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS Genetics, 2010.

http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832
</Text>
  </row>
  <row>
    <Id>595</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>326</PostId>
    <RevisionGUID>ef212838-3471-421b-96ec-1db125e1480e</RevisionGUID>
    <CreationDate>2010-03-16T20:36:45.76</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>We are using [37signals][1]' [Basecamp][2] and [Backpack][3] to exchange data, results, ideas and other staff. It's not free, but not so expensive. As for codes, we usually have individual projects. All techniques as in Pierre's answer. :)


  [1]: http://37signals.com
  [2]: http://basecamphq.com
  [3]: http://backpackit.com</Text>
  </row>
  <row>
    <Id>596</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>327</PostId>
    <RevisionGUID>28cea7e3-735a-4901-b4ee-e08a0cbb7461</RevisionGUID>
    <CreationDate>2010-03-16T20:56:46.18</CreationDate>
    <IPAddress>87.0.190.248</IPAddress>
    <UserId>147</UserId>
    <Text>How can I convert the microarray quantization mathematically elaborated in the corresponding image? I need to see the image of the mathematic changes in the microarray quantization.  </Text>
  </row>
  <row>
    <Id>597</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>327</PostId>
    <RevisionGUID>28cea7e3-735a-4901-b4ee-e08a0cbb7461</RevisionGUID>
    <CreationDate>2010-03-16T20:56:46.18</CreationDate>
    <IPAddress>87.0.190.248</IPAddress>
    <UserId>147</UserId>
    <Text>Convert microarray quantization in image</Text>
  </row>
  <row>
    <Id>598</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>327</PostId>
    <RevisionGUID>28cea7e3-735a-4901-b4ee-e08a0cbb7461</RevisionGUID>
    <CreationDate>2010-03-16T20:56:46.18</CreationDate>
    <IPAddress>87.0.190.248</IPAddress>
    <UserId>147</UserId>
    <Text> émicroarrayà  éimageà </Text>
  </row>
  <row>
    <Id>599</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>127cc850-cd44-4f8a-b940-0125182709f6</RevisionGUID>
    <CreationDate>2010-03-16T22:46:17.323</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions like Pico Computing FPGA cards, CLCbio Cube and TimeLogic DeCypher.

Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel</Text>
  </row>
  <row>
    <Id>600</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>127cc850-cd44-4f8a-b940-0125182709f6</RevisionGUID>
    <CreationDate>2010-03-16T22:46:17.323</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hardware resources for HPC in Bioinformatics</Text>
  </row>
  <row>
    <Id>601</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>127cc850-cd44-4f8a-b940-0125182709f6</RevisionGUID>
    <CreationDate>2010-03-16T22:46:17.323</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> éfpgaà  éhpcà </Text>
  </row>
  <row>
    <Id>602</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>1537c031-a3d9-463b-af84-c00a358691be</RevisionGUID>
    <CreationDate>2010-03-16T22:55:37.207</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Just some explanations</Comment>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions like Pico Computing FPGA cards, CLCbio Cube and TimeLogic DeCypher.

Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel

P.S.: There are a lot of open source recipes on how to implement aligners and related on FPGAs. That's why I'm very interested in this topic.</Text>
  </row>
  <row>
    <Id>603</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>329</PostId>
    <RevisionGUID>b1cb0ea7-24a7-41d4-9f41-445f7d5a1bc3</RevisionGUID>
    <CreationDate>2010-03-16T23:18:06.647</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>My main work deals with simulations and modelling in population genetics (for several different purposes). Data are essential to validade both.

**Trivial**:

 - Gathering HUGE amounts of data (I do
   love NGS!); 
 - Parsing/converting these
   data to a usable condition;
 - Extracting the population genetics
   parameters estimates from it;

**Challenging**:

 - Knowing when to stop gathering HUGE
   amounts of data (I still love NGS!);
 - Curating data &lt;-- The real challenge;

For a population geneticist these are trully happy times. Finally we have (possibly) enough data to validate some fundamental models and theories. But, as a great philosopher said - "With great power comes great responsibility". So, carefully curated data is the great challenge from now on, IMHO.

That's all, dudes.</Text>
  </row>
  <row>
    <Id>604</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>330</PostId>
    <RevisionGUID>5dfda2a4-25d4-4f41-82ba-9dba7482a872</RevisionGUID>
    <CreationDate>2010-03-16T23:54:18.13</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Most of my sparse experience with bioinformatics came with the necessity to extract some statistics from sequence data. So, most books I can recommend deal with statistical and algorithmic approaches to biological data. 

- **An Introduction to Bioinformatics Algorithms** Neil C. Jones and Pavel A. Pevzner

- **Statistical Methods in Bioinformatics** Warren J. Ewens, Gregory R. Grant

- **Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison** David Sankoff, Joseph Kruskal

- **Bioinformatics and Computational Biology Solutions Using R and Bioconductor** Robert Gentleman, Vincent Carey, Wolfgang Huber, Rafael Irizarry, Sandrine Dudoit

Jones and Pavel are accomplished mathematicians and bioinformaticians. Their work with repeats is a must have reference. Ewens's book will become a classic. He is already a foremost figure in population genetics, both in theory and experiment. Sankoff's book still is the most important reference in sequence aligment. Unfortunatelly, these books are somewhat mind bending. They rely heavily on mathematical concepts. But, as far as I know, bioinformatics theory is indeed mathematically and algorithmically challenging.

And the last book is a very broad practical introduction to bioinformatics of array data.  Good for relaxing . . .

Cheers !
</Text>
  </row>
  <row>
    <Id>605</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>331</PostId>
    <RevisionGUID>04015900-c4f8-4241-8612-49311e6ec80d</RevisionGUID>
    <CreationDate>2010-03-17T06:52:10.983</CreationDate>
    <IPAddress>93.179.61.41</IPAddress>
    <UserId>71</UserId>
    <Text>As the number of good programmers in natural sciences is relatively low as compared to other programming projects, I think it is good to pick a model that suites the team. In these situations, I do not think coding style matters too much (write unit tests first or last, ...).

I am involved in two large chem- and bioinformatics projects: [Bioclipse][1] and the [CDK][2]. There is a bit of overlap in developers, but still both projects use different development models. Both development teams are scattered around the internet.

But what does matter very much is communication. This makes the following components important:

 - choose a version control system: I would recommend Git; it does require some training, but there is plenty of information, and we all have good education to start with.
 - choose a bug track system and make this your main development communication channel: it works independent of individual developers' time lines.
 - have mailing lists to discuss issues in more detail, ask for advice, etc
 - choose coding standards: these can be small and large, and are aimed at removing getting annoyed to much about others coding styles
 - put persons in charge and have them take responsibility over the code

The CDK even adds to this that code is reviewed before it gets into the main version. Git makes it very easy to developed in such a distributed way (not just in location, but also in time). The person in charge is the gate keeper and decides how and when code gets incorporated into the main version, and ensures everyone lives up to coding and project standards.

Wikis, blogs, waves, etc are useful for documenting things. More important is to add proper documentation to the source code.

  [1]: http://www.bioclipse.net
  [2]: http://cdk.sf.net</Text>
  </row>
  <row>
    <Id>606</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>312</PostId>
    <RevisionGUID>c0770c26-3302-45ab-a70c-611f4090b338</RevisionGUID>
    <CreationDate>2010-03-17T07:45:22.923</CreationDate>
    <IPAddress>92.241.193.227</IPAddress>
    <UserId>71</UserId>
    <Comment>added 317 characters in body</Comment>
    <Text>*Note: the below answer is meant to be constructive.* The best way to start in any field is just to listen, learn, and do something. By actually doing something, you best show your intentions, and you get more people listening to your questions.

I am pretty sure Google can help you with getting started, and otherwise have a look around at this forum for topics you like. I have seen questions like yours many times, like so many others before you, you have no idea where to start.

However, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.

The reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.

So, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.</Text>
  </row>
  <row>
    <Id>607</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>332</PostId>
    <RevisionGUID>7f4435b0-dba2-489d-ae36-5af6ac397b6f</RevisionGUID>
    <CreationDate>2010-03-17T08:40:50.24</CreationDate>
    <IPAddress>94.173.32.155</IPAddress>
    <UserId>149</UserId>
    <Text>Do inform Ensembl via helpdesk@ensembl.org; if it is an error then the Havana curators can put this back in. Send them the ENSG number from the previous release, or the protein sequence, or a page from the archive site. If they think it should have been removed, they will give you a good reason.</Text>
  </row>
  <row>
    <Id>608</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>300</PostId>
    <RevisionGUID>f228af1f-ce37-482c-b695-ba17d302109c</RevisionGUID>
    <CreationDate>2010-03-17T10:39:37.833</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>added 446 characters in body</Comment>
    <Text>&lt;p&gt;You can also checked [http://www.bioinformatics.fr/jobs.php][1] with a dedicated RSS feed.&lt;/p&gt;
&lt;p&gt;When I have the time I also try to compile jobs from other sources like :&lt;/p&gt;

 - [jobs.ac.uk][2] 
 - [bioinformatics.org][3]
 - [listbioinfo][4] (see Pierre post)
 - [iscb.org][5] 
 - [biospace.com][6]


  [1]: http://www.bioinformatics.fr/jobs.php
  [2]: http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&amp;x=0&amp;y=0
  [3]: http://www.bioinformatics.org/jobs/
  [4]: http://listes.sfbi.fr/wws/info/bioinfo
  [5]: http://www.iscb.org/iscb-careers
  [6]: http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&amp;TheLocation=%25%25</Text>
  </row>
  <row>
    <Id>609</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>4ed44e71-f601-4d3d-8297-1d28de74e9fe</RevisionGUID>
    <CreationDate>2010-03-17T11:59:54.783</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Major editing, much improved content</Comment>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:

[CLCbio Cube][1]

[TimeLogic DeCypher][2]

[Pico Computing E-FPGA][3]


For the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:

[Field Programmable Gate Array][4]
[Reconfigurable Computing][5]

There are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:

[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]


Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel


  [1]: http://www.clcbio.com/index.php?id=616
  [2]: http://www.timelogic.com/decypher_intro.html
  [3]: http://www.picocomputing.com/e_series.html
  [4]: http://en.wikipedia.org/wiki/Fpga
  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing
  [6]: http://www.biomedcentral.com/1471-2105/8/185</Text>
  </row>
  <row>
    <Id>610</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>4ed44e71-f601-4d3d-8297-1d28de74e9fe</RevisionGUID>
    <CreationDate>2010-03-17T11:59:54.783</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Major editing, much improved content</Comment>
    <Text> éfpgaà  éhpcà  éreconfigurableöcomputingà </Text>
  </row>
  <row>
    <Id>611</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>333</PostId>
    <RevisionGUID>70e6f49e-9c61-47d1-bfc0-b9db52a7d614</RevisionGUID>
    <CreationDate>2010-03-17T12:15:03.647</CreationDate>
    <IPAddress>81.10.131.15</IPAddress>
    <UserId>136</UserId>
    <Text>From what I've read, FPGAs are fine, but expensive. Have you looked into other, more readily available (and easier to program, mostly) architectures? I'm thinking of GPUs (CUDA, OpenCL), and Cell B.E. chips (in Playstation 3, programmable via C/C++ and also via OpenCL)?</Text>
  </row>
  <row>
    <Id>612</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>1ebeac22-9c8e-4f72-af29-9d07da222d3d</RevisionGUID>
    <CreationDate>2010-03-17T13:38:36.977</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 56 characters in body</Comment>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7](check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:

[CLCbio Cube][1]

[TimeLogic DeCypher][2]

[Pico Computing E-FPGA][3]


For the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:

[Field Programmable Gate Array][4]
[Reconfigurable Computing][5]

There are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:

[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]


Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel


  [1]: http://www.clcbio.com/index.php?id=616
  [2]: http://www.timelogic.com/decypher_intro.html
  [3]: http://www.picocomputing.com/e_series.html
  [4]: http://en.wikipedia.org/wiki/Fpga
  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing
  [6]: http://www.biomedcentral.com/1471-2105/8/185
  [7]: http://www.hcnet.usp.br/</Text>
  </row>
  <row>
    <Id>613</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>334</PostId>
    <RevisionGUID>1f31dacb-96a0-479a-9aa1-f3d546b1190c</RevisionGUID>
    <CreationDate>2010-03-17T16:51:43.887</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Is it possible for two different Affymetrix probe set IDs to have common annotations to a single gene ? I am looking for the concept behind Affy probe set IDs. Any literature or links ? </Text>
  </row>
  <row>
    <Id>614</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>334</PostId>
    <RevisionGUID>1f31dacb-96a0-479a-9aa1-f3d546b1190c</RevisionGUID>
    <CreationDate>2010-03-17T16:51:43.887</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? </Text>
  </row>
  <row>
    <Id>615</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>334</PostId>
    <RevisionGUID>1f31dacb-96a0-479a-9aa1-f3d546b1190c</RevisionGUID>
    <CreationDate>2010-03-17T16:51:43.887</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text> émicroarrayà  éannotationà  éaffymetrixà </Text>
  </row>
  <row>
    <Id>616</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>335</PostId>
    <RevisionGUID>443f3f29-4e15-4729-b608-eee0630c1f4f</RevisionGUID>
    <CreationDate>2010-03-17T16:55:23.92</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I used to check Biojobs at FriendFeed,  [Bioinformatics.org][1]  and [Bioinformatics.fr][2] 


  [1]: http://www.bioinformatics.org/jobs/?show=archives
  [2]: http://bioinformatics.fr/jobs.php</Text>
  </row>
  <row>
    <Id>617</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>336</PostId>
    <RevisionGUID>ee973d83-3630-4d5c-9193-34acb11d8b86</RevisionGUID>
    <CreationDate>2010-03-17T17:00:00.923</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text>Different probesets are certainly capable of mapping to the same gene on the standard Affymetrix GeneChip platform.

Groups of probes are combined into probesets and multiple probesets *MAY* exist for a gene

NetAffx is the Affymetrix clearing house of Affymetrix probe ID info : [http://www.affymetrix.com/analysis/index.affx][1]

You might be interested in the BrainArray Custom CDFs which reannotate and regroup Affymetrix probes and probesets which are kept more up to date [http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp][2] They also have tools for mapping probesets between chips/species [http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp][3]

And interestingly a resource I have only just found called [ADAPT][4] which "describes the many-to-many relationships between Affymetrix™ probesets transcripts and genes, by directly mapping every probe against publicly available mRNAs/cDNA sequences from RefSeq and Ensembl."


  [1]: http://www.affymetrix.com/analysis/index.affx
  [2]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp
  [3]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp
  [4]: http://bioinformatics.picr.man.ac.uk/adapt/Welcome.adapt</Text>
  </row>
  <row>
    <Id>618</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>334</PostId>
    <RevisionGUID>a71c49b1-f346-4528-8d9d-8b7d3a865455</RevisionGUID>
    <CreationDate>2010-03-17T17:01:00.883</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> émicroarrayà  éannotationà  éaffymetrixà  éprobesetà </Text>
  </row>
  <row>
    <Id>619</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>337</PostId>
    <RevisionGUID>85a82209-d566-48e5-9a55-ecebe29911a8</RevisionGUID>
    <CreationDate>2010-03-17T17:02:19.923</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>Yes, many probe sets associated with the same gene.

Here is the technical documentation from Affymetrix on probe set design:

[Transcript Assignment for NetAffx™ Annotations][1]


  [1]: https://www.affymetrix.com/support/technical/whitepapers/Transcript_Assignment_whitepaper.pdf</Text>
  </row>
  <row>
    <Id>620</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>338</PostId>
    <RevisionGUID>949159b2-a9c8-405c-9d6c-0020d3e274bc</RevisionGUID>
    <CreationDate>2010-03-17T18:00:23.64</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. 


On the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches.   

Anyway, have fun with new beasts, whatever they will be :-)</Text>
  </row>
  <row>
    <Id>621</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>338</PostId>
    <RevisionGUID>255981dc-9f70-41b9-b206-090c905e1f55</RevisionGUID>
    <CreationDate>2010-03-17T18:11:11.26</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>corrected word</Comment>
    <Text>All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. 


On the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches.   

Anyway, have fun with new servers, whatever they will be :-)</Text>
  </row>
  <row>
    <Id>622</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>339</PostId>
    <RevisionGUID>61fa58c3-03ed-4494-9f33-8a7b703da0f9</RevisionGUID>
    <CreationDate>2010-03-17T20:51:53.697</CreationDate>
    <IPAddress>207.229.236.211</IPAddress>
    <UserId>87</UserId>
    <Text>Just want to clarify : Are you looking for Orthologs/Paralogs of knockdown genes ? If yes, I support Dave Bridges comments, you could try a bi-directional blast searches. If you are looking for large number of genes from a well annotated genome, you may look for database that reports orthologs. I have used orthologs from Inparanoid for fly genome.  </Text>
  </row>
  <row>
    <Id>623</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>340</PostId>
    <RevisionGUID>f1c0788a-1ad3-495a-9063-52a8eba68d25</RevisionGUID>
    <CreationDate>2010-03-17T21:03:20.707</CreationDate>
    <IPAddress>67.109.12.251</IPAddress>
    <UserId>116</UserId>
    <Text>Have you looked at the COGS database at the NCBI? 
http://www.ncbi.nlm.nih.gov/COG/

I'm not sure how current it is these days, and if the human coverage would be sufficient for your needs, but when I used to do structure-function work, I found it useful.

Given what you said in your response to Chris, I suspect you're going to be mostly looking at signaling proteins, so the EC numbers probably won't help you. But if you do find yourself looking at an enzyme that isn't a phosphatase or a kinase, EC numbers might help. In that case, MetaCyc might also be useful:
http://metacyc.org/

My gut instinct on this one, though, is that you're going to get at best a 90% solution, and you'll have to do that last 10% by hand, using literature.</Text>
  </row>
  <row>
    <Id>624</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>341</PostId>
    <RevisionGUID>dc774d6a-5562-482a-aa7e-7eac49d29835</RevisionGUID>
    <CreationDate>2010-03-17T21:22:29.397</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>&lt;p&gt;If you are looking for genes that encode proteins that could play the same role in a pathway, then you can parse the XML files provided by KEGG Pathays Database.&lt;/p&gt;

&lt;p&gt;For instance let's take the mTOR signaling pathway. You can see that at some step of the pathway several proteins (genes) can be involved like it is the case for AKT1 in green : There is the number 3 because you can have either AKT1, AKT2 or AKT3.&lt;/p&gt;

![alt text][1]

&lt;p&gt;So by parsing the related XML file (hsa04150.xml) you can easily get the related Entrez geneid 207, 2008, 1000 that are enclosed in the following XML part:&lt;/p&gt;

        &lt;entry id="33" name="hsa:10000 hsa:207 hsa:208" type="gene" link="http://www.genome.jp/dbget-bin/www_bget?hsa+10000+207+208"&gt;
        &lt;graphics name="AKT3..." fgcolor="#000000" bgcolor="#BFFFBF"
             type="rectangle" x="339" y="291" width="45" height="17"/&gt;
        &lt;/entry&gt;

&lt;p&gt;In this pathway there are other instances like this one. (when there is a number at the upper left side of the protein).&lt;/p&gt;

&lt;p&gt;So may be it could be a way to identify functionally redundant genes.&lt;/p&gt;

Hope this helps.

Fred


  [1]: http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif</Text>
  </row>
  <row>
    <Id>625</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>342</PostId>
    <RevisionGUID>9ca5c1e3-495e-46fd-a05d-5949226f853a</RevisionGUID>
    <CreationDate>2010-03-17T21:52:53.143</CreationDate>
    <IPAddress>67.109.12.251</IPAddress>
    <UserId>116</UserId>
    <Text>To put my answer in context: I work in industry. I've worked in both small biotechs and large pharmas. I am not the coder on the projects I work on- these days, I'm the project manager. Earlier in my career, I was the "translator" between the scientists and the programmers (that job has had many different titles, and was rarely my sole job function).

I have found various permutations of agile programming to be the most successful. The one exception to this has been when I've worked on projects in the more heavily regulated drug development (vs. drug discovery) arena. In those cases, the internal processes have often required a waterfall-like process. For awhile, I specialized a bit in fitting the agile-like development approach favored by my programmers into the waterfall process required by corporate policy.</Text>
  </row>
  <row>
    <Id>626</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>343</PostId>
    <RevisionGUID>7882719e-d2dc-4cb9-901e-d1d8a9ec62d7</RevisionGUID>
    <CreationDate>2010-03-17T21:55:59.577</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I think the best way is to get in to a lab for a rotation project / part-time project depending on your schedule and work on a live project. You may either help the group to code something, they can help you to get familiarize with some common bioinformatics tools and approaches. I think this will be the best way. 

If you can work on your own, pick your language (Perl, Python, Java, Ruby) send a mail to respective bio* mailing list. You will definitely get a small project. You can help the open source community and also get to understand the field and its generic requirements. 

Go ahead, Future is Open, Bioinformatics is Open. All the best ! </Text>
  </row>
  <row>
    <Id>627</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>344</PostId>
    <RevisionGUID>e23fd990-40bd-4bd1-a9b7-7881bed79496</RevisionGUID>
    <CreationDate>2010-03-18T00:24:55.337</CreationDate>
    <IPAddress>71.185.140.161</IPAddress>
    <UserId>73</UserId>
    <Text>A lot of universities and companies never post to national boards and their websites do not get spidered. When I was looking for my first bioinformatics job I collected a list of every job board of every major university I could find and checked each one daily.

Here is my list (some of these might have moved by now)

http://www.bioplanet.com/planetforums/viewthread.php?tid=2644</Text>
  </row>
  <row>
    <Id>628</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>345</PostId>
    <RevisionGUID>9771aa55-3e2f-4571-86f8-75ee0f366476</RevisionGUID>
    <CreationDate>2010-03-18T01:54:11.593</CreationDate>
    <IPAddress>216.9.19.80</IPAddress>
    <UserId>72</UserId>
    <Text>Don't forget to network.  Many of my jobs have been found because I knew someone who pointed me to it or approached me about it.</Text>
  </row>
  <row>
    <Id>629</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>346</PostId>
    <RevisionGUID>7904c10a-3a71-407b-8913-b9d834925952</RevisionGUID>
    <CreationDate>2010-03-18T02:03:54.117</CreationDate>
    <IPAddress>216.9.19.80</IPAddress>
    <UserId>72</UserId>
    <Text>Like Melanie, I've worked in industry as a programmer, as a product manager, etc.  In my experience, an iterative, "agile" (without getting dogmatic about what agile means) works way better than the waterfall models.  In a research driven environment with constant change, incomplete requirements and needs, I would argue it's the only good way. 

The other key point, don't go for all the features you can, since chances are you will need to re-implement parts anyway.

(Disclaimer - I don't work in science these days)</Text>
  </row>
  <row>
    <Id>630</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>347</PostId>
    <RevisionGUID>524d90d5-a999-40b6-86f6-15687e36fa64</RevisionGUID>
    <CreationDate>2010-03-18T07:58:22.503</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>&lt;p&gt;Yes of course it is possible. For instance you have the probeset 203074_at from HG-U133 Plus 2 that is associated to ANXA8, ANXA8L1 and ANXA8L2.&lt;/p&gt;

&lt;p&gt;In our team, for all the probe sets of the HG-U133 Plus 2 we are performing Blast sequence alignment between the 11 probes of a probset against all mRNAs from Ensembl and Refseq in order to associate them to the right transcript(s).&lt;/p&gt;

&lt;p&gt;And for additional information, please find below some interesting reading suggestions  concerning the mapping between the affymetrix probe sets and the mRNAs&lt;/p&gt;

 1. [Alternative mapping of probes to genes for Affymetrix chips][1]
 2. [A sequence-based identification of the genes detected by probesets on the Affymetrix U133 plus 2.0 array][2]
 3. [Evolving gene/transcript definitions significantly alter the interpretation of GeneChip data][3]
 4. [Detecting false expression signals
    in    high-density oligonucleotide
    arrays    by an in silico
    approach][4]


  


  [1]: http://www.biomedcentral.com/1471-2105/5/111
  [2]: http://www.ncbi.nlm.nih.gov/pubmed/15722477
  [3]: http://www.ncbi.nlm.nih.gov/pubmed/16284200
  [4]: http://www.ncbi.nlm.nih.gov/pubmed/15718097</Text>
  </row>
  <row>
    <Id>631</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>348</PostId>
    <RevisionGUID>900cfb4a-cbb6-49b7-b738-3f2b3fb7660d</RevisionGUID>
    <CreationDate>2010-03-18T10:02:35.297</CreationDate>
    <IPAddress>193.62.204.234</IPAddress>
    <UserId>99</UserId>
    <Text>Is there any tool that will tell me how different/similar two chip-seq peak sets are in two different parts of the genome? For example, if I have a ~10Kb region in the genome with a series of peaks and another ~10Kb region in the genome with another set of peaks from the same experiment, can I calculate a distance measure between these two peak set profiles with any available tool?</Text>
  </row>
  <row>
    <Id>632</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>348</PostId>
    <RevisionGUID>900cfb4a-cbb6-49b7-b738-3f2b3fb7660d</RevisionGUID>
    <CreationDate>2010-03-18T10:02:35.297</CreationDate>
    <IPAddress>193.62.204.234</IPAddress>
    <UserId>99</UserId>
    <Text>distance measure between chip-seq peak set profiles</Text>
  </row>
  <row>
    <Id>633</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>348</PostId>
    <RevisionGUID>900cfb4a-cbb6-49b7-b738-3f2b3fb7660d</RevisionGUID>
    <CreationDate>2010-03-18T10:02:35.297</CreationDate>
    <IPAddress>193.62.204.234</IPAddress>
    <UserId>99</UserId>
    <Text> échipöseqà  édistanceà  éprofilesà </Text>
  </row>
  <row>
    <Id>634</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>349</PostId>
    <RevisionGUID>bd08e6a3-7364-4d85-a6b4-43c4d5a505f4</RevisionGUID>
    <CreationDate>2010-03-18T10:06:47.77</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text>Do you aim to make your resources as widely available and reusable as possible? 

Conversely, do you try to protect the investment of time and resources that went into producing the IP?

The choice of license can be a tricky thing, and getting it wrong can cause considerable problems for you, and for others attempting to build on your work.

Things to consider:

[ISCB Discussion report on software sharing][1]

[Ontology licensing][2]

[Attribution vs Citation][3]




  [1]: http://iscb-discussion.blogspot.com/2008/03/iscb-member-feedback-sought-on-revised.html
  [2]: http://themindwobbles.wordpress.com/2009/11/12/science-commons-provide-a-list-of-considerations-for-researchers-looking-to-license-their-ontology/
  [3]: http://peanutbutter.wordpress.com/2009/07/10/attribution-vs-citation-do-you-know-the-difference/</Text>
  </row>
  <row>
    <Id>635</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>349</PostId>
    <RevisionGUID>bd08e6a3-7364-4d85-a6b4-43c4d5a505f4</RevisionGUID>
    <CreationDate>2010-03-18T10:06:47.77</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text>What license do you use when you release code and data?</Text>
  </row>
  <row>
    <Id>636</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>349</PostId>
    <RevisionGUID>bd08e6a3-7364-4d85-a6b4-43c4d5a505f4</RevisionGUID>
    <CreationDate>2010-03-18T10:06:47.77</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text> élicensingà  égeneralà  ésoftwareà </Text>
  </row>
  <row>
    <Id>637</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>350</PostId>
    <RevisionGUID>7fd21b19-bc24-441a-95c5-7505462564ec</RevisionGUID>
    <CreationDate>2010-03-18T10:59:10.78</CreationDate>
    <IPAddress>82.126.30.234</IPAddress>
    <UserId>30</UserId>
    <Text>my code ( http://code.google.com/p/lindenb/ ) is released under **GNU General Public License v2** but frankly,  the characteristics of all the available licenses are just vague for me. I just want a license that would say: 
&gt; use my code as much as you want but 
&gt; tell me if you're doing something
&gt; interesting with it, cite my work if an article is published, and remember me if
&gt; you're getting millionaire.
</Text>
  </row>
  <row>
    <Id>638</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>351</PostId>
    <RevisionGUID>953953b9-211d-479d-b6e8-d5fa74ef9002</RevisionGUID>
    <CreationDate>2010-03-18T11:21:20.02</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Most of the time I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.

If I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. 

For slides and written material I pay more attention, I always use a [Creative Commons][1] license, usually [commercial work/free to share][2] 


  [1]: http://creativecommons.org/
  [2]: http://creativecommons.org/licenses/by/3.0/us/</Text>
  </row>
  <row>
    <Id>639</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>352</PostId>
    <RevisionGUID>1b80011b-4623-4ff5-baf0-37f8856c38ae</RevisionGUID>
    <CreationDate>2010-03-18T12:10:10.17</CreationDate>
    <IPAddress>128.143.18.68</IPAddress>
    <UserId>138</UserId>
    <Text>I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project **might** catch wind because it is inside some corporate codebase (i.e. has users) even if they do not have technically have to release the modified sources.</Text>
  </row>
  <row>
    <Id>640</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>353</PostId>
    <RevisionGUID>841d171b-151b-4644-9ebb-732034fdaf08</RevisionGUID>
    <CreationDate>2010-03-18T13:26:46.6</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>One important consideration is that of the support that made the software possible. When someone's work is supported by public grants (aka taxpayers) both ethical considerations and probably the law requires that the software be made available with few strings attached.
 
The fundamental differences between the Open Source licenses can be found in the conditions specifying the licensing of derived work based on the software. Some licenses do not impose any conditions: MIT, BSD; others strictly mandate that any type of derived work must be licensed the same conditions as the original work GPL. 

I have been on various sides of software licensing, but now I think that each situation is unique thus no general rule or recommendation applies to all situations.</Text>
  </row>
  <row>
    <Id>641</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>354</PostId>
    <RevisionGUID>42421768-e21a-4e9b-a558-8abec45c5674</RevisionGUID>
    <CreationDate>2010-03-18T14:28:46.533</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>Without getting into a licensing discussion: I prefer to use the most permissive licenses like MIT/BSD instead of GPL. The bottom line is being I never want the license to be a reason for people *not* to use my code--though I can see the reasons why some libraries choose different licenses.</Text>
  </row>
  <row>
    <Id>642</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>355</PostId>
    <RevisionGUID>36b91dff-1d12-4e06-ad6f-ee35d62ed0f6</RevisionGUID>
    <CreationDate>2010-03-18T14:40:57.9</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Hi,

this is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions

 1. We assume that the  position of each peak is defined independently of the rest
 2. Within one peak the distribution of the reads is governed by a reasonably normal distribution

Thus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. 

The results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:

![alt text][1]

The upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.
The interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.

I do have a tool that does this pretty automatically but since I am not fully convinced of its correctness it is not yet publicly available.

Not so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.


  [1]: http://atlas.bx.psu.edu/_images/genie-compare.png</Text>
  </row>
  <row>
    <Id>643</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>355</PostId>
    <RevisionGUID>72c53ba1-ca90-4f57-8a77-72a64d32f07f</RevisionGUID>
    <CreationDate>2010-03-18T14:48:21.32</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 25 characters in body</Comment>
    <Text>Hi,

this is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions

 1. We assume that the  position of each peak is defined independently of the rest
 2. Within one peak the distribution of the reads is governed by a reasonably normal distribution

Thus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. 

The results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:

![alt text][1]

The upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.
The interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.

I do have a tool that does this pretty automatically but since I am not yet convinced of the correctness of the approach as a whole it is not yet publicly available.

Not so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.


  [1]: http://atlas.bx.psu.edu/_images/genie-compare.png</Text>
  </row>
  <row>
    <Id>644</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>351</PostId>
    <RevisionGUID>4da34575-5cf3-4a43-b28c-a8e3132d0e3d</RevisionGUID>
    <CreationDate>2010-03-18T16:46:12.683</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>corrected spelling</Comment>
    <Text>Most of the times I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.

If I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. 

For slides and written material I pay more attention, I always use a [Creative Commons][1] license, usually [commercial work/free to share][2] 


  [1]: http://creativecommons.org/
  [2]: http://creativecommons.org/licenses/by/3.0/us/</Text>
  </row>
  <row>
    <Id>645</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>356</PostId>
    <RevisionGUID>2afaa645-9752-4889-9c4c-d2379b1047f1</RevisionGUID>
    <CreationDate>2010-03-18T19:54:45.077</CreationDate>
    <IPAddress>128.143.18.68</IPAddress>
    <UserId>138</UserId>
    <Text>Looking only at the beautiful plots and not knowing what they really mean it seems to me that the a homegrown approach is unnecessary because after normalization you end up with two probability mass functions. There are multiple distance measures on probability distributions, but the Jensen-Shannon divergence seems (to me) to be most useful here because it can be generalized to multiple reads and has a probabilistic interpretation (the probability that the two runs represent samples drawn from the same background distribution) 

see: 

El-Yaniv, R., Fine, S. &amp; Tishby, N. Agnostic classification of Markovian sequences. In Advances in Neural Information Processing (NIPS-97  (1997).


</Text>
  </row>
  <row>
    <Id>646</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>357</PostId>
    <RevisionGUID>9359382d-280c-433c-a2c4-89a6da88969a</RevisionGUID>
    <CreationDate>2010-03-18T20:33:35.567</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text>Is there a package in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, "gene_symbol"), or another tool that you'd use for this job?</Text>
  </row>
  <row>
    <Id>647</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>357</PostId>
    <RevisionGUID>9359382d-280c-433c-a2c4-89a6da88969a</RevisionGUID>
    <CreationDate>2010-03-18T20:33:35.567</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text>Is there a package/function in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, "gene_symbol")</Text>
  </row>
  <row>
    <Id>648</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>357</PostId>
    <RevisionGUID>9359382d-280c-433c-a2c4-89a6da88969a</RevisionGUID>
    <CreationDate>2010-03-18T20:33:35.567</CreationDate>
    <IPAddress>198.123.49.13</IPAddress>
    <UserId>121</UserId>
    <Text> érà  égeneà  ésymbolà </Text>
  </row>
  <row>
    <Id>649</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>357</PostId>
    <RevisionGUID>1b535e16-1e03-4351-8c99-21f5511a5398</RevisionGUID>
    <CreationDate>2010-03-18T20:45:19.583</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>modified your title</Comment>
    <Text>How do I access and query entire genome sequences with R</Text>
  </row>
  <row>
    <Id>650</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>225</PostId>
    <RevisionGUID>58da32a4-562c-4ddd-921c-d286ea8c19c7</RevisionGUID>
    <CreationDate>2010-03-18T21:30:55.213</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Comment>add link to new paper.</Comment>
    <Text>[EDIT]
Just saw [this][1] today (http://www.biomedcentral.com/1471-2105/11/143) which could be another piece of software to check out. I didnt read it carefully, but it looks like it builds on primer3.
[/EDIT]


Since you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. 
Actually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use [bowtie][2].

As far as I know, [primer3][3] does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.

or, you could use BLAST and find nearby hits between the pairs.


  [1]: http://www.biomedcentral.com/1471-2105/11/143
  [2]: http://bowtie-bio.sourceforge.net/index.shtml
  [3]: http://primer3.sourceforge.net/</Text>
  </row>
  <row>
    <Id>651</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>358</PostId>
    <RevisionGUID>9e1bf72e-13ee-452a-862a-fac013fbf8a2</RevisionGUID>
    <CreationDate>2010-03-18T21:37:45.437</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text>Fasta files are pretty easy to manipulate using the seqinR package, if you've got the memory to handle it.  (~4GB for chr1)

    library(seqinr)
    seq = read.fasta("chr1.fa",seqtype="DNA")
    geneSeq = seq[[1]][geneStart:geneStop]
    
There's probably a better way to do it, but this may get you started.</Text>
  </row>
  <row>
    <Id>652</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>359</PostId>
    <RevisionGUID>22199839-6fdc-4bc1-a55f-28b843628b4f</RevisionGUID>
    <CreationDate>2010-03-18T21:47:46.41</CreationDate>
    <IPAddress>82.126.20.213</IPAddress>
    <UserId>30</UserId>
    <Text>Ok, here is my java solution. It only uses some *remote* resources (the anonymous mysql server and the DAS server of the UCSC). My piece of code takes a list of refGene as its arguments and only prints the genes/geneomic-sequences to stdout but one could imagine it would store a pair(name,sequence) in memory.



    import java.sql.Connection;
    import java.sql.DriverManager;
    import java.sql.PreparedStatement;
    import java.sql.ResultSet;
    
    import javax.xml.parsers.SAXParser;
    import javax.xml.parsers.SAXParserFactory;
    
    import org.xml.sax.Attributes;
    import org.xml.sax.SAXException;
    import org.xml.sax.helpers.DefaultHandler;
    
    public class Gene2Seq
    	{
    	private static class DASHandler
    		extends DefaultHandler
    		{
    		private boolean inDNA=false;
    		@Override
    		public void startElement(String uri, String localName, String qName,
    				Attributes attributes) throws SAXException
    			{
    			inDNA=(qName.equals("DNA"));
    			}
    		@Override
    		public void endElement(String uri, String localName, String qName)
    				throws SAXException
    			{
    			inDNA=false;
    			}
    		@Override
    		public void characters(char[] ch, int start, int length)
    				throws SAXException
    			{
    			if(inDNA) System.out.print(new String(ch, start, length).replace("\n", ""));
    			}
    		}
    	
    	public static void main(String[] args) throws Throwable
    		{
    		//put the JDBC driver for mysql in the $CLASSPATH
    		Class.forName("com.mysql.jdbc.Driver");
    		Connection con = DriverManager.getConnection(
    				"jdbc:mysql://genome-mysql.cse.ucsc.edu/hg19",
    				"genome", ""
    				);
    		SAXParserFactory f=SAXParserFactory.newInstance();
    		SAXParser parser=f.newSAXParser();
    		PreparedStatement pstmt=con.prepareStatement(
    				"select name,chrom,txStart,txEnd from refGene where name2=?"
    				);
    		for(String name: args)
    			{
    			pstmt.setString(1, name);
    			ResultSet row=pstmt.executeQuery();
    			while(row.next())
    				{
    				System.out.println("&gt;"+row.getString(1)+"|"+row.getString(2)+":"+row.getInt(3)+"-"+row.getInt(4));
    				parser.parse(
    						"http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment="+row.getString(2)+":"+(row.getInt(3)+1)+","+(row.getInt(4)+1),
    						new DASHandler());
    				System.out.println();
    				}
    			row.close();
    			}
    		
    		pstmt.close();
    		con.close();
    		}
    	}


output with **EIF4G1**:



    &gt;NM_004953|chr3:184038262-184053145
    agatgggctgaaagtggaactcaaggggtttctggcacctacctacctgcttcccgctggggggtggggagttggcccag....
    &gt;NM_182917|chr3:184032970-184053145
    tcctcgacggccgccgcccgcctggccttttagggcctgactcccgcccttcctggcctacactcctgggcggcggcagg....
    &gt;NM_198241|chr3:184032355-184053145
    gaagcggtggccgccgagcgggatctgtgcggggagccggaaatggt....


</Text>
  </row>
  <row>
    <Id>653</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>360</PostId>
    <RevisionGUID>81f06a7a-489b-431a-b7dc-a860271c7f81</RevisionGUID>
    <CreationDate>2010-03-18T22:33:25.823</CreationDate>
    <IPAddress>130.155.25.114</IPAddress>
    <UserId>66</UserId>
    <Text>
seqinR ([http://cran.r-project.org/web/packages/seqinr/index.html][1]) is a good option for R.

If you don't need the whole genome locally, you can fetch sequences from Ensembl using biomaRt ([http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html][2]):

    library(biomaRt)
    ensembl &lt;- useMart("ensembl",dataset="hsapiens_gene_ensembl")
    seq     &lt;- getSequence(id = "A2M", type="hgnc_symbol", mart = ensembl, seqType = "transcript_exon_intron")


I would also consider one of the Bio* libraries ([http://www.open-bio.org/wiki/Projects][3]) for sequence retrieval and manipulation.


  [1]: http://cran.r-project.org/web/packages/seqinr/index.html
  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html
  [3]: http://www.open-bio.org/wiki/Projects</Text>
  </row>
  <row>
    <Id>654</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>361</PostId>
    <RevisionGUID>44373a70-38de-4f7e-a161-5659fcf09851</RevisionGUID>
    <CreationDate>2010-03-19T09:19:43.65</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>R has gotten a lot of sequence handling and searching routines recently that make it a good choice also for sequence analysis in bioinformatics.

Have a look at the [BSGenome package in BioConductor][1]. It is meant to hold the genome sequence and allow fast sequence searches in the genome sequence. It *does not* contain real genome annotations though. There are readymade packages for a bunch of eukaryote genomes you can download, but of course your organism has to be in the list. This can be used together with the [BioStrings][2] package that allows for fast sequence searches and manipulation. 

It could be a good team with biomaRt (already mentioned, I really recommend this) if you want further local sequence processing or if you already have the gene start/end coordinates, or alternatively transfer the coordinates only and cut these out of the BSGenome.


  [1]: http://www.bioconductor.org/packages/2.5/bioc/html/BSgenome.html
  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/Biostrings.html</Text>
  </row>
  <row>
    <Id>655</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>352</PostId>
    <RevisionGUID>075f603e-33a9-4847-a06d-3805f7e5993c</RevisionGUID>
    <CreationDate>2010-03-19T11:57:06.647</CreationDate>
    <IPAddress>128.143.18.68</IPAddress>
    <UserId>138</UserId>
    <Comment>grammar</Comment>
    <Text>I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project **might** catch wind because it is inside some corporate codebase (i.e. has users) even if they do not technically have to release the modified sources.</Text>
  </row>
  <row>
    <Id>656</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>362</PostId>
    <RevisionGUID>d42761d6-60c9-41f4-9eb3-297649053efe</RevisionGUID>
    <CreationDate>2010-03-19T13:49:39.463</CreationDate>
    <IPAddress>82.126.80.213</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
Thanks to [Neil][1], I've discovered that **Biomart** is not just a HTML front-end but it can also be invoked as a [web service][2].

So, I played with java and the following webservice: http://www.ensembl.org/biomart/martwsdl .

${jAVA_HOME}/bin/**wsimport**  http://www.ensembl.org/biomart/martwsdl

was called to generate the java sources from the **WSDL** file and I also wrote the following client:

    import org.ensembl._80.martservicesoap.*;
    
    public class BioMartClient
     {
     public static void  main(String args[]) throws Exception
      {
      BioMartSoapService service=new BioMartSoapService();
      MartServiceSoap martsoap= service.getBioMartSoapPort();
      for(Mart mart: martsoap.getRegistry())
       {
       System.out.println(mart.getName());
       }
      }
     }

but the program throwed the following exception when it invokes **getRegistry**():

    Exception in thread "main" com.sun.xml.internal.ws.server.UnsupportedMediaException: Unsupported Content-Type: text/html; charset=utf-8 Supported ones are: [text/xml]
            at com.sun.xml.internal.ws.encoding.StreamSOAPCodec.decode(StreamSOAPCodec.java:284)
    (...)
            at $Proxy30.getRegistry(Unknown Source)
            at BioMartClient.main(BioMartClient.java:9)


I also tested a few more BioMart servers: Sometimes *getRegistry* just returns an empty list (http://www.biomart.org/biomart/martwsdl ), sometimes the path *martwsdl* does not exist ( http://www.wormbase.org/biomart/martwsdl ), etc...

In the end I didn't find any server containing some data that could be processed via the SOAP protocol.

Is it a known issue ? Am I missing something ? Is there a functional BioMart+SOAP server anywhere ?

Thanks,



  [1]: http://biostar.stackexchange.com/questions/357
  [2]: http://www.biomart.org/martservice.html</Text>
  </row>
  <row>
    <Id>657</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>362</PostId>
    <RevisionGUID>d42761d6-60c9-41f4-9eb3-297649053efe</RevisionGUID>
    <CreationDate>2010-03-19T13:49:39.463</CreationDate>
    <IPAddress>82.126.80.213</IPAddress>
    <UserId>30</UserId>
    <Text>Anyone using "Biomart + Java Web Services" ?</Text>
  </row>
  <row>
    <Id>658</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>362</PostId>
    <RevisionGUID>d42761d6-60c9-41f4-9eb3-297649053efe</RevisionGUID>
    <CreationDate>2010-03-19T13:49:39.463</CreationDate>
    <IPAddress>82.126.80.213</IPAddress>
    <UserId>30</UserId>
    <Text> ébiomartà  éwsdlà  ésoapà  éjavaà  éwebserviceà </Text>
  </row>
  <row>
    <Id>659</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>176</PostId>
    <RevisionGUID>f87e42c9-0478-4a2f-b87e-1348a248de96</RevisionGUID>
    <CreationDate>2010-03-19T14:27:47.787</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>formatting</Comment>
    <Text>No idea how to do it exactly but I can think about two routes to investigate:

* LASTZ has something called "quantum DNA":

http://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna

* instead of using "linear" aligner go for graph based ones:

 POA     http://bioinfo.mbi.ucla.edu/poa/

 AliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/

</Text>
  </row>
  <row>
    <Id>660</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>363</PostId>
    <RevisionGUID>39461e1a-45be-481f-a9f7-7ce1f8efc37e</RevisionGUID>
    <CreationDate>2010-03-19T15:14:27.55</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>Given some genomic data in a well-known format (e.g. GFF) with gene models, what tool(s) do you use to visualize that data. 
What tools allow you to add your own tracks of data easily? 
I'm interested in both desktop and web-based tools--with preference to those that are customizable via some kind of API.</Text>
  </row>
  <row>
    <Id>661</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>363</PostId>
    <RevisionGUID>39461e1a-45be-481f-a9f7-7ce1f8efc37e</RevisionGUID>
    <CreationDate>2010-03-19T15:14:27.55</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>What tools/libraries do you use to visualize genomic feature data?</Text>
  </row>
  <row>
    <Id>662</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>363</PostId>
    <RevisionGUID>39461e1a-45be-481f-a9f7-7ce1f8efc37e</RevisionGUID>
    <CreationDate>2010-03-19T15:14:27.55</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text> évisualizationà  égenomeà  éplottingà </Text>
  </row>
  <row>
    <Id>663</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>364</PostId>
    <RevisionGUID>10e4a542-1d68-4512-918f-cdfa45055193</RevisionGUID>
    <CreationDate>2010-03-19T15:24:07.907</CreationDate>
    <IPAddress>82.126.16.202</IPAddress>
    <UserId>30</UserId>
    <Text>I'm using the well-known UCSC Genome Browser http://genome.ucsc.edu/goldenPath/help/customTrack.html

I also wrote an experimental implementation of [Jan Aerts' LocusTree][1] based on BerkeleyDB (see http://plindenbaum.blogspot.com/2009/11/java-implementation-of-jan-aerts.html )

![LocusTree][2]


  [1]: http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html
  [2]: http://4.media.tumblr.com/tumblr_kt8yz0W4AP1qznaooo1_400.jpg</Text>
  </row>
  <row>
    <Id>664</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>365</PostId>
    <RevisionGUID>21ea2248-4672-4ed3-be02-952a76f423f8</RevisionGUID>
    <CreationDate>2010-03-19T15:46:08.333</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Hi Pierre,

actually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], "In principle it's standardized, but everyone has different standards."

However, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.

I might give it a try and generate a simple Axis2 client, then I will edit and provide the 
java code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.

This is what I just tried in soapui:
connect to: http://www.biomart.org/biomart/martwsdl
then call "getRegistry" as you did with the following message:
  
      &lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:mar="http://www.biomart.org:80/MartServiceSoap"&gt;
    
       &lt;soapenv:Header/&gt;
    
       &lt;soapenv:Body&gt;
    
          &lt;mar:getRegistry/&gt;
       &lt;/soapenv:Body&gt;
    &lt;/soapenv:Envelope&gt;

Then you will get this response, which looks very much ok.

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;






  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan
  [2]: http://www.soapui.org/









</Text>
  </row>
  <row>
    <Id>665</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>366</PostId>
    <RevisionGUID>d298d75f-5fb0-4590-915e-6f0d0b6a617a</RevisionGUID>
    <CreationDate>2010-03-19T16:08:53.667</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>For desktop level genome visualization the [Integrated Genome Browser][1] is a very nice tool.

PS. Web based tool authors always tend to over-complicate things (that includes me too ;-) ), maybe it is accidental complexity, maybe it is avoidable. I wish I knew. There is a server side, there is a client side, state needs to be saved between interactions and that turns  into a disconnect that needs to be bridged.


  [1]: http://www.bioviz.org/igb/</Text>
  </row>
  <row>
    <Id>666</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>367</PostId>
    <RevisionGUID>86c10b6c-b8e6-41a8-837a-927243464510</RevisionGUID>
    <CreationDate>2010-03-19T16:44:35.42</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text>I'll put in a plug for  [Genboree](http://genboree.org/java-bin/login.jsp), which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a [REST API](http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview) that's fairly new.

Since I do a lot of copy-number work, I do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.</Text>
  </row>
  <row>
    <Id>667</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>366</PostId>
    <RevisionGUID>8eb1475f-87ea-4aad-aa75-2f105456d3f2</RevisionGUID>
    <CreationDate>2010-03-19T17:18:34.82</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>deleted 325 characters in body</Comment>
    <Text>For desktop level genome visualization the [Integrated Genome Browser][1] is a very nice tool.

  [1]: http://www.bioviz.org/igb/</Text>
  </row>
  <row>
    <Id>668</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>365</PostId>
    <RevisionGUID>bcd9bb67-c74e-42a3-bbbe-2cd6f29f7864</RevisionGUID>
    <CreationDate>2010-03-19T17:18:42.077</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 165 characters in body</Comment>
    <Text>Hi Pierre,

actually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], "In principle it's standardized, but everyone has different standards."

However, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.

I might give it a try and generate a simple Axis2 client, then I will edit and provide the 
java code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.

This is what I just tried in soapui:
with SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl
With other tools (eg curl, see comments), send the xml-message below to the 
service endpoint address: http://www.biomart.org/biomart/martsoap

then call "getRegistry" as you did with the following message:
  
      &lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:mar="http://www.biomart.org:80/MartServiceSoap"&gt;
    
       &lt;soapenv:Header/&gt;
    
       &lt;soapenv:Body&gt;
    
          &lt;mar:getRegistry/&gt;
       &lt;/soapenv:Body&gt;
    &lt;/soapenv:Envelope&gt;

Then you will get this response, which looks very much ok.

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;






  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan
  [2]: http://www.soapui.org/









</Text>
  </row>
  <row>
    <Id>669</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>367</PostId>
    <RevisionGUID>1883536f-76e8-4cc2-8abd-38b85ac0ea3f</RevisionGUID>
    <CreationDate>2010-03-19T17:22:51.893</CreationDate>
    <IPAddress>128.249.106.234</IPAddress>
    <UserId>117</UserId>
    <Comment>added 5 characters in body</Comment>
    <Text>I'll put in a plug for  [Genboree](http://genboree.org/java-bin/login.jsp), which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a [REST API](http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview) that's fairly new.

Since I do a lot of copy-number work, I also do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.</Text>
  </row>
  <row>
    <Id>670</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>368</PostId>
    <RevisionGUID>46b13ecc-fdfd-4d43-ab7f-c0cfd2a8ea5b</RevisionGUID>
    <CreationDate>2010-03-19T17:51:58.357</CreationDate>
    <IPAddress>159.92.206.174</IPAddress>
    <UserId>120</UserId>
    <Text>I like the Broad's IGV: [http://www.broadinstitute.org/igv/][1] for genome browsing. It handles lots of common data formats, including SAM/BAM files if you're dealing with NGS-scale datasets. Apparently you can talk to it it via http, but you can't say anything very complicated: [http://www.broadinstitute.org/igv/PortCommands][2]

  [1]: http://www.broadinstitute.org/igv/
  [2]: http://www.broadinstitute.org/igv/PortCommands
</Text>
  </row>
  <row>
    <Id>671</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>369</PostId>
    <RevisionGUID>e73ca9f4-a187-4242-9311-447f57c9d086</RevisionGUID>
    <CreationDate>2010-03-19T18:25:34.75</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>As tagged correctly, this is a multiple sequence alignment problem, so pairwise/database alignment tools (BLAST or maybe B/LASTZ as mentioned above) are not an option. 
So well understood tools such as [ClustalW][1], or T-Coffe, or DIALIGN, might already do the job. Try low gap extension/opening costs. I would try a well-known algorithm and try the more 'esoteric' stuff later on, and only if that doesn't give good results.

Better than ClustalW maybe in your case
[Dialign][2]: It uses no gap-costs. 

&gt; This approach can be used for both global and local alignment, but it is particularly successful in situations where sequences share only local  homologies. (From the BiBiServ description)

This seems to fit your case quite well.

Another possibility would be to mask out the portions of each sequence that is a priori known to be less conserved. That requires to have knowledge about each sequence and to manually design a mask. Or even a vector of base-specific weights, but I don't know any MSA tool that takes such input. If you find one, please post it here :)




  [1]: http://www.ebi.ac.uk/Tools/clustalw2/
  [2]: http://bibiserv.techfak.uni-bielefeld.de/dialign/</Text>
  </row>
  <row>
    <Id>672</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>370</PostId>
    <RevisionGUID>e0e3b36a-9d2a-4e7c-82b2-0f5e10f07808</RevisionGUID>
    <CreationDate>2010-03-19T20:51:09.38</CreationDate>
    <IPAddress>89.253.99.150</IPAddress>
    <UserId>26</UserId>
    <Text>I use [Artemis][1] and [ACT][2] from the Sanger Institute. The former is a genome viewer and annotation tool. The latter is used for comparing genomes.

However, I'm not sure that there's an API for it...


  [1]: http://www.sanger.ac.uk/resources/software/artemis/
  [2]: http://www.sanger.ac.uk/resources/software/act/</Text>
  </row>
  <row>
    <Id>673</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>371</PostId>
    <RevisionGUID>69304642-8c0b-4297-9c29-707295f0eabb</RevisionGUID>
    <CreationDate>2010-03-19T21:56:40.777</CreationDate>
    <IPAddress>122.108.178.250</IPAddress>
    <UserId>90</UserId>
    <Text>A bit different from the linear browsers listed above is the genome visualization tool [circos][1]. It can plot a wide range of different data types onto the radially displayed chromosomes. Everything can be customized and is quite easy to use. 

![alt text][2]


  [1]: http://mkweb.bcgsc.ca/circos/
  [2]: http://mkweb.bcgsc.ca/circos/tutorial_images/100px/tutorial-05-05.png</Text>
  </row>
  <row>
    <Id>674</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>365</PostId>
    <RevisionGUID>560a537c-e475-450b-ad31-04178efb0d68</RevisionGUID>
    <CreationDate>2010-03-19T22:36:03.347</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 1180 characters in body</Comment>
    <Text>Edit:
**Conclusion: It does not work and is unlikely to work without changing the service.**

Testing bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.
I actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.  

Actually, I tried to use a generated Axis2 client and got an exception.
Then, I tried to validate the response message in SoapUI from BioMart, and it does not validate!

    line 4: Expected element 'mart' instead of 'mart@http://www.biomart.org:80/MartServiceSoap' here in element getRegistryResponse@http://www.biomart.org:80/MartServiceSoap

So it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. 

Maybe, you wish to join me in this effort?


----------


Hi Pierre,

actually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], "In principle it's standardized, but everyone has different standards."

However, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.

I might give it a try and generate a simple Axis2 client, then I will edit and provide the 
java code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.

This is what I just tried in soapui:
with SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl
With other tools (eg curl, see comments), send the xml-message below to the 
service endpoint address: http://www.biomart.org/biomart/martsoap

then call "getRegistry" as you did with the following message:
  
      &lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:mar="http://www.biomart.org:80/MartServiceSoap"&gt;
    
       &lt;soapenv:Header/&gt;
    
       &lt;soapenv:Body&gt;
    
          &lt;mar:getRegistry/&gt;
       &lt;/soapenv:Body&gt;
    &lt;/soapenv:Envelope&gt;

Then you will get this response, which looks very much ok.

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;






  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan
  [2]: http://www.soapui.org/









</Text>
  </row>
  <row>
    <Id>675</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>372</PostId>
    <RevisionGUID>73ad9312-4c2d-470f-8c60-3201b8ed85f7</RevisionGUID>
    <CreationDate>2010-03-19T23:16:11.83</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>It's interesting to see votes for the IGV; I've looked at it only recently and it does look very promising as a desktop viewer.

I'm a long-time user of the [Generic Genome Browser][1], a Bioperl-based web application. It is extremely customizable and can act as both DAS server and client. Be prepared to spend quite a bit of time "munging" your GFF files into shape and working on the config file to get the desired results.

I also like Bioperl's [Bio::Graphics][2] as a way to take simple text files (including GFF) and quickly generate very attractive plots.  There's a similar, but less extensive [Ruby library][3] too.

I've recently tried [GenomeGraphs][4], an R Bioconductor package. It fetches annotations from Ensembl and plots them as tracks. It's a good way to overlay quantitative data onto genomic features:  here is a [sample plot][5].


  [1]: http://gmod.org/wiki/Gbrowse
  [2]: http://bioperl.org/wiki/HOWTO:Graphics
  [3]: http://bio-graphics.rubyforge.org/
  [4]: http://www.bioconductor.org/packages/release/bioc/html/GenomeGraphs.html
  [5]: http://twitpic.com/19350x</Text>
  </row>
  <row>
    <Id>676</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>373</PostId>
    <RevisionGUID>788ca338-fde3-4048-a1d3-16660e288725</RevisionGUID>
    <CreationDate>2010-03-20T08:22:48.323</CreationDate>
    <IPAddress>92.241.196.40</IPAddress>
    <UserId>71</UserId>
    <Text>Regarding Open Data, these require different licenses. I recommend reading the [Panton Principles][1].


  [1]: http://pantonprinciples.org/</Text>
  </row>
  <row>
    <Id>677</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>374</PostId>
    <RevisionGUID>019e947c-d34d-422d-b66a-57f255e85769</RevisionGUID>
    <CreationDate>2010-03-20T11:37:31.03</CreationDate>
    <IPAddress>87.91.205.66</IPAddress>
    <UserId>154</UserId>
    <Text>If you want to obtain domains as well as the annotations that come along, you can do it locally with an RPS-BALST. Here for example to obtain Pfam annotations :
&gt; rpsblast -i ".$InputPath."/".$item." -d ~/Bioinfo/cdd/Pfam -e 0.000000000001 -o ".$elemt[0]."_Pfam.rpsblast -T T -m 7

- i = the input path
- d = the database path
- e = the e-value cut-off value
- o = the output name
- T T and -m 7 = to have the output in XML format

You can download all the databases fromm CDD http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.
 You'll obtain external source databases like Pfam, SMART, COG, PRK, TIGRFAM. </Text>
  </row>
  <row>
    <Id>678</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>375</PostId>
    <RevisionGUID>1488d068-727a-45b6-bdf5-293ff6b62ae1</RevisionGUID>
    <CreationDate>2010-03-20T12:24:42.773</CreationDate>
    <IPAddress>87.91.205.66</IPAddress>
    <UserId>154</UserId>
    <Text>Hi everyone,

As input files, I use swissprot files. 
I have a perl script which parses all the `enter code here`files to retieve all the EMBL ids and GeneID from the DR features line for each protein.
I would like to know if there's an automatic way to retrieve all the corresponding DNA squences for each protein on the list. Thanks for your help.

Best,

Kirsley

</Text>
  </row>
  <row>
    <Id>679</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>375</PostId>
    <RevisionGUID>1488d068-727a-45b6-bdf5-293ff6b62ae1</RevisionGUID>
    <CreationDate>2010-03-20T12:24:42.773</CreationDate>
    <IPAddress>87.91.205.66</IPAddress>
    <UserId>154</UserId>
    <Text>How to retrive the DNA sequence from a list of EMBL and GeneID</Text>
  </row>
  <row>
    <Id>680</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>375</PostId>
    <RevisionGUID>1488d068-727a-45b6-bdf5-293ff6b62ae1</RevisionGUID>
    <CreationDate>2010-03-20T12:24:42.773</CreationDate>
    <IPAddress>87.91.205.66</IPAddress>
    <UserId>154</UserId>
    <Text> éswissprotà  édnaà  éproteinà  éemblà  égenbankà </Text>
  </row>
  <row>
    <Id>681</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>376</PostId>
    <RevisionGUID>a9bb2498-e7e4-4ce0-86e1-59ef8d697a8e</RevisionGUID>
    <CreationDate>2010-03-20T12:51:20.103</CreationDate>
    <IPAddress>82.126.89.118</IPAddress>
    <UserId>30</UserId>
    <Text>from a geneid you can get the information as XML from the NCBI  with **EFetch**. e.g. for GeneId=2.

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&amp;id=2&amp;retmode=xml

and you can then get the accession of each RNA sequence under: `(...)/Gene-commentary_products/Gene-commentary/Gene-commentary_type[@value='mRNA']/Gene-commentary_accession` (use XSLT/XPATH to extract this information)

and for each accession you get the DNA sequence  with EFetch.

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&amp;id=NM_000014&amp;rettype=fasta&amp;retmode=xml

</Text>
  </row>
  <row>
    <Id>682</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>377</PostId>
    <RevisionGUID>8ae18711-c9cb-4ab8-92af-44ff194c761e</RevisionGUID>
    <CreationDate>2010-03-20T13:02:12.357</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>Yes there is if your organism is in Ensembl - [BioMart][1].  Here is how you'd use the web interface, assuming that you want human sequences:

 1. Go to BioMart and click MARTVIEW
 2. Select database = Ensembl Genes 57
 3. Select dataset = Homo sapiens genes
 4. Click "Filters" to the left and open the "Gene" selection
 5. From the dropdown box, select the IDs that you want to use (e.g. UniProt/TrEMBL)
 6. Either paste your list in the box or upload the file
 7. Click "Attributes" to the left, select the "Sequences" radio button and open the "Sequences" tab
 8. Select what type of sequence (e.g. unspliced transcript)
 9. Click "Results" (in menu bar, top-left of page)

This will return the first 10 sequences. You can download the rest as a file. There is also programmatic access to Ensembl:  Perl API, biomaRt for R Bioconductor.

If this doesn't work for you, the [Bioperl][2] library should be able to retrieve sequences given IDs.


  [1]: http://www.biomart.org
  [2]: http://www.bioperl.org</Text>
  </row>
  <row>
    <Id>683</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>378</PostId>
    <RevisionGUID>b3850bb6-5311-4f18-9135-4d5dfc36fc74</RevisionGUID>
    <CreationDate>2010-03-20T15:12:06.51</CreationDate>
    <IPAddress>98.231.133.77</IPAddress>
    <UserId>89</UserId>
    <Text>What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.

I have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?


  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm
  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html</Text>
  </row>
  <row>
    <Id>684</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>378</PostId>
    <RevisionGUID>b3850bb6-5311-4f18-9135-4d5dfc36fc74</RevisionGUID>
    <CreationDate>2010-03-20T15:12:06.51</CreationDate>
    <IPAddress>98.231.133.77</IPAddress>
    <UserId>89</UserId>
    <Text>Drawing chromosome ideogams with data</Text>
  </row>
  <row>
    <Id>685</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>378</PostId>
    <RevisionGUID>b3850bb6-5311-4f18-9135-4d5dfc36fc74</RevisionGUID>
    <CreationDate>2010-03-20T15:12:06.51</CreationDate>
    <IPAddress>98.231.133.77</IPAddress>
    <UserId>89</UserId>
    <Text> échromosomeà  éideogramà  éplottingà </Text>
  </row>
  <row>
    <Id>686</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>379</PostId>
    <RevisionGUID>ca3518c4-db8a-492e-9fd5-bcc259a40bf0</RevisionGUID>
    <CreationDate>2010-03-20T15:35:11.017</CreationDate>
    <IPAddress>82.126.6.192</IPAddress>
    <UserId>30</UserId>
    <Text>I found this bookmark in my del.icio.us 

&gt; "Idiographica: a general-purpose web
&gt; application to build idiograms
&gt; on-demand for human, mouse and rat"

 doi:10.1093/bioinformatics/btm455 

http://www.ncrna.org/idiographica/

![idiographica][1]

There is also [gff2ps][2] 

Or you can use the **custom tracks** in the [UCSC genome Browser][3].


  [1]: http://www.ncrna.org/idiographica/image/idiogram_sample1s
  [2]: http://genome.crg.es/software/gfftools/GFF2PS.html
  [3]: http://genome.ucsc.edu/goldenPath/help/customTrack.html</Text>
  </row>
  <row>
    <Id>687</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>378</PostId>
    <RevisionGUID>d3790f2b-6d9b-4892-8485-4dcc5528ac39</RevisionGUID>
    <CreationDate>2010-03-20T16:10:27.787</CreationDate>
    <IPAddress>137.187.250.79</IPAddress>
    <UserId>89</UserId>
    <Comment>added 164 characters in body</Comment>
    <Text>What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.

I have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?

**UPDATE**:
I need something like this:
![chromosome plot example][3]


  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm
  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html
  [3]: http://img233.imageshack.us/img233/6805/chrexample.jpg "chromosome plot example"</Text>
  </row>
  <row>
    <Id>688</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>380</PostId>
    <RevisionGUID>31fe9af1-490a-4957-8de3-087290c298d8</RevisionGUID>
    <CreationDate>2010-03-20T17:35:00.013</CreationDate>
    <IPAddress>71.185.140.161</IPAddress>
    <UserId>73</UserId>
    <Text>Circos is very popular these days
http://mkweb.bcgsc.ca/circos/</Text>
  </row>
  <row>
    <Id>689</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>381</PostId>
    <RevisionGUID>96fe0786-29ca-4b05-9fb1-79a080b0bb4d</RevisionGUID>
    <CreationDate>2010-03-20T23:07:51.72</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>You can try [Flash GViewer][1].
&lt;p&gt;I found it so nice that I tried to do a SVG version of it but not enough spare time to finish it.&lt;/p&gt;


  [1]: http://gmod.org/wiki/Flashgviewer/</Text>
  </row>
  <row>
    <Id>690</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>300</PostId>
    <RevisionGUID>f3fd5eeb-f980-49c3-9905-b695cc3ba2cd</RevisionGUID>
    <CreationDate>2010-03-20T23:10:36.863</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Comment>deleted 3 characters in body</Comment>
    <Text>You can also checked [http://www.bioinformatics.fr/jobs.php][1] with a dedicated RSS feed.&lt;/p&gt;
&lt;p&gt;When I have the time I also try to compile jobs from other sources like :&lt;/p&gt;

 - [jobs.ac.uk][2] 
 - [bioinformatics.org][3]
 - [listbioinfo][4] (see Pierre post)
 - [iscb.org][5] 
 - [biospace.com][6]


  [1]: http://www.bioinformatics.fr/jobs.php
  [2]: http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&amp;x=0&amp;y=0
  [3]: http://www.bioinformatics.org/jobs/
  [4]: http://listes.sfbi.fr/wws/info/bioinfo
  [5]: http://www.iscb.org/iscb-careers
  [6]: http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&amp;TheLocation=%25%25</Text>
  </row>
  <row>
    <Id>691</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>365</PostId>
    <RevisionGUID>4030e98f-afee-4bf3-97d2-1699172e2ac9</RevisionGUID>
    <CreationDate>2010-03-21T11:17:33.3</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 419 characters in body</Comment>
    <Text>Edit:
**Conclusion: It does not work and is unlikely to work without changing the service.**

**In the meantime, I would like to ask everyone who has similar experiences with non-functional SOAP/REST web-services, non-parsable WSDLS, non-validating XML-messages or other problems with service interoperability not to give up, but to report to the providers, to challenge them to improve the interoperability!**

Those experiencing similar problems with  BioMart can for example report to: mart-dev@ebi.ac.uk

Testing bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.
I actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.  

Actually, I tried to use a generated Axis2 client and got an exception.
Then, I tried to validate the response message in SoapUI from BioMart, and it does not validate!

    line 4: Expected element 'mart' instead of 'mart@http://www.biomart.org:80/MartServiceSoap' here in element getRegistryResponse@http://www.biomart.org:80/MartServiceSoap

So it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. 

Maybe, you wish to join me in this effort?


----------


Hi Pierre,

actually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], "In principle it's standardized, but everyone has different standards."

However, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.

I might give it a try and generate a simple Axis2 client, then I will edit and provide the 
java code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.

This is what I just tried in soapui:
with SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl
With other tools (eg curl, see comments), send the xml-message below to the 
service endpoint address: http://www.biomart.org/biomart/martsoap

then call "getRegistry" as you did with the following message:
  
      &lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:mar="http://www.biomart.org:80/MartServiceSoap"&gt;
    
       &lt;soapenv:Header/&gt;
    
       &lt;soapenv:Body&gt;
    
          &lt;mar:getRegistry/&gt;
       &lt;/soapenv:Body&gt;
    &lt;/soapenv:Envelope&gt;

Then you will get this response, which looks very much ok.

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;






  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan
  [2]: http://www.soapui.org/









</Text>
  </row>
  <row>
    <Id>692</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>382</PostId>
    <RevisionGUID>e5889f6d-6bd7-4789-93c5-f877dcb3e546</RevisionGUID>
    <CreationDate>2010-03-21T13:21:00.207</CreationDate>
    <IPAddress>87.91.205.66</IPAddress>
    <UserId>154</UserId>
    <Text>Thanks for your answers! I could not try with BioMart as my organism is not present on Ensembl. I forgot to precise that I am working on Chlamydiales.</Text>
  </row>
  <row>
    <Id>693</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>383</PostId>
    <RevisionGUID>334ec6de-3b87-44dc-94d8-1919e3058133</RevisionGUID>
    <CreationDate>2010-03-21T16:42:53.93</CreationDate>
    <IPAddress>68.48.94.77</IPAddress>
    <UserId>95</UserId>
    <Text>I guess a follow on to this question is "What are the best sites to advertise informatics jobs when you are on a limited budget."  My system includes posting on:

 - **[LinkedIn][1]** - Free when you post via your status profile and groups.
 - **[Nature Jobs][2]** - Free
 - **[GenomeWeb][3]** - Free
 - **[Bioinformatics(dot)org][4]** - $75 / year professional membership needed
 - **[Craigslist][5]** - Free in most cities and a great way to find local candidates if you are in a bigger biotech city (DC, Boston, SD)
 - **[ISCB][6]** - Free if you are a member, which is like 100 bucks.
 - **[Dice.com][7]** - Expensive, but targeted. Geared more to technology professionals, have found several great SE and sys admin candidates here.

Then, use sites like Twitter, FriendFeed, LinkedIn, Facebook, etc to spread thew word about the availability of these positions, and point candidates to your website.  I use [Wufoo][8] to generate applications, track candidates via the reports, etc.

I find all of these are great ways to find entry-mid level candidates. 

There is no substitute for trusted referrals or candidates from your existing network of professionals.

Of course these are all great sites to search for a new job as well, that why I use them. ;-)


  [1]: http://www.linkedin.com/
  [2]: http://www.nature.com/naturejobs/index.html
  [3]: http://www.genomeweb.com/jobs
  [4]: http://www.genomeweb.com/jobs
  [5]: http://washingtondc.craigslist.org/sci/
  [6]: http://www.iscb.org/iscb-careers
  [7]: http://www.dice.com/
  [8]: http://Wufoo.com</Text>
  </row>
  <row>
    <Id>694</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>384</PostId>
    <RevisionGUID>f79d8e29-ca99-42b9-b7e0-67876132db5a</RevisionGUID>
    <CreationDate>2010-03-21T21:00:25.287</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>Hi again,

I was finally able to edit the received message such that it can be validated. The biomart reponse semed to completely screw up namespaces and they use [XML-schema instance][1]. :o)
If you look at that w3c site you see that they say this should never be used.
So compare the valid edited reponse massage with the real (but shortened) output.
The next step is to make the maintainers have their service send valid XML

Here is the edited and schema-valid response, only the first mart given:


    &lt;soap:Envelope 
    soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" 
    
    xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" 
    xmlns:xsd="http://www.w3.org/2001/XMLSchema" 
    xmlns:tns="http://www.biomart.org:80/MartServiceSoap"
    xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;tns:getRegistryResponse&gt;
             &lt;mart&gt;
                &lt;name&gt;ensembl&lt;/name&gt;
                &lt;displayName&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host&gt;www.biomart.org&lt;/host&gt;
                &lt;path&gt;/biomart/martservice&lt;/path&gt;
                &lt;port&gt;80&lt;/port&gt;
                &lt;visible&gt;1&lt;/visible&gt;
                &lt;default&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets/&gt;
                &lt;martUser/&gt;
                &lt;redirect&gt;1&lt;/redirect&gt;
             &lt;/mart&gt;
           
          &lt;/tns:getRegistryResponse&gt;
       &lt;/soap:Body&gt;
    &lt;/soap:Envelope&gt;

And compare this with the original response:

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"     
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" 
    xmlns:xsd="http://www.w3.org/2001/XMLSchema" 
    xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;
          &lt;/getRegistryResponse&gt;
       &lt;/soap:Body&gt;
    &lt;/soap:Envelope&gt;


  [1]: http://www.w3.org/2001/XMLSchema-instance

</Text>
  </row>
  <row>
    <Id>695</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>385</PostId>
    <RevisionGUID>5a6946cc-c11e-44ab-b28b-bbfdb6726cc5</RevisionGUID>
    <CreationDate>2010-03-22T08:21:22.287</CreationDate>
    <IPAddress>147.100.115.243</IPAddress>
    <UserId>158</UserId>
    <Text>Hi, 

I like this thread: begins as a troll, ends with nice advices

  ---jmf</Text>
  </row>
  <row>
    <Id>696</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>384</PostId>
    <RevisionGUID>e936a448-b07a-4950-8d3f-3862c05e24ec</RevisionGUID>
    <CreationDate>2010-03-22T10:29:25.523</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
  </row>
  <row>
    <Id>697</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>384</PostId>
    <RevisionGUID>e936a448-b07a-4950-8d3f-3862c05e24ec</RevisionGUID>
    <CreationDate>2010-03-22T10:29:25.523</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 103 characters in body</Comment>
    <Text>Hi again,

I was finally able to edit the received message such that it can be validated. The biomart reponse semed to screw up namespace definitions and they use [XML-schema instance][1]. :o)

The schema instance definitions had no obvious use and did not validate. So I just removed them. 

If you look at that w3c site you see that W3C says this should never be used.
So compare the valid edited reponse massage with the real (but shortened) output.
The next step is to make the maintainers have their service send valid XML

Here is the edited and schema-valid response, only the first mart given:


    &lt;soap:Envelope 
    soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/" 
    
    xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" 
    xmlns:xsd="http://www.w3.org/2001/XMLSchema" 
    xmlns:tns="http://www.biomart.org:80/MartServiceSoap"
    xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;tns:getRegistryResponse&gt;
             &lt;mart&gt;
                &lt;name&gt;ensembl&lt;/name&gt;
                &lt;displayName&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host&gt;www.biomart.org&lt;/host&gt;
                &lt;path&gt;/biomart/martservice&lt;/path&gt;
                &lt;port&gt;80&lt;/port&gt;
                &lt;visible&gt;1&lt;/visible&gt;
                &lt;default&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets/&gt;
                &lt;martUser/&gt;
                &lt;redirect&gt;1&lt;/redirect&gt;
             &lt;/mart&gt;
           
          &lt;/tns:getRegistryResponse&gt;
       &lt;/soap:Body&gt;
    &lt;/soap:Envelope&gt;

And compare this with the original response:

    &lt;soap:Envelope soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"     
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xmlns:soapenc="http://schemas.xmlsoap.org/soap/encoding/" 
    xmlns:xsd="http://www.w3.org/2001/XMLSchema" 
    xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;
       &lt;soap:Body&gt;
          &lt;getRegistryResponse xmlns="http://www.biomart.org:80/MartServiceSoap"&gt;
             &lt;mart&gt;
                &lt;name xsi:type="xsd:string"&gt;ensembl&lt;/name&gt;
                &lt;displayName xsi:type="xsd:string"&gt;ENSEMBL GENES 57 (SANGER UK)&lt;/displayName&gt;
                &lt;database xsi:type="xsd:string"&gt;ensembl_mart_57&lt;/database&gt;
                &lt;host xsi:type="xsd:string"&gt;www.biomart.org&lt;/host&gt;
                &lt;path xsi:type="xsd:string"&gt;/biomart/martservice&lt;/path&gt;
                &lt;port xsi:type="xsd:string"&gt;80&lt;/port&gt;
                &lt;visible xsi:type="xsd:int"&gt;1&lt;/visible&gt;
                &lt;default xsi:type="xsd:int"&gt;1&lt;/default&gt;
                &lt;serverVirtualSchema xsi:type="xsd:string"&gt;default&lt;/serverVirtualSchema&gt;
                &lt;includeDatasets xsi:type="xsd:string"/&gt;
                &lt;martUser xsi:type="xsd:string"/&gt;
                &lt;redirect xsi:nil="true" xsi:type="xsd:int"/&gt;
             &lt;/mart&gt;
          &lt;/getRegistryResponse&gt;
       &lt;/soap:Body&gt;
    &lt;/soap:Envelope&gt;


  [1]: http://www.w3.org/2001/XMLSchema-instance

</Text>
  </row>
  <row>
    <Id>698</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>365</PostId>
    <RevisionGUID>e86ec449-b834-4176-8d0b-8c9a56de976d</RevisionGUID>
    <CreationDate>2010-03-22T10:30:08.16</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
  </row>
  <row>
    <Id>699</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>386</PostId>
    <RevisionGUID>e117c68b-4b17-4e11-8cf1-c10107d86ed5</RevisionGUID>
    <CreationDate>2010-03-22T10:30:55.053</CreationDate>
    <IPAddress>158.64.77.254</IPAddress>
    <UserId>161</UserId>
    <Text>Hi !
Briefly, I use R/Bioconductor, combined with PHP and MySQL. PHP can encapsulate programmes/scripts from other languages, such as Perl and Java, and can easly manage webapps by URL. Also nice for UI and run on Linux/MacOSX/Window$.
</Text>
  </row>
  <row>
    <Id>700</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>4f08e69e-5b5b-4acd-96d9-c65c21477a93</RevisionGUID>
    <CreationDate>2010-03-22T11:34:06.047</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi people,

I've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .

Hence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods. A list explaing why a given method is reliable (or why someone should use it). Who wants to contribute?</Text>
  </row>
  <row>
    <Id>701</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>4f08e69e-5b5b-4acd-96d9-c65c21477a93</RevisionGUID>
    <CreationDate>2010-03-22T11:34:06.047</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>What are the most reliable normalization method for microarrays?</Text>
  </row>
  <row>
    <Id>702</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>4f08e69e-5b5b-4acd-96d9-c65c21477a93</RevisionGUID>
    <CreationDate>2010-03-22T11:34:06.047</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> émicroarrayà  édataönormalizationà  émethodsà </Text>
  </row>
  <row>
    <Id>703</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>388</PostId>
    <RevisionGUID>87c5a8d3-e5d2-4838-8393-004fa287b8f4</RevisionGUID>
    <CreationDate>2010-03-22T11:59:39.737</CreationDate>
    <IPAddress>130.88.91.103</IPAddress>
    <UserId>160</UserId>
    <Text>Ok, I realise that some of you work on a genome campus or your mum may be a Nobel prize winner, but, given a socially average situation, how do you explain your work, and for a 50 point bonus, how do you feel as you do it?</Text>
  </row>
  <row>
    <Id>704</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>388</PostId>
    <RevisionGUID>87c5a8d3-e5d2-4838-8393-004fa287b8f4</RevisionGUID>
    <CreationDate>2010-03-22T11:59:39.737</CreationDate>
    <IPAddress>130.88.91.103</IPAddress>
    <UserId>160</UserId>
    <Text>How do you explain what you do to the guy on the street or your mum?</Text>
  </row>
  <row>
    <Id>705</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>388</PostId>
    <RevisionGUID>87c5a8d3-e5d2-4838-8393-004fa287b8f4</RevisionGUID>
    <CreationDate>2010-03-22T11:59:39.737</CreationDate>
    <IPAddress>130.88.91.103</IPAddress>
    <UserId>160</UserId>
    <Text> éwhatöisöbioinformaticsà </Text>
  </row>
  <row>
    <Id>706</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>389</PostId>
    <RevisionGUID>2dd0c7d6-a296-4937-95a4-87cb688af35d</RevisionGUID>
    <CreationDate>2010-03-22T12:04:48.933</CreationDate>
    <IPAddress>81.53.108.244</IPAddress>
    <UserId>30</UserId>
    <Text>I tell them: "there must [be a page on wikipedia][1] about it".


  [1]: http://en.wikipedia.org/wiki/Bioinformatics</Text>
  </row>
  <row>
    <Id>707</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>390</PostId>
    <RevisionGUID>9dbcf0a8-97e1-4f65-be21-1078a0401ab2</RevisionGUID>
    <CreationDate>2010-03-22T12:20:32.473</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I go to the streets and stop all the people I encounter, and I explain them what I do in my lab, so I accumulate a lot of experience and become better at explaining things :-)

Seriously, if you want to be able to explain your project to other people, you have to be able to explain it to your workmates first.. so I prepare a seminar every once in a while and I try to be active at group meetings. In my first year of phd I was able to prepare a seminar every month (as a mean), I also went to python meetings etc..

Non peer-review journals like The Scientist or Scientific American can give you good examples on how to translate a complex scientific experiment in a language that is easy to understand for everybody.

Another way to improve comes from the fact that I use a lot of A7 papers to take notes, so I constantly have to reduce my tasks to short phrases. However, it would take too long to explain this system better here..

I think that in general, if you want to improve your communications skills, you have to practice a lot, there is no other way to do it. </Text>
  </row>
  <row>
    <Id>708</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>391</PostId>
    <RevisionGUID>9cd91b61-8bd3-4a64-be8b-4846241c3ea8</RevisionGUID>
    <CreationDate>2010-03-22T13:03:12.263</CreationDate>
    <IPAddress>130.238.45.93</IPAddress>
    <UserId>71</UserId>
    <Text>While [BioTorrent][1] is still rather unpopulated, I quite like the idea of having such torrents seeded by university IT or library departments. Now, I want to analyze the data, so the question is, how can the data be used directly in my workflow system ([BioPerl][2] or [R][3] scripts, [Taverna][4] or [Bioclipse][5] workflows)?

Are there libraries in a suitable programming language to download torrents automatically, without human interaction?

  [1]: http://www.biotorrents.net/browse.php?page=1
  [2]: http://www.bioperl.org/
  [3]: http://www.r-project.org/
  [4]: http://taverna.sf.net
  [5]: http://bioclipse.net</Text>
  </row>
  <row>
    <Id>709</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>391</PostId>
    <RevisionGUID>9cd91b61-8bd3-4a64-be8b-4846241c3ea8</RevisionGUID>
    <CreationDate>2010-03-22T13:03:12.263</CreationDate>
    <IPAddress>130.238.45.93</IPAddress>
    <UserId>71</UserId>
    <Text>How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?</Text>
  </row>
  <row>
    <Id>710</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>391</PostId>
    <RevisionGUID>9cd91b61-8bd3-4a64-be8b-4846241c3ea8</RevisionGUID>
    <CreationDate>2010-03-22T13:03:12.263</CreationDate>
    <IPAddress>130.238.45.93</IPAddress>
    <UserId>71</UserId>
    <Text> étorrentà  ébioinformaticsà  édataà </Text>
  </row>
  <row>
    <Id>711</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>392</PostId>
    <RevisionGUID>adc09598-adf0-4f83-ab0f-9c8051e5226d</RevisionGUID>
    <CreationDate>2010-03-22T13:18:01.243</CreationDate>
    <IPAddress>130.155.80.14</IPAddress>
    <UserId>66</UserId>
    <Text>I recommend that you visit PubMed, enter "microarray (normalisation OR normalization) as a query, select some of the review articles and have a good read. Then, armed with appropriate keywords (RMA, GCRMA, MAS), head to Google and obtain some more opinions.

It is not so surprising that people cannot agree on methods. A normalisation method is just a statistical model that tries to explain what happens when probes meet gene chips. Different models have different assumptions. Some of these are: how to distinguish within-array effects from between-array effects?  Are mismatch probes ever useful?  (RMA says no, because MM probes often, in fact, match).  How is "background" distributed across a chip?

Experiments also vary. Which of your experiments are comparable? Should you even be comparing, say, samples prepared last week and frozen to samples freshly-prepared today? If you do want to compare, you can only hope that each set will show some characteristic (batch effect) for which you can correct. 

How do you conclude that a method is "right", or "better"?  You might try to validate using another experimental method, such as real-time PCR. Or you might conduct "spike-in" experiments, where you know what the "true positives" should be, then see how well each method picks them out.  That's the approach taken in [this paper][1].  Or, you might try several methods on your own favourite dataset. Of course, someone else will then try them on their favourite dataset - and reach totally opposite conclusions!  Or you might just ask "what do most people do?"

That's the long answer. The short answer: RMA ;-)

  [1]: http://nar.oxfordjournals.org/cgi/content/full/31/4/e15</Text>
  </row>
  <row>
    <Id>712</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>393</PostId>
    <RevisionGUID>3f2068dd-a8d7-4984-bc04-c7181b4e6c17</RevisionGUID>
    <CreationDate>2010-03-22T13:19:59.45</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>The lack of reproducibility in microarray methods is well known problem. In my opinion the reasons for this go way beyond the choice of normalization and are primarily caused by biological and experimental variability. Some are convinced that one method must be substantially better than the other, but I suspect that is because that particular method worked well for them under some specific circumstances. 

I read studies that demonstrated that the upper 50% percent (the strongest signals) were recovered identically across just about all methodologies, whereas the bottom half contained a different subset for each method. So maybe the best strategy is to be more strict with the results, beyond what the original estimate of the significance is - of course it could be that this approach removes the genes of interest.


That's the long answer. The short answer: the best normalization is the one you understand the best. 

;-)
</Text>
  </row>
  <row>
    <Id>713</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>394</PostId>
    <RevisionGUID>3bd98f03-e399-48b4-8670-eef95a5adeff</RevisionGUID>
    <CreationDate>2010-03-22T13:45:56.087</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I don't think there is an R library for torrents. I have tried searching [here][1] and on [CRAN][2], but there is nothing.

Perl, on the other side, has [many libraries][3] for downloading torrents. Python [supports torrents][4] as well.

Once you have chosen a library, just write a script to download the torrent and to give a return signal when it is finished. 

However, I would object on the reproducibility of using data downloaded with a torrent: what would you do if the torrent disappears or is modified after you have used it? How do you take into account the version of the data?
Moreover, consider that scientific databases have to release their data often, and every release would require a different torrent to be seed. That would make it more difficult to control and keep.



  [1]: http://www.rseek.org/?cx=010923144343702598753%3Aboaz1reyxd4&amp;q=torrent&amp;sa=Search+functions%2C+lists%2C+and+more&amp;cof=FORID%3A11&amp;siteurl=www.rseek.org%2F%3Fq%3Dtorrent#467
  [2]: http://cran.r-project.org/
  [3]: http://search.cpan.org/search?query=torrent&amp;mode=all
  [4]: http://pypi.python.org/pypi?%3Aaction=search&amp;term=torrent&amp;submit=search</Text>
  </row>
  <row>
    <Id>714</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>395</PostId>
    <RevisionGUID>b1ebff0d-02fe-4ccf-a11e-bae9502126f5</RevisionGUID>
    <CreationDate>2010-03-22T14:28:56.393</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. 

You need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:

For non-scientists:

- The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. ("better cancer treatments", "new malaria drugs")

- The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. ("understanding XYZ part of disease ABC by looking at things through a microscope", "figuring out how the brain stores memories by sticking people in cool scanners")

- The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.

For scientists:

- The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)

- The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?

- The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.

</Text>
  </row>
  <row>
    <Id>715</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>77ef11e2-5b5b-4604-86e3-7048f48939fc</RevisionGUID>
    <CreationDate>2010-03-22T14:45:10.39</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>fixed grammar</Comment>
    <Text>What are the most reliable normalization methods for microarrays?</Text>
  </row>
  <row>
    <Id>716</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>396</PostId>
    <RevisionGUID>7feae5fb-381a-487f-ab44-5ee0caf20bff</RevisionGUID>
    <CreationDate>2010-03-22T15:16:13.223</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>thanks for all the replies so far. i just want to add a couple i've found:
Annoj with a nice demo here: http://neomorph.salk.edu/epigenome/epigenome.html
seems to be a pretty nice web-interface and i've been able to get my own annotations drawn. it may be an abandoned project, and i wasn't able to find the javascript source (only the packed/minified version).

also [genometools][1] wraps cairo to allow simple drawing of regions: here's the image from their home page. ![alt text][2] And they have bindings to a variety of scripting languages.

  [1]: http://genometools.org
  [2]: http://genometools.org/images/annotation.png</Text>
  </row>
  <row>
    <Id>717</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>397</PostId>
    <RevisionGUID>e6607b84-3188-4308-9b46-7732630d1062</RevisionGUID>
    <CreationDate>2010-03-22T15:43:48.743</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>My opening line: "I work at the intersection between computers and biology". 

Often there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). 

Then one can go with finding "interesting paragraphs", "repeated, mostly boring parts", etc. Works for non-scientist (at least thatś my impression...).

In short: if possible, find analogy everyone can somehow relate to. 
You get minus points for anything sounding too technical.  
 
  
 </Text>
  </row>
  <row>
    <Id>718</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>398</PostId>
    <RevisionGUID>8ccf5367-1fd7-4873-96c6-db29b06c54ae</RevisionGUID>
    <CreationDate>2010-03-22T15:48:32.947</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>I went to several sites to look for a new position (thanks to recent [question][1]). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.

 - Bioinformatics Internship
 - Bioinformatics Postdoc 
 - Bioinformatics Analyst (I, II, III) 
 - Senior Bioinformatics Analyst 
 - Bioinformatics Analyst Programmer (I, II, III)
 - Bioinformatics Developer Senior
 - Bioinformatics Developer
 - Bioinformatician (I, II, III)
 - Bioinformatics Expert 
 - Bioinformatics Systems Administrator 
 - Bioinformatics Research Fellow 
 - Bioinformatics Research Assistant 
 - Bioinformatics Research Associate 
 - Bioinformatics Scientist (Researcher) 
 - Bioinformatics Senior (Staff) Scientist
 - Bioinformatics Project Manager
 - Director (Head) of Bioinformatics

  [1]: http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs</Text>
  </row>
  <row>
    <Id>719</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>398</PostId>
    <RevisionGUID>8ccf5367-1fd7-4873-96c6-db29b06c54ae</RevisionGUID>
    <CreationDate>2010-03-22T15:48:32.947</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>What different bioinformatics positions mean?</Text>
  </row>
  <row>
    <Id>720</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>398</PostId>
    <RevisionGUID>8ccf5367-1fd7-4873-96c6-db29b06c54ae</RevisionGUID>
    <CreationDate>2010-03-22T15:48:32.947</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text> éjobà  écareerà  égeneralà </Text>
  </row>
  <row>
    <Id>721</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>2acb152a-1801-4a6b-9740-0894ccf41115</RevisionGUID>
    <CreationDate>2010-03-22T16:12:52.463</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> ésequenceà  éalignmentà  éscoringmatrixà </Text>
  </row>
  <row>
    <Id>722</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>399</PostId>
    <RevisionGUID>ea89ef31-2c71-4cc1-b326-f423bab58575</RevisionGUID>
    <CreationDate>2010-03-22T16:48:47.99</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I use these simple facts : I work on data from human genome project, and explain that its one of the biggest scientific achievement ever. I use that data to analyze proteins involved in X diseases. We are trying to understand these proteins and its various aspects related to disease using computer programs, database, software etc. I will clarify that I won't do any wet lab experiments, instead I use computers for the experiments and we call it as dry lab. This used to work for me most of the time. 
</Text>
  </row>
  <row>
    <Id>723</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>397</PostId>
    <RevisionGUID>05059d79-98f2-4f8a-8812-54eaee243fdf</RevisionGUID>
    <CreationDate>2010-03-22T16:49:23.99</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>spell</Comment>
    <Text>My opening line: "I work at the intersection between computers and biology". 

Often there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). 

Then one can go with finding "interesting paragraphs", "repeated, mostly boring parts", etc. Works for non-scientist (at least that my impression...).

In short: if possible, find analogy everyone can somehow relate to. 
You get minus points for anything sounding too technical.  
 
  
 </Text>
  </row>
  <row>
    <Id>724</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>400</PostId>
    <RevisionGUID>605b0b1d-1e0b-4553-8ac2-862f0d98575d</RevisionGUID>
    <CreationDate>2010-03-22T17:01:04.58</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I think most of positions will have a brief, yet concise description that will explain the necessary qualification required for a particular position. I think the requirement depends on the nature of positions and there is no specific /systematic rule applies for different category of positions. </Text>
  </row>
  <row>
    <Id>725</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>388</PostId>
    <RevisionGUID>814038ad-867c-45f6-ad63-34ed61997d3b</RevisionGUID>
    <CreationDate>2010-03-22T17:25:16.173</CreationDate>
    <IPAddress>82.126.75.252</IPAddress>
    <UserId>30</UserId>
    <Comment>edited tags</Comment>
    <Text> éwhatöisöbioinformaticsà  énotöprogrammingörelatedà </Text>
  </row>
  <row>
    <Id>726</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>395</PostId>
    <RevisionGUID>3c2f4224-448f-4151-98b2-b5b4799b0a3a</RevisionGUID>
    <CreationDate>2010-03-22T17:27:40.68</CreationDate>
    <IPAddress>128.249.106.234</IPAddress>
    <UserId>117</UserId>
    <Comment>added 294 characters in body</Comment>
    <Text>I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. 

You need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:

For non-scientists:

- The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. ("better cancer treatments", "new malaria drugs")

- The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. ("understanding XYZ part of disease ABC by looking at things through a microscope", "figuring out how the brain stores memories by sticking people in cool scanners")

- The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.

For scientists:

- The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)

- The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?

- The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.


Once you get these down, practice the final element, which is being enthusiastic about your work. After all, you probably think that what you’re researching is one of the coolest and most important things ever. If that comes across to your audience, they’ll be engaged and interested too.

</Text>
  </row>
  <row>
    <Id>727</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>401</PostId>
    <RevisionGUID>54dd516a-3b32-4b89-b608-1e2e5fa85b08</RevisionGUID>
    <CreationDate>2010-03-22T17:34:19.973</CreationDate>
    <IPAddress>82.126.75.252</IPAddress>
    <UserId>30</UserId>
    <Text>sorry, I'm only speaking 'java' here.

I would create an interface ScoreMatrix:

    public interface ScoreMatrix
         {
         public int getScore(char aa1,char aa2);
         }

that would be used by your AlignmentTool

    public interface AlignmentTool
         {
         public void setScoreMatrix(ScoreMatrix m);
         public ScoreMatrix getScoreMatrix();
         public void align(String seq1,String seq);
         (...)
         }

and Blosum62 would be an implementation of ScoreMatrix

    public class Blosum62 implements ScoreMatrix
        {
        public int getScore(char aa1,char aa2) 
            {
            switch(upper(aa1))
              {
              (...)
               {
               case 'A' :
               switch(upper(aa2))
                 {
                 (...)
                 case 'A': return 98;
                 (...)
                 }
              }
            }
        }


</Text>
  </row>
  <row>
    <Id>728</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>398</PostId>
    <RevisionGUID>ff6fd723-251d-4a3a-8ad8-e8785e6be561</RevisionGUID>
    <CreationDate>2010-03-22T17:35:20.05</CreationDate>
    <IPAddress>82.126.75.252</IPAddress>
    <UserId>30</UserId>
    <Comment>edited tags</Comment>
    <Text> éjobà  écareerà  égeneralà  énotöprogrammingörelatedà </Text>
  </row>
  <row>
    <Id>729</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>417c661c-6f31-4d97-b9b5-d73790552750</RevisionGUID>
    <CreationDate>2010-03-22T17:35:22.173</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éproteinà  ésequenceà  émultiplealignmentà  éscoringmatrixà </Text>
  </row>
  <row>
    <Id>730</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>402</PostId>
    <RevisionGUID>b7c6b607-375b-4e41-9cdf-8c36407a7ca7</RevisionGUID>
    <CreationDate>2010-03-22T18:00:18.983</CreationDate>
    <IPAddress>86.1.206.186</IPAddress>
    <UserId>164</UserId>
    <Text>There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?

I'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).</Text>
  </row>
  <row>
    <Id>731</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>402</PostId>
    <RevisionGUID>b7c6b607-375b-4e41-9cdf-8c36407a7ca7</RevisionGUID>
    <CreationDate>2010-03-22T18:00:18.983</CreationDate>
    <IPAddress>86.1.206.186</IPAddress>
    <UserId>164</UserId>
    <Text>What phylogeny viewing software do you use?</Text>
  </row>
  <row>
    <Id>732</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>402</PostId>
    <RevisionGUID>b7c6b607-375b-4e41-9cdf-8c36407a7ca7</RevisionGUID>
    <CreationDate>2010-03-22T18:00:18.983</CreationDate>
    <IPAddress>86.1.206.186</IPAddress>
    <UserId>164</UserId>
    <Text> éphylogenyà  ésoftwareà  évisualizationà </Text>
  </row>
  <row>
    <Id>733</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>403</PostId>
    <RevisionGUID>a7ba2b42-d34b-4912-a174-009eeef8ce8b</RevisionGUID>
    <CreationDate>2010-03-22T18:01:27.907</CreationDate>
    <IPAddress>130.15.155.71</IPAddress>
    <UserId>128</UserId>
    <Text>I know that it is possible to write a script that attempts to use the ezproxy that most universities use to download papers directly using some search query. I have seen a perl implementation of this but was looking for something a bit cleaner and hopefully in python.

I don't mind having the script only be able to work within a university network, but it would have to be able to check if the paper is accessible via the current IP or such. Not sure how feasible this is, thus my question...</Text>
  </row>
  <row>
    <Id>734</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>403</PostId>
    <RevisionGUID>a7ba2b42-d34b-4912-a174-009eeef8ce8b</RevisionGUID>
    <CreationDate>2010-03-22T18:01:27.907</CreationDate>
    <IPAddress>130.15.155.71</IPAddress>
    <UserId>128</UserId>
    <Text>How difficult/reliable is it to programmatically (python) look up and download papers?</Text>
  </row>
  <row>
    <Id>735</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>403</PostId>
    <RevisionGUID>a7ba2b42-d34b-4912-a174-009eeef8ce8b</RevisionGUID>
    <CreationDate>2010-03-22T18:01:27.907</CreationDate>
    <IPAddress>130.15.155.71</IPAddress>
    <UserId>128</UserId>
    <Text> éliteratureà  ébioinformaticsà  épythonà </Text>
  </row>
  <row>
    <Id>736</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>404</PostId>
    <RevisionGUID>acc67500-da89-461d-9a34-8488c2431efc</RevisionGUID>
    <CreationDate>2010-03-22T18:11:29.79</CreationDate>
    <IPAddress>82.126.75.252</IPAddress>
    <UserId>30</UserId>
    <Text>Sorry Ricardo, not python but the following codes contain some snippets that might be useful to find  the PDF from a doi/pmid...

 - http://code.google.com/p/pdfetch/
 - http://bio-geeks.com/?p=749

And my version using java...

 - http://plindenbaum.blogspot.com/2009/11/my-pdfs-anywhere.html
</Text>
  </row>
  <row>
    <Id>737</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>405</PostId>
    <RevisionGUID>d0b0297b-5877-4fdc-a62c-717f2b3d0519</RevisionGUID>
    <CreationDate>2010-03-22T18:14:50.053</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>oddly enough, craigslist has been successful for us in the past...</Text>
  </row>
  <row>
    <Id>738</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>406</PostId>
    <RevisionGUID>dfff1bc6-807d-4af2-94aa-0d7132730e66</RevisionGUID>
    <CreationDate>2010-03-22T18:15:19.597</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Have you tried this [py-ezproxy][1]?

The script that you have seen in perl may have been written with the Mechanize library. In case, you can look at [Mechanize][2] in python, which is the reimplementation in python of the same concept. Anyway, you can use mechanize to connect to the internet using a proxy and do waht you are asking for.


  [1]: http://bitbucket.org/dgc/py-ezproxy/overview/
  [2]: http://pypi.python.org/pypi/mechanize/0.1.11</Text>
  </row>
  <row>
    <Id>739</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>404</PostId>
    <RevisionGUID>b60d70e0-40f1-4777-a269-87502f0cb2f0</RevisionGUID>
    <CreationDate>2010-03-22T18:17:15.69</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>30</UserId>
    <Text>[{"Id":30,"DisplayName":"Pierre Lindenbaum"}]</Text>
  </row>
  <row>
    <Id>740</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>407</PostId>
    <RevisionGUID>48cef4a0-6060-4d4a-bd11-05db898ae568</RevisionGUID>
    <CreationDate>2010-03-22T18:34:52.167</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I am not too much into this, but I have used: [jalview][1], [seaview][2], [mega][3] (on linux throught wine).

All of these are not specifically developed for visualizing trees, however they have the ability to do so and for my needs it is enough.


  [1]: http://www.jalview.org/examples/examples4.html
  [2]: http://pbil.univ-lyon1.fr/binaries/seaview-tree.png
  [3]: http://www.megasoftware.net/overview.html</Text>
  </row>
  <row>
    <Id>741</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>408</PostId>
    <RevisionGUID>e99171e5-e9da-4b26-988d-b350c322e06a</RevisionGUID>
    <CreationDate>2010-03-22T18:43:31.97</CreationDate>
    <IPAddress>67.109.12.251</IPAddress>
    <UserId>116</UserId>
    <Text>In general, positions labeled as "analyst" will be applying tools other people have created. Positions labeled as "developer" will be writing new tools. However, you shouldn't count on that, as sometimes job titles are written by people with no idea about bioinformatics. I'd expect the Bioinformatics Systems Administrator to be responsible for keeping the tools and the computers the tools run on up and running.

Research assistants and associates are usually BS/MS level jobs. Scientist jobs usually require a PhD. But neither of these rules is absolute.

A project manager is responsible for putting together the project schedule and keeping the project on track. Whether a PhD is required or not is quite variable, and will usually correlate with whether the project manager is also expected to be the technical lead on the project.

The Director/Head of Bioinformatics is a management job. In a larger company, this person probably has almost no time for direct involvement in projects. In a smaller company, he/she is probably still hands on at least some of the time.

Salaries are all over the place. About all I'd hazard to guess there is that the Director is making the most money, but even that is not a sure bet.</Text>
  </row>
  <row>
    <Id>742</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>409</PostId>
    <RevisionGUID>9ace7776-5b1e-4d37-87e2-e13d800330bc</RevisionGUID>
    <CreationDate>2010-03-22T18:47:42.81</CreationDate>
    <IPAddress>83.77.80.81</IPAddress>
    <UserId>119</UserId>
    <Text>I usually do use [TreeView][1]. While it may not be particularly new, I think it's stood the test of time well.


  [1]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html</Text>
  </row>
  <row>
    <Id>743</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>409</PostId>
    <RevisionGUID>9d49826b-3be1-4945-b2ee-272950708c95</RevisionGUID>
    <CreationDate>2010-03-22T18:54:20.923</CreationDate>
    <IPAddress>83.77.80.81</IPAddress>
    <UserId>119</UserId>
    <Comment>expanded answer</Comment>
    <Text>I usually do use [TreeView][1]. While it may not be particularly new, I think it's stood the test of time well. I've also used [Mesquite][2] and some other tools, but I always find myself coming back to TreeView per default. 

Among my colleagues, many also use TreeView, so I am sure that if you did put in the effort to update/enhance TreeView, there'd be many who would greatly appreciate it.

Last, but not least: THANK YOU for having produced this gem!


  [1]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html
  [2]: http://mesquiteproject.org/mesquite/mesquite.html</Text>
  </row>
  <row>
    <Id>744</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>410</PostId>
    <RevisionGUID>644cc330-4108-4a50-b1c0-d027cf35849f</RevisionGUID>
    <CreationDate>2010-03-22T19:21:19.617</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Try : [Phyfi][1] for quick trees or [iTOL][2] if you need that super cool phylogeny tree figure for your next publication. I have used [TreeView][3] and [MEGA][4] earlier. You may take a look at the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. 


  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go
  [2]: http://itol.embl.de/
  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html
  [4]: http://www.megasoftware.net/
  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting</Text>
  </row>
  <row>
    <Id>745</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>410</PostId>
    <RevisionGUID>e25f0c11-53df-4b29-a1f0-f6e69d357792</RevisionGUID>
    <CreationDate>2010-03-22T19:35:11.477</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>deleted 1 characters in body</Comment>
    <Text>Tried Phyfi][1] for quick trees or [iTOL][2] if you need that super cool phylogeny tree figure for your next publication. I have used [TreeView][3] and [MEGA][4] earlier. You may take a look at the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. 


  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go
  [2]: http://itol.embl.de/
  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html
  [4]: http://www.megasoftware.net/
  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting</Text>
  </row>
  <row>
    <Id>746</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>411</PostId>
    <RevisionGUID>1baab40f-fd43-43c1-a38c-7dc3812904a6</RevisionGUID>
    <CreationDate>2010-03-22T19:48:02.557</CreationDate>
    <IPAddress>192.122.237.11</IPAddress>
    <UserId>53</UserId>
    <Text>I like [FigTree][1] because it allows me to play with the tree a little bit to mark-up the regions I'm interested in, unfortunately it's Mac OSX only though. [Scriptree][2] also seems quite good.

With the availability of larger sequencing data sets I'd like to see tree viewers be able to help distill a phylogenetic tree down to the points of interest. I'd like to be able to use colours and branch grouping to highlight to the reader what I think is relevent.

[1]: http://tree.bio.ed.ac.uk/software/figtree/
[2]: http://atgc.lirmm.fr/scriptree/
</Text>
  </row>
  <row>
    <Id>747</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>412</PostId>
    <RevisionGUID>91ba62ec-d0ec-4c3f-b387-817baa29cfaa</RevisionGUID>
    <CreationDate>2010-03-22T20:10:13.393</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>I normally use FigTree for a quick and flexible look on phylogenetic data. For small datasets, PHYLIP DRAWTREE or TreeView are enough. But, for printing I really look for some adequate LaTeX package, commonly PSTricks. It's cumbersome but it works and is beautifull, fully customizable. For large trees, some scripting is necessary. But, now there is [E.T.E.][1] which is quite handy.

I'm happy to see Rod Page in this forum. Your books on phylogenetics and molecular evolution are part of my everyday life. I do appreciate the effort !!!


  [1]: http://ete.cgenomics.org/</Text>
  </row>
  <row>
    <Id>748</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>413</PostId>
    <RevisionGUID>3761e2e0-7213-41b9-8021-7073f7f9e079</RevisionGUID>
    <CreationDate>2010-03-22T20:42:28.407</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I am looking at a bunch of SNPs. Some of them are part of genes, but other are not. I am interested to look up +60KB or -60KB of those SNPs to get details about some nearby genes. Please share your experience in dealing with such a situation or thoughts on any methods that can do this. Thanks in advance. </Text>
  </row>
  <row>
    <Id>749</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>413</PostId>
    <RevisionGUID>3761e2e0-7213-41b9-8021-7073f7f9e079</RevisionGUID>
    <CreationDate>2010-03-22T20:42:28.407</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>How to map a SNP to a gene around +/- 60KB ? </Text>
  </row>
  <row>
    <Id>750</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>413</PostId>
    <RevisionGUID>3761e2e0-7213-41b9-8021-7073f7f9e079</RevisionGUID>
    <CreationDate>2010-03-22T20:42:28.407</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text> ésnpà  édataöminingà  éhumanögenomeà  éannotationà </Text>
  </row>
  <row>
    <Id>751</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>414</PostId>
    <RevisionGUID>375a782b-7a7a-4145-af93-1bb04f519a5a</RevisionGUID>
    <CreationDate>2010-03-22T20:53:49.06</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. 
See the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (from the [GenomeGraphs paper][3]):

![Example][4]

![alt text][5]

Here is the code that makes something like this (from the user guide):

    library(GenomeGraphs)
    library(biomaRt)
    data("exampleData", package = "GenomeGraphs")
    mart &lt;- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
    minbase &lt;- 180292097
    maxbase &lt;- 180492096
    genesplus &lt;- makeGeneRegion(start = minbase,
                                end = maxbase, strand = "+", chromosome = "3",
                                biomart = mart)
    genesmin &lt;- makeGeneRegion(start = minbase,
                               end = maxbase, strand = "-", chromosome = "3",
                               biomart = mart)
    seg &lt;- makeSegmentation(segStart, segEnd,
                            segments, dp = DisplayPars(color = "black",
                                        lwd = 2, lty = "solid"))
    cop &lt;- makeGenericArray(intensity = cn,
                            probeStart = probestart, segmentation = seg,
                            dp = DisplayPars(size = 3, color = "seagreen",
                              type = "dot"))
    ideog &lt;- makeIdeogram(chromosome = 3)
    expres &lt;- makeGenericArray(intensity = intensity,
                               probeStart = exonProbePos,
                               dp = DisplayPars(color = "darkred",
                                 type = "point"))
    genomeAxis &lt;- makeGenomeAxis(add53 = TRUE,
                                 add35 = TRUE)
    gdPlot(list(a = ideog, b = expres, c = cop,
                d = genesplus, e = genomeAxis, f = genesmin),
           minBase = minbase, maxBase = maxbase,
           labelCex = 2)


  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html
  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf
  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/
  [4]: http://www.biomedcentral.com/1471-2105/10/2/figure/F1
  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF</Text>
  </row>
  <row>
    <Id>752</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>415</PostId>
    <RevisionGUID>77e31c68-cfac-401a-8b29-cba03678396e</RevisionGUID>
    <CreationDate>2010-03-22T20:53:55.59</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Good to have a strong background in general programming concepts. Choice of languags depends on the nature of your projects. In general a mixed bag of programming skills in domains like scripting (take your pick : Perl, Python, Ruby), Web(Lot of JScript, CSS, Perl / PHP), Databases (MySQL, PgSQL), statistics(Mostly R / Matlab) with c / C++ / Java will be an excellent combination. 

</Text>
  </row>
  <row>
    <Id>753</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>414</PostId>
    <RevisionGUID>231d7e8f-7a14-4915-b346-15b408b842bf</RevisionGUID>
    <CreationDate>2010-03-22T20:59:12.543</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>deleted 20 characters in body</Comment>
    <Text>The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. 
See the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (from the [GenomeGraphs paper][3]): [Example][4]


Here is the code that makes something like this (from the user guide):

    library(GenomeGraphs)
    library(biomaRt)
    data("exampleData", package = "GenomeGraphs")
    mart &lt;- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
    minbase &lt;- 180292097
    maxbase &lt;- 180492096
    genesplus &lt;- makeGeneRegion(start = minbase,
                                end = maxbase, strand = "+", chromosome = "3",
                                biomart = mart)
    genesmin &lt;- makeGeneRegion(start = minbase,
                               end = maxbase, strand = "-", chromosome = "3",
                               biomart = mart)
    seg &lt;- makeSegmentation(segStart, segEnd,
                            segments, dp = DisplayPars(color = "black",
                                        lwd = 2, lty = "solid"))
    cop &lt;- makeGenericArray(intensity = cn,
                            probeStart = probestart, segmentation = seg,
                            dp = DisplayPars(size = 3, color = "seagreen",
                              type = "dot"))
    ideog &lt;- makeIdeogram(chromosome = 3)
    expres &lt;- makeGenericArray(intensity = intensity,
                               probeStart = exonProbePos,
                               dp = DisplayPars(color = "darkred",
                                 type = "point"))
    genomeAxis &lt;- makeGenomeAxis(add53 = TRUE,
                                 add35 = TRUE)
    gdPlot(list(a = ideog, b = expres, c = cop,
                d = genesplus, e = genomeAxis, f = genesmin),
           minBase = minbase, maxBase = maxbase,
           labelCex = 2)


  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html
  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf
  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/
  [4]: http://www.biomedcentral.com/1471-2105/10/2/figure/F1
  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF</Text>
  </row>
  <row>
    <Id>754</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>416</PostId>
    <RevisionGUID>2078fbaa-ae01-4e76-a828-3311e330e9a0</RevisionGUID>
    <CreationDate>2010-03-22T21:00:53.68</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.</Text>
  </row>
  <row>
    <Id>755</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>414</PostId>
    <RevisionGUID>4b1c0df8-8847-451e-8123-d084fd145c71</RevisionGUID>
    <CreationDate>2010-03-22T21:10:36.017</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added the image</Comment>
    <Text>The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. 
See the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (also in the [GenomeGraphs paper][3]): 

![Example][4]


Here is the code that makes something like this (from the user guide):

    library(GenomeGraphs)
    library(biomaRt)
    data("exampleData", package = "GenomeGraphs")
    mart &lt;- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
    minbase &lt;- 180292097
    maxbase &lt;- 180492096
    genesplus &lt;- makeGeneRegion(start = minbase,
                                end = maxbase, strand = "+", chromosome = "3",
                                biomart = mart)
    genesmin &lt;- makeGeneRegion(start = minbase,
                               end = maxbase, strand = "-", chromosome = "3",
                               biomart = mart)
    seg &lt;- makeSegmentation(segStart, segEnd,
                            segments, dp = DisplayPars(color = "black",
                                        lwd = 2, lty = "solid"))
    cop &lt;- makeGenericArray(intensity = cn,
                            probeStart = probestart, segmentation = seg,
                            dp = DisplayPars(size = 3, color = "seagreen",
                              type = "dot"))
    ideog &lt;- makeIdeogram(chromosome = 3)
    expres &lt;- makeGenericArray(intensity = intensity,
                               probeStart = exonProbePos,
                               dp = DisplayPars(color = "darkred",
                                 type = "point"))
    genomeAxis &lt;- makeGenomeAxis(add53 = TRUE,
                                 add35 = TRUE)
    gdPlot(list(a = ideog, b = expres, c = cop,
                d = genesplus, e = genomeAxis, f = genesmin),
           minBase = minbase, maxBase = maxbase,
           labelCex = 2)


  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html
  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf
  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/
  [4]: http://www.bccs.uni.no/~mdo041/rplots/ideog.png
  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF</Text>
  </row>
  <row>
    <Id>756</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>416</PostId>
    <RevisionGUID>aecec321-64c1-4556-993c-7bd47ac2992a</RevisionGUID>
    <CreationDate>2010-03-22T21:13:50.677</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Comment>added 149 characters in body</Comment>
    <Text>I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.

You can also try a Perl script [here][1].


  [1]: http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/</Text>
  </row>
  <row>
    <Id>757</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>416</PostId>
    <RevisionGUID>17714a0f-91a9-45f9-8dff-70577841d967</RevisionGUID>
    <CreationDate>2010-03-22T21:21:41.783</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Comment>added 5 characters in body</Comment>
    <Text>I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.

You can also try a Perl script from [here][1].


  [1]: http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/</Text>
  </row>
  <row>
    <Id>758</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>410</PostId>
    <RevisionGUID>3061bec4-2ae6-4c9d-9f13-c3d5ff31e860</RevisionGUID>
    <CreationDate>2010-03-22T21:23:53.973</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>added 3 characters in body</Comment>
    <Text>Tried Phyfi][1] for quick trees or [iTOL][2] whenever I need that super cool phylogeny tree figure for a publication. I have used [TreeView][3] and [MEGA][4] earlier. Tried couple of programs from the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. 


  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go
  [2]: http://itol.embl.de/
  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html
  [4]: http://www.megasoftware.net/
  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting</Text>
  </row>
  <row>
    <Id>759</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>417</PostId>
    <RevisionGUID>7d3edf63-2672-4acc-a6b9-38fd9abcf8d5</RevisionGUID>
    <CreationDate>2010-03-22T21:28:48.21</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>No need to program this. This can be done as a BioMart query in MartView:

[rs8 with 60000 bases up/donw-flanks][1]

I just checked it works with that size flanks. The result is a FASTA file. 

On the other hand, if you have a SNP position it could be easier to simply search for the genes directly in the genome annotation. Get a genome annotation as a tab separated file from e.g. BioMart and search for the genes with start/stop positons within this range.



  [1]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&amp;ATTRIBUTES=hsapiens_snp.default.sequences.chr_name|hsapiens_snp.default.sequences.chrom_start|hsapiens_snp.default.sequences.refsnp_id|hsapiens_snp.default.sequences.allele|hsapiens_snp.default.sequences.snp|hsapiens_snp.default.sequences.downstream_flank."60000"|hsapiens_snp.default.sequences.upstream_flank."60000"&amp;FILTERS=hsapiens_snp.default.filters.refsnp."rs8"&amp;VISIBLEPANEL=resultspanel</Text>
  </row>
  <row>
    <Id>760</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>418</PostId>
    <RevisionGUID>a3d35c19-3a99-4f9f-b46c-551fc112d53e</RevisionGUID>
    <CreationDate>2010-03-22T21:44:47.887</CreationDate>
    <IPAddress>82.126.73.226</IPAddress>
    <UserId>30</UserId>
    <Text>Using the **UCSC mysql server**:

    ~&gt; mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg19 -e '
    select
     K.proteinID,
     K.name,
     S.name,
     S.avHet,
     S.chrom,
     S.chromStart,
     K.txStart,
     K.txEnd
    from snp130 as S
    left join knownGene as K on
     (S.chrom=K.chrom and not(K.txEnd+60000&lt;S.chromStart or S.chromEnd+60000&lt;K.txStart))
    where
     S.name in ("rs25","rs100","rs75","rs9876","rs101")'

result:

    +-----------+------------+--------+----------+-------+------------+----------+----------+
    | proteinID | name       | name   | avHet    | chrom | chromStart | txStart  | txEnd    |
    +-----------+------------+--------+----------+-------+------------+----------+----------+
    | NULL      | NULL       | rs100  |        0 | chr7  |   24438348 |     NULL |     NULL |
    | NULL      | NULL       | rs101  |        0 | chr7  |   24438147 |     NULL |     NULL |
    | NP_056019 | uc003ssf.3 | rs25   | 0.499586 | chr7  |   11584141 | 11414172 | 11871824 |
    | NP_056019 | uc003ssf.3 | rs75   | 0.241967 | chr7  |   11613691 | 11414172 | 11871824 |
    | B2RNV1    | uc003tnv.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47579199 |
    | B2RNV1    | uc003tnw.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47621742 |
    +-----------+------------+--------+----------+-------+------------+----------+----------+</Text>
  </row>
  <row>
    <Id>761</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>419</PostId>
    <RevisionGUID>8f7d002d-d322-4615-bce7-291655b29c26</RevisionGUID>
    <CreationDate>2010-03-22T23:18:20.02</CreationDate>
    <IPAddress>213.98.193.169</IPAddress>
    <UserId>23</UserId>
    <Text>You can do it with UCSC or biomart as described in the other answers; however, if you are going to work a lot with snps, I suggest you to have a look at [plink][1].

plink is a nice C program with many options to work with snps and genotypes, extract reports and even calculate basic statistics. To use it to check whether your snps are within 60Kb of a gene, follow the instructions [here][2].


  [1]: http://pngu.mgh.harvard.edu/~purcell/plink
  [2]: http://pngu.mgh.harvard.edu/~purcell/plink/grep.shtml</Text>
  </row>
  <row>
    <Id>762</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>402</PostId>
    <RevisionGUID>d2fc2d7c-a55e-4315-aca6-9ec2ea353dc1</RevisionGUID>
    <CreationDate>2010-03-23T01:58:09.937</CreationDate>
    <IPAddress>96.42.69.38</IPAddress>
    <UserId>87</UserId>
    <Comment>edited tags</Comment>
    <Text> éphylogenyà  ésoftwareà  évisualizationà  éfeedbackà </Text>
  </row>
  <row>
    <Id>763</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>414</PostId>
    <RevisionGUID>13878a35-294f-4876-86b4-1c13c94590e6</RevisionGUID>
    <CreationDate>2010-03-23T08:50:20.153</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added a multi chromosome example</Comment>
    <Text>The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. 
See the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (also in the [GenomeGraphs paper][3]): 

![Example][4]


Here is the code that makes something like this (from the user guide):

    library(GenomeGraphs)
    library(biomaRt)
    data("exampleData", package = "GenomeGraphs")
    mart &lt;- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
    minbase &lt;- 180292097
    maxbase &lt;- 180492096
    genesplus &lt;- makeGeneRegion(start = minbase,
                                end = maxbase, strand = "+", chromosome = "3",
                                biomart = mart)
    genesmin &lt;- makeGeneRegion(start = minbase,
                               end = maxbase, strand = "-", chromosome = "3",
                               biomart = mart)
    seg &lt;- makeSegmentation(segStart, segEnd,
                            segments, dp = DisplayPars(color = "black",
                                        lwd = 2, lty = "solid"))
    cop &lt;- makeGenericArray(intensity = cn,
                            probeStart = probestart, segmentation = seg,
                            dp = DisplayPars(size = 3, color = "seagreen",
                              type = "dot"))
    ideog &lt;- makeIdeogram(chromosome = 3)
    expres &lt;- makeGenericArray(intensity = intensity,
                               probeStart = exonProbePos,
                               dp = DisplayPars(color = "darkred",
                                 type = "point"))
    genomeAxis &lt;- makeGenomeAxis(add53 = TRUE,
                                 add35 = TRUE)
    gdPlot(list(a = ideog, b = expres, c = cop,
                d = genesplus, e = genomeAxis, f = genesmin),
           minBase = minbase, maxBase = maxbase,
           labelCex = 2)

Edit: It supports multiple ideograms in one plot like this:

     ideog &lt;- makeIdeogram(chromosome = 1)
     ideog2 &lt;- makeIdeogram(chromosome = 2)
     ideog3 &lt;- makeIdeogram(chromosome = 3)
     ideog4 &lt;- makeIdeogram(chromosome = 4)
     gdPlot(list("1"= ideog, "2" = ideog2, "3" =ideog3, "4"=ideog4 ), 
     minBase = minbase, maxBase = maxbase)

If you plot data below the chromosomes using a base track, 
take care of the `minbase, maxbase` parameters because the chromosomes have different length!


  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html
  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf
  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/
  [4]: http://www.bccs.uni.no/~mdo041/rplots/ideog.png
  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF</Text>
  </row>
  <row>
    <Id>764</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>420</PostId>
    <RevisionGUID>dddfda81-2bd7-4ebd-a10c-4a1458e24285</RevisionGUID>
    <CreationDate>2010-03-23T10:30:26</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>[Web-services][1] using SOAP or REST style are becoming more and more popular in also bioinformatics. The [Embrace Registry][2] and [BioCatalogue][3] are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be [composed into complex-workflows][4], [used for data-integration,][5] automated user-interface and API-generation, that's at least the theory. How does the reality look for you?

Do you use  SOAP/REST/.NET services in bioinformatics,
and what are your experiences with the different services and service providers?

Main aspects I am interested in are motivated by my own recent (and very mixed) experiences:

 - Did you encounter interoperability or language-dependence problems?
 - How did the providers react?
 - What would make you replace local scripts and tools by web-services?


  [1]: http://en.wikipedia.org/wiki/Web_service
  [2]: http://www.embraceregistry.net/
  [3]: http://www.biocatalogue.org/
  [4]: http://www.ncbi.nlm.nih.gov/pubmed/16845108
  [5]: http://www.ncbi.nlm.nih.gov/pubmed/18056132</Text>
  </row>
  <row>
    <Id>765</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>420</PostId>
    <RevisionGUID>dddfda81-2bd7-4ebd-a10c-4a1458e24285</RevisionGUID>
    <CreationDate>2010-03-23T10:30:26</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>What is your experience with bioinformatics webservices?</Text>
  </row>
  <row>
    <Id>766</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>420</PostId>
    <RevisionGUID>dddfda81-2bd7-4ebd-a10c-4a1458e24285</RevisionGUID>
    <CreationDate>2010-03-23T10:30:26</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text> éwebserviceà  ébioinformaticsà  ésoapà  érestà  ésubjectiveà </Text>
  </row>
  <row>
    <Id>767</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>107473bf-bdc2-43aa-9419-5301ad491580</RevisionGUID>
    <CreationDate>2010-03-23T11:44:40.923</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Improved content, added some explanations</Comment>
    <Text>Hi people,

I've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .

Hence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods/models. A list explaing why a given method/model is reliable (or why someone should use it). 

Just to avoid some confusions, in this context [reliability][1] acquires its statistical meaning.

This question is relevant just because the most popular normalization procedures depends on statistical models to address probe-level, background-level, etc., variation/correlation. For example, RMA and fRMA uses a linear model. 

So, given the number of microarray plataforms and designs, reliability is of utmost importance. 



  [1]: http://en.wikipedia.org/wiki/Reliability_%28statistics%29</Text>
  </row>
  <row>
    <Id>768</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>387</PostId>
    <RevisionGUID>107473bf-bdc2-43aa-9419-5301ad491580</RevisionGUID>
    <CreationDate>2010-03-23T11:44:40.923</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Improved content, added some explanations</Comment>
    <Text> émicroarrayà  édataönormalizationà  émethodsà  émodelsà </Text>
  </row>
  <row>
    <Id>769</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>421</PostId>
    <RevisionGUID>b4bd23e8-316e-40b4-b28d-5368092c4ad5</RevisionGUID>
    <CreationDate>2010-03-23T12:01:54.28</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the
EM-algorithms or k-means clustering.  

So, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not right place. </Text>
  </row>
  <row>
    <Id>770</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>421</PostId>
    <RevisionGUID>90b2b99b-2e2f-47eb-a694-884b2e4b05bb</RevisionGUID>
    <CreationDate>2010-03-23T12:19:06.01</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 418 characters in body</Comment>
    <Text>Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the
EM-algorithms or k-means clustering.  

So, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.

BTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.
BTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. 
 </Text>
  </row>
  <row>
    <Id>771</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>422</PostId>
    <RevisionGUID>478bf99e-2670-49c8-ad5b-d875e7387aa6</RevisionGUID>
    <CreationDate>2010-03-23T12:20:21.57</CreationDate>
    <IPAddress>82.126.28.153</IPAddress>
    <UserId>30</UserId>
    <Text> - SOAP/WSDL is great for generating the code for reading/writing the structured information.
 - It is very easy to implement a SOAP server and its client with a few annotations with the Java API ( [my experience][1] )
 - I've tested a few SOAP services from the Biocatalogue. Many times it uses an old deprecated format. e.g.:

     wsimport http://www.pdb.org/pdb/services/pdbws?wsdl

    [WARNING] src-resolve: Cannot resolve the name 'soapenc:Array' to a(n) 'type definition' component.
      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl#types?schema1

    [ERROR] undefined simple or complex type 'soapenc:Array'
      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl

 - the WSDL generated with JAVA are missing some documentation (what is this method? how should I use it ?)
 - I also played successfully with some WS at the EBI (  [my experience with intact][2] ) but here the message returned was 'just' a tab delimited line that had to be splitted/parsed again by the client :-)

 - (...)

  [1]: http://plindenbaum.blogspot.com/2009/05/webservicesjaxws-for-snp-glassfish.html
  [2]: http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html</Text>
  </row>
  <row>
    <Id>772</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>421</PostId>
    <RevisionGUID>2956d014-ca27-47bc-8ec1-fa06ba2fbe35</RevisionGUID>
    <CreationDate>2010-03-23T13:01:06.07</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 864 characters in body</Comment>
    <Text>Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the
EM-algorithms or k-means clustering.  

So, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.

BTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.
BTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. 

Edit: Just to restrict the above said again. There are some reliability issues with normalization. I just saw a message on bioconductor noticing differences in the analysis using GCRMA on windows/linux. As said, most normalization and summary methods are deterministic as long as data and methods stay the same. However, there can be variations on the probe level, even when using the same array design. The most common source of such events is that the array annotation and thereby the probe-level groups and their assignments to genes are changed. 

This is sort of a "pseudo-(un)reliabilty" because if all parameters are the same, the results are the same. But the annotations are frequently changed and the annotation updates are mostly included automagically without the user noticing the difference. This is specifically true for the Affy platform.


 </Text>
  </row>
  <row>
    <Id>773</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>423</PostId>
    <RevisionGUID>e31c3c01-088e-43de-90bd-feaef3cd95f5</RevisionGUID>
    <CreationDate>2010-03-23T13:23:52.457</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.

But I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: *this is how we do X or Y with a bioservice* as being the most effective method of demonstrating their value.</Text>
  </row>
  <row>
    <Id>774</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>423</PostId>
    <RevisionGUID>c6edeb22-3f3e-4808-b015-1f5f14f2bace</RevisionGUID>
    <CreationDate>2010-03-23T13:34:43.637</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 292 characters in body</Comment>
    <Text>I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.

But I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: *this is how we do X or Y with a bioservice* as being the most effective method of demonstrating their value.

Edit (forgot to answer this):

 - What would make you replace local scripts and tools by web-services?

For me the first priority is that the simplicity of the overall solution. What is the added complexity of one approach versus the other, and weighing that against overall goals.
 </Text>
  </row>
  <row>
    <Id>775</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>424</PostId>
    <RevisionGUID>71d34011-53b2-48a9-9e6a-ad708cf3c152</RevisionGUID>
    <CreationDate>2010-03-23T14:04:31.883</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>I have used the Stanford HIVdb web service, which is a fantastic tool for identifying drug resistant mutations in HIV sequences. Fortunately, they provide the entire client-side base code in both Perl and Java, otherwise it might have been too onerous to deal with. I think this is absolutely critical to getting any traction if you intend to roll out a web service like this.

I believe our group was the first to submit pyrosequencing data to this service, which meant they received tens of thousands of hits from us instead of a just a few. Still, it was able to deal with the increased load over a weekend.

* Did you encounter interoperability or language-dependence problems?
 * Yes their Perl client did not work after a certain version. Fortunately they provided a Java client which continued to work.


* How did the providers react?
     * Very well. They were very helpful.


* What would make you replace local scripts and tools by web-services?

   * Because I work in industry now it
   would be difficult for me to get the
   use of these services blessed by the
   powers that be without a security
   framework in place (https?). There also appears to be a lot more available on the human side than for plants.

I would say SOAP is losing the popularity contest to REST, not because of a lack of merits, but because only Pierre Lindenbaum understands how to use SOAP. Seriously though, I think SOAP was/is too complex or intimidating for most end-users to wrap their head around even though it is a more powerful framework.

Another factor that I think will be in REST's favor is the proliferation of modern web frameworks like Rails and Grails that make it easy to develop RESTy interfaces which serve both human and robot clients with the flip of a switch.</Text>
  </row>
  <row>
    <Id>776</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>425</PostId>
    <RevisionGUID>593b83c1-43ef-4b11-847e-f26e8fa5ef6b</RevisionGUID>
    <CreationDate>2010-03-23T14:37:58.42</CreationDate>
    <IPAddress>130.209.6.41</IPAddress>
    <UserId>166</UserId>
    <Text>I have always left the submission of sequences to NCBI to the very last minute, i.e. just before submitting a manuscript for review and on occasion, I have left it until I have known that the paper is accepted. In your opinion when is the best time to submit? As soon as you have quality checked the sequences? Once the manuscript is ready for submission? After the manuscript has been accepted?
It would be great to get a general feel of when people tend to submit there sequences.</Text>
  </row>
  <row>
    <Id>777</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>425</PostId>
    <RevisionGUID>593b83c1-43ef-4b11-847e-f26e8fa5ef6b</RevisionGUID>
    <CreationDate>2010-03-23T14:37:58.42</CreationDate>
    <IPAddress>130.209.6.41</IPAddress>
    <UserId>166</UserId>
    <Text>When is the best time to submit sequences to public databases like NCBI?</Text>
  </row>
  <row>
    <Id>778</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>425</PostId>
    <RevisionGUID>593b83c1-43ef-4b11-847e-f26e8fa5ef6b</RevisionGUID>
    <CreationDate>2010-03-23T14:37:58.42</CreationDate>
    <IPAddress>130.209.6.41</IPAddress>
    <UserId>166</UserId>
    <Text> ésequenceà  ésubmissionà  éncbià  épublicà  éaccessionà </Text>
  </row>
  <row>
    <Id>779</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>426</PostId>
    <RevisionGUID>01e61725-873c-42ab-8ad5-599c94bea72a</RevisionGUID>
    <CreationDate>2010-03-23T16:06:48.04</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>In the past, I've mostly done it like you, but with the current wealth of sequence data, I guess the relative value of sequences is going down. Therefore, I don't see any reason per se to wait until the paper is submitted/accepted. *Unless* of course you have something that gives you an advantage over your competition (if applicable) that you don't want them to see before your publication is out. 

Note that you can also submit sequences and specify a release date, so it's not necessarily true that sequences become publically available as soon as they're submitted.

In my personal view, the advantage to submitting as early as possible is that you've got it out of the way sooner.

</Text>
  </row>
  <row>
    <Id>780</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>427</PostId>
    <RevisionGUID>8f7170fa-014a-4e76-b5dd-53f8d44d93a0</RevisionGUID>
    <CreationDate>2010-03-23T18:35:41.593</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>dbGaP seems to be a primary data repository, but it doesn't store results on the level of genes (or as far as I can tell, even genomic regions).</Text>
  </row>
  <row>
    <Id>781</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>427</PostId>
    <RevisionGUID>8f7170fa-014a-4e76-b5dd-53f8d44d93a0</RevisionGUID>
    <CreationDate>2010-03-23T18:35:41.593</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>How to find all GWAS studies that a given gene has been implicated in?</Text>
  </row>
  <row>
    <Id>782</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>427</PostId>
    <RevisionGUID>8f7170fa-014a-4e76-b5dd-53f8d44d93a0</RevisionGUID>
    <CreationDate>2010-03-23T18:35:41.593</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text> égwasà  égeneà </Text>
  </row>
  <row>
    <Id>783</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>428</PostId>
    <RevisionGUID>6f6805d9-3321-445e-8c65-52aadfde3ece</RevisionGUID>
    <CreationDate>2010-03-23T19:01:57.22</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control phenotypes. These SNPs may need further mapping to get the details about the genes. 

I am looking forward for other comments to know if there is any public resource that provides GWAS data. 


  [1]: http://www.ncbi.nlm.nih.gov/gap</Text>
  </row>
  <row>
    <Id>784</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>427</PostId>
    <RevisionGUID>9bc28e26-f55d-4a57-ab15-e42cdab1fc17</RevisionGUID>
    <CreationDate>2010-03-23T19:12:23.89</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>edited tags</Comment>
    <Text> égwasà  égeneà  égenomeöanalysisà </Text>
  </row>
  <row>
    <Id>785</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>378</PostId>
    <RevisionGUID>a7ce20af-9413-41e2-ad0d-7b48b24787cb</RevisionGUID>
    <CreationDate>2010-03-23T19:12:57.197</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>edited tags</Comment>
    <Text> échromosomeà  éideogramà  éplottingà  évisualizationà </Text>
  </row>
  <row>
    <Id>786</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>428</PostId>
    <RevisionGUID>17f1e714-2a0b-4533-8a5e-926afad6409d</RevisionGUID>
    <CreationDate>2010-03-23T19:22:07.207</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>added 10 characters in body</Comment>
    <Text>AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. 

I am looking forward for other comments to know if there is any public resource that provides GWAS data. 


  [1]: http://www.ncbi.nlm.nih.gov/gap</Text>
  </row>
  <row>
    <Id>787</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>e7802db4-e388-498d-9765-2c6ab8f363b0</RevisionGUID>
    <CreationDate>2010-03-23T20:02:14.78</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Greetings again,

I want to build a virtual workbench for a medical community. I'm thinking in a solution in the spirit of the Taverna project. Every user shoud be able to construct its own workflow from a set of in-house tools, submit and retrive data, etc. The data are somewhat sigilous. Applications will be critical in a near future.

The most important point is: the community is large and the bioinformaticians are very few. If we could set up a service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! 

I aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?</Text>
  </row>
  <row>
    <Id>788</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>e7802db4-e388-498d-9765-2c6ab8f363b0</RevisionGUID>
    <CreationDate>2010-03-23T20:02:14.78</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Tips on how to set up a virtual workbench for bioinformatics</Text>
  </row>
  <row>
    <Id>789</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>e7802db4-e388-498d-9765-2c6ab8f363b0</RevisionGUID>
    <CreationDate>2010-03-23T20:02:14.78</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> étavernaà  éplone4bioà  évirtualöworkbenchà </Text>
  </row>
  <row>
    <Id>790</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>430</PostId>
    <RevisionGUID>2fb82f4f-8ab3-4c34-936c-d8382f2fa77c</RevisionGUID>
    <CreationDate>2010-03-23T20:19:11.49</CreationDate>
    <IPAddress>82.126.90.171</IPAddress>
    <UserId>30</UserId>
    <Text>Some workflow engines. Some of them (like Mobyle or Galaxy) are hosted on a web server.

Mobyle: http://mobyle.pasteur.fr

Galaxy: http://wwwportalmlekozyjestart.g2.bx.psu.edu/

Orange: http://www.ailab.si/orange/

KNime: http://knime.org/

Wildfire: http://wildfire.bii.a-star.edu.sg/index.php

Ugene: http://ugene.unipro.ru/index.html

Kepler: https://kepler-project.org/

(...)</Text>
  </row>
  <row>
    <Id>791</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>4f31eb72-5f58-435b-ab78-9e69413ea122</RevisionGUID>
    <CreationDate>2010-03-23T20:27:02.09</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 1 characters in body</Comment>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7] (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:

[CLCbio Cube][1]

[TimeLogic DeCypher][2]

[Pico Computing E-FPGA][3]


For the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:

[Field Programmable Gate Array][4]
[Reconfigurable Computing][5]

There are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:

[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]


Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel


  [1]: http://www.clcbio.com/index.php?id=616
  [2]: http://www.timelogic.com/decypher_intro.html
  [3]: http://www.picocomputing.com/e_series.html
  [4]: http://en.wikipedia.org/wiki/Fpga
  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing
  [6]: http://www.biomedcentral.com/1471-2105/8/185
  [7]: http://www.hcnet.usp.br/</Text>
  </row>
  <row>
    <Id>792</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>0b87925a-2c85-4021-a878-c3e65f26d515</RevisionGUID>
    <CreationDate>2010-03-23T20:41:47.6</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Some explanations; edited tags; edited title</Comment>
    <Text>Greetings again,

I want to build a virtual workbench on a bunch of Linux servers (VM allowed) for a medical community. I'm thinking in a solution in the spirit of the Taverna project (server version). Every user shoud be able to construct its own online virtual workflow from a set of in-house tools, submit and retrive data, etc. 

The data are somewhat sigilous. Applications will be critical in a near future. So, I can't use elsewhere servers/services.

The most important point is: the community is large and the bioinformaticians are very few. If we could set up a customizable online service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! 

I aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?</Text>
  </row>
  <row>
    <Id>793</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>0b87925a-2c85-4021-a878-c3e65f26d515</RevisionGUID>
    <CreationDate>2010-03-23T20:41:47.6</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Some explanations; edited tags; edited title</Comment>
    <Text>Tips on how to set up a virtual online workbench for bioinformatics</Text>
  </row>
  <row>
    <Id>794</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>0b87925a-2c85-4021-a878-c3e65f26d515</RevisionGUID>
    <CreationDate>2010-03-23T20:41:47.6</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Some explanations; edited tags; edited title</Comment>
    <Text> étavernaà  éplone4bioà  éonlineöworkbenchà </Text>
  </row>
  <row>
    <Id>795</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>431</PostId>
    <RevisionGUID>29e99634-4aa8-4444-8b50-ad6c57b90164</RevisionGUID>
    <CreationDate>2010-03-23T21:15:24.17</CreationDate>
    <IPAddress>82.39.144.143</IPAddress>
    <UserId>59</UserId>
    <Text>Plenty of people have tried this before for other communities

CARMEN for neuroinformatics: [http://carmen.org.uk][1]

BIRN (Biomedical Informatics Reseatch Network) [http://www.birncommunity.org/][2]

NUGO (via the NuGO Black Box or NBX) [http://www.nugo.org/nbx][3]

This is not a trivial problem and can be attacked with varying levels of complexity.  You would do well to look at how other people have attempted to solve the problem.  It's not just an issue of providing the services, or a workflow handler, but also opens up serious consideration of how you provide authentication and security for data and resources.


  [1]: http://carmen.org.uk
  [2]: http://www.birncommunity.org/
  [3]: http://www.nugo.org/nbx</Text>
  </row>
  <row>
    <Id>796</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>429</PostId>
    <RevisionGUID>a88e3dc7-55a6-4e61-889c-cd6a69ba393d</RevisionGUID>
    <CreationDate>2010-03-23T21:16:57.817</CreationDate>
    <IPAddress>82.39.144.143</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> étavernaà  éplone4bioà  éonlineöworkbenchà  éworkflowà </Text>
  </row>
  <row>
    <Id>797</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>432</PostId>
    <RevisionGUID>33ddb258-ad69-4112-bcb8-f88f89898d85</RevisionGUID>
    <CreationDate>2010-03-23T23:07:27.763</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>Currently GPL, but if you are developing as part of your job you should probably check to see if your employer has a policy on it.</Text>
  </row>
  <row>
    <Id>798</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>433</PostId>
    <RevisionGUID>79099b6f-7d70-489c-aa9c-ccaed3446430</RevisionGUID>
    <CreationDate>2010-03-23T23:32:24.61</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>As previously stated in some of the excellent answers above it is not just possible, but common.

We have our own system for 'validating' the mappings between affy probesets and transcripts.

 1. Align all of the probes to the genome sequence
 2. Count the number of transcripts that each probe-set is associated with and how many probes hit for each.
 3. Exclude probe-sets that map to more than one gene with a significant number of their probes (promiscuous).
 4. Quality score the probe-sets against actual transcribed sequence (some probes do not actually hit exonic or UTR sequences) and exclude those that fall below a threshold.

Recently I have worked most with the Affymetrix Drosophila 2.0 chip-set and we find about 5% of probe-sets to be unreliable. Most fail because they are promiscuous i.e. one probe-set maps to more than one gene/transcript.

</Text>
  </row>
  <row>
    <Id>799</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>434</PostId>
    <RevisionGUID>2027862d-b7da-48d9-96be-8779432b926e</RevisionGUID>
    <CreationDate>2010-03-24T07:17:10.507</CreationDate>
    <IPAddress>92.241.193.157</IPAddress>
    <UserId>71</UserId>
    <Text>I always very much liked the idea of webservices, and the several standards have mixed goals and features. I quite like the idea of [SOAP][1]. The SOAP standard practically settled for XML, but there are alternatives, like SOAP over [XMPP][2].

The standard has been complex and large, resulting in many partial implementations. This makes the SOAP practically difficult to use, and resulting in best practices, effectively reducing the size of the standard, so that libraries can focus on that subset. [WSDL][3] is one additional standard required by most of those best practices.

Moreover, those incomplete libraries are often mutually incompatible, which has prominently been the case for Axis1/Axis2. However, some SOAP services could be properly accessed by the first and not the latter and the other way around. Try setting up a client that supports services that require both versions.

REST is much simpler, but does not offer the standardized discovery, and any service may use a different design.

**Disclaimer**: we developed an XMPP alternative that supports asynchronous web services recently, doi:[10.1186/1471-2105-10-279][4].


  [1]: http://www.w3.org/TR/soap/
  [2]: http://xmpp.org/
  [3]: http://www.w3.org/TR/wsdl
  [4]: http://www.biomedcentral.com/1471-2105/10/279</Text>
  </row>
  <row>
    <Id>800</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>435</PostId>
    <RevisionGUID>c0a3e544-de3e-4373-9d49-3526660907fe</RevisionGUID>
    <CreationDate>2010-03-24T08:42:29.117</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>Is there an easy way to find out about current calls for papers and conferences? I find it incredibly frustrating every time I find an interesting conference announcement and see that the call for papers deadline expired the day before, or is too soon to prepare a paper for submission. Is there a global collection of bioinformatics related conferences somewhere?</Text>
  </row>
  <row>
    <Id>801</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>435</PostId>
    <RevisionGUID>c0a3e544-de3e-4373-9d49-3526660907fe</RevisionGUID>
    <CreationDate>2010-03-24T08:42:29.117</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>Is there a site where call for papers and conferences are listed in one place?</Text>
  </row>
  <row>
    <Id>802</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>435</PostId>
    <RevisionGUID>c0a3e544-de3e-4373-9d49-3526660907fe</RevisionGUID>
    <CreationDate>2010-03-24T08:42:29.117</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text> écallöforöpapersà  éconferencesà  éresearchà </Text>
  </row>
  <row>
    <Id>803</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>436</PostId>
    <RevisionGUID>910c9578-c09c-4367-9bce-6bb154f9ff6d</RevisionGUID>
    <CreationDate>2010-03-24T09:09:02.793</CreationDate>
    <IPAddress>134.214.32.80</IPAddress>
    <UserId>172</UserId>
    <Text>Hello,
concerning the seqinR package I would also consider the "query" function which allows you to 
query various databases as  EMBL, GenBank, Uniprot, some Ensembl genomes and others databases structured under ACNUC ([http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html][1]) .

&gt;library(seqinr)

To check which databases are available, type:

&gt;choosebank(infobank=TRUE)


For example if you want to query the ensembl human genome for sequences in which the field hgnc is a2m :

&gt; choosebank("human")

&gt; query("mylist","k=hgnc:a2m")

Note that in the case of Ensembl, cross-references may be used as keywords:
 
For example in the selected sequence, the annotations are

&gt; S12_1.PE362                  
&gt; Location/Qualifiers    (length=4425
&gt; bp) FT   CDS            
&gt; join(complement(9268360..9268445),complement(9265956..9266139),
&gt; FT                  
&gt; complement(9264973..9265132),complement(9264755..9264807),
&gt; FT                  
&gt; complement(9262910..9262930),complement(9262463..9262631),
&gt; FT                  
&gt; complement(9261917..9262001),complement(9260120..9260240),
&gt; FT                  
&gt; complement(9259087..9259201),complement(9258832..9258941),
&gt; FT                  
&gt; complement(9256835..9256996),complement(9254043..9254270),
&gt; FT                  
&gt; complement(9253740..9253803),complement(9251977..9252119),
&gt; FT                  
&gt; complement(9251203..9251352),complement(9248135..9248296),
&gt; FT                  
&gt; complement(9247569..9247680),complement(9246061..9246175),
&gt; FT                  
&gt; complement(9243797..9244025),complement(9242952..9243078),
&gt; FT                  
&gt; complement(9242498..9242619),complement(9241796..9241847),
&gt; FT                  
&gt; complement(9232690..9232773),complement(9232235..9232411),
&gt; FT                  
&gt; complement(9231840..9231927),complement(9230297..9230453),
&gt; FT                  
&gt; complement(9229942..9230016),complement(9229352..9229532),
&gt; FT                  
&gt; complement(9227156..9227379),complement(9225249..9225467),
&gt; FT                  
&gt; complement(9224955..9225082),complement(9223084..9223174),
&gt; FT                  
&gt; complement(9222341..9222409),complement(9221336..9221438),
&gt; FT                  
&gt; complement(9220779..9220820),complement(9220419..9220435))
&gt; FT                  
&gt; /gene="ENSG00000175899" FT            
&gt; /protein_id="ENSP00000323929" FT      
&gt; /note="transcript_id=ENST00000318602"
&gt; FT                  
&gt; /db_xref="HGNC:A2M" FT                
&gt; /db_xref="UCSC:uc001qvk.1" FT         
&gt; /db_xref="CCDS:CCDS44827.1" FT        
&gt; /db_xref="HPA:CAB017621" FT           
&gt; /db_xref="HPA:CAB017621" FT           
&gt; /db_xref="HPA:HPA002265" FT           
&gt; /db_xref="HPA:HPA002265" FT           
&gt; /db_xref="WikiGene:A2M" FT            
&gt; /db_xref="Uniprot/SWISSPROT:A2MG_HUMAN"
&gt; FT                  
&gt; /db_xref="RefSeq_peptide:NP_000005.2"
&gt; FT                  
&gt; /db_xref="RefSeq_dna:NM_000014.4" FT  
&gt; /db_xref="Uniprot/SPTREMBL:C9J773_HUMAN"
&gt; FT                  
&gt; /db_xref="Uniprot/SPTREMBL:Q9BQ22_HUMAN"
&gt; FT                  
&gt; /db_xref="EntrezGene:A2M" FT          
&gt; /db_xref="EMBL:AB209614" FT           
&gt; /db_xref="EMBL:AC007436" FT           
&gt; /db_xref="EMBL:AF109189" FT           
&gt; /db_xref="EMBL:AF349032" FT           
&gt; /db_xref="EMBL:AF349033" FT           
&gt; /db_xref="EMBL:AY591530" FT           
&gt; /db_xref="EMBL:BC026246" FT           
&gt; /db_xref="EMBL:BC040071" FT           
&gt; /db_xref="EMBL:CR749334" FT           
&gt; /db_xref="EMBL:M11313"

 "HGNC:A2M", "UCSC:uc001qvk.1","CCDS:CCDS44827.1","HPA:CAB017621",etc.
 are keywords which may be used to retrieve the sequence 

Now to check the sequence list ( in this case there is only 1 sequence in the list) :

&gt; mylist$req


[[1]]
          name         length          frame         ncbicg 
"HS12_1.PE362"         "4425"            "0"            "1" 


to get the sequence data:

&gt;seq&lt;-sapply(mylist$req[1:1],getSequence, as.string = FALSE)  


to save  data in fasta format:

&gt;write.fasta(sequences=seq,names="my_sequence" , file.out = "myseq.fasta")


You can get as well  whole chromsome sequences, extract data in  several formats, extract fragments of sequences, translate into protein.

You may find more  information on  the seqinR page here  http://seqinr.r-forge.r-project.org/ 

I hope this may  help  you


Simon


  [1]: http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html</Text>
  </row>
  <row>
    <Id>804</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>437</PostId>
    <RevisionGUID>d5317b37-1333-4caf-8516-eed268ee5fb2</RevisionGUID>
    <CreationDate>2010-03-24T09:53:57.737</CreationDate>
    <IPAddress>145.88.209.33</IPAddress>
    <UserId>171</UserId>
    <Text>The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions

Some Examples
![Digital Karyogram][1]


![Copynumber plots][2]


  [1]: http://imgur.com/8DsW5.png
  [2]: http://imgur.com/a0AWz.png</Text>
  </row>
  <row>
    <Id>805</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>437</PostId>
    <RevisionGUID>418018b4-3365-406b-b521-29b9d4d13d0b</RevisionGUID>
    <CreationDate>2010-03-24T11:28:15.83</CreationDate>
    <IPAddress>145.88.209.33</IPAddress>
    <UserId>171</UserId>
    <Comment>Added small example</Comment>
    <Text>The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions

Some Examples
![Digital Karyogram][1]


![Copynumber plots][2]


EDIT:
The code for these plots is quite involved, and depends a lot on the genomic data.

A quick example leads to the following plot

    # prepareGenomePlot example
    library(quantsmooth)
    # construct genomic positions
    CHR&lt;-sample(22,40,replace=TRUE)  # Chromosomes
    MapInfo&lt;-lengthChromosome(CHR,"bases")*runif(length(CHR)) # position on chromosome
    chrompos&lt;-prepareGenomePlot(data.frame(CHR,MapInfo),paintCytobands = TRUE, organism="hsa")
    # Chrompos returns a matrix with the positions of the elements on the plot
    # You can use all kinds of base graphics functions to annotate the chromosomes
    points(chrompos[,2],chrompos[,1]+0.1,pch="x",col="red")
    # Show connection between 3rd and 4th element
    segments(chrompos[3,2],chrompos[3,1],chrompos[4,2],chrompos[4,1],col="blue",lwd=2)

![PrepareGenomePlot Example][3]


  [1]: http://imgur.com/8DsW5.png
  [2]: http://imgur.com/a0AWz.png
  [3]: http://imgur.com/RscFr.png</Text>
  </row>
  <row>
    <Id>806</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>438</PostId>
    <RevisionGUID>0d4c15a2-175a-454d-9be6-c1102593b79a</RevisionGUID>
    <CreationDate>2010-03-24T11:35:32.11</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text>At the risk of sounding slightly daft - no, not that I know of.

I personally get my information about upcoming conferences from the mailing lists I subscribe to where every upcoming barely relevant call for papers is spammed liberally across half a dozen of them at a time, ensuring that there is no way for me to not know about their existence!

[http://www.bioinformatics.org/][1] however do seem to have lots of CfP's on their news front page.


  [1]: http://www.bioinformatics.org/</Text>
  </row>
  <row>
    <Id>807</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>439</PostId>
    <RevisionGUID>66845018-7731-40bf-9956-8a0f4e570a24</RevisionGUID>
    <CreationDate>2010-03-24T11:45:01.15</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>There is no centralized place to this end. But, there are a few very important hubs, though. These are very important:

[Genetics Society Meetings][1]
[ISCB Meetings][2]

IEEE has some interesting meetings too.

To avoid deadline frustation, I recommend you to follow this societies closely (use their RSS, Twitter or mail lists). Many conferences just spike out suddenly and have very short time windows (at least in South America). And always be prepared. Keep your preprints in good shape. Life will be much easier and a lot more funnier.


  [1]: http://www.genetics.org.uk/page/3190/External-meetings.html
  [2]: http://www.iscb.org/iscb-conferences</Text>
  </row>
  <row>
    <Id>808</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>437</PostId>
    <RevisionGUID>9243e005-5390-44f9-93d4-0e9840a9a568</RevisionGUID>
    <CreationDate>2010-03-24T11:58:41.09</CreationDate>
    <IPAddress>145.88.209.33</IPAddress>
    <UserId>171</UserId>
    <Comment>Added reference for more examples</Comment>
    <Text>The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions

Some Examples
![Digital Karyogram][1]


![Copynumber plots][2]


EDIT:
The code for these plots is quite involved, and depends a lot on the genomic data.

The supplementary data for Genome Res. 2007 17: 368-376, doi:10.1101/gr.5686107 contains the data and script to produce the figures for the paper, which also contain some of these ideograms

A quick example leads to the following plot

    # prepareGenomePlot example
    library(quantsmooth)
    # construct genomic positions
    CHR&lt;-sample(22,40,replace=TRUE)  # Chromosomes
    MapInfo&lt;-lengthChromosome(CHR,"bases")*runif(length(CHR)) # position on chromosome
    chrompos&lt;-prepareGenomePlot(data.frame(CHR,MapInfo),paintCytobands = TRUE, organism="hsa")
    # Chrompos returns a matrix with the positions of the elements on the plot
    # You can use all kinds of base graphics functions to annotate the chromosomes
    points(chrompos[,2],chrompos[,1]+0.1,pch="x",col="red")
    # Show connection between 3rd and 4th element
    segments(chrompos[3,2],chrompos[3,1],chrompos[4,2],chrompos[4,1],col="blue",lwd=2)

![PrepareGenomePlot Example][3]


  [1]: http://imgur.com/8DsW5.png
  [2]: http://imgur.com/a0AWz.png
  [3]: http://imgur.com/RscFr.png</Text>
  </row>
  <row>
    <Id>809</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>440</PostId>
    <RevisionGUID>0f3e2162-5e6d-47b7-8ca8-fdcbca1882b9</RevisionGUID>
    <CreationDate>2010-03-24T12:26:41.753</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>We have certainly written scripts using Mechanize for this in the past which picked up ~85-90% of articles for which PDFs were available. This trawled around looking for links, forwards etc.. to PDFs.

So you could go that way, but I wonder if you might want to take a look at Pubget http://pubget.com/. I haven't had a close look, but they have an API that you might be able to use to do the hard work for you. As I say I don't know how good the return rate is with this.</Text>
  </row>
  <row>
    <Id>810</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>441</PostId>
    <RevisionGUID>acbf5a09-7a68-4311-ac2d-2e4fdf2cd693</RevisionGUID>
    <CreationDate>2010-03-24T12:39:46.563</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>I have started running R jobs on a high performance compute cluster, but inevitably find that I am just performing array jobs which are ultimately not taking advantage of true parallelism, although they do speed up the experiment.

I would like to start writing some parallel code in R where parallelized functions are available and wondered what people's experiences of this are and what packages you would recommend ?</Text>
  </row>
  <row>
    <Id>811</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>441</PostId>
    <RevisionGUID>acbf5a09-7a68-4311-ac2d-2e4fdf2cd693</RevisionGUID>
    <CreationDate>2010-03-24T12:39:46.563</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>Which R packages, if any, are best for high performance computing ?</Text>
  </row>
  <row>
    <Id>812</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>441</PostId>
    <RevisionGUID>acbf5a09-7a68-4311-ac2d-2e4fdf2cd693</RevisionGUID>
    <CreationDate>2010-03-24T12:39:46.563</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text> éhpcà  érà  éparallelà  écranà </Text>
  </row>
  <row>
    <Id>813</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>442</PostId>
    <RevisionGUID>11d8bbe0-bef8-48f2-9b0e-20b12db18073</RevisionGUID>
    <CreationDate>2010-03-24T12:49:25.533</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>I know of two, but have not used either:

 1. [R/parallel – speeding up bioinformatics analysis with R][1]
 2. [The gputools package enables GPU computing in R][2]

See also [CRAN Task View: High-Performance and Parallel Computing with R][3].


  [1]: http://www.biomedcentral.com/1471-2105/9/390
  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/26/1/134
  [3]: http://cran.r-project.org/web/views/HighPerformanceComputing.html</Text>
  </row>
  <row>
    <Id>814</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>327</PostId>
    <RevisionGUID>fc7f8e5f-2842-46ab-ae89-660197dde1c3</RevisionGUID>
    <CreationDate>2010-03-24T13:03:47.35</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>815</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>441</PostId>
    <RevisionGUID>83fac468-9cd7-4872-8f96-d05c1d70d0e1</RevisionGUID>
    <CreationDate>2010-03-24T13:15:10.26</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>changed the word high performance to parallel</Comment>
    <Text>Which R packages, if any, are best for parallel computing ?</Text>
  </row>
  <row>
    <Id>816</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>443</PostId>
    <RevisionGUID>8f4ddd27-4cb0-4e9a-a468-6bef9e30ccf3</RevisionGUID>
    <CreationDate>2010-03-24T13:29:32.68</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Maybe this question is best suited for stackoverflow.
Have a look at [this discussion][1] and follow [this search][2].


  [1]: http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors
  [2]: http://stackoverflow.com/search?q=[r]+parallel</Text>
  </row>
  <row>
    <Id>817</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>444</PostId>
    <RevisionGUID>3ad08064-2902-4776-9f73-49d413f57875</RevisionGUID>
    <CreationDate>2010-03-24T13:33:26.75</CreationDate>
    <IPAddress>128.240.229.68</IPAddress>
    <UserId>59</UserId>
    <Text>Have you looked at REvolution R?

[http://www.revolution-computing.com/][1]

sudo apt-get install revolution-r 

will get you up and running in Ubuntu in no time.

"REvolution R runs many computationally-intensive programs faster, especially on multiprocessor systems. REvolution R is built with high-performance compilers and linked with computational libraries that take advantage of multiple processors simultaneously to reduce the time to complete many common mathematical operations. You do not need to modify your code to benefit from these optimizations. "


  [1]: http://www.revolution-computing.com/</Text>
  </row>
  <row>
    <Id>818</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>445</PostId>
    <RevisionGUID>830e8128-848b-42c8-ab9b-9845fc023bd8</RevisionGUID>
    <CreationDate>2010-03-24T13:53:06.5</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Fundamentally the most important element of parallel computing revolves around requirement of *inter-process communication*. 

There are many problems that require no such communication and thus can be simply be parallelized by splitting the input data into chunks and running multiple instances of the program in question. I don't personally consider this "parallel" computing but others call it as such. Many of the solutions you'll find for R are handy convenience functions for starting up R as new processes then collecting the results of their run. 

The *true parallel* computing revolves around the ability to quickly exchange data across different parallel processes. These are necessary when one process needs some results computed in a different process. Most of the time this requires specialized libraries or computing models and is not something that I would recommend one to undertake as a side project. 

There are some libraries written to take advantage of multiple cores. This is called *implicit parallelism*. In this case while the original may be a single threaded program, some internal functions are able to perform over multiple cores. 

Your primary course of action is to identify whether the problem that you wish to parallelize can be partitioned just by its input data and/or whether the functionality that you need is available via implicit parallelism. If so you have many straightforward solutions. If not then the solution will be a lot more complicated.
</Text>
  </row>
  <row>
    <Id>819</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>446</PostId>
    <RevisionGUID>ae1f010e-9b58-4156-9f48-3be7be4407a0</RevisionGUID>
    <CreationDate>2010-03-24T14:22:41.09</CreationDate>
    <IPAddress>121.121.9.46</IPAddress>
    <UserId>176</UserId>
    <Text>how about the issue of patenting after submitting the data? will there be any complications since these data are already in public domain</Text>
  </row>
  <row>
    <Id>820</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>447</PostId>
    <RevisionGUID>14c4f057-7e64-44f2-87db-8261aaee7aea</RevisionGUID>
    <CreationDate>2010-03-24T14:37:13.653</CreationDate>
    <IPAddress>204.56.6.58</IPAddress>
    <UserId>74</UserId>
    <Text>[GOrilla][1] makes nice pictures.


  [1]: http://cbl-gorilla.cs.technion.ac.il/</Text>
  </row>
  <row>
    <Id>821</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>448</PostId>
    <RevisionGUID>5d3be22d-3487-49a8-96f6-7d49cda7b8bd</RevisionGUID>
    <CreationDate>2010-03-24T14:44:20.743</CreationDate>
    <IPAddress>147.99.111.194</IPAddress>
    <UserId>177</UserId>
    <Text>If you know a little python or are interested in learning, you can use the mpi4py and rpy packages. The first one provides access to the MPI library for parallel computing very simply and the second allows you to use R from within your python program. With both you can do a lot ...</Text>
  </row>
  <row>
    <Id>822</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>449</PostId>
    <RevisionGUID>4a5d5a19-49e0-4908-b028-2f961ae45410</RevisionGUID>
    <CreationDate>2010-03-24T14:51:19.587</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>Like several of the others I also recommend DAVID to wet lab biologists. It is well maintained, but you should check the version on the particular species annotation(s) they are currently using as it it sometimes not the latest.

They use a variant of the Fisher exact statistic for their p-value calculations called the EASE score which they wrote up in a paper a few years back http://www.ncbi.nlm.nih.gov/pubmed/14519205 which is more conservative that the standard.</Text>
  </row>
  <row>
    <Id>823</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>450</PostId>
    <RevisionGUID>fb4588e7-ddfb-4133-a5d8-bb0ebb3e1fcd</RevisionGUID>
    <CreationDate>2010-03-24T15:45:11.533</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Just heard of [ResearchRaven][1] : A Place to Announce Upcoming Meetings and Calls for Papers. 


  [1]: http://www.researchraven.com/</Text>
  </row>
  <row>
    <Id>824</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>451</PostId>
    <RevisionGUID>97bb9382-6583-42d5-9bf6-0cdc636fc5f0</RevisionGUID>
    <CreationDate>2010-03-24T16:00:03.223</CreationDate>
    <IPAddress>67.237.56.153</IPAddress>
    <UserId>179</UserId>
    <Text>This is more of a general question as I am new to this site.  I teach at a community college and am trying to determine some projects that 1st year and 2nd year biology students could do.  Ideally, the project would be able to be continuous as 1. the turnover rate for the students would be pretty quick and 2. this couldn't be research done at universities.  

One thought I had involved the periodical cicadas.  These cicadas have life cycles where they are underground for either 13 or 17 years.  As a result, there are different populations of cicadas that are genetically isolated from each other.  One population will come out in 2011, another one in 2013 etc. etc.  When the populations emerge varies from state to state.  

Would there be any value to sequencing these different populations?  What type of analysis would I do for each one?  There are a lot of details to be figured out and I would have to write a grant to get some equipment. I would also partner with a local university to see if I could use some of their equipment. Before I start trying to figure out the smaller details though, I just wanted some feedback to see if this would be worthwhile and what are some other details I may not have thought of.

The only other idea I had was sequencing some fungi as this area has not gotten a lot of attention.  Any ideas or comments are welcome.  Thank you!  </Text>
  </row>
  <row>
    <Id>825</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>451</PostId>
    <RevisionGUID>97bb9382-6583-42d5-9bf6-0cdc636fc5f0</RevisionGUID>
    <CreationDate>2010-03-24T16:00:03.223</CreationDate>
    <IPAddress>67.237.56.153</IPAddress>
    <UserId>179</UserId>
    <Text>Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?</Text>
  </row>
  <row>
    <Id>826</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>451</PostId>
    <RevisionGUID>97bb9382-6583-42d5-9bf6-0cdc636fc5f0</RevisionGUID>
    <CreationDate>2010-03-24T16:00:03.223</CreationDate>
    <IPAddress>67.237.56.153</IPAddress>
    <UserId>179</UserId>
    <Text> écollegeöresearchöprojectà </Text>
  </row>
  <row>
    <Id>827</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>452</PostId>
    <RevisionGUID>b19f203f-0673-48dd-8acd-397bbd9a75c4</RevisionGUID>
    <CreationDate>2010-03-24T16:07:09.737</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>I'm dealing with some of the same problems right now - trying to adapt an R package to multi-core machines. I've had some luck using the [multicore/doMC](http://cran.r-project.org/web/packages/doMC/index.html) and [foreach](http://cran.r-project.org/web/packages/foreach/index.html) packages. They essentially take a for loop and parcel out the iterations to multiple cores. This is essentially splitting the input data, not the more implicit parallelism, but seems to work fairly well. This approach  doesn't solve the problem of splitting jobs among multiple cluster nodes, though.

I also looked at R/parallel, but had major problems getting it to work. Lots of cryptic error messages and failure in simple cases that looked just like the vignettes.  I can't recommend it.</Text>
  </row>
  <row>
    <Id>828</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>453</PostId>
    <RevisionGUID>c2c4caa2-c662-457f-80b3-236b69df67be</RevisionGUID>
    <CreationDate>2010-03-24T16:28:03.93</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>You seem to be going at this a bit backwards. The first step in science is to make a hypothesis, then choose the appropriate tools to answer it.  That may include genome sequencing, it may not. It seems like you've got a hammer, and you're looking for a nail.

If you want to study cicadas, start reading up them. Look at the literature and see what other people are studying and what big unanswered cicada questions rewwwportalmlekozyjestart. If you lack access to subscription journals, try your local library, or other [online resources](http://friendfeed.com/references-wanted).  I suspect some of the questions relate to the different cycle lengths - have there been certain genes implicated? Do we know whether it's governed by differential gene expression, genomic factors, or even epigenomics? Has anyone sequenced them already? I'm sure some population geneticists would be interested in divergence patterns between the groups - might help you understand whether they're still the same species, or whether they're slowly splitting apart from each other because of the time differential in emergence.

The same applies for fungi. Find out what some of the big unanswered questions are, then try to figure out what approach you might take to answer some of them. Then narrow it down further to manageable size projects that a new biologist could handle.
</Text>
  </row>
  <row>
    <Id>829</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>454</PostId>
    <RevisionGUID>32e20537-8260-497d-86c9-142daeb90005</RevisionGUID>
    <CreationDate>2010-03-24T16:53:56.78</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text>While I've looked for this sort of information I've never actually found a reasonable database of this sort of information.  OMIM is close to what you're looking for but its data is woefully sparse.  [SNPpedia][1] is a wikipedia-like website trying to annotate the SNPs implicated in diseases but it is also terribly sparse.

Good luck.


  [1]: http://www.snpedia.com</Text>
  </row>
  <row>
    <Id>830</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>451</PostId>
    <RevisionGUID>49775593-5d62-49f9-b387-7480763518fc</RevisionGUID>
    <CreationDate>2010-03-24T16:59:47.05</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>edited tags</Comment>
    <Text> écollegeöresearchöprojectà  éeducationà </Text>
  </row>
  <row>
    <Id>831</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>455</PostId>
    <RevisionGUID>927c57f4-aa01-4a21-8985-37a236f89c80</RevisionGUID>
    <CreationDate>2010-03-24T17:07:42.337</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>It is a brainstorming question, so I will just give my 0.02$.
There are a number of fairly simple lab techniques producing useful but often not publishable results. 

If you want to stick with Magicicada, quick look in Animal Genome Size Database http://www.genomesize.com/ reveals that there are no entries for Cicadidae.
So measuring of DNA content, counting chromosomes will be both new and useful for downstream DNA sequencing projects. 


Yes, having genomic sequences for species with such life-cycles will be great for chronobiology. But it is a bit over the top as a student project. 

At this point [NCBI][1] list just 19 nucleotide sequences for all Magicicada. So yes, you can contribute sequencing almost anything from any of these species, but if this is supposed to be more than an exercise in DNA extraction, subcloning and feeding sequencing machines then you will have to pick something interesting. 

Like sequencing as many as possible genes responsible for molecular clock. But then you are again on square one: complicated project requiring substantial funding.    
  

  [1]: http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=38085</Text>
  </row>
  <row>
    <Id>832</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>456</PostId>
    <RevisionGUID>229daba7-739e-4f60-aed9-1258c746b885</RevisionGUID>
    <CreationDate>2010-03-24T17:25:03.087</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>I am looking for something like Amazon User Reviews but for journal articles.</Text>
  </row>
  <row>
    <Id>833</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>456</PostId>
    <RevisionGUID>229daba7-739e-4f60-aed9-1258c746b885</RevisionGUID>
    <CreationDate>2010-03-24T17:25:03.087</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>Are there websites which allow users to post comments on peer-reviewed articles?</Text>
  </row>
  <row>
    <Id>834</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>456</PostId>
    <RevisionGUID>229daba7-739e-4f60-aed9-1258c746b885</RevisionGUID>
    <CreationDate>2010-03-24T17:25:03.087</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text> épeeröreviewà  éarticlesà  éjournalsà </Text>
  </row>
  <row>
    <Id>835</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>435</PostId>
    <RevisionGUID>95111f73-98b2-4e8e-921f-33eaa44962c4</RevisionGUID>
    <CreationDate>2010-03-24T17:26:13.29</CreationDate>
    <IPAddress>82.126.24.10</IPAddress>
    <UserId>30</UserId>
    <Comment>edited tags</Comment>
    <Text> écallöforöpapersà  éconferencesà  éresearchà  énotöprogrammingörelatedà </Text>
  </row>
  <row>
    <Id>836</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>457</PostId>
    <RevisionGUID>fdc168cf-13ce-4d13-982e-fb3d13cac7cb</RevisionGUID>
    <CreationDate>2010-03-24T17:29:36.22</CreationDate>
    <IPAddress>67.237.56.153</IPAddress>
    <UserId>179</UserId>
    <Text>I don't know of any, but I am not as well versed in these areas as others here are - sounds like a great idea if there aren't any websites though!</Text>
  </row>
  <row>
    <Id>837</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>458</PostId>
    <RevisionGUID>eae53eec-f1d3-48cb-9803-f72fde21e97c</RevisionGUID>
    <CreationDate>2010-03-24T17:38:37.487</CreationDate>
    <IPAddress>82.126.24.10</IPAddress>
    <UserId>30</UserId>
    <Text>Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .
I also found http://acawiki.org/Home in my bookmarks: 
&gt; AcaWiki is like a "Wikipedia for
&gt; academic research" designed to
&gt; increase the impact of scholars,
&gt; students, and bloggers by enabling
&gt; them to share summaries and discuss
&gt; academic papers online

and the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)
</Text>
  </row>
  <row>
    <Id>838</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>459</PostId>
    <RevisionGUID>02f2a18c-b2fb-4303-98a9-1b9b97badb6c</RevisionGUID>
    <CreationDate>2010-03-24T17:40:43.627</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>The [PLoS Journals](http://www.plos.org/) let you comment on the articles directly.</Text>
  </row>
  <row>
    <Id>839</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>460</PostId>
    <RevisionGUID>8d4138a4-9f88-4aaf-8cc2-eb106338023e</RevisionGUID>
    <CreationDate>2010-03-24T17:40:47.387</CreationDate>
    <IPAddress>130.209.6.40</IPAddress>
    <UserId>164</UserId>
    <Text>A good place for information on cicadas is [Chris Simon's web site](http://hydrodictyon.eeb.uconn.edu/projects/cicada/simon_lab/lab_pages/current.php). She maintains [Cicada Central](http://hydrodictyon.eeb.uconn.edu/projects/cicada/cc.php) which has loads of resources. You might also take a look at a recent PLoS ONE paper from her lab [doi:10.1371/journal.pone.0000892](http://dx.doi.org/10.1371/journal.pone.0000892). Chris might have some suggestions on possible projects.</Text>
  </row>
  <row>
    <Id>840</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>461</PostId>
    <RevisionGUID>a3cb83d7-1d43-453c-a26d-e0f84bd68555</RevisionGUID>
    <CreationDate>2010-03-24T17:40:58.34</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>This question is somewhat fortuitous. I have a paper on Physica A with a automata model for *Magicicada*. Of course, to build the model we discussed a lot the underlying genetic architecture and possible ecological scenarios. It's a fair complicated problem. Despite plentiful cirscunstancial evidence, there are no sound ones for the underlying genetics. No clue about the biological clock, too. And aging and lifecycle are tipically governed by nontrivial QTL.
&lt;p&gt;
Nevertheless, would be fantastic if you could track down the evolution of this two populations, phylogenetically speaking. This can be done at protein level and/or DNA level with just gels, PCR and Sanger sequencing. It's low resolution, but works.
&lt;p&gt; This will be a great opportunity to teach evolutionary theory, ecology and scientific methodology. I can sure help with specific details.</Text>
  </row>
  <row>
    <Id>841</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>459</PostId>
    <RevisionGUID>1a64a1af-8a8c-430e-8470-0960a691c1d4</RevisionGUID>
    <CreationDate>2010-03-24T17:46:49.353</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Comment>added 65 characters in body</Comment>
    <Text>The [PLoS Journals](http://www.plos.org/) let you comment on the articles directly, which I suppose is like reviewing an amazon product on its page.</Text>
  </row>
  <row>
    <Id>842</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>458</PostId>
    <RevisionGUID>95c7af38-af59-4477-a8b4-0b4310680864</RevisionGUID>
    <CreationDate>2010-03-24T17:59:47.473</CreationDate>
    <IPAddress>82.126.24.10</IPAddress>
    <UserId>30</UserId>
    <Comment>google</Comment>
    <Text>Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .
I also found http://acawiki.org/Home in my bookmarks: 
&gt; AcaWiki is like a "Wikipedia for
&gt; academic research" designed to
&gt; increase the impact of scholars,
&gt; students, and bloggers by enabling
&gt; them to share summaries and discuss
&gt; academic papers online

Google side wiki ? http://www.google.com/sidewiki/intl/en/index.html

and the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)
</Text>
  </row>
  <row>
    <Id>843</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>462</PostId>
    <RevisionGUID>5880bf14-d360-40f4-985b-b39a9ebc9839</RevisionGUID>
    <CreationDate>2010-03-24T18:18:41.413</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I think most of the enrichment analysis tools deals with same class of statistics methods (p-value, FDR, Boneferroni etc). Defining background is a very important in such enrichment methods. To get real meaning of enrichment with respect to your experiments, you should be able to upload the background. For example, if you are looking at a set of a genes from a particular tissue, a background of that tissue give more meaningful results than a background of whole genome.</Text>
  </row>
  <row>
    <Id>844</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>195</PostId>
    <RevisionGUID>e2df9edf-72ee-4bd1-af9b-4ab075513425</RevisionGUID>
    <CreationDate>2010-03-24T18:32:00.357</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>added 94 characters in body</Comment>
    <Text>I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): 

1. [Genes, Proteins and Computers][1] : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. 
2. [Bioinformatics by David Mount][2] : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. 
3. [Bioinformatics : Unix/Linux, Data Processing and Programming][3] : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. 
4. [Bioinformatics : Machine learning approaches][4] Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For computer science students : here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. 
5. [An Introduction to Bioinformatics Algorithms][5] This one is my favorite, especially the pseudocode section and classification of algorithms and its concise description. Book features extensive content on the algorithms used in bioinforamtics categorized into different groups with interesting cartoons. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. 

PS. I have couple of more like [Computational Genome Analysis][6], [Programming Collective Intelligence][7] etc. But they are more of specialized in to different sub-domains of bioinformatics. 

  [1]: http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545
  [2]: http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087
  [3]: http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6
  [4]: http://books.google.com/books?id=pxSM7R1sdeQC&amp;dq=Pierre+baldi+%2B+bioinformatics&amp;printsec=frontcover&amp;source=bn&amp;hl=en&amp;ei=IoGRS6uCIJT-NYLA8Z0N&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4&amp;ved=0CBUQ6AEwAw#v=onepage&amp;q=&amp;f=false
  [5]: http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&amp;ttype=2
  [6]: http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851
  [7]: http://oreilly.com/catalog/9780596529321</Text>
  </row>
  <row>
    <Id>845</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>463</PostId>
    <RevisionGUID>7cafcfa2-47f1-4625-a83e-337581db9195</RevisionGUID>
    <CreationDate>2010-03-24T18:48:27.53</CreationDate>
    <IPAddress>82.126.95.218</IPAddress>
    <UserId>30</UserId>
    <Text>I've never found a good bioinformatics book.

All the books I've glanced  :

  -  were too much theoretical
  -  were too much trivial
  -  don't have enough examples (code...)
  -  only used perl
  -  ...

at the end, I learned much more at reading the blogs and the IT sites.
</Text>
  </row>
  <row>
    <Id>846</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>464</PostId>
    <RevisionGUID>4705a92b-4c8b-4105-ae69-91dd752da868</RevisionGUID>
    <CreationDate>2010-03-24T18:53:23.637</CreationDate>
    <IPAddress>82.126.95.218</IPAddress>
    <UserId>30</UserId>
    <Text>[Bosco Ho][1]'s **ANNOTATR** :

http://annotatr.appspot.com/


  [1]: http://boscoh.com/</Text>
  </row>
  <row>
    <Id>847</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>465</PostId>
    <RevisionGUID>2bede61c-1117-46b8-bb8f-2fa5a606fc04</RevisionGUID>
    <CreationDate>2010-03-24T19:07:25.137</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Storing large amounts of data will become a problem for the bioinformatics, sooner or later. I've faced this problem recently and a lot of questions that I've never thought before just surfaced. The most obvious are:
How to decide the filesystem? How to partition a large (TB range) HD? When is a cheap solution (e. g. a bunch of low-end HDs) inappropriate?
&lt;p&gt;
These are pressing issues here at brazilian medical community. Everyone wants to buy a NGS machine, mass spec or microarray but no one perceives the forthcomming data flood. 
&lt;p&gt;
In practical terms, how do you store your data? A good reason for a given decision would be great too.


</Text>
  </row>
  <row>
    <Id>848</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>465</PostId>
    <RevisionGUID>2bede61c-1117-46b8-bb8f-2fa5a606fc04</RevisionGUID>
    <CreationDate>2010-03-24T19:07:25.137</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Tips to build a data storage for bioinformatics</Text>
  </row>
  <row>
    <Id>849</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>465</PostId>
    <RevisionGUID>2bede61c-1117-46b8-bb8f-2fa5a606fc04</RevisionGUID>
    <CreationDate>2010-03-24T19:07:25.137</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> étipsà  édataöstorageà  épracticalà </Text>
  </row>
  <row>
    <Id>850</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>466</PostId>
    <RevisionGUID>db52e4f2-1f16-4e38-bceb-5d6dc34e6487</RevisionGUID>
    <CreationDate>2010-03-24T19:53:31.603</CreationDate>
    <IPAddress>92.241.193.121</IPAddress>
    <UserId>71</UserId>
    <Text>Alternatively, you can blog about the article. Websites like [ResearchBlogging][1], [Chemical blogspace][2] and [NatureBlogs][3], and the PLoS journals will index those blogs and link the comments to the papers. Using userscripts you can have those comments show up on the journal website when you use your [GreaseMonkey][4]-enabled browser (e.g. [Firefox][5] or [Chrome][6]) to look at the article website (see doi:[10.1186/1471-2105-8-487][7]).

An example screenshot of a journal ToC:
![alt text][8]

  [1]: http://researchblogging.org/
  [2]: http://cb.openmolecules.net/papers.php
  [3]: http://blogs.nature.com/
  [4]: http://en.wikipedia.org/wiki/Greasemonkey
  [5]: http://firefox.com
  [6]: http://www.google.com/chrome
  [7]: http://www.biomedcentral.com/1471-2105/8/487
  [8]: http://blueobelisk.sourceforge.net/wiki/images/6/60/CBandPG.png</Text>
  </row>
  <row>
    <Id>851</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>467</PostId>
    <RevisionGUID>4b1c7ad7-8e57-475d-89d3-96bb99f2db6b</RevisionGUID>
    <CreationDate>2010-03-24T19:58:24.693</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>I'm not an expert sysadmin, but here's something to consider: If you're connecting a file server to a cluster of compute nodes, don't forget to provide scratch space on each compute machine. This will allow users to do I/O intensive operations locally, rather than saturating the network and your disks with requests.</Text>
  </row>
  <row>
    <Id>852</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>468</PostId>
    <RevisionGUID>ae2b71ee-e9b8-45a7-91e8-e62c6546660f</RevisionGUID>
    <CreationDate>2010-03-24T20:04:44.69</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>&lt;p&gt;You can find a listing at http://www.bioinformatics.fr/events.php.&lt;/p&gt;
&lt;p&gt;I try to update it during my spare time.&lt;/p&gt;
&lt;p&gt;There is an associated RSS Feed.&lt;/p&gt;

</Text>
  </row>
  <row>
    <Id>853</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>469</PostId>
    <RevisionGUID>721356e3-cc72-4d50-a0a0-46b9029742fc</RevisionGUID>
    <CreationDate>2010-03-24T20:05:25.753</CreationDate>
    <IPAddress>129.25.16.227</IPAddress>
    <UserId>92</UserId>
    <Text>I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?</Text>
  </row>
  <row>
    <Id>854</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>469</PostId>
    <RevisionGUID>721356e3-cc72-4d50-a0a0-46b9029742fc</RevisionGUID>
    <CreationDate>2010-03-24T20:05:25.753</CreationDate>
    <IPAddress>129.25.16.227</IPAddress>
    <UserId>92</UserId>
    <Text>Markov chain for generating random protein sequences</Text>
  </row>
  <row>
    <Id>855</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>469</PostId>
    <RevisionGUID>721356e3-cc72-4d50-a0a0-46b9029742fc</RevisionGUID>
    <CreationDate>2010-03-24T20:05:25.753</CreationDate>
    <IPAddress>129.25.16.227</IPAddress>
    <UserId>92</UserId>
    <Text> émarkovà </Text>
  </row>
  <row>
    <Id>856</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>469</PostId>
    <RevisionGUID>e1941a33-ec6b-4653-aad1-b69ac50c41f1</RevisionGUID>
    <CreationDate>2010-03-24T20:07:11.337</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Comment>edited tags</Comment>
    <Text> émarkovà  échainà </Text>
  </row>
  <row>
    <Id>857</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>470</PostId>
    <RevisionGUID>6326f85a-4cb0-46bd-b8f0-f06d106e2b64</RevisionGUID>
    <CreationDate>2010-03-24T20:25:11.863</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>You might check out this blog post about using Amazon Web Services for analysis of NGS data: http://defsci.blogspot.com/2010/01/ruby-aws-easy-map-reduce.html

Not directly about data storage per se, but certainly your NGS analysis strategy affects your data storage needs...</Text>
  </row>
  <row>
    <Id>858</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>471</PostId>
    <RevisionGUID>1e9012e8-0740-4d45-bc12-82d6a2b1238d</RevisionGUID>
    <CreationDate>2010-03-24T20:46:40.413</CreationDate>
    <IPAddress>90.218.5.12</IPAddress>
    <UserId>180</UserId>
    <Text>I really have one main usage for TreeViewX, and that is to quickly visualize a tree from the clipboard when I'm coding. I used TreeView for that previously, but I think I can't run that any more on my new OSX version (10.7 Pussycat or whatever). I vaguely miss the ability to show unrooted trees, which TreeView used to have but the X version doesn't seem to. All in all I find either very handy for this one use case. Other programs (e.g. mesquite) just aren't lightweight and quick enough.</Text>
  </row>
  <row>
    <Id>859</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>472</PostId>
    <RevisionGUID>6dd8733d-5b85-4e1d-89e6-e96069dc3a25</RevisionGUID>
    <CreationDate>2010-03-24T20:47:16.31</CreationDate>
    <IPAddress>204.56.6.100</IPAddress>
    <UserId>74</UserId>
    <Text>My person-on-the-street explanation would include where I work, the term Bioinformatics, and something like "I use computers to analyze biological data so we can better understand how life works". I tend to emphasize that I like my job, I find it interesting, and that the complexity of life continues to amaze me.

As I'm explaining, I feel, nervous, proud, and afraid they won't understand. 

I am also slightly afraid they might think I am evil and enjoy killing cuddly animals and/or babies.</Text>
  </row>
  <row>
    <Id>860</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>428</PostId>
    <RevisionGUID>8b3df77d-9814-4639-86f6-a0b3faf4899a</RevisionGUID>
    <CreationDate>2010-03-24T20:51:05.927</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>added new suggestions</Comment>
    <Text>AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. 

[NHGRI website][2] provides A Catalog of Published Genome-Wide Association Studies: They provide a detailed table of GWAS and their details. As of 03/24/10, this table includes 517 publications and 2443 SNPs. You may map this SNPs to get the respective genes. 

Also this [manuscript][3] provides results from various GWAS studies. 

I am looking forward for other comments to know if there is any public resource that provides GWAS data. 


  [1]: http://www.ncbi.nlm.nih.gov/gap
  [2]: http://www.genome.gov/26525384
  [3]: http://www.biomedcentral.com/1471-2350/10/6</Text>
  </row>
  <row>
    <Id>861</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>473</PostId>
    <RevisionGUID>a1207c96-a272-4f2d-9cd9-aa7b83a567d9</RevisionGUID>
    <CreationDate>2010-03-24T21:03:21.293</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>You are very much right, and secure and reliable storage *is* already a problem. Im not a sysadmin person but got some insight from my work. Here is a little overview how it might [have looked in 2007 for a medium size setup][1] (this is a bit dated but I am sure it became just much bigger ;) ). 

BTW: I don't believe there much difference in requirements between bioinformatics storage and any other large scientific/business data. So, to get recommendations about top brands in storage better ask this on a sys-admin board, I guess there are some. 

Maybe most important about storage: 
Storage is nothing without a proper backup solution. And the backup systems are often much more expensive than the disks because you need some overhead for incremental backups. 
And that need to be taken care of by some admin.

A tape archive system could also be used to store rarely used data.

If possible use an extensible solution and at that time that was some hotswappable RAID  (5?? or so) array disks. Why hot-swappable? Because disks fail and then it's nice to be able to replace them. 

For data transfer of terabytes, fast connections are needed and that was fibre-channel. Redundant file servers are also nice to have. As you are working in a hospital, there
might be even sensitive person related data, so you might even have to think about cryptographic file systems.

Of course this is sort of a maximum scenario and one can work with less. On my small  linux machines I am using Ext3 fs on some TB without many problems, also UFS worked very robust on FreeBSD and Mac.  

but as you say, your institute bought a/some highly expensive machines, the follow up costs must be considered. So if there is an application for research grants for a new -omics-machine (can call it ferrari too) then you have to be willing to pay the fuel, sorry the infrastructure and sysadmins.




  [1]: http://www.cebitec.uni-bielefeld.de/brf/infrastructure/infrastructure.html</Text>
  </row>
  <row>
    <Id>862</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>473</PostId>
    <RevisionGUID>9cbfe2c3-c0d5-4cc9-a19e-8ea8d5f21785</RevisionGUID>
    <CreationDate>2010-03-24T21:08:24.44</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>deleted 1 characters in body; added 1 characters in body</Comment>
    <Text>You are very much right, and secure and reliable storage *is* already a problem. Im not a sysadmin person but got some insight from my work. Here is a little overview how it might [have looked in 2007 for a medium size setup][1] (this is a bit dated but I am sure it became just much bigger ;) ). 

BTW: I don't believe there much difference in requirements between bioinformatics storage and any other large scientific/business data. So, to get recommendations about top brands in storage better ask this on a sys-admin board, I guess there are some. 

Maybe most important about storage: 
Storage is nothing without a proper backup solution. And the backup systems are often much more expensive than the disks because you need some overhead for incremental backups. 
And that need to be taken care of by some admin.

A tape archive system could also be used to store rarely used data.

If possible use an extensible solution and at that time that was some hotswappable RAID  (5?? or so) array disks. Why hot-swappable? Because disks fail and then it's nice to be able to replace them. 

For data transfer of terabytes, fast connections are needed and that was fibre-channel. Redundant file servers are also nice to have. As you are working in a hospital, there
might be even sensitive person related data, so you might even have to think about cryptographic file systems.

Of course this is sort of a maximum scenario and one can work with less. On my small  linux machines I am using Ext3 fs on some TB without many problems, also UFS worked very robust on FreeBSD and Mac.  

but as you say, your institute bought a/some highly expensive machines, the follow up costs must be considered. So if there is an application for research grants for a new -omics-machine (can call it ferrari too) then you have to be willing to pay the fuel, sorry the infrastructure and sysadmins.




  [1]: http://www.cebitec.uni-bielefeld.de/brf/infrastructure/infrastructure.html</Text>
  </row>
  <row>
    <Id>863</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>474</PostId>
    <RevisionGUID>e5101b17-00c5-4c09-9025-34d53a54c49e</RevisionGUID>
    <CreationDate>2010-03-24T21:19:55.073</CreationDate>
    <IPAddress>82.126.82.190</IPAddress>
    <UserId>30</UserId>
    <Text>Do you know any **public** scientific SQL server ?

for example, I would cite:

 - UCSC	http://genome.ucsc.edu/FAQ/FAQdownloads#download29
 - ENSEMBL	http://uswest.ensembl.org/info/data/mysql.html
 - GO	http://www.geneontology.org/GO.database.shtml#mirrors

(I'll give a +1 to each correct answer)
</Text>
  </row>
  <row>
    <Id>864</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>474</PostId>
    <RevisionGUID>e5101b17-00c5-4c09-9025-34d53a54c49e</RevisionGUID>
    <CreationDate>2010-03-24T21:19:55.073</CreationDate>
    <IPAddress>82.126.82.190</IPAddress>
    <UserId>30</UserId>
    <Text>What are the public SQL servers for bioinformatics ?</Text>
  </row>
  <row>
    <Id>865</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>474</PostId>
    <RevisionGUID>e5101b17-00c5-4c09-9025-34d53a54c49e</RevisionGUID>
    <CreationDate>2010-03-24T21:19:55.073</CreationDate>
    <IPAddress>82.126.82.190</IPAddress>
    <UserId>30</UserId>
    <Text> ésqlà  ébioinformaticsà  éserverà  épublicà  éresourcesà </Text>
  </row>
  <row>
    <Id>866</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>475</PostId>
    <RevisionGUID>b9c6a212-9ffb-4b98-968b-e7818491a0fb</RevisionGUID>
    <CreationDate>2010-03-24T21:25:18.793</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>(Sorry, this is not an add, even if it sound like...)

My favourite bioinformatics book is a biology book [Lewin's Genes X][1]. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see the computer science as a means ti analyse genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.

Maybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to "Cell").


  [1]: http://www.jbpub.com/catalog/9780763766320/</Text>
  </row>
  <row>
    <Id>867</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>475</PostId>
    <RevisionGUID>667081c6-656c-456a-9702-e7b228184ea9</RevisionGUID>
    <CreationDate>2010-03-24T22:07:16.18</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 6 characters in body</Comment>
    <Text>(Sorry, this is not an add, even if it sound like...)

My favourite bioinformatics book is a biology book [Lewin's Genes X][1]. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see computer science as a means to better understand genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.

Maybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to "Cell").


  [1]: http://www.jbpub.com/catalog/9780763766320/</Text>
  </row>
  <row>
    <Id>868</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>476</PostId>
    <RevisionGUID>5ec8e736-00ef-42aa-95a1-991777f082c1</RevisionGUID>
    <CreationDate>2010-03-24T22:18:05.113</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>Flybase has direct access to its postgres chado database.

http://flybase.org/forums/viewtopic.php?f=14&amp;t=114
 
hostname: flybase.org
port: 5432
username: flybase
password: no password
database name: flybase

e.g.
psql -h flybase.org -U flybase flybase</Text>
  </row>
  <row>
    <Id>869</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>477</PostId>
    <RevisionGUID>3ced23b6-d7e7-41b2-959b-722136afb2d6</RevisionGUID>
    <CreationDate>2010-03-24T23:06:53.23</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>It seems Python programmers like writing Markov generators.  I often see this topic pop up on Python blogs in the context of generating pseudo random text. A quick search shows a few hits:

 - [Markov chains][1]
 - [Pseudo random text generator][2]
 - [Markov chains in python][3]
 - [Markov chain algorithm][4]

I guess you would only need to change to tokenizer to split on letters rather than words.

  [1]: http://www.evanfosmark.com/2009/11/python-markov-chains-and-how-to-use-them/
  [2]: http://uswaretech.com/blog/2009/06/pseudo-random-text-markov-chains-python/
  [3]: http://justinbozonier.posterous.com/markov-chains-in-python
  [4]: http://code.activestate.com/recipes/194364-the-markov-chain-algorithm/</Text>
  </row>
  <row>
    <Id>870</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>478</PostId>
    <RevisionGUID>fe90c3ac-2027-4abc-b4fe-0eea272148fb</RevisionGUID>
    <CreationDate>2010-03-25T00:44:54.097</CreationDate>
    <IPAddress>130.155.25.114</IPAddress>
    <UserId>66</UserId>
    <Text>[PublicHouse][1] - uses the [BioWarehouse][2] system; requires user registration.


  [1]: http://biowarehouse.ai.sri.com/PublicHouseOverview.html
  [2]: http://biowarehouse.ai.sri.com/index.html</Text>
  </row>
  <row>
    <Id>871</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>215</PostId>
    <RevisionGUID>a3a48b00-736b-4eaf-911b-d57d5f950ee0</RevisionGUID>
    <CreationDate>2010-03-25T07:09:27.74</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Comment>edited tags</Comment>
    <Text> éassemblyà  éunambiguousà  éfastqà  éngsà  ésequencingà </Text>
  </row>
  <row>
    <Id>872</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>479</PostId>
    <RevisionGUID>bd1e6617-bc1e-4468-9694-aa77b1c8488c</RevisionGUID>
    <CreationDate>2010-03-25T07:34:14.82</CreationDate>
    <IPAddress>202.185.55.241</IPAddress>
    <UserId>185</UserId>
    <Text>I would like to compare the amino acid and the codon usage content between two organisms.
What statistical test would be appropriate for this purpose? And what are the inputs needed?</Text>
  </row>
  <row>
    <Id>873</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>479</PostId>
    <RevisionGUID>bd1e6617-bc1e-4468-9694-aa77b1c8488c</RevisionGUID>
    <CreationDate>2010-03-25T07:34:14.82</CreationDate>
    <IPAddress>202.185.55.241</IPAddress>
    <UserId>185</UserId>
    <Text>amino acid content statistical test</Text>
  </row>
  <row>
    <Id>874</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>479</PostId>
    <RevisionGUID>bd1e6617-bc1e-4468-9694-aa77b1c8488c</RevisionGUID>
    <CreationDate>2010-03-25T07:34:14.82</CreationDate>
    <IPAddress>202.185.55.241</IPAddress>
    <UserId>185</UserId>
    <Text> éstatisticà </Text>
  </row>
  <row>
    <Id>875</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>480</PostId>
    <RevisionGUID>ca2474dc-9fa1-49b7-bda8-8f7debd1caf8</RevisionGUID>
    <CreationDate>2010-03-25T07:57:13.163</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>I recommend that you study the work of Jean Lobry, who has done a lot of work in this area.

Search PubMed for "Lobry JR[AU]" or see his [partial list of publications][1].

He has also written an R package called [seqinR][2] which contains many methods for statistical analysis of sequences, including composition. Read the documentation, in particular chapter 9 on multivariate analysis.


  [1]: http://pbil.univ-lyon1.fr/members/lobry/
  [2]: http://seqinr.r-forge.r-project.org/</Text>
  </row>
  <row>
    <Id>876</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>479</PostId>
    <RevisionGUID>6cc1e85a-8f72-4f5c-85f7-6614c8ad5c9b</RevisionGUID>
    <CreationDate>2010-03-25T08:01:20.863</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Comment>edited tags</Comment>
    <Text> éstatisticsà  ésequenceöcompositionà </Text>
  </row>
  <row>
    <Id>877</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>481</PostId>
    <RevisionGUID>6a3fed32-269b-465d-9a31-8211dad08795</RevisionGUID>
    <CreationDate>2010-03-25T09:37:15.57</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.

 - Direct SQL Access to MGI
 - http://www.informatics.jax.org/software.shtml#sql

Note that this is a public 'free' service, but that you do need to contact user support to get your login and password. They can also provide some custom SQLs to you if you contact user support.</Text>
  </row>
  <row>
    <Id>878</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>482</PostId>
    <RevisionGUID>78f8b1c8-70d6-4634-9c7c-b223571304e2</RevisionGUID>
    <CreationDate>2010-03-25T09:41:26.77</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>All of the BioMed Central journals accept comments on journal articles, so that is currently 207 journals.

They have a policy on comments which you can access here :-

http://www.biomedcentral.com/info/about/commentpolicy</Text>
  </row>
  <row>
    <Id>879</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>483</PostId>
    <RevisionGUID>72681482-03a3-4edf-8fec-a0ab8e6006a8</RevisionGUID>
    <CreationDate>2010-03-25T11:31:01.033</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I have two groups of data (not distributed under a normal distribution): I would like to test the hypothesis that the first group has a lower (or narrower) standard deviation than the other.

An alternative explanation to this is that I would like to tell whether the first group is less 'variable', 'heterogeneous', than the first. 

A [kruskal-wallis][1] won't do it because it compares the medians of two or more groups, and I am not interested in that.

A [Levene][2] or a [Brown-Forsynth][3] test compare the variance between the two groups and tell whether they have the same variance. This is better, but I would also like to tell if the variance in the first group is lower than in the other(s) group(s).

A simple [Chi-Square][4] test would tell me whether the standard deviation of a group is equal to a certain value, and the one-tailed version can tell me whether it is higher/lower.

An additional difficulty is that I would have to do this test as a two-way, because I have two grouping variables, but I would like to ask you if you can point me to any direction or give me some hint, I have not many ideas on where to search :-)


  [1]: http://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test
  [2]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm
  [3]: http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test
  [4]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm</Text>
  </row>
  <row>
    <Id>880</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>483</PostId>
    <RevisionGUID>72681482-03a3-4edf-8fec-a0ab8e6006a8</RevisionGUID>
    <CreationDate>2010-03-25T11:31:01.033</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>test whether the variance in a group is lower than in another</Text>
  </row>
  <row>
    <Id>881</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>483</PostId>
    <RevisionGUID>72681482-03a3-4edf-8fec-a0ab8e6006a8</RevisionGUID>
    <CreationDate>2010-03-25T11:31:01.033</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> éstatisticà  étestà  érà  éstandardödeviationà </Text>
  </row>
  <row>
    <Id>882</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>484</PostId>
    <RevisionGUID>18270538-263e-4263-9dd6-6a1d74206285</RevisionGUID>
    <CreationDate>2010-03-25T11:50:50.473</CreationDate>
    <IPAddress>159.92.206.174</IPAddress>
    <UserId>120</UserId>
    <Text>I really like [Biological Sequence Analysis, Durbin et al.][1] and, although not really bioinformatics-specific, I found [Perl Medic, Peter J. Scott][2] made a big difference to my newbie Perl code. For biology text books, I mainly relied on [Lewin][3] and [Alberts][4] for background during my undergrad.


  [1]: http://www.amazon.co.uk/Biological-Sequence-Analysis-Probabilistic-Proteins/dp/0521629713
  [2]: http://www.amazon.co.uk/Perl-Medic-Maintaining-Inherited-Code/dp/0201795264
  [3]: http://www.amazon.co.uk/Genes-IX-Benjamin-Lewin/dp/0763752223
  [4]: http://www.amazon.co.uk/Molecular-Biology-Cell-Bruce-Alberts/dp/0815341067/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1269517727&amp;sr=1-1</Text>
  </row>
  <row>
    <Id>883</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>485</PostId>
    <RevisionGUID>936168a8-fe7d-4c29-9bb7-7c54078669f2</RevisionGUID>
    <CreationDate>2010-03-25T11:54:05.437</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Look for the F-test or [Bartlett's test][1]. As your data is non-normal you need something more robust against deviation from normality. [Leven's test is for example mentioned as an alternative][2]


  [1]: http://en.wikipedia.org/wiki/Bartlett%27s_test
  [2]: http://en.wikipedia.org/wiki/Levene_test</Text>
  </row>
  <row>
    <Id>884</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>483</PostId>
    <RevisionGUID>18f823ef-4019-465a-95bf-2346ca991780</RevisionGUID>
    <CreationDate>2010-03-25T11:54:29.627</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Comment>edited tags</Comment>
    <Text> éstatisticsà  étestingà  érà  éstandardödeviationà </Text>
  </row>
  <row>
    <Id>885</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>a72715ba-bddf-4d1a-b1cc-ed6f4d93e3f0</RevisionGUID>
    <CreationDate>2010-03-25T13:51:09.083</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.

Which C++ libraries are people using to deal with NGS data?

</Text>
  </row>
  <row>
    <Id>886</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>a72715ba-bddf-4d1a-b1cc-ed6f4d93e3f0</RevisionGUID>
    <CreationDate>2010-03-25T13:51:09.083</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>Which C++ libraries are best for dealing with fastq files?</Text>
  </row>
  <row>
    <Id>887</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>a72715ba-bddf-4d1a-b1cc-ed6f4d93e3f0</RevisionGUID>
    <CreationDate>2010-03-25T13:51:09.083</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text> écççà </Text>
  </row>
  <row>
    <Id>888</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>487</PostId>
    <RevisionGUID>df779fbc-6cfc-41fc-8126-94481b2557c2</RevisionGUID>
    <CreationDate>2010-03-25T13:59:26.867</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed and adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, &lt;, &gt;) and significance/power levels.

I don't know much about your experimental/test design. You could furnish additional detais.</Text>
  </row>
  <row>
    <Id>889</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>1bee28fa-8204-4575-8148-64a8c2621627</RevisionGUID>
    <CreationDate>2010-03-25T14:08:58.86</CreationDate>
    <IPAddress>144.32.17.75</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> écççà  éfastqà  éparserà </Text>
  </row>
  <row>
    <Id>890</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>14e42a1e-474f-413a-ba62-98414e38d26c</RevisionGUID>
    <CreationDate>2010-03-25T14:09:23.727</CreationDate>
    <IPAddress>144.32.17.75</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> écççà  éfastqà </Text>
  </row>
  <row>
    <Id>891</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>488</PostId>
    <RevisionGUID>16a29714-02bb-4aed-8c57-e15b178e9ac7</RevisionGUID>
    <CreationDate>2010-03-25T14:10:58.637</CreationDate>
    <IPAddress>144.32.17.75</IPAddress>
    <UserId>59</UserId>
    <Text>I wouldn't dream of doing this I admit, I tend to handle fastq files with applications other people develop.

However there is a FASTA/FASTQ c++ parser here:

[http://lh3lh3.users.sourceforge.net/parsefastq.shtml][1] which might serve as a base for what you want to do.

It's from Heng Li who also works on SAMtools, BWA and MAQ


  [1]: http://lh3lh3.users.sourceforge.net/parsefastq.shtml</Text>
  </row>
  <row>
    <Id>892</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>486</PostId>
    <RevisionGUID>0bd0e82f-c2ca-4de9-9219-c288f64eca3c</RevisionGUID>
    <CreationDate>2010-03-25T14:14:45.573</CreationDate>
    <IPAddress>144.32.17.75</IPAddress>
    <UserId>59</UserId>
    <Comment>edited tags</Comment>
    <Text> écççà  éfastqà  éngsà </Text>
  </row>
  <row>
    <Id>893</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>489</PostId>
    <RevisionGUID>7438e74a-7afa-4639-a9d7-b062f42dabbd</RevisionGUID>
    <CreationDate>2010-03-25T14:44:17.62</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>I saw a SeqAn poster at ISMB last year. No experience with the library (nor C++) myself but they support the fastq format and they made the impression that they are quite competent.

[SeqAn file formats][1]


  [1]: http://www.seqan.de/dddoc/html/TAG_File+_Format.html</Text>
  </row>
  <row>
    <Id>894</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>490</PostId>
    <RevisionGUID>c34d6026-9ab1-443d-86bc-5c0f10787e15</RevisionGUID>
    <CreationDate>2010-03-25T15:20:23.713</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>We're currently gearing up to implement some of our fragmented analyses into Taverna workflows. The motivation for us is to provide web applications for both ourselves and other community members (for both dry and wet lab people) to get the most out of our high throughput data sources. There is no denying that part of this motivation is not purely philanthropic, but also to raise the impact of our work which makes our funders happy.

From a technical point of view we are having to implement our own web services from quite a wide range of sources; mainly Perl, C, C++ and R. Some of these are quite easy to do fairly directly with SOAP/WDSL (especially for Perl). Others like R can take advantage of some recent tools such as RShell http://www.ncbi.nlm.nih.gov/pubmed/19607662. The hardest is implementing new algorithms in C or C++ into usable web services, which we really are feeling our way around at the moment.</Text>
  </row>
  <row>
    <Id>895</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>491</PostId>
    <RevisionGUID>47cf62a7-70b9-465d-ab52-b033ac786400</RevisionGUID>
    <CreationDate>2010-03-25T15:42:08.64</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>We use an agile technique with SVN using the Eclipse development suite http://www.eclipse.org/, the SVN-Team plugin http://www.eclipse.org/subversive/ and either sourceforge or an internal SVN service.

Our team work tends to be done face to face, though we do have a personal wiki and use google apps as well.</Text>
  </row>
  <row>
    <Id>896</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>492</PostId>
    <RevisionGUID>ef041239-e6fa-44d1-b8b1-4f1962da01c4</RevisionGUID>
    <CreationDate>2010-03-25T16:29:02.88</CreationDate>
    <IPAddress>147.99.215.194</IPAddress>
    <UserId>186</UserId>
    <Text>I found this one few days ago : http://www.wikicfp.com/
I found it ok, also you have to check 2 categories : bioinformatics and computational biology</Text>
  </row>
  <row>
    <Id>897</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>481</PostId>
    <RevisionGUID>a5107642-3347-4e19-b725-e0580649631e</RevisionGUID>
    <CreationDate>2010-03-25T16:50:09.42</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>corrected my own English !</Comment>
    <Text>This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.

 - Direct SQL Access to MGI
 - http://www.informatics.jax.org/software.shtml#sql

Note that this is a public 'free' service, but that you do need to contact user support to get your login and password. They are also happy to provide some custom SQL scripts to get you started.</Text>
  </row>
  <row>
    <Id>898</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>493</PostId>
    <RevisionGUID>98c7f60f-23a9-4ccd-a43e-382c5441a10d</RevisionGUID>
    <CreationDate>2010-03-25T18:31:18.937</CreationDate>
    <IPAddress>130.209.6.40</IPAddress>
    <UserId>164</UserId>
    <Text>I've learnt pretty much everything from doing, i.e. programming, and rely heavily on online resources. There have been occasional programming books that I've used to bootstrap learning about a language (especially if it was a major leap, say from procedural to object-oriented languages, or from standalone application programming to web scripting). Of the bioinformatics books mentioned so far, [Durbin et al., Biological Sequence Analysis](http://rads.stackoverflow.com/amzn/click/0521629713) was the book I got the most out of, especially the section on RNA secondary structure, which I was obsessed with for a time. Good description of the problem, algorithms clearly explained, and pseudocode. Great stuff.

Perhaps off topic, but the books I find most fun and inspiring to read have been more general web-oriented books such as  [Ambient Findability: What We Find Changes Who We Become ](http://rads.stackoverflow.com/amzn/click/0596007655).</Text>
  </row>
  <row>
    <Id>899</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>494</PostId>
    <RevisionGUID>45740c78-5ed5-4bf3-963b-e74f8168a284</RevisionGUID>
    <CreationDate>2010-03-25T19:42:11.207</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>It's a simple &amp; straight questions. Just think about an app that when you found it, you first thought would be - "OMG!!! That's it" - or smth like - "I wish I could have found/written/idealized it before". 

My example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (yeah, population genetics) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. Hence, a whole new level of information would available for NGS data. That's what I really miss, right now. What's your story?

</Text>
  </row>
  <row>
    <Id>900</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>494</PostId>
    <RevisionGUID>45740c78-5ed5-4bf3-963b-e74f8168a284</RevisionGUID>
    <CreationDate>2010-03-25T19:42:11.207</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Which application is truly missing in bioinformatics?</Text>
  </row>
  <row>
    <Id>901</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>494</PostId>
    <RevisionGUID>45740c78-5ed5-4bf3-963b-e74f8168a284</RevisionGUID>
    <CreationDate>2010-03-25T19:42:11.207</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> ésubjectiveà  éreliefà  éfunà </Text>
  </row>
  <row>
    <Id>902</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>495</PostId>
    <RevisionGUID>8bb8985a-f475-4a5d-870c-ff43201b2aec</RevisionGUID>
    <CreationDate>2010-03-25T19:55:48.797</CreationDate>
    <IPAddress>85.2.252.177</IPAddress>
    <UserId>119</UserId>
    <Text>    /irony on
Something like the following is missing for bioinformatics:
http://pdos.csail.mit.edu/scigen/

    /irony off

Seriously, I think whatever it is, a *clean and well documented API* - as you say - is something it should provide.</Text>
  </row>
  <row>
    <Id>903</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>496</PostId>
    <RevisionGUID>edd52467-09ec-448a-b1a4-1bfe125b950e</RevisionGUID>
    <CreationDate>2010-03-25T20:03:16.48</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Text>I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.

There are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.</Text>
  </row>
  <row>
    <Id>904</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>494</PostId>
    <RevisionGUID>a3979bc4-5427-432c-8bdd-a75e94efe52c</RevisionGUID>
    <CreationDate>2010-03-25T20:12:38.13</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>minor language corrections</Comment>
    <Text>It's a simple &amp; straight questions. Just think about an app that when you found it, you first thought would be - "OMG!!! That's it" - or smth like - "I wish I could have found/written/idealized it before". 

My example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (yeah, population genetics) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. Hence, a whole new level of information would be available for NGS data (at least for me). That's what I really miss, right now. What's your story?

</Text>
  </row>
  <row>
    <Id>905</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>497</PostId>
    <RevisionGUID>24863d65-9ada-43ec-ab88-979ca267adcf</RevisionGUID>
    <CreationDate>2010-03-25T20:27:23.31</CreationDate>
    <IPAddress>85.2.252.177</IPAddress>
    <UserId>119</UserId>
    <Text>I whole-heartedly agree with Pierre's answer w.r.t. what I'd like a licence to say. Be that as it may, I have sometimes used the [Artistic License 2.0][1].


  [1]: http://www.opensource.org/licenses/artistic-license-2.0.php</Text>
  </row>
  <row>
    <Id>906</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>498</PostId>
    <RevisionGUID>3b190923-978a-4d6e-803e-31a8dd03e93f</RevisionGUID>
    <CreationDate>2010-03-25T20:39:53.37</CreationDate>
    <IPAddress>82.126.78.49</IPAddress>
    <UserId>30</UserId>
    <Text>I want a [bio2rdf][1] for the whole scientific *corpus*.


  [1]: http://bio2rdf.org/</Text>
  </row>
  <row>
    <Id>907</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>496</PostId>
    <RevisionGUID>01a5a088-8881-47eb-ae91-8f338c0167fd</RevisionGUID>
    <CreationDate>2010-03-25T21:37:22</CreationDate>
    <IPAddress>52.129.8.50</IPAddress>
    <UserId>73</UserId>
    <Comment>added 93 characters in body</Comment>
    <Text>I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.

There are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.

I would also like a proper "finishing tool" to visualize and reconcile Velvet assemblies.</Text>
  </row>
  <row>
    <Id>908</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>499</PostId>
    <RevisionGUID>60419df2-0458-45fd-abca-623805fde8c1</RevisionGUID>
    <CreationDate>2010-03-26T00:25:36.89</CreationDate>
    <IPAddress>130.155.25.114</IPAddress>
    <UserId>66</UserId>
    <Text>I think it would be incorrect to imagine that there is a single, "killer app" for bioinformatics.  I don't see bioinformatics as a field, discipline or topic.  For me it is about:  (1) inputs - many, diverse types of biological data, (2) processes - the code that we write to handle the data and (3) outputs - what the code produces and the subsequent biological interpretation.

That said, I'm sure there are tools we would all like to see when we handle whatever data type comes our way.  I'd like to see:

 1. A RESTful API for every public, online database
 2. Better web applications for data integration - so that when I search for, e.g. a gene, everything that's known about that gene and its products is presented to me in a way that enables effective data exploration

There are those who say that the "linked data web" is the answer to (2), which remains to be seen...</Text>
  </row>
  <row>
    <Id>909</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>500</PostId>
    <RevisionGUID>7c0a848d-de08-4ff1-a5a4-569a8e84db2f</RevisionGUID>
    <CreationDate>2010-03-26T00:45:47.01</CreationDate>
    <IPAddress>98.231.133.77</IPAddress>
    <UserId>89</UserId>
    <Text>I'd like Bioconductor-like repository would exist for MATLAB. Probably not gonna happen. :(</Text>
  </row>
  <row>
    <Id>910</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>501</PostId>
    <RevisionGUID>00e697ae-3c4b-49ff-b3a3-bf0e1e2af8f7</RevisionGUID>
    <CreationDate>2010-03-26T06:18:57.273</CreationDate>
    <IPAddress>216.9.20.172</IPAddress>
    <UserId>72</UserId>
    <Text>The number one tenet of storage at scale is "things fail".  When you scale up, you will find that 2-5% of your disks are going to fail and when you have a lot of spindles that's a pretty large number.  You have to manage against such failures, so it isn't just about buying TBs of disk.  You need to design your systems to be fail gracefully.  Depending on your applications/goals you might need to make any storage solution highly available, which means you need redundancy, and to scale reads you will almost certainly need to partition your data.  

I recommend checking out some of the presentations by Chris Dagdigian, e.g. http://blog.bioteam.net/wp-content/uploads/2010/03/cdag-xgen-storageForNGS_v3.pdf

</Text>
  </row>
  <row>
    <Id>911</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>502</PostId>
    <RevisionGUID>582aba06-e6f6-4349-aa6d-c567d4631bba</RevisionGUID>
    <CreationDate>2010-03-26T09:27:26.227</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>Does anyone have an idea on how to make NCBI BLAST work with custom Matrices? i.e. ones that are not provided by the BLOSUM series that come as a default with NCBI BLAST.
</Text>
  </row>
  <row>
    <Id>912</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>502</PostId>
    <RevisionGUID>582aba06-e6f6-4349-aa6d-c567d4631bba</RevisionGUID>
    <CreationDate>2010-03-26T09:27:26.227</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>Custom Matrices with NCBI BLAST</Text>
  </row>
  <row>
    <Id>913</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>502</PostId>
    <RevisionGUID>582aba06-e6f6-4349-aa6d-c567d4631bba</RevisionGUID>
    <CreationDate>2010-03-26T09:27:26.227</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text> éblastà  ématricesà </Text>
  </row>
  <row>
    <Id>914</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>503</PostId>
    <RevisionGUID>60aa9078-ade8-45f6-929b-906ddf45d5e2</RevisionGUID>
    <CreationDate>2010-03-26T09:31:41.053</CreationDate>
    <IPAddress>147.99.215.194</IPAddress>
    <UserId>187</UserId>
    <Text>Do you use a specific assembler that you would like to recommend? Is there a particular trend to use a specific class of assemblers (for example de Bruijn-based)? Is there an assembler that runs on 32bit OSs so that I can play in small scale (in my desktop) before going real scale (in the server)?</Text>
  </row>
  <row>
    <Id>915</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>503</PostId>
    <RevisionGUID>60aa9078-ade8-45f6-929b-906ddf45d5e2</RevisionGUID>
    <CreationDate>2010-03-26T09:31:41.053</CreationDate>
    <IPAddress>147.99.215.194</IPAddress>
    <UserId>187</UserId>
    <Text>Which assembler to use for metagenomic sequences?</Text>
  </row>
  <row>
    <Id>916</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>503</PostId>
    <RevisionGUID>60aa9078-ade8-45f6-929b-906ddf45d5e2</RevisionGUID>
    <CreationDate>2010-03-26T09:31:41.053</CreationDate>
    <IPAddress>147.99.215.194</IPAddress>
    <UserId>187</UserId>
    <Text> émetagenomeöassemblyà </Text>
  </row>
  <row>
    <Id>917</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>504</PostId>
    <RevisionGUID>a3c83193-fc6a-4383-ba26-01bc96c4f171</RevisionGUID>
    <CreationDate>2010-03-26T10:50:46.887</CreationDate>
    <IPAddress>150.254.122.5</IPAddress>
    <UserId>188</UserId>
    <Text>We have lots of individual projects, but thematically close to each other. Individual means, there is a lab leader who brings the idea, a PhD student who brings them to life, and a postdoc for troubleshooting. Plus eventually one to few undergraduates who are supposed to work with the result.&lt;br&gt;

We are using a portfolio of Agile-inspired techniques to keep everything neat. In my opinion, using a version control system (SVN, GIT, Bazaar) is a must. For half of the projects we have unit tests and do TDD (these tend to be more successful - an observation not a causality). For implementation, we are doing Pair Programming and code reviews frequently. Sometimes we use Trac, iterations, and Kanban.

For communication, I couldn't do anything without a whiteboard and several pin boards in the lab.
</Text>
  </row>
  <row>
    <Id>918</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>505</PostId>
    <RevisionGUID>a86f86d5-9286-4809-b500-0331471e4dc7</RevisionGUID>
    <CreationDate>2010-03-26T11:22:59.407</CreationDate>
    <IPAddress>86.20.111.107</IPAddress>
    <UserId>189</UserId>
    <Text>Hi i am probably in the wrong placeso i probably wont be able to get back to this page as i have been to lots of pages over the weeks any way if you can help please
 i bought a new computer and downloaded Riva tuner not realising what it did it obviously overclocked and i have no display (Nvidia GT 220 Graphics card ) i am now running on onboard Graphics motherboard is Biostar  GF 8100 M2G+   i was told clear CMOS i have moved jumpers from 1-2 to 2-3 and back to 1-2 about 30 times with power cord disconnected, i have held down INSERT while pressing start 20 times i have re-installed windows Vista 3 times in the bios is still the warning CLEAR CMOS IF THIS HAS BEEN OVERCLOCKED,??? I AM AT MY WITTS END, i am a pensioner and i dont do overclocking i just want to get it back to normal any help will be "GREATLY" appreciated many thanks Colin.  my email is ..........colin.green57@ntlworld.com

</Text>
  </row>
  <row>
    <Id>919</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>505</PostId>
    <RevisionGUID>a86f86d5-9286-4809-b500-0331471e4dc7</RevisionGUID>
    <CreationDate>2010-03-26T11:22:59.407</CreationDate>
    <IPAddress>86.20.111.107</IPAddress>
    <UserId>189</UserId>
    <Text>Cannot Clear CMOS </Text>
  </row>
  <row>
    <Id>920</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>505</PostId>
    <RevisionGUID>a86f86d5-9286-4809-b500-0331471e4dc7</RevisionGUID>
    <CreationDate>2010-03-26T11:22:59.407</CreationDate>
    <IPAddress>86.20.111.107</IPAddress>
    <UserId>189</UserId>
    <Text> écannotclearcmosà </Text>
  </row>
  <row>
    <Id>921</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>506</PostId>
    <RevisionGUID>46504deb-02e2-4990-8587-68097041f548</RevisionGUID>
    <CreationDate>2010-03-26T11:40:16.573</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>I can tell you what does not work and suggest a possible solution.

When BLAST is installed locally on a Linux system from an NCBI package, the matrices are stored in /usr/share/ncbi/data, as plain text files.  So, I tried copying the BLOSUM62 matrix to a new file named "BLOSUM00", then running blastall as:

    blastall -p blastp -d nr -i myseq.fa -M BLOSUM00

And I got this error message:

    Searching[blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM00 is not a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM80 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM62 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM50 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM45 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: PAM250 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM62_20 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: BLOSUM90 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: PAM30 is a supported matrix
    [blastall] ERROR: Q02066.1: BlastKarlinBlkGappedCalc: PAM70 is a supported matrix

This indicates to me that the BLAST matrices are hard-coded in the BLAST source code.  One solution might be to download the BLAST source code, find the file related to "BlastKarlinBlkGappedCalc", edit the source and see if you can compile BLAST.</Text>
  </row>
  <row>
    <Id>922</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>505</PostId>
    <RevisionGUID>773c0926-4291-4d96-89bc-8a102f9ac06e</RevisionGUID>
    <CreationDate>2010-03-26T11:48:30.28</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>923</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>507</PostId>
    <RevisionGUID>ba89b4c6-d529-4d2f-8ad8-44e6ac9a7471</RevisionGUID>
    <CreationDate>2010-03-26T12:57:16.757</CreationDate>
    <IPAddress>77.170.91.52</IPAddress>
    <UserId>115</UserId>
    <Text>To answer what assembler you should use, we really need more information.

What kind of data do you have ?

How many organisms/species are in the sample you want to sequence ?

What do you want to do with the resulting assemblies ?
</Text>
  </row>
  <row>
    <Id>924</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>507</PostId>
    <RevisionGUID>14363f4d-49a3-47ea-9225-8f61e2440187</RevisionGUID>
    <CreationDate>2010-03-26T12:57:32.903</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>115</UserId>
    <Text>[{"Id":115,"DisplayName":"Jan van Haarst"}]</Text>
  </row>
  <row>
    <Id>925</Id>
    <PostHistoryTypeId>13</PostHistoryTypeId>
    <PostId>507</PostId>
    <RevisionGUID>52bcb3b0-ecc9-436e-a0a4-4a533d9d7a58</RevisionGUID>
    <CreationDate>2010-03-26T12:57:36.257</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>115</UserId>
    <Text>[{"Id":115,"DisplayName":"Jan van Haarst"}]</Text>
  </row>
  <row>
    <Id>926</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>508</PostId>
    <RevisionGUID>ecfb7d1c-bae8-468a-b32c-a8b1afefbaed</RevisionGUID>
    <CreationDate>2010-03-26T13:02:32.667</CreationDate>
    <IPAddress>67.169.211.218</IPAddress>
    <UserId>190</UserId>
    <Text>Hi, all. I am one of the people who works on ResearchRaven http://www.researchraven.com/ We have just launched. But we are certainly going to try to be a helpful resource in the biomedical field when it comes to serving as a centralized location for calls for papers and lists of meetings. Please feel free to submit such announcements for possible listing on ResearchRaven http://www.researchraven.com/submit-announcement.aspx No catch. It is all free. The aim is to free scientists from the hassle of having to search for hours for such info.
And the comments above certainly do suggest there is a need for ResearchRaven and the other sites mentioned. Here is a bit about ResearchRaven that I wrote for librarians: http://www.consortiumlibrary.org/blogs/pnc/2010/03/24/more-on-the-launch-of-researchraven-a-great-place-to-announce-upcoming-meetings-and-calls-for-papers/
Say, Egon. You are certainly well regarded by your peers in Open Science. I heard your name mentioned a lot at the Science Commons Symposium Pacific Northwest in February 2010.
Hope Leman, MLIS Research Information Technologist Center for Health Research and Quality Samaritan Health Services 815 NW 9th Street Suite 203A Corvallis, OR 97330 (541) 768-5712
</Text>
  </row>
  <row>
    <Id>927</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>509</PostId>
    <RevisionGUID>aa1cd275-7cea-47b9-8bae-21049a08d24c</RevisionGUID>
    <CreationDate>2010-03-26T13:06:59.823</CreationDate>
    <IPAddress>77.170.91.52</IPAddress>
    <UserId>115</UserId>
    <Text>There is a reason that everybody uses clusters/clouds: They are simple to setup, and very flexible. 

FPGA can be faster, but a cluster of CPU's with an optimized program will scale better and will be faster in the end.

GPGPU is rather limited to a certain type of application : do the same calculation on a lot of data, and that dat should be small.

I would put my money in a cluster/cloud, rather than invest in FPGA's and GPU's</Text>
  </row>
  <row>
    <Id>928</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>510</PostId>
    <RevisionGUID>067fab5a-a166-4b9e-a0cf-7e2c34e5bd4d</RevisionGUID>
    <CreationDate>2010-03-26T14:03:10.103</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>There is a very dirty trick to do that. You just need to name your custom matrix as a current supported matrix and put it int the matrices dir. That's the solution you can find at NCBI. It works. But, beware! Defaults are now a problem.

You can check additional details in:

http://www.ncbi.nlm.nih.gov/staff/tao/URLAPI/blastall.html#5

I'm not sure about the blast version in this site. In my box, I have ncbi-tools (ubuntu pkg) installed and, for example, PAM30 is in /usr/share/ncbi/data/PAM30. Got the idea?</Text>
  </row>
  <row>
    <Id>929</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>487</PostId>
    <RevisionGUID>3ed28806-b661-4576-95dc-2a50b4677108</RevisionGUID>
    <CreationDate>2010-03-26T14:20:34.423</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>deleted 1 characters in body</Comment>
    <Text>You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed an adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, &lt;, &gt;) and significance/power levels.

I don't know much about your experimental/test design. You could furnish additional detais.</Text>
  </row>
  <row>
    <Id>930</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>420</PostId>
    <RevisionGUID>96799ae8-e967-4279-8bca-5a3971b93168</RevisionGUID>
    <CreationDate>2010-03-26T14:59:09.723</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added somepreliminary  results</Comment>
    <Text>[Web-services][1] using SOAP or REST style are becoming more and more popular in also bioinformatics. The [Embrace Registry][2] and [BioCatalogue][3] are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be [composed into complex-workflows][4], [used for data-integration,][5] automated user-interface and API-generation, that's at least the theory. How does the reality look for you?

Do you use  SOAP/REST/.NET services in bioinformatics,
and what are your experiences with the different services and service providers?

Main aspects I am interested in are motivated by my own recent (and very mixed) experiences:

 - Did you encounter interoperability or language-dependence problems?
 - How did the providers react?
 - What would make you replace local scripts and tools by web-services?

------
Edit: I will have difficulties to choose the right answer, because everything said so far is valid.  

Here are some intermediate results. I am testing different SOAP services using Axis2/Java at the moment, using the wsdl2code to generate the Java trying adb and xmlbeans databindings. Maybe this list will grow:

 1. KEGG: wsdl2code: only with xmlbeans , usable: no, couldn't set arrayOfString because use of soapenc:array
 2. BRENDA: wsdl2code: Error message: Wsdl not WS-I compliant, usable: no
 3. BioMart soap: wsdl2code: yes, usable: no, after few mods of wsdl-file and tweaking axis2 params could send a valid message, response message is not valid 



  [1]: http://en.wikipedia.org/wiki/Web_service
  [2]: http://www.embraceregistry.net/
  [3]: http://www.biocatalogue.org/
  [4]: http://www.ncbi.nlm.nih.gov/pubmed/16845108
  [5]: http://www.ncbi.nlm.nih.gov/pubmed/18056132</Text>
  </row>
  <row>
    <Id>931</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>1401d752-da39-42c7-945f-ee85a087eeb0</RevisionGUID>
    <CreationDate>2010-03-26T15:21:13.487</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Today I had a lunchtime discussion with some colleagues about the existence of poly-allelic Single Nucleotide Polymorphisms (SNPs). Quoting Wikipedia to explain what I mean:

&gt; For example, two sequenced DNA
&gt; fragments from different individuals,
&gt; AAGC**C**TA to AAGC**T**TA, contain a
&gt; difference in a single nucleotide. In
&gt; this case we say that there are two
&gt; alleles : C and T. Almost all common
&gt; SNPs have only two alleles.

My point was that there could be some but I don't know any SNPs that have eg. 3 alleles such that there is either e.g. A/G/T, or all 4 bases in a population. If I wish to query a database, say BioMart, UCSC, HapMap for this, how would I do this?

If wanted to detect poly-allelic SNPs from sequencing data *de novo*, which method/program could be used?</Text>
  </row>
  <row>
    <Id>932</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>1401d752-da39-42c7-945f-ee85a087eeb0</RevisionGUID>
    <CreationDate>2010-03-26T15:21:13.487</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Howto detect and query poly-allelic SNPs?</Text>
  </row>
  <row>
    <Id>933</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>1401d752-da39-42c7-945f-ee85a087eeb0</RevisionGUID>
    <CreationDate>2010-03-26T15:21:13.487</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text> ésnpà  éalleleà  ésequenceà  ébiomartà  édbsnpà </Text>
  </row>
  <row>
    <Id>934</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>512</PostId>
    <RevisionGUID>c5407dce-b31c-4613-b744-0638c74fcb0f</RevisionGUID>
    <CreationDate>2010-03-26T15:53:36.707</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>This situation is rather cumbersome but quite common. Small deletions must be considered, too. There's a growing body of research on triallelic sites. You can check it yourself.

The only methodology I'm aware of is TriTyper described [here][1]. I've checked HapMart. They don't have a simple way to look for triallelic site!!! There more than a thousand of these already detected in humans.

It's not hard to get the HapMap data and search for them. But, it's strange that it's not a default filter/attribute combination possibility.

Maybe Pierre could give you a tip?



  [1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2427186/?tool=pubmed</Text>
  </row>
  <row>
    <Id>935</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>513</PostId>
    <RevisionGUID>0f65e8a3-1884-41ee-bdb9-9fa2f1ff8561</RevisionGUID>
    <CreationDate>2010-03-26T15:57:08.907</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>You can query UCSC snp130 table. The fields of interest would be observed and class.
You can use their [public mysql server][1] and run this sql query:

    SELECT name,chrom,chromStart,chromEnd,observed,class,avHet
      FROM snp130
      WHERE length(observed)&gt;3 and class="single" and avHet&gt;0

I've added a condition to find only SNPs with average heterozygosity over zero. It finds 4949 SNPs in hg19.

  [1]: http://genome.ucsc.edu/FAQ/FAQdownloads.html#download29</Text>
  </row>
  <row>
    <Id>936</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>513</PostId>
    <RevisionGUID>2b864f87-56a0-44a8-bdae-64b74f18c1d5</RevisionGUID>
    <CreationDate>2010-03-26T16:14:14.753</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Comment>added 19 characters in body</Comment>
    <Text>You can query UCSC snp130 table. The fields of interest would be observed and class.
You can use their [public mysql server][1] and run this sql query:

    SELECT name,chrom,chromStart,chromEnd,observed,class,avHet
      FROM snp130
      WHERE length(observed)&gt;3 and class="single" and avHet&gt;0

I've added a condition to find only SNPs with average heterozygosity over zero. It finds 4949 SNPs in hg19, 490 are 4-allelic.

  [1]: http://genome.ucsc.edu/FAQ/FAQdownloads.html#download29</Text>
  </row>
  <row>
    <Id>937</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>507</PostId>
    <RevisionGUID>45820c2c-57d9-4b36-95b1-307bdd544b97</RevisionGUID>
    <CreationDate>2010-03-26T17:07:21.363</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>115</UserId>
    <Text>[{"Id":115,"DisplayName":"Jan van Haarst"}]</Text>
  </row>
  <row>
    <Id>938</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>512</PostId>
    <RevisionGUID>f64925b7-1b8c-4b97-a518-332fb8d0982c</RevisionGUID>
    <CreationDate>2010-03-26T17:12:08.867</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 4 characters in body</Comment>
    <Text>This situation is rather cumbersome but quite common. Small deletions must be considered, too. There's a growing body of research on triallelic sites. You can check it yourself.

The only methodology I'm aware of is TriTyper described [here][1]. I've checked HapMart. They don't have a simple way to look for triallelic site!!! There are more than a thousand of these already detected in humans.

It's not hard to get the HapMap data and search for them. But, it's strange that it's not a default filter/attribute combination possibility.

Maybe Pierre could give you a tip?



  [1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2427186/?tool=pubmed</Text>
  </row>
  <row>
    <Id>939</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>514</PostId>
    <RevisionGUID>e61c6b43-d4bd-42c3-98c3-a4f1fc77cd13</RevisionGUID>
    <CreationDate>2010-03-26T18:21:35.353</CreationDate>
    <IPAddress>81.48.155.63</IPAddress>
    <UserId>30</UserId>
    <Text>Hum, not sure I understood your question. Do you just want to get a sub-list of all the non classical (di-allelic) snps ?

In a [previous post I described][1] a small piece of code to run a [SAX parser][2] with a javascript analyser. I'll use it here but it could be any SAX implementation.

The following script is used to scan the (big) XML files from **dbSNP**. It records the rs## and the 'non-di-allelic' observed mutations.

    var rs=null;
    var observed=null;
    var content=null;
    var pat=/[ATGC]\/[ATGC]/i;
    function startElement(uri,localName,name,atts)
            {
            if(localName=="Rs" &amp;&amp; observed==null)
                    {
                    rs="rs"+atts.getValue("rsId");
                    }
            else if(localName=="Observed")
                    {
                    content="";
                    }
            }
    function characters(s)
            {
            if(content!=null) content+=s;
            }
    
    function endElement(uri,localName,name)
            {
            if(localName=="Rs")
                    {
                    if(!observed.match(pat))
                            {
                            println(rs+"\t"+observed);
                            }
                    rs=null;
                    observed=null;
                    }
            else if(localName=="Observed")
                    {
                    observed=content;
                    }
            content=null;
            }


invoking the SAX/js script:

    java -jar saxscript.jar  -f scansnps.js  ftp:/tp.ncbi.nih.gov/snp/organisms/human_9606/XML/ds_ch1.xml.gz


result:

    rs242   -/T
    rs1433  -/A
    rs3483  -/ATTT
    rs4179  -/CAGA
    rs6485  -/AAT
    rs7563  -/AA
    rs16354 -/AACCCA
    rs16356 -/ATT
    rs16357 -/TGTGAA
    rs16358 -/ATAA
    rs16359 -/GA
    rs16360 -/TA
    rs16361 -/CT
    rs16439 -/CAGA
    rs16626 -/CGTGAAGTCC
    rs16631 -/TA
    rs16644 -/AAC
    rs16670 -/TTTAA
    rs16679 -/CT
    rs16684 -/CTCTGGC
    rs16686 -/AA
    rs16725 -/ACAAA
    rs16729 -/TCAAT
    rs20418 -/TAG
    rs20421 -/CGG
    rs20431 -/T
    rs25569 -/AC
    rs25571 -/TT
    rs140711        -/AG
    rs140758        -/GAAA
    rs140798        -/TTGT
    rs140838        -/TCGT
    rs140840        -/TT
    rs140841        -/TAACTA
    rs140849        -/GT
    rs140858        -/CT
    rs140861        -/CACT
    rs140862        -/TAAG
    rs140864        -/GAA
    rs140865        -/ACTACATGA
    rs171241        -/C
    rs209574        -/GC
    rs239965        -/T
    rs284043        -/G
    rs301740        -/TCTC
    rs316275        -/T
    rs319679        -/GTAG
    rs332778        -/T
    rs350183        -/A
    rs365861        -/A
    rs366664        -/A
    rs390580        -/CTCTCT
    rs391526        -/T
    rs393900        -/T
    rs398196        -/A
    rs410422        -/TT
    rs420240        -/T
    rs431835        -/AGATAT
    rs435486        -/AAAAA
    rs446074        -/A
    rs446693        -/GA
    rs480306        -/TGG
    rs481407        -/TATT
    rs485475        -/CAACAACAC
    rs486207        -/G
    (....)


hope it helps

  [1]: http://plindenbaum.blogspot.com/2009/06/event-driven-xml-parsing-sax-with.html
  [2]: http://en.wikipedia.org/wiki/Simple_API_for_XML</Text>
  </row>
  <row>
    <Id>940</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>515</PostId>
    <RevisionGUID>b5e3702e-5ef9-4da3-9730-1b0da8b6600b</RevisionGUID>
    <CreationDate>2010-03-26T18:42:29.913</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Web based genome browser (WGB) which does not require 110 Perl modules (one of which simply will not install). WGB with can handle multiple eukariotic genomes, next gen sequence data and can render things more pleasant for the eye than &gt;&gt;&gt;&gt;&gt;---- or sharp square boxes. 

Maybe with this:
http://genometools.org/annotationsketch.html
or Google Maps.




</Text>
  </row>
  <row>
    <Id>941</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>516</PostId>
    <RevisionGUID>0b23ccd9-dc92-4ecb-bca0-394a6901bee0</RevisionGUID>
    <CreationDate>2010-03-26T20:46:16.357</CreationDate>
    <IPAddress>204.56.6.68</IPAddress>
    <UserId>74</UserId>
    <Text>You could try [e-PCR][1] or [in-silico PCR][2]. e-PCR is available to run locally. 

  [1]: http://www.ncbi.nlm.nih.gov/projects/e-pcr/
  [2]: http://genome.ucsc.edu/cgi-bin/hgPcr?command=start</Text>
  </row>
  <row>
    <Id>942</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>517</PostId>
    <RevisionGUID>d8aa0421-5281-4a5e-a6af-94b40a1b688e</RevisionGUID>
    <CreationDate>2010-03-26T21:00:56.663</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text>I'm making a large number of seqlogos programatically. They are hundreds of columns wide and so running a seqlogo normally creates letters that are too thin to see. I've noticed that I only care about a few of these columns (not necessarily consecutive columns) ... most are noise but some are highly conserved.

I use something like this snippet:

    conserve_cell = seqlogo(wide_seqs, 'displaylogo', false);
    high_bit_cols = any(conserve_cell{2}&gt;1.0,1);
    [~, handle] = seqlogo(wide_seqs(:,high_bit_cols ));

Although when I do this I lose the information about which columns the data came from. 

Normally I would just change the x-axis of the seqlogo. However, seqlogo's are some sort of crazy java-based object and calls like:

    set(handle, 'xticklabel', num2str(find(high_bit_cols)))

don't work. Any help would be greatly appreciated.

Thanks,
Will</Text>
  </row>
  <row>
    <Id>943</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>517</PostId>
    <RevisionGUID>d8aa0421-5281-4a5e-a6af-94b40a1b688e</RevisionGUID>
    <CreationDate>2010-03-26T21:00:56.663</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text>Changing the x-axis of seqlogo figures in matlab</Text>
  </row>
  <row>
    <Id>944</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>517</PostId>
    <RevisionGUID>d8aa0421-5281-4a5e-a6af-94b40a1b688e</RevisionGUID>
    <CreationDate>2010-03-26T21:00:56.663</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text> ématlabà  ésequenceà  ésequenceölogoà  éaxisà  éjavaà </Text>
  </row>
  <row>
    <Id>945</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>517</PostId>
    <RevisionGUID>8036d59f-1127-4b02-a999-26f2ec7227ca</RevisionGUID>
    <CreationDate>2010-03-26T21:41:59.95</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Comment>added some initial data to show my problem</Comment>
    <Text>I'm making a large number of seqlogos programatically. They are hundreds of columns wide and so running a seqlogo normally creates letters that are too thin to see. I've noticed that I only care about a few of these columns (not necessarily consecutive columns) ... most are noise but some are highly conserved.

I use something like this snippet:

    wide_seqs = cell2mat(arrayfun(@randseq, repmat(200, [500 1]), 'uniformoutput', false));
    wide_seqs(:, [17,30, 55,70,130]) = repmat(['ATCGG'], [500 1])
    conserve_cell = seqlogo(wide_seqs, 'displaylogo', false);
    high_bit_cols = any(conserve_cell{2}&gt;1.0,1);
    [~, handle] = seqlogo(wide_seqs(:,high_bit_cols ));

Although when I do this I lose the information about which columns the data came from. 

Normally I would just change the x-axis of the seqlogo. However, seqlogo's are some sort of crazy java-based object and calls like:

    set(handle, 'xticklabel', num2str(find(high_bit_cols)))

don't work. Any help would be greatly appreciated.

Thanks,
Will</Text>
  </row>
  <row>
    <Id>946</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>f5ff4c71-900b-439f-a22b-b74ff09b7d13</RevisionGUID>
    <CreationDate>2010-03-27T08:33:32.077</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 214 characters in body; edited tags</Comment>
    <Text>Today I had a lunchtime discussion with some colleagues about the existence of poly-allelic Single Nucleotide Polymorphisms (SNPs). Quoting Wikipedia to explain what I mean:

&gt; For example, two sequenced DNA
&gt; fragments from different individuals,
&gt; AAGC**C**TA to AAGC**T**TA, contain a
&gt; difference in a single nucleotide. In
&gt; this case we say that there are two
&gt; alleles : C and T. Almost all common
&gt; SNPs have only two alleles.

My point was that there could be some but I don't know any SNPs that have eg. 3 alleles such that there is either e.g. A/G/T, or all 4 bases in a population. If I wish to query a database, say BioMart, UCSC, HapMap for this, how would I do this?

If wanted to detect poly-allelic SNPs from sequencing data *de novo*, which method/program could be used?

Edit: So far this seems to be real great stuff, got at least two different methods of getting the query right! 
But what about *de novo* detection? Would for example MAQ detect tri-allelic SNPs in short-reads?</Text>
  </row>
  <row>
    <Id>947</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>f5ff4c71-900b-439f-a22b-b74ff09b7d13</RevisionGUID>
    <CreationDate>2010-03-27T08:33:32.077</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 214 characters in body; edited tags</Comment>
    <Text> ésnpà  éalleleà  émaqà  ébiomartà  édbsnpà </Text>
  </row>
  <row>
    <Id>948</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>518</PostId>
    <RevisionGUID>bf053250-4464-437b-8ffe-9c7fdb2384f9</RevisionGUID>
    <CreationDate>2010-03-27T17:38:24.963</CreationDate>
    <IPAddress>130.223.9.66</IPAddress>
    <UserId>141</UserId>
    <Text>I want to download all EST sequences from Genbank that are in the Order Hymenoptera. 

This is easy by pointing and clicking:
 http://www.ncbi.nlm.nih.gov/sites/entrez?term=Hymenoptera&amp;cmd=Search&amp;db=nucest

However, I cannot get the efetch/eutils syntax right to do this in the commandline.

Note that contrarily to the following question, I do not know the identifiers for these ESTs:
http://biostar.stackexchange.com/questions/375/how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid

Thanks!

yannick</Text>
  </row>
  <row>
    <Id>949</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>518</PostId>
    <RevisionGUID>bf053250-4464-437b-8ffe-9c7fdb2384f9</RevisionGUID>
    <CreationDate>2010-03-27T17:38:24.963</CreationDate>
    <IPAddress>130.223.9.66</IPAddress>
    <UserId>141</UserId>
    <Text>How to download all EST sequences for organism XX from ncbi?</Text>
  </row>
  <row>
    <Id>950</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>518</PostId>
    <RevisionGUID>bf053250-4464-437b-8ffe-9c7fdb2384f9</RevisionGUID>
    <CreationDate>2010-03-27T17:38:24.963</CreationDate>
    <IPAddress>130.223.9.66</IPAddress>
    <UserId>141</UserId>
    <Text> éeutilsà  éretreivalà  ésequenceà </Text>
  </row>
  <row>
    <Id>951</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>519</PostId>
    <RevisionGUID>79cbd537-daac-4851-85bd-b9229082e7a3</RevisionGUID>
    <CreationDate>2010-03-27T18:14:05.33</CreationDate>
    <IPAddress>87.74.74.80</IPAddress>
    <UserId>99</UserId>
    <Text>Hi,

Where can I find example input files for abyss-explorer?
Is the format specified somewhere?</Text>
  </row>
  <row>
    <Id>952</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>519</PostId>
    <RevisionGUID>79cbd537-daac-4851-85bd-b9229082e7a3</RevisionGUID>
    <CreationDate>2010-03-27T18:14:05.33</CreationDate>
    <IPAddress>87.74.74.80</IPAddress>
    <UserId>99</UserId>
    <Text>adjacency files for abyss-explorer</Text>
  </row>
  <row>
    <Id>953</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>519</PostId>
    <RevisionGUID>79cbd537-daac-4851-85bd-b9229082e7a3</RevisionGUID>
    <CreationDate>2010-03-27T18:14:05.33</CreationDate>
    <IPAddress>87.74.74.80</IPAddress>
    <UserId>99</UserId>
    <Text> éabyssà  éassemblyà  évisualizationà </Text>
  </row>
  <row>
    <Id>954</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>520</PostId>
    <RevisionGUID>0fe77ed6-5480-4c18-872a-a870be6dda27</RevisionGUID>
    <CreationDate>2010-03-27T18:53:39.413</CreationDate>
    <IPAddress>82.126.70.241</IPAddress>
    <UserId>30</UserId>
    <Text>use the try db=nucest, retmax=300000 and term=Hymenoptera[Organism] 

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=nucest&amp;retmax=300000&amp;term=Hymenoptera[Organism]

and the call efetch with the list of ID, e.g:

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&amp;id=281381068&amp;rettype=fasta
</Text>
  </row>
  <row>
    <Id>955</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>520</PostId>
    <RevisionGUID>a818cc82-6c8e-4f6f-9160-57893546ab18</RevisionGUID>
    <CreationDate>2010-03-27T18:59:12.6</CreationDate>
    <IPAddress>82.126.70.241</IPAddress>
    <UserId>30</UserId>
    <Comment>typo</Comment>
    <Text>try db=nucest, retmax=300000 and term=Hymenoptera[Organism] 

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=nucest&amp;retmax=300000&amp;term=Hymenoptera[Organism]

and the call efetch with the list of ID, e.g:

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&amp;id=281381068&amp;rettype=fasta
</Text>
  </row>
  <row>
    <Id>956</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>521</PostId>
    <RevisionGUID>10373e61-65f5-4a6d-8771-2d70a3b07ad7</RevisionGUID>
    <CreationDate>2010-03-27T20:45:10.897</CreationDate>
    <IPAddress>88.18.100.189</IPAddress>
    <UserId>62</UserId>
    <Text>You can start with TaxonomyBrowser:
 
* http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi

* click on checkbox "Nucleotide EST", 

* Click Display button

* click on 290,764 link

* You get there: http://bit.ly/d3zNOf

* Pull-down menus: Summary-&gt;Fasta, Send to -&gt; File (regular download of a file in i.e. Firefox)

</Text>
  </row>
  <row>
    <Id>957</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>c66c30c6-0073-4009-a9ce-a7fa0f804b4d</RevisionGUID>
    <CreationDate>2010-03-28T10:35:57.84</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>edited title</Comment>
    <Text>How to detect and query poly-allelic SNPs?</Text>
  </row>
  <row>
    <Id>958</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>518</PostId>
    <RevisionGUID>8747608f-96f6-4351-80fb-9beb2ee6e640</RevisionGUID>
    <CreationDate>2010-03-28T13:44:29.477</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Comment>edited tags</Comment>
    <Text> éeutilsà  éretrievalà  ésequenceà </Text>
  </row>
  <row>
    <Id>959</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>520</PostId>
    <RevisionGUID>dec34317-58e2-4903-bba8-c2fa63d9d4df</RevisionGUID>
    <CreationDate>2010-03-28T15:29:49.747</CreationDate>
    <IPAddress>81.53.108.38</IPAddress>
    <UserId>30</UserId>
    <Comment>typo</Comment>
    <Text>try db=nucest, retmax=300000 and term=Hymenoptera[Organism] 

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=nucest&amp;retmax=300000&amp;term=Hymenoptera[Organism]

and then call efetch with the list of ID, e.g:

http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&amp;id=281381068&amp;rettype=fasta
</Text>
  </row>
  <row>
    <Id>960</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>522</PostId>
    <RevisionGUID>e9bd1c45-9c82-41e0-93ec-3fbeb76d94d2</RevisionGUID>
    <CreationDate>2010-03-28T16:50:38.35</CreationDate>
    <IPAddress>130.223.9.66</IPAddress>
    <UserId>141</UserId>
    <Text>What are your needs?

http://stackoverflow.com/questions/1890285/are-there-any-existing-solutions-for-creating-a-generic-dna-sequence-database-wit/1893358

I think chado/Apollo is the way to go.</Text>
  </row>
  <row>
    <Id>961</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>523</PostId>
    <RevisionGUID>fb2d89ef-6459-40df-97bc-66f9bfcb53a4</RevisionGUID>
    <CreationDate>2010-03-28T21:47:06.62</CreationDate>
    <IPAddress>70.176.12.226</IPAddress>
    <UserId>194</UserId>
    <Text>http://www.biomedcentral.com/1471-2350/10/6

See if this helps possibly.</Text>
  </row>
  <row>
    <Id>962</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>df87d0a9-8807-409b-991c-bf33e4031fa7</RevisionGUID>
    <CreationDate>2010-03-29T13:59:49.397</CreationDate>
    <IPAddress>144.32.213.51</IPAddress>
    <UserId>197</UserId>
    <Text>I'm having trouble rearranging a DNA sequence. I need to rearrange randomly a given DNA sequence so the G/C content remains the same and so does the A/T content and therefore the length. I can generate random sequences but I cannot rearrange a given sequence randomly.

Any help would be great thanks.
</Text>
  </row>
  <row>
    <Id>963</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>df87d0a9-8807-409b-991c-bf33e4031fa7</RevisionGUID>
    <CreationDate>2010-03-29T13:59:49.397</CreationDate>
    <IPAddress>144.32.213.51</IPAddress>
    <UserId>197</UserId>
    <Text>Rearranging DNA sequences</Text>
  </row>
  <row>
    <Id>964</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>df87d0a9-8807-409b-991c-bf33e4031fa7</RevisionGUID>
    <CreationDate>2010-03-29T13:59:49.397</CreationDate>
    <IPAddress>144.32.213.51</IPAddress>
    <UserId>197</UserId>
    <Text> épythonà  édnaà </Text>
  </row>
  <row>
    <Id>965</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>512</PostId>
    <RevisionGUID>58dc8be2-bc1d-42b8-b1ec-6e27eda5464e</RevisionGUID>
    <CreationDate>2010-03-29T14:06:12.787</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Major content additions</Comment>
    <Text>This situation is rather cumbersome but quite common. Small deletions must be considered, too. There's a growing body of research on triallelic sites. You can check it yourself.

The only methodology I'm aware of is TriTyper described [here][1]. I've checked HapMart. They don't have a simple way to look for triallelic site!!! There are more than a thousand of these already detected in humans.

It's not hard to get the HapMap data and search for them. But, it's strange that it's not a default filter/attribute combination possibility.

Maybe Pierre could give you a tip?

--Edit--

After a somewhat long search for genotype calling, genotype imputation and poly-allelism detection I can conclude with a high degree of confidence: there is no such software. Yes. I was unable to find a software that explicitly treats the problem. Actual detection relies on brute force (i. .e, experimental verification) for which there are a lot of well developed methodologies. But, there are evidences that a large number of SNPs are miscalled right now. So, I do recommend a paper and two reviews about this:

[Genotyping Technologies for Genetic Research][2] - Review

[Genotype imputation][3] - Review

[Human Triallelic Sites: Evidence for a New Mutational Mechanism?][4] - Interesting Paper

At the beginning I thought that locating and naming a SNPs was a simple task. Now I can see that it's much more subtle. I check the SNPs definition. It includes indels too !!! So, genotype calling is a rather unexplored area. Most works just deal with biallelic sites for a given base. 


  [1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2427186/?tool=pubmed
  [2]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev-genom-082908-150116
  [3]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.genom.9.081307.164242
  [4]: http://www.genetics.org/cgi/content/short/184/1/233
</Text>
  </row>
  <row>
    <Id>966</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>525</PostId>
    <RevisionGUID>220696c9-b619-4835-8e39-9198c35dbc6c</RevisionGUID>
    <CreationDate>2010-03-29T14:14:08.153</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi Jess,

You can use [Sean Eddy's Squid][1] lib from Sean Eddy to do this. It's will generate a set of command-line application able to shuffle you sequence in several ways. Additionally, you can use [uShuffle][2] which will do a similar job. Both can shuffle preserving the base counts and preserving n-base (dibase, tribase, etc.) counts too.

  [1]: http://selab.janelia.org/software.html
  [2]: http://digital.cs.usu.edu/~mjiang/ushuffle/</Text>
  </row>
  <row>
    <Id>967</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>511</PostId>
    <RevisionGUID>1c963ef3-5f30-42b4-bbc0-c2f780561870</RevisionGUID>
    <CreationDate>2010-03-29T14:28:58.81</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>*de novo* SNPs with or without reference sequence?</Comment>
    <Text>Today I had a lunchtime discussion with some colleagues about the existence of poly-allelic Single Nucleotide Polymorphisms (SNPs). Quoting Wikipedia to explain what I mean:

&gt; For example, two sequenced DNA
&gt; fragments from different individuals,
&gt; AAGC**C**TA to AAGC**T**TA, contain a
&gt; difference in a single nucleotide. In
&gt; this case we say that there are two
&gt; alleles : C and T. Almost all common
&gt; SNPs have only two alleles.

My point was that there could be some but I don't know any SNPs that have eg. 3 alleles such that there is either e.g. A/G/T, or all 4 bases in a population. If I wish to query a database, say BioMart, UCSC, HapMap for this, how would I do this?

If wanted to detect poly-allelic SNPs from sequencing data (*de novo*) using a reference sequence, which method/program could be used?

Edit: So far this seems to be real great stuff, got at least two different methods of getting the query right! 
But what about *de novo* (sorry, of course a reference sequence can be used, that's not really de novo) detection? Would for example [Maq][1] detect tri-allelic SNPs in short-reads?


  [1]: http://maq.sourceforge.net/</Text>
  </row>
  <row>
    <Id>968</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>526</PostId>
    <RevisionGUID>5cebd629-68fe-4756-8b92-ee79bd266217</RevisionGUID>
    <CreationDate>2010-03-29T14:44:41.87</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Regarding the SNP detection part of my question I just read through the Maq-FAQ.
If there are poly-allelic SNPs in the databases, they must have been detect somehow, and
yes, [Maq][1] can be used to detect poly-allelic SNPs, at least according to the [user manual][2] the call is:

&gt; maq cns2snp consensus.cns &gt;cns.snp

&gt;    Extract list of SNPs

Then following the [FAQ][3]: 

&gt; Consensus Calling
&gt; 
&gt; * What do those "S", "M" and so on mean in the cns2snp output?
&gt; 
&gt;   They are IUB codes for heterozygotes. Briefly:
&gt; 
&gt;     M=A/C, K=G/T, Y=C/T, R=A/G, W=A/T, S=G/C,
&gt;
&gt;     D=A/G/T, B=C/G/T, H=A/C/T, V=A/C/G,
&gt;
&gt;     N=A/C/G/T

I still have to test this on real data but at least in theory this should work and all types of SNPs can be predicted. This does not tell you anything about the validity of the called SNPs though. Should have a look at the papers mentioned by Jarretinha. 




  [1]: http://maq.sourceforge.net/
  [2]: http://maq.sourceforge.net/maq-man.shtml
  [3]: http://maq.sourceforge.net/faq.shtml</Text>
  </row>
  <row>
    <Id>969</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>514</PostId>
    <RevisionGUID>d1700f27-03be-408e-8b98-ff91a9875893</RevisionGUID>
    <CreationDate>2010-03-29T14:45:03.113</CreationDate>
    <IPAddress>82.126.3.249</IPAddress>
    <UserId>30</UserId>
    <Comment>observed==null</Comment>
    <Text>Hum, not sure I understood your question. Do you just want to get a sub-list of all the non classical (di-allelic) snps ?

In a [previous post I described][1] a small piece of code to run a [SAX parser][2] with a javascript analyser. I'll use it here but it could be any SAX implementation.

The following script is used to scan the (big) XML files from **dbSNP**. It records the rs## and the 'non-di-allelic' observed mutations.

    var rs=null;
    var observed=null;
    var content=null;
    var pat=/[ATGC]\/[ATGC]/i;
    function startElement(uri,localName,name,atts)
            {
            if(localName=="Rs" &amp;&amp; observed==null)
                    {
                    rs="rs"+atts.getValue("rsId");
                    }
            else if(localName=="Observed" &amp;&amp; observed==null)
                    {
                    content="";
                    }
            }
    function characters(s)
            {
            if(content!=null) content+=s;
            }
    
    function endElement(uri,localName,name)
            {
            if(localName=="Rs")
                    {
                    if(!observed.match(pat))
                            {
                            println(rs+"\t"+observed);
                            }
                    rs=null;
                    observed=null;
                    }
            else if(observed==null &amp;&amp; localName=="Observed")
                    {
                    observed=content;
                    }
            content=null;
            }


invoking the SAX/js script:

    java -jar saxscript.jar  -f scansnps.js  ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/XML/ds_ch1.xml.gz


result:

    rs242   -/T
    rs1433  -/A
    rs3483  -/ATTT
    rs4179  -/CAGA
    rs6485  -/AAT
    rs7563  -/AA
    rs16354 -/AACCCA
    rs16356 -/ATT
    rs16357 -/TGTGAA
    rs16358 -/ATAA
    rs16359 -/GA
    rs16360 -/TA
    rs16361 -/CT
    rs16439 -/CAGA
    rs16626 -/CGTGAAGTCC
    rs16631 -/TA
    rs16644 -/AAC
    rs16670 -/TTTAA
    rs16679 -/CT
    rs16684 -/CTCTGGC
    rs16686 -/AA
    rs16725 -/ACAAA
    rs16729 -/TCAAT
    rs20418 -/TAG
    rs20421 -/CGG
    rs20431 -/T
    rs25569 -/AC
    rs25571 -/TT
    rs140711        -/AG
    rs140758        -/GAAA
    rs140798        -/TTGT
    rs140838        -/TCGT
    rs140840        -/TT
    rs140841        -/TAACTA
    rs140849        -/GT
    rs140858        -/CT
    rs140861        -/CACT
    rs140862        -/TAAG
    rs140864        -/GAA
    rs140865        -/ACTACATGA
    rs171241        -/C
    rs209574        -/GC
    rs239965        -/T
    rs284043        -/G
    rs301740        -/TCTC
    rs316275        -/T
    rs319679        -/GTAG
    rs332778        -/T
    rs350183        -/A
    rs365861        -/A
    rs366664        -/A
    rs390580        -/CTCTCT
    rs391526        -/T
    rs393900        -/T
    rs398196        -/A
    rs410422        -/TT
    rs420240        -/T
    rs431835        -/AGATAT
    rs435486        -/AAAAA
    rs446074        -/A
    rs446693        -/GA
    rs480306        -/TGG
    rs481407        -/TATT
    rs485475        -/CAACAACAC
    rs486207        -/G
    (....)


hope it helps

  [1]: http://plindenbaum.blogspot.com/2009/06/event-driven-xml-parsing-sax-with.html
  [2]: http://en.wikipedia.org/wiki/Simple_API_for_XML</Text>
  </row>
  <row>
    <Id>970</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>527</PostId>
    <RevisionGUID>fa018736-b91c-43c9-bc19-5ce6fae969fc</RevisionGUID>
    <CreationDate>2010-03-29T15:23:38.24</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>What language are you using?  Here's something in Ruby:


    class Array
      #fisher-yates/knuth shuffle
      def shuffle!
        n = length
        for i in 0...n
          r = Kernel.rand(n-i)+i
          self[r], self[i] = self[i], self[r]
        end
        self
      end
    
      # Return a shuffled copy of the array
      def shuffle
        dup.shuffle!
      end
    end

        
    string = "AAATTTGGGCCC"
    string.split(//).shuffle.join("")   

    &gt; "AACGCTTTCAGG"


As always, there may be a more concise way to do this, but this will get the job done.</Text>
  </row>
  <row>
    <Id>971</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>528</PostId>
    <RevisionGUID>10b631fe-6f65-4574-8b08-21ab1eb05138</RevisionGUID>
    <CreationDate>2010-03-29T16:03:08.213</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>If you fancy doing it in Perl there are three different ways you can try listed here :-

http://perldoc.perl.org/perlfaq4.html#How-do-I-shuffle-an-array-randomly%3f</Text>
  </row>
  <row>
    <Id>972</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>529</PostId>
    <RevisionGUID>a014fb23-1846-40f3-9636-f97c7c1b088d</RevisionGUID>
    <CreationDate>2010-03-29T16:31:51.09</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>here's a function in python that "mutates" the original sequence, maintaining gc, at content.


    import random
        
    def seq_shuffler(original_seq="ACCAACXTGGGGTTTCCGGGGCCCCC"):
        original_seq = list(original_seq)
        while True:
            random.shuffle(original_seq)
            yield "".join(original_seq)
    
    
    random_seq_gen = seq_shuffler()
    print random_seq_gen.next()
    print random_seq_gen.next()
    print random_seq_gen.next()
    print random_seq_gen.next()
    
    # or loop.
    for k in random_seq_gen:
        print k

</Text>
  </row>
  <row>
    <Id>973</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>530</PostId>
    <RevisionGUID>9a63761f-87c1-4db7-8644-8792cdb5d018</RevisionGUID>
    <CreationDate>2010-03-29T23:14:48.393</CreationDate>
    <IPAddress>198.123.49.48</IPAddress>
    <UserId>121</UserId>
    <Text>I'm trying to access Cyanobase through BiomaRt, but failing:

    &gt; cyanobase &lt;- useDataset(dataset="Synechocystis", mart = cyanobase)
    Checking attributes ... ok
    Checking filters ... ok
    
    &gt; attributes &lt;- listAttributes(cyanobase)  # this shows me there is an attribute called "CDS" for example.
    
    &gt; getBM(attribute=("CDS"), mart = cyanobase)
    Error in getBM(attribute = ("CDS"), mart = cyanobase) : 
      Invalid attribute(s): CDS 
    Please use the function 'listAttributes' to get valid attribute names

I have checked the attributes list and CDS is there but I don't know why the getBM function fails to find it.  I tried changing the dataset to another cyanobacteria and it still fails, I've also tried other attributes, but no luck.  I also tried the human example using ensemble in the biomaRt manual and this works fine.  When I change to cyanobase, it fails with this error.  Any ideas?  Thanks.</Text>
  </row>
  <row>
    <Id>974</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>530</PostId>
    <RevisionGUID>9a63761f-87c1-4db7-8644-8792cdb5d018</RevisionGUID>
    <CreationDate>2010-03-29T23:14:48.393</CreationDate>
    <IPAddress>198.123.49.48</IPAddress>
    <UserId>121</UserId>
    <Text>Accessing Cyanobase with the BiomaRt / getBM method</Text>
  </row>
  <row>
    <Id>975</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>530</PostId>
    <RevisionGUID>9a63761f-87c1-4db7-8644-8792cdb5d018</RevisionGUID>
    <CreationDate>2010-03-29T23:14:48.393</CreationDate>
    <IPAddress>198.123.49.48</IPAddress>
    <UserId>121</UserId>
    <Text> écyanobaseà  ébiomartà  érà  égetbmà </Text>
  </row>
  <row>
    <Id>976</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>531</PostId>
    <RevisionGUID>dc1f1fd5-5254-46dd-b100-86dbb42766e2</RevisionGUID>
    <CreationDate>2010-03-30T08:12:03.477</CreationDate>
    <IPAddress>189.114.82.219</IPAddress>
    <UserId>31</UserId>
    <Text>shuffleseq from EMBOSS shuffles a set of sequences maintaining composition.


[http://emboss.sourceforge.net/][1]


  [1]: http://emboss.sourceforge.net/</Text>
  </row>
  <row>
    <Id>977</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>66ef14e0-7d35-40e7-b5a0-bd615a3708de</RevisionGUID>
    <CreationDate>2010-03-30T09:07:27.367</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>edited tags</Comment>
    <Text> épythonà  édnaà  érubyà </Text>
  </row>
  <row>
    <Id>978</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>d323904e-8c38-40df-a15a-467a53297278</RevisionGUID>
    <CreationDate>2010-03-30T09:07:59.643</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>edited tags</Comment>
    <Text> épythonà  édnaà  érubyà  éperlà </Text>
  </row>
  <row>
    <Id>979</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>532</PostId>
    <RevisionGUID>183f3d1a-565a-47b9-8aa0-efedcbd284b1</RevisionGUID>
    <CreationDate>2010-03-30T09:52:47.22</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>OK I got a bit obsessed with doing this in R because I thought you could do it in one line, which you can !! (not including the input that is)

\#input string of choice

a &lt;- 'agcactacgactacgacagcata';

\#shuffle it

paste(sample(unlist(strsplit(a,split=''))),collapse='');</Text>
  </row>
  <row>
    <Id>980</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>532</PostId>
    <RevisionGUID>eeb35ea4-ce15-4e55-a659-10283160eafa</RevisionGUID>
    <CreationDate>2010-03-30T10:56:57.683</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>added 173 characters in body</Comment>
    <Text>OK I got a bit obsessed with doing this in R because I thought you could do it in one line, which you can !! (not including the input that is)

    #input string of choice
    a &lt;- 'agcactacgactacgacagcata';

    #shuffle it
    paste(sample(unlist(strsplit(a,split=''))),collapse='');

and to do this 100 times and print out the answer:-

    for(i in 1:100){
        print(paste(sample(unlist(strsplit(a,split=''))),collapse=''),q=F);
    }</Text>
  </row>
  <row>
    <Id>981</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>524</PostId>
    <RevisionGUID>517597f1-ee6a-4d4d-82ca-af767b142f29</RevisionGUID>
    <CreationDate>2010-03-30T10:57:39.4</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Comment>edited tags</Comment>
    <Text> épythonà  édnaà  érubyà  éperlà  érà </Text>
  </row>
  <row>
    <Id>982</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>533</PostId>
    <RevisionGUID>a3e0c682-d172-4b6c-aa55-da2263677663</RevisionGUID>
    <CreationDate>2010-03-30T11:45:30.553</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Hi John,
you are asking a very "special interest" question without providing even a reproducible code example, I really wonder how someone can assume to get an answer. Where do you find the cyanobase mart? (http://genome.kazusa.or.jp/cyanobase/). I found the site by google but didn't find a link to the mart service, I cannot even see, if such exists. 

Such questions would be better posed to the bioconductor mailing list or the operators of this mart site, including a reproducible example. But in this case it is maybe just a simple R-syntax error so I can help you anyway:

The attributes arg requires a character vector, ("CDS")  is not a character vector, so you just forgot a c("CDS"). Try to replace: 

    getBM(attribute=("CDS"), mart = cyanobase)

by

    getBM(attribute=c("CDS"), mart = cyanobase)

</Text>
  </row>
  <row>
    <Id>983</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>534</PostId>
    <RevisionGUID>e33f5298-e231-484e-af79-0eeffb499778</RevisionGUID>
    <CreationDate>2010-03-30T12:48:23.07</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Hello,

&lt;p&gt;I have a set of murine Affymetrix probes of interest. And I am wondering which ones are related to genes encoding membran proteins.&lt;/p&gt;
&lt;p&gt;My guess is to first link the probes of interest to their genes and then filter these genes with GO terms such as "plasma membrane".&lt;/p&gt;
&lt;p&gt;I was wondering if someone as a better solution that I didn't think about.&lt;/p&gt;
&lt;p&gt;Thanks in advance. Fred&lt;/p&gt;</Text>
  </row>
  <row>
    <Id>984</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>534</PostId>
    <RevisionGUID>e33f5298-e231-484e-af79-0eeffb499778</RevisionGUID>
    <CreationDate>2010-03-30T12:48:23.07</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>How to filter Affymetrix Probes related to murine genes encoding membran proteins</Text>
  </row>
  <row>
    <Id>985</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>534</PostId>
    <RevisionGUID>e33f5298-e231-484e-af79-0eeffb499778</RevisionGUID>
    <CreationDate>2010-03-30T12:48:23.07</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text> éaffymetrixà  égoà  éannotationà  émouseà  égeneà </Text>
  </row>
  <row>
    <Id>986</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>535</PostId>
    <RevisionGUID>dbd3052e-49c4-439b-be42-126d124ec18a</RevisionGUID>
    <CreationDate>2010-03-30T13:01:11.807</CreationDate>
    <IPAddress>195.220.69.253</IPAddress>
    <UserId>199</UserId>
    <Text>Hello,

If you or someone in your neighborhood know R programming, I would consider using biomaRt R package. It could be a straightforward way for such a task.

Cheers

tony</Text>
  </row>
  <row>
    <Id>987</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>536</PostId>
    <RevisionGUID>963ba15a-d6db-4906-b358-b4bcaa2d4cd3</RevisionGUID>
    <CreationDate>2010-03-30T15:06:08.65</CreationDate>
    <IPAddress>130.15.155.54</IPAddress>
    <UserId>128</UserId>
    <Text>I'm looking for a programmatic way to access Ensembl or UCSC's genome browser using something like python or ruby. Perl is just not my thing, sadly.
PyCogent seems to have something that I have not yet tested properly, but just wanted to ping the community before going ahead and coding something that might already exist.

Any ideas?</Text>
  </row>
  <row>
    <Id>988</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>536</PostId>
    <RevisionGUID>963ba15a-d6db-4906-b358-b4bcaa2d4cd3</RevisionGUID>
    <CreationDate>2010-03-30T15:06:08.65</CreationDate>
    <IPAddress>130.15.155.54</IPAddress>
    <UserId>128</UserId>
    <Text>Is there a non-perl alternative to accessing Ensembl's API?</Text>
  </row>
  <row>
    <Id>989</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>536</PostId>
    <RevisionGUID>963ba15a-d6db-4906-b358-b4bcaa2d4cd3</RevisionGUID>
    <CreationDate>2010-03-30T15:06:08.65</CreationDate>
    <IPAddress>130.15.155.54</IPAddress>
    <UserId>128</UserId>
    <Text> éensemblà  épythonà  ébiopythonà  épycogentà  égenomeöbrowserà </Text>
  </row>
  <row>
    <Id>990</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>537</PostId>
    <RevisionGUID>44d13d28-b5e4-4e60-9258-1672aafbbae3</RevisionGUID>
    <CreationDate>2010-03-30T15:40:22.473</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>The two ones I know under current development are PyCogent:

http://pycogent.sourceforge.net/examples/query_ensembl.html

and pygr:

http://github.com/mkszuba/pygr/blob/master/doc/rest/tutorials/ucsc_ensembl.rst

I haven't played with either but both look useful.</Text>
  </row>
  <row>
    <Id>991</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>538</PostId>
    <RevisionGUID>b5b6bd17-e91a-453c-9f38-881d2fe0fa8b</RevisionGUID>
    <CreationDate>2010-03-30T16:11:06.083</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>The answer is provided in [the same topic][1] on StackOverflow.


  [1]: http://stackoverflow.com/questions/2526714/changing-the-x-axis-of-seqlogo-figures-in-matlab/2546567#2546567</Text>
  </row>
  <row>
    <Id>992</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>539</PostId>
    <RevisionGUID>5512d2fe-6ab8-4e3f-8f71-627424b00b1a</RevisionGUID>
    <CreationDate>2010-03-30T17:21:34.593</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>I have been asked to recommend introductory books and resources to R and Bioconductor. My problem is just, I never read a book to learn R or Bioconductor, so I have no experience with this and cannot recommend one. I am interested in mainly introductory books, possibly targeting various groups of readers (computer scientists, molecular biologists, (bio-)statisticians), any recommendation appreciated.  

For example, I used the following resources:

 - The [R-manuals][1], especially [the R intro][2]
 - There are also [a lot of contributed documents there][3] on the R web site, but I didn't 
use.
 - If a package from Bioconductor interests me, I read the package vignette.
 - I read the Bioconductor mailing list, that helps to see what other people use.
 - I have the "[Venebles, Ripley. S Programming][4]" book, that is hardly introductory. 

Which books did you find helpful or completely useless to learn R/Bioconductor? For example: [R Programming for Bioinformatics][5] looks promising, anybody read it?

Or do you share my reluctance towards R-books and prefer online resources?


  [1]: http://cran.r-project.org/manuals.html
  [2]: http://cran.r-project.org/doc/manuals/R-intro.html
  [3]: http://cran.r-project.org/other-docs.html
  [4]: http://www.springer.com/statistics/computanional+statistics/book/978-0-387-98966-2
  [5]: http://www.bioconductor.org/pub/RBioinf/</Text>
  </row>
  <row>
    <Id>993</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>539</PostId>
    <RevisionGUID>5512d2fe-6ab8-4e3f-8f71-627424b00b1a</RevisionGUID>
    <CreationDate>2010-03-30T17:21:34.593</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Recommend your favorite introductory "R in bioinformatics" books and resources</Text>
  </row>
  <row>
    <Id>994</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>539</PostId>
    <RevisionGUID>5512d2fe-6ab8-4e3f-8f71-627424b00b1a</RevisionGUID>
    <CreationDate>2010-03-30T17:21:34.593</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text> érà  ébooksà  ébooköreviewà  ébioconductorà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>995</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>540</PostId>
    <RevisionGUID>832ff8eb-67a7-4549-9ae2-de850ce0b39e</RevisionGUID>
    <CreationDate>2010-03-30T18:10:22.767</CreationDate>
    <IPAddress>80.31.221.199</IPAddress>
    <UserId>23</UserId>
    <Text>In theory, you could try to use the [Ensembl Java APIs][1] with Python throught the Jython interpreter. However, I don't recommend you that, for you sanity.

I follow the pygr's mailing list and they have released a [new tutorial][2] on their Ensembl APIs lately, which means that they are stil developing that part. However, I have never tried that module, when I looked at it one year ago it didn's seem complete yet, I am not sure whether it is complete or not now.


  [1]: http://agd.vital-it.ch/info/software/java/index.html
  [2]: http://github.com/mkszuba/pygr/commit/8cf1c9b2d3d8eb7b0bca929ca46bc9a2a87092fa</Text>
  </row>
  <row>
    <Id>996</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>530</PostId>
    <RevisionGUID>7e767d05-0898-402c-b37d-73566d27e136</RevisionGUID>
    <CreationDate>2010-03-30T18:36:03.357</CreationDate>
    <IPAddress>198.123.49.48</IPAddress>
    <UserId>121</UserId>
    <Comment>edited to make it a (non)working example...</Comment>
    <Text>I'm trying to access Cyanobase through BiomaRt, but failing:

    library(biomaRt)
    cyanobase &lt;- useMart("cyanobase_1",dataset="Synechocystis")
    Checking attributes ... ok
    Checking filters ... ok
    
    &gt; attributes &lt;- listAttributes(cyanobase)  # this shows me there is an attribute called "CDS" for example.
    
    &gt; getBM(attribute=("CDS"), mart = cyanobase)
    Error in getBM(attribute = ("CDS"), mart = cyanobase) : 
      Invalid attribute(s): CDS 
    Please use the function 'listAttributes' to get valid attribute names

I have checked the attributes list and CDS is there but I don't know why the getBM function fails to find it.  I tried changing the dataset to another cyanobacteria and it still fails, I've also tried other attributes, but no luck.  I also tried the human example using ensemble in the biomaRt manual and this works fine.  When I change to cyanobase, it fails with this error.  Any ideas?  Thanks.</Text>
  </row>
  <row>
    <Id>997</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>541</PostId>
    <RevisionGUID>a086be7c-0998-404c-ac7f-1353fd5787d3</RevisionGUID>
    <CreationDate>2010-03-30T18:40:38.663</CreationDate>
    <IPAddress>52.129.8.52</IPAddress>
    <UserId>73</UserId>
    <Text>Theresa Scott's Intro deserves a mention although it can be a bit verbose.

[An Introduction to the
Fundamentals &amp; Functionality of
the R Programming Language][1]

For Bioconductor and short read analysis I would stick with Girke's cookbook which I have found amazingly helpful. I would gladly have paid $100 for access to it.

[HT Sequence Analysis with R and Bioconductor
][2]

Have not read [R in a Nutshell][3] yet but from what I saw in [Baseball Hacks][4] and the initial reviews I have a good feeling about it.

I would avoid R Programming for Bioinformatics as that book is really geared toward package development.

I co-wrote an O'Reilly Short Cut, "Data Mashups in R", that is designed to be a little more fun than some of the scientific stuff out there while still exploring data manipulation in R, using packages, XML, web services, rudimentary plotting, and even some statistics. It costs $5 if you are not a Safari subscriber.

[Data Mashups in R][5]


  [1]: http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TheresaScott/Scott.IntroToR.I.pdf
  [2]: http://manuals.bioinformatics.ucr.edu/home/ht-seq
  [3]: http://oreilly.com/catalog/9780596801717
  [4]: http://oreilly.com/catalog/9780596009427
  [5]: http://oreilly.com/catalog/9780596804787</Text>
  </row>
  <row>
    <Id>998</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>538</PostId>
    <RevisionGUID>f370b2e7-6daa-4007-8858-7d03f1ebff6e</RevisionGUID>
    <CreationDate>2010-03-30T18:59:53.333</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Comment>deleted 6 characters in body</Comment>
    <Text>The answers are provided in [the same topic][1] on StackOverflow.


  [1]: http://stackoverflow.com/questions/2526714/changing-the-x-axis-of-seqlogo-figures-in-matlab/2546567</Text>
  </row>
  <row>
    <Id>999</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>541</PostId>
    <RevisionGUID>0001a539-8049-4ab6-841d-168fee3bd25f</RevisionGUID>
    <CreationDate>2010-03-30T19:11:40.847</CreationDate>
    <IPAddress>52.129.8.52</IPAddress>
    <UserId>73</UserId>
    <Comment>added 15 characters in body</Comment>
    <Text>Theresa Scott's Intro deserves a mention although it can be a bit verbose.

[An Introduction to the
Fundamentals &amp; Functionality of
the R Programming Language][1]

For Bioconductor and short read analysis I would stick with Girke's cookbook which I have found amazingly helpful. I would gladly have paid $100 for access to it.

[HT Sequence Analysis with R and Bioconductor
][2]

Have not read [R in a Nutshell][3] yet but from what I saw in Joseph Adler's [Baseball Hacks][4] and the initial reviews I have a good feeling about it.

I would avoid R Programming for Bioinformatics as that book is really geared toward package development.

I co-wrote an O'Reilly Short Cut, "Data Mashups in R", that is designed to be a little more fun than some of the scientific stuff out there while still exploring data manipulation in R, using packages, XML, web services, rudimentary plotting, and even some statistics. It costs $5 if you are not a Safari subscriber.

[Data Mashups in R][5]


  [1]: http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TheresaScott/Scott.IntroToR.I.pdf
  [2]: http://manuals.bioinformatics.ucr.edu/home/ht-seq
  [3]: http://oreilly.com/catalog/9780596801717
  [4]: http://oreilly.com/catalog/9780596009427
  [5]: http://oreilly.com/catalog/9780596804787</Text>
  </row>
  <row>
    <Id>1000</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>542</PostId>
    <RevisionGUID>aa643a29-6980-41f5-bd33-db3981271903</RevisionGUID>
    <CreationDate>2010-03-30T19:12:27.347</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>I looked into this myself before I resigned myself to using the Perl APIs. I wouldn't be too down on them as they have a lot of functionality (but still depend on BioPerl1.5 !).

You can access the Ensembl database directly through their MySQL server, but building the queries for the very complex schema is very time consuming. I can see them coming under increasing pressure to provide support for other languages (Python certainly would be very popular) but they have a lot of work to do as it is and I think an initiative like that would probably require extra funding.

You can access the MySQL server using the details here http://www.ensembl.org/info/data/mysql.html</Text>
  </row>
  <row>
    <Id>1001</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>543</PostId>
    <RevisionGUID>1641731a-2ad0-4554-b5c2-32b8a11b1e1a</RevisionGUID>
    <CreationDate>2010-03-30T20:02:58.573</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>As Tony suggested you can do this easily in R using biomaRt:-

    library(biomaRt);
    ensembl &lt;- useMart('ensembl',dataset='mmusculus_gene_ensembl');
    #get all genes with affyids just for this example
    affys &lt;- getBM(mart=ensembl,attributes='affy_mg_u74a');
    #just take 100 for this example
    affys &lt;- affys[1:100,]
    #get genes
    affy_genes &lt;-getBM(
         mart=ensembl,attributes=c('mgi_automatic_gene_symbol','mgi_curated_gene_symbol','affy_mg_u74a'),
         filters=c('affy_mg_u74a','go'),
         values=list(affys,'GO:0005886')
    );

This is just an example you should check what attributes and which array set you want to use using the listAttributes() and listFilters() functions. Hope this is useful.</Text>
  </row>
  <row>
    <Id>1002</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>544</PostId>
    <RevisionGUID>1a7f88a3-28a1-4a9b-b279-350c7671dafa</RevisionGUID>
    <CreationDate>2010-03-30T21:28:54.267</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I am working on a pipe-line for scanning human genome regions to identify known enhancers, non-coding genes, TFBS, regulatory regions etc (except coding genes and SNPs). Wondering if something like that exist already ? Any recommendations on programs to include in the pipe line for specific applications like TFBS, regulatory elements etc. I have already tried BioMart and Galaxy, but can't find exactly what am looking for. </Text>
  </row>
  <row>
    <Id>1003</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>544</PostId>
    <RevisionGUID>1a7f88a3-28a1-4a9b-b279-350c7671dafa</RevisionGUID>
    <CreationDate>2010-03-30T21:28:54.267</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Suggestions : Developing a pipe-line for scanning genomic regions to identify known genomic elements</Text>
  </row>
  <row>
    <Id>1004</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>544</PostId>
    <RevisionGUID>1a7f88a3-28a1-4a9b-b279-350c7671dafa</RevisionGUID>
    <CreationDate>2010-03-30T21:28:54.267</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text> éhumanögenomeà  égenomeöanalysisà  épipelineà  éworkflowà </Text>
  </row>
  <row>
    <Id>1005</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>545</PostId>
    <RevisionGUID>e4e6d435-c7d0-4882-bc7a-de7d8b62c782</RevisionGUID>
    <CreationDate>2010-03-30T21:55:30.42</CreationDate>
    <IPAddress>80.31.221.199</IPAddress>
    <UserId>23</UserId>
    <Text>Yes there is something for this already. Have a look at [Vista][1] which you can use to locate Regulatory Sequences and do comparative analysis, or [Transfac][2] for Transcription Factors Binding sites.


  [1]: http://genome.lbl.gov/vista/index.shtml
  [2]: http://www.gene-regulation.com/pub/databases.html</Text>
  </row>
  <row>
    <Id>1006</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>546</PostId>
    <RevisionGUID>e4abea3f-d00b-48ba-ae6d-60d645dbd2a4</RevisionGUID>
    <CreationDate>2010-03-31T03:24:22.4</CreationDate>
    <IPAddress>115.64.15.31</IPAddress>
    <UserId>66</UserId>
    <Text>Jan has written Ruby libraries for both [Ensembl][1] and [UCSC][2] APIs.  Here is his [original blog post][3] on the Ensembl library.

There is certainly a lot of scope for writing libraries.  However, I tend to agree with Ian:  sometimes, when a working tool already exists, it's better to just swallow your disdain and work out how to use it.


  [1]: http://wiki.github.com/jandot/ruby-ensembl-api/
  [2]: http://github.com/jandot/ruby-ucsc-api
  [3]: http://saaientist.blogspot.com/2007/08/ruby-api-to-ensembl-database.html</Text>
  </row>
  <row>
    <Id>1007</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>547</PostId>
    <RevisionGUID>1b747243-a46b-4d31-b0f8-2d76845f3526</RevisionGUID>
    <CreationDate>2010-03-31T05:18:46.227</CreationDate>
    <IPAddress>134.115.89.44</IPAddress>
    <UserId>152</UserId>
    <Text>While the EMBOSS solution is probably the best, if it needs to be incorporated into a script, the Bioruby library gives you the very convenient 'randomize' method:

    require 'bio'
    s = Bio::Sequence::NA.new("ACCAACXTGGGGTTTCCGGGGCCCCC")
    s.randomize         # ==&gt; "tagccggcctxgatcactgcgcgccg"


</Text>
  </row>
  <row>
    <Id>1008</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>548</PostId>
    <RevisionGUID>a88f7aab-c629-4ba4-9d25-33b45dc5530f</RevisionGUID>
    <CreationDate>2010-03-31T06:17:29.973</CreationDate>
    <IPAddress>132.216.96.163</IPAddress>
    <UserId>201</UserId>
    <Text>I'm writing a sociology of science dissertation and am thinking about bioinformatics- it's a flourishing discipline and I have a few questions for anyone who has a couple of minutes for me. Please feel free to answer any or all of these ;)

I'll start out with a couple of simple ones and if anyone answers me hopefully I can post some follow-ups..

1. What degree do you have (i.e. PhD), what year did you get it in, and what discipline was it in? 

2. Would you say that there is a distinction between a numerical and visual science? If so, what is the difference?

3. Are bioinformaticians more keen on 'open science' than scientists in other disciplines? If so, why? 

4. Do biologists need to understand bioinformatics? 

Thanks!
</Text>
  </row>
  <row>
    <Id>1009</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>548</PostId>
    <RevisionGUID>a88f7aab-c629-4ba4-9d25-33b45dc5530f</RevisionGUID>
    <CreationDate>2010-03-31T06:17:29.973</CreationDate>
    <IPAddress>132.216.96.163</IPAddress>
    <UserId>201</UserId>
    <Text>Questions for all bioinformaticians</Text>
  </row>
  <row>
    <Id>1010</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>548</PostId>
    <RevisionGUID>a88f7aab-c629-4ba4-9d25-33b45dc5530f</RevisionGUID>
    <CreationDate>2010-03-31T06:17:29.973</CreationDate>
    <IPAddress>132.216.96.163</IPAddress>
    <UserId>201</UserId>
    <Text> ésociologyofscienceà  ébioinformaticscultureà  égeneralà </Text>
  </row>
  <row>
    <Id>1011</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>549</PostId>
    <RevisionGUID>7d37de17-0e9d-4297-9619-73e295efd2d3</RevisionGUID>
    <CreationDate>2010-03-31T06:24:48.777</CreationDate>
    <IPAddress>193.170.124.186</IPAddress>
    <UserId>136</UserId>
    <Text>1.) I have the equivalent to a Masters degree in bioinformatics, I started 2002

4.) Bioinformaticians need to understand Biologists, not the other way round. Bioinformatics should be the bridge between the totally incompatible worlds of biologists and software engineering. Otherwise the quality of the resulting software is going to be very poor.</Text>
  </row>
  <row>
    <Id>1012</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>550</PostId>
    <RevisionGUID>879ec901-a29b-418c-8b50-cd617299506d</RevisionGUID>
    <CreationDate>2010-03-31T07:06:39.143</CreationDate>
    <IPAddress>134.115.89.44</IPAddress>
    <UserId>152</UserId>
    <Text>On the ABySS-Explorer [project page][1], there are links to two example data sets, a [Human BAC clone assembly][2] and an [E.coli genome assembly][3].

The files that you need from your assembly are the adjacency file (**.adj**), the contigs (**.fasta**) and the distance file (**.dist**). 

These files need to be in the same directory, and it's easiest to simply open them where they lie in the assembly folder.


  [1]: http://www.bcgsc.ca/platform/bioinfo/software/abyss-explorer
  [2]: http://www.bcgsc.ca/downloads/abyss-explorer/data/humanBAC_abyss-1.1.2.zip
  [3]: http://www.bcgsc.ca/downloads/abyss-explorer/data/ecoli_abyss-1.1.2.zip</Text>
  </row>
  <row>
    <Id>1013</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>551</PostId>
    <RevisionGUID>e93ad60a-2fb6-4b03-bb78-3b4365656abd</RevisionGUID>
    <CreationDate>2010-03-31T08:53:51.393</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>Hello everybody,

I need an advice concerning the reconstruction of haplotypes from the genotypes on SNPs for different sets of individuals.
Here is the situation:

I am using fastPHASE.
I have 2 different levels of analysis:
- first level, the global level: looking at a set of 940 individuals
- second level, the regional level: looking at subsets of these 940 individuals. Then I have 100 individuals for Africa, 64 for AMerica and so on.

I have filtered the SNPs for MAF&gt;=0.05 and known genotype for &gt;= 90% of the individuals for each region and for the global level (giving different subsets of SNPs). So I am wondering if I have to run fastPHASE for each region or if, for each region I can extract from the phased data obtained for the Global, the haplotypes for my sub sets of SNPs and individuals. This is possible because intrinsically at the Global level the subset of SNPs does contain all the SNPs from each subset for each population.

Since fastPHASE is very time-demanding, extracting from the phased data obtained for the Global level will allow me to save A LOT OF TIME: I wouldn't run fastPHASE for the 7 regions.
On the other hand I guess that fastPHASE do not run the same way if we have intermediate SNPs (extracting form phased haplotypes obtained at the Global level) and if not (running fastPHASE for each region). How important will you expect the difference to be?
 
I do not know if it is clear enough and if you have a defenitive answer for this.
Anyway thanks for your help!

cheers
Pierre</Text>
  </row>
  <row>
    <Id>1014</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>551</PostId>
    <RevisionGUID>e93ad60a-2fb6-4b03-bb78-3b4365656abd</RevisionGUID>
    <CreationDate>2010-03-31T08:53:51.393</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>reconstruction of haplotypes from the genotypes on SNPs</Text>
  </row>
  <row>
    <Id>1015</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>551</PostId>
    <RevisionGUID>e93ad60a-2fb6-4b03-bb78-3b4365656abd</RevisionGUID>
    <CreationDate>2010-03-31T08:53:51.393</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text> éreconstructionà  éofà  éhaplotypesà  éhgdpà  éfastphaseà </Text>
  </row>
  <row>
    <Id>1016</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>552</PostId>
    <RevisionGUID>77e0aab1-ee98-4fe2-af81-bb1ec433ef78</RevisionGUID>
    <CreationDate>2010-03-31T08:54:56.113</CreationDate>
    <IPAddress>92.241.194.193</IPAddress>
    <UserId>71</UserId>
    <Text>You might [this paper][1] on [Cyrrile2][2] interesting, describing a pipelining environment for genome annotation.


  [1]: http://www.biomedcentral.com/1471-2105/9/96
  [2]: http://www.ab.wur.nl/Cyrille2</Text>
  </row>
  <row>
    <Id>1017</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>553</PostId>
    <RevisionGUID>c38ecb94-7e17-467e-bc3a-04d160129663</RevisionGUID>
    <CreationDate>2010-03-31T08:57:15.693</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>88</UserId>
    <Text>A comment, not answering your question but which may help a lot people using R:
If you are very annoyed that it is impossible to make a google search for R, use 
rseek.org. It is basicly R-specific google.
 </Text>
  </row>
  <row>
    <Id>1018</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>526</PostId>
    <RevisionGUID>f764e7f6-6de5-45c9-938d-d5daffd98244</RevisionGUID>
    <CreationDate>2010-03-31T09:33:32.507</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 1538 characters in body</Comment>
    <Text>Regarding the SNP detection part of my question I just read through the Maq-FAQ.
If there are poly-allelic SNPs in the databases, they must have been detect somehow, and
yes, [Maq][1] can be used to detect poly-allelic SNPs, at least according to the [user manual][2] the call is:

&gt; maq cns2snp consensus.cns &gt;cns.snp

&gt;    Extract list of SNPs

Then following the [FAQ][3]: 

&gt; Consensus Calling
&gt; 
&gt; * What do those "S", "M" and so on mean in the cns2snp output?
&gt; 
&gt;   They are IUB codes for heterozygotes. Briefly:
&gt; 
&gt;     M=A/C, K=G/T, Y=C/T, R=A/G, W=A/T, S=G/C,
&gt;
&gt;     D=A/G/T, B=C/G/T, H=A/C/T, V=A/C/G,
&gt;
&gt;     N=A/C/G/T

I still have to test this on real data but at least in theory this should work and all types of SNPs can be predicted. This does not tell you anything about the validity of the called SNPs though. Should have a look at the papers mentioned by Jarretinha. 

## Edit: SNP-detection ##

Did some more reading/thinking to get this right.
In principle polymorphism are studied by taking samples from members of (possibly multiple) populations
(see e.g.: [NCBI SNP primer][4], [HapMap, Nature (2005)][5]). If a second allele for a genomic position is prevalent in a significant (however this is defined, e.g. there was a &gt;=1% criterium) part of the population, then it becomes a SNP. If a third or fourth allele is discovered at the same locus and meeting the detection criteria and is submitted, then this becomes what we find in the databases given the searches above.

To detect *point mutations* from a single sample by high-throughput sequencing is rather new and something very different. 
Can this be called a SNP? Not immediately, because the prevalence in a population is not assessed. As Jarretinha stated, the number of point mutations depends on the ploidy of the organism. For human somatic cells (diploid) there at most two different alleles possible in the consensus sequence (found by Maq) if the marker is heterozygous (e.g. A/C). If the reference is different at that point, that might give rise to (e.g. T/A/C) that there exist are more than three alleles.

If the sample has higher ploidy, or of course due to sequencing/alignment errors, then more than more heterozygotes can be in the consensus, and that is why aligners support this.


  [1]: http://maq.sourceforge.net/
  [2]: http://maq.sourceforge.net/maq-man.shtml
  [3]: http://maq.sourceforge.net/faq.shtml
  [4]: http://www.ncbi.nlm.nih.gov/About/primer/snps.html
  [5]: http://www.nature.com/nature/journal/v437/n7063/abs/nature04226.html</Text>
  </row>
  <row>
    <Id>1019</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>554</PostId>
    <RevisionGUID>c2023db2-0f51-4347-a6bd-aa925d075c4a</RevisionGUID>
    <CreationDate>2010-03-31T09:56:57.827</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>This one seems also good:

- http://www.conference-service.com/conferences/index.html</Text>
  </row>
  <row>
    <Id>1020</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>551</PostId>
    <RevisionGUID>df13a95a-f1b0-4272-9abe-f79998b1f13d</RevisionGUID>
    <CreationDate>2010-03-31T10:29:52.427</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éreconstructionöoföhaplotyà  éhaplotypesà  éhgdpà  éfastphaseà </Text>
  </row>
  <row>
    <Id>1021</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>551</PostId>
    <RevisionGUID>01da5f92-550c-46d8-bfeb-0d998b3db6c0</RevisionGUID>
    <CreationDate>2010-03-31T10:30:24.047</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éhaplotypeöreconstructionà  éhaplotypesà  égenotypesà  éfastphaseà </Text>
  </row>
  <row>
    <Id>1022</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>526</PostId>
    <RevisionGUID>0f255113-3c3e-446c-bb18-ea40073f5d55</RevisionGUID>
    <CreationDate>2010-03-31T10:53:31.583</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 40 characters in body</Comment>
    <Text>Regarding the SNP detection part of my question I just read through the Maq-FAQ.
If there are poly-allelic SNPs in the databases, they must have been detect somehow, and
yes, [Maq][1] can be used to detect poly-allelic SNPs, at least according to the [user manual][2] the call is:

&gt; maq cns2snp consensus.cns &gt;cns.snp

&gt;    Extract list of SNPs

Then following the [FAQ][3]: 

&gt; Consensus Calling
&gt; 
&gt; * What do those "S", "M" and so on mean in the cns2snp output?
&gt; 
&gt;   They are IUB codes for heterozygotes. Briefly:
&gt; 
&gt;     M=A/C, K=G/T, Y=C/T, R=A/G, W=A/T, S=G/C,
&gt;
&gt;     D=A/G/T, B=C/G/T, H=A/C/T, V=A/C/G,
&gt;
&gt;     N=A/C/G/T

I still have to test this on real data but at least in theory this should work and all types of SNPs can be predicted. This does not tell you anything about the validity of the called SNPs though. Should have a look at the papers mentioned by Jarretinha. 

## Edit: SNP-detection ##

Did some more reading/thinking to get this right.
In principle polymorphism are studied by taking samples from members of (possibly multiple) populations
(see e.g.: [NCBI SNP primer][4], [HapMap, Nature (2005)][5]). If a second allele for a genomic position is prevalent in a significant (however this is defined, e.g. there was a &gt;=1% criterium) part of the population, then it becomes a SNP. If a third or fourth allele is discovered at the same locus and meeting the detection criteria and is submitted, then this becomes what we find in the databases given the searches above.

To detect *point mutations* from a single sample by high-throughput sequencing is rather new and something very different. 
Can this be called a SNP? Not immediately, because the prevalence in a population is not assessed. As Jarretinha stated, the number of point mutations that can be found for a single position depends on the ploidy of the organism. For human somatic cells (diploid) there at most two different alleles possible in the consensus sequence (found by Maq) if the marker is heterozygous (e.g. A/C). If the reference is different at that point, that might give rise to (e.g. T/A/C) that there exist are more than three alleles.

If the sample has higher ploidy, or of course due to sequencing/alignment errors, then more than more heterozygotes can be in the consensus, and that is why aligners support this.


  [1]: http://maq.sourceforge.net/
  [2]: http://maq.sourceforge.net/maq-man.shtml
  [3]: http://maq.sourceforge.net/faq.shtml
  [4]: http://www.ncbi.nlm.nih.gov/About/primer/snps.html
  [5]: http://www.nature.com/nature/journal/v437/n7063/abs/nature04226.html</Text>
  </row>
  <row>
    <Id>1023</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>555</PostId>
    <RevisionGUID>73f34065-fd42-4163-abc4-120fc4860f7a</RevisionGUID>
    <CreationDate>2010-03-31T12:13:40.547</CreationDate>
    <IPAddress>82.39.177.33</IPAddress>
    <UserId>59</UserId>
    <Text>You could also, once you have found a method to translate your identifiers, look for matches with genes that exist within existing membrane protein databases.

A quick Google suggests that a couple exist and are up to date, I'm sure the NAR database issue would supply half a dozen more.

PTBTM: [http://pdbtm.enzim.hu/][1]

MPDB: [http://www.mpdb.tcd.ie/][2]

The former at least offers downloads (the latter does not appear to) which would facilitate bringing the data into whatever package you're using for your array analysis.

I'd be interested to see how the GO term approach intersects with this one.

  [1]: http://pdbtm.enzim.hu/
  [2]: http://www.mpdb.tcd.ie/</Text>
  </row>
  <row>
    <Id>1024</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>556</PostId>
    <RevisionGUID>49000849-062f-4421-a321-87b587035a5f</RevisionGUID>
    <CreationDate>2010-03-31T13:30:16.803</CreationDate>
    <IPAddress>81.48.218.55</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
I'm playing with the anonymous mysql server for ENSEMBL

    mysql -h ensembldb.ensembl.org --port 5306  -u anonymous -D homo_sapiens_core_57_37b

and I'm trying to do some reverse engineering to see how the tables are linked (I've generated a [DOT file mapping the foreign keys][1]). I'm playing with '*my*' protein *ROXAN* ( http://www.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000100403 )

I can get the record in the **gene** table for this protein:

    mysql&gt; select * from gene_stable_id as GSI,gene as G
           where GSI.stable_id ="ENSG00000100403" and
           G.gene_id=GSI.gene_id\G
    *************************** 1. row ***************************
                    gene_id: 55916
                  stable_id: ENSG00000100403
                    version: 9
               created_date: 2008-04-29 11:17:41
              modified_date: 2009-08-05 14:27:16
                    gene_id: 55916
                    biotype: protein_coding
                analysis_id: 8047
              seq_region_id: 27510
           seq_region_start: 41697526
             seq_region_end: 41756151
          seq_region_strand: 1
            display_xref_id: 16961747
                     source: ensembl
                     status: KNOWN
                description: zinc finger CCCH-type containing 7B [Source:HGNC Symbol;Acc:30869]
                 is_current: 1
    canonical_transcript_id: 146331
       canonical_annotation: NULL
    1 row in set (0.07 sec)

I can also retrieve  5 records in **XREF** for the keyword "**ROXAN**".

    mysql&gt; select * from external_synonym as S,
           xref as X ,
           external_db as D
           where D.external_db_id=X.external_db_id and
           S.synonym="ROXAN"
           and X.xref_id=S.xref_id \G
    *************************** 1. row ***************************
                   xref_id: 298451
                   synonym: RoXaN
                   xref_id: 298451
            external_db_id: 2310
             dbprimary_acc: OTTHUMT00000337751
             display_label: OTTHUMT00000337751
                   version: 2
               description: NULL
                 info_type: NULL
                 info_text: NULL
            external_db_id: 2310
                   db_name: Vega_transcript
                db_release: 1
                    status: KNOWNXREF
    dbprimary_acc_linkable: 1
    display_label_linkable: 0
                  priority: 5
           db_display_name: Vega transcript
                      type: MISC
         secondary_db_name: NULL
        secondary_db_table: NULL
               description: NULL
    *************************** 2. row ***************************
                   xref_id: 16506778
                   synonym: RoXaN
                   xref_id: 16506778
            external_db_id: 1100
             dbprimary_acc: 30869
             display_label: ZC3H7B
                   version: 0
               description: zinc finger CCCH-type containing 7B
                 info_type: DIRECT
                 info_text: Generated via havana
            external_db_id: 1100
                   db_name: HGNC
                db_release: 1
                    status: KNOWNXREF
    dbprimary_acc_linkable: 1
    display_label_linkable: 1
                  priority: 100
           db_display_name: HGNC Symbol
                      type: PRIMARY_DB_SYNONYM
         secondary_db_name: NULL
        secondary_db_table: NULL
               description: NULL
    *************************** 3. row ***************************
                   xref_id: 15396769
                   synonym: RoXaN
                   xref_id: 15396769
            external_db_id: 1300
             dbprimary_acc: 23264
             display_label: ZC3H7B
                   version: 0
               description: zinc finger CCCH-type containing 7B
                 info_type: DEPENDENT
                 info_text: NULL
            external_db_id: 1300
                   db_name: EntrezGene
                db_release: 1
                    status: KNOWNXREF
    dbprimary_acc_linkable: 1
    display_label_linkable: 0
                  priority: 10
           db_display_name: EntrezGene
                      type: MISC
         secondary_db_name: NULL
        secondary_db_table: NULL
               description: NULL
    *************************** 4. row ***************************
                   xref_id: 16966653
                   synonym: RoXaN
                   xref_id: 16966653
            external_db_id: 12405
             dbprimary_acc: MPRIP-205
             display_label: MPRIP-205
                   version: 0
               description: NULL
                 info_type: MISC
                 info_text: via havana
            external_db_id: 12405
                   db_name: HGNC_automatic_transcript
                db_release: 1
                    status: KNOWNXREF
    dbprimary_acc_linkable: 1
    display_label_linkable: 0
                  priority: 5
           db_display_name: HGNC (automatic)
                      type: MISC
         secondary_db_name: NULL
        secondary_db_table: NULL
               description: NULL
    *************************** 5. row ***************************
                   xref_id: 16961747
                   synonym: RoXaN
                   xref_id: 16961747
            external_db_id: 12300
             dbprimary_acc: 30869
             display_label: ZC3H7B
                   version: 0
               description: NULL
                 info_type: MISC
                 info_text: via havana
            external_db_id: 12300
                   db_name: HGNC_curated_gene
                db_release: 1
                    status: KNOWNXREF
    dbprimary_acc_linkable: 1
    display_label_linkable: 0
                  priority: 5
           db_display_name: HGNC (curated)
                      type: MISC
         secondary_db_name: NULL
        secondary_db_table: NULL
               description: NULL
    5 rows in set (0.17 sec)

I wish I could find the **gene(s)** from the keyword *ROXAN*.

OK, here I got 5 'xref' records and I know that **gene** is linked to **xref** via gene.display_xref_id=xref.xref_id . Xref can also have links to some other db (e.g. **transcript**), so I guess there is something in xref, something like a flag, telling that 'this' **xref** record is pointing to **gene**.


Is it true ? What is that flag ?

Thanks

Pierre
  [1]: http://gist.github.com/349662</Text>
  </row>
  <row>
    <Id>1025</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>556</PostId>
    <RevisionGUID>49000849-062f-4421-a321-87b587035a5f</RevisionGUID>
    <CreationDate>2010-03-31T13:30:16.803</CreationDate>
    <IPAddress>81.48.218.55</IPAddress>
    <UserId>30</UserId>
    <Text>Playing with mysql/Ensembl (I): mapping 'gene' to 'xref'</Text>
  </row>
  <row>
    <Id>1026</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>556</PostId>
    <RevisionGUID>49000849-062f-4421-a321-87b587035a5f</RevisionGUID>
    <CreationDate>2010-03-31T13:30:16.803</CreationDate>
    <IPAddress>81.48.218.55</IPAddress>
    <UserId>30</UserId>
    <Text> éensemblà  ésqlà  émysqlà  éschemaà </Text>
  </row>
  <row>
    <Id>1027</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>557</PostId>
    <RevisionGUID>185c8bec-4461-43ca-a1f4-09ea72fea9bd</RevisionGUID>
    <CreationDate>2010-03-31T15:22:50.37</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>You have a line there that reads:

    db_name: HGNC_curated_gene

Maybe the information of interest is represented by the database name.</Text>
  </row>
  <row>
    <Id>1028</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>558</PostId>
    <RevisionGUID>03af434d-a376-49a2-afd1-0a43fe110cc3</RevisionGUID>
    <CreationDate>2010-03-31T15:41:09.587</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>You have the HUGO gene name in display_label field.
If you want to show also Ensembl id, you can connect both queries with

    ... and X.xref_id = G.display_xref_id

I suppose stable id corresponds to gene in HGNC_curated_gene external db.
</Text>
  </row>
  <row>
    <Id>1029</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>559</PostId>
    <RevisionGUID>657439f0-9d47-48b1-9cc2-90a2e8e8e842</RevisionGUID>
    <CreationDate>2010-03-31T17:22:42.62</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>I thought it would be useful to summarize all the Google Summer of Code Project related to bioinformatics this year. The limit for the student to apply is from March 29th to April 9th, so if you are a master student with free time on this summer you should better have a look at the projects soon.

Useful links: 

- http://code.google.com/soc/
- http://www.genomeweb.com/blog/one-crazy-summer-google-code 
</Text>
  </row>
  <row>
    <Id>1030</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>559</PostId>
    <RevisionGUID>657439f0-9d47-48b1-9cc2-90a2e8e8e842</RevisionGUID>
    <CreationDate>2010-03-31T17:22:42.62</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text>Which google summer of code projects are available for bioinformatics in 2010?</Text>
  </row>
  <row>
    <Id>1031</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>559</PostId>
    <RevisionGUID>657439f0-9d47-48b1-9cc2-90a2e8e8e842</RevisionGUID>
    <CreationDate>2010-03-31T17:22:42.62</CreationDate>
    <IPAddress>193.145.46.52</IPAddress>
    <UserId>23</UserId>
    <Text> éprojectà  égsocà  écollegeöresearchöprojectà  éstudentà </Text>
  </row>
  <row>
    <Id>1032</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>560</PostId>
    <RevisionGUID>72d92016-35dc-4b60-b797-b72b2695cf07</RevisionGUID>
    <CreationDate>2010-03-31T18:27:49.097</CreationDate>
    <IPAddress>78.86.219.16</IPAddress>
    <UserId>38</UserId>
    <Text>BioPython GSoC projects: http://www.biopython.org/wiki/Google_Summer_of_Code</Text>
  </row>
  <row>
    <Id>1033</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>494</PostId>
    <RevisionGUID>51c57fe3-0f94-4f1a-89ee-d8d347c52185</RevisionGUID>
    <CreationDate>2010-03-31T18:47:39.643</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>Trying to save the question</Comment>
    <Text>It's a simple &amp; straight questions. Just think about an app that when you found it, you first thought would be - "OMG!!! That's it" - or smth like - "I wish I could have found/written/idealized it before". Don't need to be a bioinformatical swiss knife or a McGuyver paper clip. Just smth that would make your life much happier/easier.

My example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (population genetics rlz!) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. That's what I really miss, right now. What's your story?

-- Edit --

I'm considering to start a bounty for this question. Maybe the first answer to get 10 up votes. Where are people's whishes? Don't be afraid, bionformaticians like me are lousy critics.</Text>
  </row>
  <row>
    <Id>1034</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>512</PostId>
    <RevisionGUID>493fb948-3a44-4013-9d3e-21e4938da98f</RevisionGUID>
    <CreationDate>2010-03-31T19:00:53.313</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 263 characters in body</Comment>
    <Text>This situation is rather cumbersome but quite common. Small deletions must be considered, too. There's a growing body of research on triallelic sites. You can check it yourself.

The only methodology I'm aware of is TriTyper described [here][1]. I've checked HapMart. They don't have a simple way to look for triallelic site!!! There are more than a thousand of these already detected in humans.

It's not hard to get the HapMap data and search for them. But, it's strange that it's not a default filter/attribute combination possibility.

Maybe Pierre could give you a tip?

--Edit--

After a somewhat long search for genotype calling, genotype imputation and poly-allelism detection I can conclude with a high degree of confidence: there is no such software. Yes. I was unable to find a software that explicitly treats the problem. Actual detection relies on brute force (i. .e, experimental verification) for which there are a lot of well developed methodologies. But, there are evidences that a large number of SNPs are miscalled right now. So, I do recommend a paper and two reviews about this:

[Genotyping Technologies for Genetic Research][2] - Review

[Genotype imputation][3] - Review

[Human Triallelic Sites: Evidence for a New Mutational Mechanism?][4] - Interesting Paper

At the beginning I thought that locating and naming a SNPs was a simple task. Now I can see that it's much more subtle. I check the SNPs definition. It includes indels too !!! So, genotype calling is a rather unexplored area. Most works just deal with biallelic sites for a given base. 

-- Edit --

After researching little bit more I've stumble upon more software problems. All programs/algoritms/equations to estimate population genetics parameters (N_e, LD, recombination rate, etc) from SNPs data also assume biallelic loci with no indels. 


  [1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2427186/?tool=pubmed
  [2]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev-genom-082908-150116
  [3]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.genom.9.081307.164242
  [4]: http://www.genetics.org/cgi/content/short/184/1/233
</Text>
  </row>
  <row>
    <Id>1035</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>561</PostId>
    <RevisionGUID>f1c97f88-5c3f-4a6b-b1b2-34e91af1bd4d</RevisionGUID>
    <CreationDate>2010-03-31T19:23:37.117</CreationDate>
    <IPAddress>82.126.5.212</IPAddress>
    <UserId>30</UserId>
    <Text>OK, [got an answer][1] from [Jan Aerts][2] on the ensembl mailing list:


&gt; The object_xref table is what you're
&gt; looking for. This table makes the
&gt; connection from the xref table to one
&gt; of the following other tables: gene,
&gt; transcript and translation. Example
&gt; rows:

    
    mysql&gt; select * from object_xref limit 2;
    +----------------+------------+---------------------+----------+--------------------+-------------+
    | object_xref_id | ensembl_id | ensembl_object_type | xref_id  | linkage_annotation | analysis_id |
    +----------------+------------+---------------------+----------+--------------------+-------------+
    |       12799800 |     192551 | Transcript          | 11798151 | NULL               |        NULL |
    |       12799799 |     192551 | Transcript          | 11798150 | NULL               |        NULL |
    +----------------+------------+---------------------+----------+--------------------+-------------+
    2 rows in set (0.14 sec)
    

&gt;     Hope this helps,
&gt;     jan.


  [1]: http://listserver.ebi.ac.uk/mailing-lists-archives/ensembl-dev/msg05863.html
  [2]: http://saaientist.blogspot.com/</Text>
  </row>
  <row>
    <Id>1036</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>562</PostId>
    <RevisionGUID>319ffe37-b59d-4d59-ae90-321adce540d0</RevisionGUID>
    <CreationDate>2010-03-31T20:42:05.913</CreationDate>
    <IPAddress>92.241.193.22</IPAddress>
    <UserId>71</UserId>
    <Text> 1. [GenMAPP, Cytoscape, WikiPathways &amp; Reactome][1]
 2. [Marine Biological Laboratory Biodiversity Informatics Group-Encyclopedia of Life Project][2]
 3. [NESCent - National Evolutionary Synthesis Center][3]
 4. [OMII-UK][4] (Includes [Taverna][5])
 5. [Open Bioinformatics Foundation][6]
 6. [OpenMRS][7]


  [1]: http://socrates2.cgl.ucsf.edu/GenMAPP/wiki/Google_Summer_of_Code_2010
  [2]: http://wiki.eol.org/pages/viewpage.action?pageId=4457203
  [3]: http://hackathon.nescent.org/Phyloinformatics_Summer_of_Code_2010
  [4]: http://www.omii.ac.uk/wiki/GoogleSummerOfCode#section-GoogleSummerOfCode-2010ProjectIdeas
  [5]: http://taverna.sf.net/
  [6]: http://open-bio.org/wiki/Google_Summer_of_Code
  [7]: http://openmrs.org/wiki/Summer_of_Code_2010</Text>
  </row>
  <row>
    <Id>1037</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>562</PostId>
    <RevisionGUID>9b835bce-e9da-4d54-a9ad-c6cfa5172daf</RevisionGUID>
    <CreationDate>2010-03-31T20:49:04.107</CreationDate>
    <IPAddress>92.241.193.22</IPAddress>
    <UserId>71</UserId>
    <Comment>added 77 characters in body</Comment>
    <Text> 1. [GenMAPP, Cytoscape, WikiPathways &amp; Reactome][1]
 2. [Marine Biological Laboratory Biodiversity Informatics Group-Encyclopedia of Life Project][2]
 3. [NESCent - National Evolutionary Synthesis Center][3]
 4. [OMII-UK][4] (Includes [Taverna][5])
 5. [Open Bioinformatics Foundation][6]
 6. [OpenMRS][7]

From http://socghop.appspot.com/gsoc/program/accepted_orgs/google/gsoc2010.

  [1]: http://socrates2.cgl.ucsf.edu/GenMAPP/wiki/Google_Summer_of_Code_2010
  [2]: http://wiki.eol.org/pages/viewpage.action?pageId=4457203
  [3]: http://hackathon.nescent.org/Phyloinformatics_Summer_of_Code_2010
  [4]: http://www.omii.ac.uk/wiki/GoogleSummerOfCode#section-GoogleSummerOfCode-2010ProjectIdeas
  [5]: http://taverna.sf.net/
  [6]: http://open-bio.org/wiki/Google_Summer_of_Code
  [7]: http://openmrs.org/wiki/Summer_of_Code_2010</Text>
  </row>
  <row>
    <Id>1038</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>328</PostId>
    <RevisionGUID>1b8d1a85-c49b-4b1f-898f-a0d4770b4547</RevisionGUID>
    <CreationDate>2010-04-01T14:02:04.96</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 160 characters in body</Comment>
    <Text>Greetings everybody,

We're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7] (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:

[CLCbio Cube][1]

[TimeLogic DeCypher][2]

[Pico Computing E-FPGA][3]


For the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:

[Field Programmable Gate Array][4]
[Reconfigurable Computing][5]

There are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:

[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]


Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?


Cheers,
Daniel

-- Edit --

Finally, my server is online!!! For now it's just some Xeons with lots of RAM. But, in a near future some Tesla/Fermi will be added. Happy !!!


  [1]: http://www.clcbio.com/index.php?id=616
  [2]: http://www.timelogic.com/decypher_intro.html
  [3]: http://www.picocomputing.com/e_series.html
  [4]: http://en.wikipedia.org/wiki/Fpga
  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing
  [6]: http://www.biomedcentral.com/1471-2105/8/185
  [7]: http://www.hcnet.usp.br/</Text>
  </row>
  <row>
    <Id>1039</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>563</PostId>
    <RevisionGUID>493a0958-9a1f-4cdf-832f-91260eb8f808</RevisionGUID>
    <CreationDate>2010-04-01T14:17:17.223</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi everyone, 

Returning to the hardware series of my bionformatics life, I do wish to know what people manage to do with their PCI slots. Nowadays, most server mobos come with an astonishing number of PCI slots in a wide range of configurations/versions. So, the balance between versatility and adequacy can be complicated to attain.

In my case, I normally choose adequacy over versatility, i. e., mobos with PCI slots that I will certainly use (in the almost present time). But, it's quite common to see clusters/servers with many unused PCI slots. Other kinds of slots share the same situation. 

So, what do you do with your PCI slots?</Text>
  </row>
  <row>
    <Id>1040</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>563</PostId>
    <RevisionGUID>493a0958-9a1f-4cdf-832f-91260eb8f808</RevisionGUID>
    <CreationDate>2010-04-01T14:17:17.223</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>What do you do with your PCI slots?</Text>
  </row>
  <row>
    <Id>1041</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>563</PostId>
    <RevisionGUID>493a0958-9a1f-4cdf-832f-91260eb8f808</RevisionGUID>
    <CreationDate>2010-04-01T14:17:17.223</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> éhardwareà  épcià  éconfigurationà </Text>
  </row>
  <row>
    <Id>1042</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>564</PostId>
    <RevisionGUID>dbdb356e-42f6-4d67-a502-e15d4289ccb1</RevisionGUID>
    <CreationDate>2010-04-01T14:17:38.9</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Here http://bit.ly/9CLset is the last review about various nextgen assemblers. 

If you plan on using Sanger sequencing and want to do some test runs then you may get real sequencing data including SCF files from: 
http://bit.ly/bkQCFG

Get some data for several species, run phrap or cap3 on them. To do this in GUI, use Staden or Consed. Keep in mind this route is close to being a thing of the past. 

</Text>
  </row>
  <row>
    <Id>1043</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>512</PostId>
    <RevisionGUID>e1b13acd-7366-4781-bcf5-dd65b7783ed0</RevisionGUID>
    <CreationDate>2010-04-01T16:39:42.093</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 260 characters in body</Comment>
    <Text>This situation is rather cumbersome but quite common. Small deletions must be considered, too. There's a growing body of research on triallelic sites. You can check it yourself.

The only methodology I'm aware of is TriTyper described [here][1]. I've checked HapMart. They don't have a simple way to look for triallelic site!!! There are more than a thousand of these already detected in humans.

It's not hard to get the HapMap data and search for them. But, it's strange that it's not a default filter/attribute combination possibility.

Maybe Pierre could give you a tip?

--Edit--

After a somewhat long search for genotype calling, genotype imputation and poly-allelism detection I can conclude with a high degree of confidence: there is no such software. Yes. I was unable to find a software that explicitly treats the problem. Actual detection relies on brute force (i. .e, experimental verification) for which there are a lot of well developed methodologies. But, there are evidences that a large number of SNPs are miscalled right now. So, I do recommend a paper and two reviews about this:

[Genotyping Technologies for Genetic Research][2] - Review

[Genotype imputation][3] - Review

[Human Triallelic Sites: Evidence for a New Mutational Mechanism?][4] - Interesting Paper

At the beginning I thought that locating and naming a SNPs was a simple task. Now I can see that it's much more subtle. I check the SNPs definition. It includes indels too !!! So, genotype calling is a rather unexplored area. Most works just deal with biallelic sites for a given base. 

-- Edit --

After researching little bit more I've stumble upon more software problems. All programs/algoritms/equations to estimate population genetics parameters (N_e, LD, recombination rate, etc) from SNPs data also assume biallelic loci with no indels. 

-- Edit --

A paper with a partial solution.

[Accurate detection and genotyping of SNPs utilizing population sequencing data][5]

But, there is still more to it. I'm thinking about the problem.


  [1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2427186/?tool=pubmed
  [2]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev-genom-082908-150116
  [3]: http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.genom.9.081307.164242
  [4]: http://www.genetics.org/cgi/content/short/184/1/233
  [5]: http://genome.cshlp.org/content/20/4/537.abstract</Text>
  </row>
  <row>
    <Id>1044</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>563</PostId>
    <RevisionGUID>4b739e79-5796-4953-9c39-86a28bc68b96</RevisionGUID>
    <CreationDate>2010-04-01T17:08:16.03</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 98 characters in body</Comment>
    <Text>Hi everyone, 

Returning to the hardware series of my bionformatics life, I do wish to know what people manage to do with their PCI slots. Nowadays, most server mobos come with an astonishing number of PCI slots in a wide range of configurations/versions. So, the balance between versatility and adequacy can be complicated to attain.

In my case, I normally choose adequacy over versatility, i. e., mobos with PCI slots that I will certainly use. But, it's quite common to see workstations/clusters/servers with many unused PCI slots. Other kinds of slots share the same situation. 

I was wondering what kind of clever things one can do with these unused/unplanned resources. Possibly nothing.

So, what do you do with your PCI slots?</Text>
  </row>
  <row>
    <Id>1045</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>565</PostId>
    <RevisionGUID>8ae2d8fc-7ff8-49d0-9b51-a5a7285a565b</RevisionGUID>
    <CreationDate>2010-04-01T18:36:23.82</CreationDate>
    <IPAddress>130.223.48.139</IPAddress>
    <UserId>141</UserId>
    <Text>Following up on Pierre's answer &amp; my comment, here's how to do it in ruby, using NCBI's eutils.
 
    #!~/bin/ruby
    require 'bio'
        
    ncbi        = Bio::NCBI::REST.new
    sequenceIDs = ncbi.esearch("Hymenoptera[organism]",
                               { "db"=&gt;"protein", "rettype"=&gt;"gb", "retmax"=&gt; 10000000})    
    sequences   = ncbi.efetch(ids = sequenceIDs,
                              {"db"=&gt;"protein", "rettype"=&gt;"fasta", "retmax"=&gt; 10000000})

    # ncbi returns a single big string with records separated by two newlines              
    sequences.gsub!("\n\n", "\n")
    File.open('genbankHymenopteranProts.fasta', 'w') {|f| f.write(sequences) }


</Text>
  </row>
  <row>
    <Id>1046</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>566</PostId>
    <RevisionGUID>cb206ece-1e07-4308-8fed-92ff955eeda1</RevisionGUID>
    <CreationDate>2010-04-01T18:58:22.21</CreationDate>
    <IPAddress>130.223.48.139</IPAddress>
    <UserId>141</UserId>
    <Text>I want to be able to orally describe what I want to visualize and it to just happen without me having to think about how to do it.</Text>
  </row>
  <row>
    <Id>1047</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>567</PostId>
    <RevisionGUID>a0be98ea-ca6c-4cdd-8acf-f73237a02b58</RevisionGUID>
    <CreationDate>2010-04-01T21:11:40.107</CreationDate>
    <IPAddress>132.183.96.217</IPAddress>
    <UserId>203</UserId>
    <Text>If you're worried about them being empty, you could always fill them up with NVIDIA Tesla boards.</Text>
  </row>
  <row>
    <Id>1048</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>565</PostId>
    <RevisionGUID>ca02ed1d-7fe2-4c37-9e05-336d1ae9cdab</RevisionGUID>
    <CreationDate>2010-04-02T07:31:46.88</CreationDate>
    <IPAddress>83.77.65.242</IPAddress>
    <UserId>141</UserId>
    <Comment>added 2 characters in body</Comment>
    <Text>Following up on Pierre's answer &amp; my comment, here's how to do it in ruby, using NCBI's eutils.
 
    #!/sw/bin/ruby
    require 'bio'
        
    ncbi        = Bio::NCBI::REST.new
    sequenceIDs = ncbi.esearch("Hymenoptera[organism]",
                               { "db"=&gt;"protein", "rettype"=&gt;"gb", "retmax"=&gt; 10000000})    
    sequences   = ncbi.efetch(ids = sequenceIDs,
                              {"db"=&gt;"protein", "rettype"=&gt;"fasta", "retmax"=&gt; 10000000})

    # ncbi returns a single big string with records separated by two newlines              
    sequences.gsub!("\n\n", "\n")
    File.open('genbankHymenopteranProts.fasta', 'w') {|f| f.write(sequences) }


</Text>
  </row>
  <row>
    <Id>1049</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>568</PostId>
    <RevisionGUID>e327b52c-03ce-4274-986a-566a8a21775b</RevisionGUID>
    <CreationDate>2010-04-02T14:57:25.05</CreationDate>
    <IPAddress>83.136.166.178</IPAddress>
    <UserId>204</UserId>
    <Text>At ActiveEon, we have provided support for several users in the bio-tech (IPMC, INRA, ...). We develop a software solution federating own resources (clusters, servers, ...) with cloud (EC2, ...). It ease access and use of cloud resources.
See http://www.activeeon.com and http://proactive.inria.fr/</Text>
  </row>
  <row>
    <Id>1050</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>569</PostId>
    <RevisionGUID>14b09053-81d2-403b-be14-862dc82608a6</RevisionGUID>
    <CreationDate>2010-04-02T17:49:47.31</CreationDate>
    <IPAddress>146.186.155.55</IPAddress>
    <UserId>4</UserId>
    <Text>I've been doing genome wide expression studies in S. cerevisiae, but a recent publication performed similar experiments using my gene of interest's orthologue in C. elegans. I want to see if genes I found to be highly/lowly expressed in my microarray study (yeast) were highly/lowly in their study (worms). Does anyone have a file which has genes and their orthologues (yeast/worms)? Or is there a way I could do this through NCBI without going gene by gene? I know how to write in python so if someone could suggest a method using script that would be helpful too.
Thanks

</Text>
  </row>
  <row>
    <Id>1051</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>569</PostId>
    <RevisionGUID>14b09053-81d2-403b-be14-862dc82608a6</RevisionGUID>
    <CreationDate>2010-04-02T17:49:47.31</CreationDate>
    <IPAddress>146.186.155.55</IPAddress>
    <UserId>4</UserId>
    <Text>How do I match orthologues in one species to another, genome scale? </Text>
  </row>
  <row>
    <Id>1052</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>569</PostId>
    <RevisionGUID>14b09053-81d2-403b-be14-862dc82608a6</RevisionGUID>
    <CreationDate>2010-04-02T17:49:47.31</CreationDate>
    <IPAddress>146.186.155.55</IPAddress>
    <UserId>4</UserId>
    <Text> égeneöexpressionà  éorthologuesà </Text>
  </row>
  <row>
    <Id>1053</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>570</PostId>
    <RevisionGUID>d2457e81-f019-42c8-b874-f72cbc636d6e</RevisionGUID>
    <CreationDate>2010-04-02T18:07:46.117</CreationDate>
    <IPAddress>205.170.235.246</IPAddress>
    <UserId>126</UserId>
    <Text>Is bootstrapping a possibility?  Resample from your data, calculate the variance, repeat.  This should leave you with a vector of bootstrapped variance estimates for each of your desired groups.  Perform the appropriate test on those estimates (e.g., t-test if you're comparing two groups and the estimates turn out normally).

I think the `boot` package is the norm for resampling in R, but here's some **untested** code to clarify the idea:

    n &lt;- 1000
    x &lt;- rnorm(mean = 0, sd = 1, n = n)
    y &lt;- rnorm(mean = 0, sd = 1.1, n = n)
    
    nboots &lt;- 10000
    bootvar.x &lt;- vector(mode = "numeric", length = nboots)
    bootvar.y &lt;- vector(mode = "numeric", length = nboots)
    
    for(i in seq_len(nboots)){
      bootvar.x[i] &lt;- var(sample(x, size = n, replace = TRUE))
      bootvar.y[i] &lt;- var(sample(y, size = n, replace = TRUE))
    }
    
    require(ggplot2)
    #Probably a better way to do this
    bootvar.x2 &lt;- data.frame(var = bootvar.x, group = "x")
    bootvar.y2 &lt;- data.frame(var = bootvar.y, group = "y")
    bootvars &lt;- rbind(bootvar.x2, bootvar.y2)
    
    ggplot(bootvars, aes(x = var, group = group, colour = group)) + geom_density()
    
    t.test(bootvar.x, bootvar.y)


**Disclaimer:** I've read a bit about bootstrapping.  Please don't assume I actually know anything.  This is just a suggestion for something to check out.</Text>
  </row>
  <row>
    <Id>1054</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>571</PostId>
    <RevisionGUID>a07c06cc-29b5-4dca-9b6f-5a0160acf9d4</RevisionGUID>
    <CreationDate>2010-04-02T18:54:28.07</CreationDate>
    <IPAddress>129.25.16.227</IPAddress>
    <UserId>92</UserId>
    <Text>Try ROUNDUP: [http://roundup.hms.harvard.edu/roundup/index.php?action=input_cluster][1] or [homologene][2]


  [1]: http://roundup.hms.harvard.edu/roundup/index.php?action=input_cluster
  [2]: http://www.ncbi.nlm.nih.gov/homologene</Text>
  </row>
  <row>
    <Id>1055</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>572</PostId>
    <RevisionGUID>9ec9b465-e305-4d57-8b05-92d0f3a0a18b</RevisionGUID>
    <CreationDate>2010-04-02T18:56:27.773</CreationDate>
    <IPAddress>92.241.199.216</IPAddress>
    <UserId>71</UserId>
    <Text>I am looking for a formal definition of the concept *dimensionality space*. I know what it is, but looking for a solid, citable definition. You get bonus points if you can point me to the correct term for the space defining the various dimensionality spaces. Seriously!</Text>
  </row>
  <row>
    <Id>1056</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>572</PostId>
    <RevisionGUID>9ec9b465-e305-4d57-8b05-92d0f3a0a18b</RevisionGUID>
    <CreationDate>2010-04-02T18:56:27.773</CreationDate>
    <IPAddress>92.241.199.216</IPAddress>
    <UserId>71</UserId>
    <Text>What are the formal definitions of a dimensionality space and the space spanning those spaces?</Text>
  </row>
  <row>
    <Id>1057</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>572</PostId>
    <RevisionGUID>9ec9b465-e305-4d57-8b05-92d0f3a0a18b</RevisionGUID>
    <CreationDate>2010-04-02T18:56:27.773</CreationDate>
    <IPAddress>92.241.199.216</IPAddress>
    <UserId>71</UserId>
    <Text> éstatisticsà  émathematicsà </Text>
  </row>
  <row>
    <Id>1058</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>573</PostId>
    <RevisionGUID>a2247aca-da3b-4915-acf3-b936e0e1b304</RevisionGUID>
    <CreationDate>2010-04-02T19:01:14.03</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>If you want to do it with scripting (Perl) the very powerful Ensembl Compara database is really very good. It has what is probably the best orthology walking pipeline out there at the moment.

http://www.ensembl.org/info/docs/api/compara/compara_tutorial.html

If you want to make your life ball-bouncingly easy just use the Ensembl BioMart service http://www.ensembl.org/biomart/martview just chose one of your species then under the "filter" chose "multi species comparison" then from the pull-down menu pick the other species. At the bottom you can add an additional dataset, chose the other species and then from the filter fro this dataset again chose the "multi-species comparison" and pick the other species from the pull-down menu. Hit results and it will provide you with a table mapping genes from one species on to the other. If you want to use smaller subsets of genes just provide those gene ids in the gene section of the filter selection and provide the ids. Hope that helps.

</Text>
  </row>
  <row>
    <Id>1059</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>574</PostId>
    <RevisionGUID>a6f5aeb2-87f3-4123-bcb9-d2674aa73e37</RevisionGUID>
    <CreationDate>2010-04-02T19:22:48.44</CreationDate>
    <IPAddress>189.62.203.252</IPAddress>
    <UserId>148</UserId>
    <Text>Hi there,

Now a practical question. I need to generate the set of sequences at a given edit distance from a reference. Let's assume Levenshtein distance for the matter. From example, I have a sequence of a TFBS and want to generate all sequences with edit distance equal 2. Of course, efficiency is very important as the problem tends to become very very large rapidly with increasing distance/reference size.

I've already searched Knuth collection and the usual sources. But found only efficient solutions for comparison. </Text>
  </row>
  <row>
    <Id>1060</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>574</PostId>
    <RevisionGUID>a6f5aeb2-87f3-4123-bcb9-d2674aa73e37</RevisionGUID>
    <CreationDate>2010-04-02T19:22:48.44</CreationDate>
    <IPAddress>189.62.203.252</IPAddress>
    <UserId>148</UserId>
    <Text>How to generate a set of sequences at a given edit distance from a reference?</Text>
  </row>
  <row>
    <Id>1061</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>574</PostId>
    <RevisionGUID>a6f5aeb2-87f3-4123-bcb9-d2674aa73e37</RevisionGUID>
    <CreationDate>2010-04-02T19:22:48.44</CreationDate>
    <IPAddress>189.62.203.252</IPAddress>
    <UserId>148</UserId>
    <Text> éeditödistanceà  écombinatorialà  ésequenceà </Text>
  </row>
  <row>
    <Id>1062</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>575</PostId>
    <RevisionGUID>22bcca78-c89d-487c-b655-f2d5602efe14</RevisionGUID>
    <CreationDate>2010-04-02T19:31:34.793</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>Any basic linear algebra textbook should do fine for a citation. Btw, what is the connection to bioinformatics? 
You are asking for the definition of  dimensionality of vector-spaces?

The (number of vectors that form) cardinality of a basis for the vector space. For example R^3 has three basis vectors, eg. the standard basis (0,0,1),  ...

http://en.wikipedia.org/wiki/Dimension_%28linear_algebra%29</Text>
  </row>
  <row>
    <Id>1063</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>575</PostId>
    <RevisionGUID>02f5ba68-de1f-4faa-a7f0-0837a717293d</RevisionGUID>
    <CreationDate>2010-04-02T19:37:24.403</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 16 characters in body</Comment>
    <Text>Any basic linear algebra textbook should do fine for a citation. Btw, what is the connection to bioinformatics? 
You are asking for the definition of  dimensionality of vector-spaces?

The (number of vectors that form) cardinality of a basis for the vector space. For example in R^3 each basis consists of three vectors, eg. the standard basis (0,0,1),  ...

http://en.wikipedia.org/wiki/Dimension_%28linear_algebra%29</Text>
  </row>
  <row>
    <Id>1064</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>576</PostId>
    <RevisionGUID>dc1826ac-5eea-4370-9269-6523cd356514</RevisionGUID>
    <CreationDate>2010-04-02T19:52:26.48</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Text>Can be quite simple:
[This BioMart query will do the job.][1] And this should be also the most comfortable solution

This will provide a mapping of yeast genes to orthologous C.elegans genes with some additional attributes. In the results page click *Go* to export this mapping as a file. Chose other attributes on the left if you like.

  [1]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&amp;ATTRIBUTES=scerevisiae_gene_ensembl.default.homologs.ensembl_gene_id|scerevisiae_gene_ensembl.default.homologs.ensembl_transcript_id|scerevisiae_gene_ensembl.default.homologs.elegans_ensembl_gene|scerevisiae_gene_ensembl.default.homologs.elegans_ensembl_peptide|scerevisiae_gene_ensembl.default.homologs.elegans_orthology_type|scerevisiae_gene_ensembl.default.homologs.homolog_cele__dm_perc_id_4015_r1|scerevisiae_gene_ensembl.default.homologs.homolog_cele__dm_perc_id_4015|scerevisiae_gene_ensembl.default.homologs.ensembl_peptide_id|scerevisiae_gene_ensembl.default.homologs.external_gene_id|scerevisiae_gene_ensembl.default.homologs.elegans_homolog_ensembl_peptide&amp;FILTERS=&amp;VISIBLEPANEL=resultspanel</Text>
  </row>
  <row>
    <Id>1065</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>577</PostId>
    <RevisionGUID>6bce361f-0b49-4443-a5ff-2d376fd9549d</RevisionGUID>
    <CreationDate>2010-04-02T19:58:24.81</CreationDate>
    <IPAddress>132.183.96.217</IPAddress>
    <UserId>203</UserId>
    <Text>Isn't the underlying problem here just going to be the number of potential sequences?  That is, I'm not sure there is going to be a way to reduce the time complexity if you need to enumerate them all.

I suppose you could build up some sort of tree that does represent all sequences in a compressed space.  Or if you need to do some computation on that set of sequences, there are probably tricks (like the suffix-array indexing in BWA etc.) where you could compute on big parts of your sequence space at once, without having to explicitly enumerate it...</Text>
  </row>
  <row>
    <Id>1066</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>572</PostId>
    <RevisionGUID>1b96b441-0d0b-4553-a849-f8f642a0378d</RevisionGUID>
    <CreationDate>2010-04-02T20:22:34.223</CreationDate>
    <IPAddress>92.241.199.216</IPAddress>
    <UserId>71</UserId>
    <Comment>added 135 characters in body</Comment>
    <Text>I am looking for a formal definition of the concept *dimensionality space*. I know what it is, but looking for a solid, citable definition. You get bonus points if you can point me to the correct term for the space defining the various dimensionality spaces. Seriously!

To clarify things, I am not asking what *dimensionality* is. I am also not asking what the concepts mean, but a citable definition.</Text>
  </row>
  <row>
    <Id>1067</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>575</PostId>
    <RevisionGUID>b6ef56e8-af7d-4cba-ba2f-6c30eecbd3ef</RevisionGUID>
    <CreationDate>2010-04-02T20:53:50.913</CreationDate>
    <IPAddress>84.202.136.164</IPAddress>
    <UserId>55</UserId>
    <Comment>added 724 characters in body</Comment>
    <Text>Any basic linear algebra textbook should do fine for a citation. Btw, what is the connection to bioinformatics? 
You are asking for the definition of  dimensionality of vector-spaces?

The (number of vectors that form) cardinality of a basis for the vector space. For example in R^3 each basis consists of three vectors, eg. the standard basis (0,0,1),  ...

http://en.wikipedia.org/wiki/Dimension_%28linear_algebra%29

Edit: Now I think I know what you mean, but still, the *isolated* use of *dimensonality space* is incorrect both in the gramatical and algebraic sense. Try a google search for  "dimensionality space" inlcuing the quotes. Dimensionality is a feature of a vector-space and there is no dimensionality space (such as a "space of dimensions"). 

*Reduced dimensionality space* seems to be used eg in the sense of 
dimension reduction, such as "Our great method reduces the 42-input space to a problem in a reduced dimensionality space (eg of dimensionality 3)"
Look for example at: 
e.g. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.4068
That might be an example headline that you might be thinking of.
 </Text>
  </row>
  <row>
    <Id>1068</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>578</PostId>
    <RevisionGUID>bbb76767-09b4-49d5-8009-4320ab0f13ba</RevisionGUID>
    <CreationDate>2010-04-02T21:26:55.857</CreationDate>
    <IPAddress>189.62.203.252</IPAddress>
    <UserId>148</UserId>
    <Text>This set would not be a space at all. What would be your metric? Or your norm? What we normally do in bioinformatics is to work with pre-topologies. They represent some sort of "sequence space" closed under edition/recombination. In a practical sense, reversible-jump Markov chains deal with variable dimensionality of parameter space and there is some theory attachted to them. Nevertheless, if you want more information about spaces and similar constructions I do recommend you to search on http://lib.org.by for the book of Kolmogorov on functional analysis or similar treatises on abstract spaces. </Text>
  </row>
  <row>
    <Id>1069</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>574</PostId>
    <RevisionGUID>24463f80-6dcf-427f-95ff-e48e6e518716</RevisionGUID>
    <CreationDate>2010-04-02T21:34:12.44</CreationDate>
    <IPAddress>189.62.203.252</IPAddress>
    <UserId>148</UserId>
    <Comment>edited title</Comment>
    <Text>How to generate the set of sequences at a given edit distance from a reference?</Text>
  </row>
  <row>
    <Id>1070</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>579</PostId>
    <RevisionGUID>b7b45f5a-7f93-45fd-8fe6-e92c84780323</RevisionGUID>
    <CreationDate>2010-04-02T21:50:33.55</CreationDate>
    <IPAddress>82.245.142.157</IPAddress>
    <UserId>205</UserId>
    <Text>If I understood your problem, I think it corresponds to enumerate all possible combinations of substitutions on all combinations of k positions in a sequence. (k is the edit distance)

This can be done by Knuth algorithm for combination enumeration. First you enumerate combinations of positions then you enumerate combinations of modifications.

I made a brute force solver for alignments based on this idea. But you can not avoid complexity. 

For example, if you want to generate sequences at an edit distance 2 (k) from a reference sequence of length 5 (m) with an alphabet of 4 (a) letters:
First, you choose 2 positions from 5 without repeats (10 pairs)
Second, on these positions, you enumerate the combinations of modifications with repeats (6).
So you have 60 sequences.

I think the number of solutions is like that : (m! / (k!*(m-k)!)) * ((a+k-2)!/(k!(a-2)!))

I hope it will helps you ;)

Bilou.
</Text>
  </row>
  <row>
    <Id>1071</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>580</PostId>
    <RevisionGUID>3e7f88c3-ac8b-4e08-b452-250f3cce2f6c</RevisionGUID>
    <CreationDate>2010-04-02T22:01:04.387</CreationDate>
    <IPAddress>82.245.142.157</IPAddress>
    <UserId>205</UserId>
    <Text>My answer comes late but I just discovered this web site.

Instead of writing the blosum matrix in a data struct, I think it is a better idea to create a function to read your matrix in a text file.

Thus, if you want to try another scoring matrix than blosum 62, you just have to read another file.

Bilou.</Text>
  </row>
  <row>
    <Id>1072</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>581</PostId>
    <RevisionGUID>27f5dd88-91a5-480c-814e-4edafd388d03</RevisionGUID>
    <CreationDate>2010-04-03T02:41:27.107</CreationDate>
    <IPAddress>71.126.238.51</IPAddress>
    <UserId>203</UserId>
    <Text>InParanoid is another database of pre-computed orthologs with convenient downloadable files http://inparanoid.sbc.su.se/cgi-bin/index.cgi</Text>
  </row>
  <row>
    <Id>1073</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>582</PostId>
    <RevisionGUID>ba08bfcf-65bf-4ec2-916d-f2a665e0fb25</RevisionGUID>
    <CreationDate>2010-04-03T04:12:59.507</CreationDate>
    <IPAddress>124.100.33.210</IPAddress>
    <UserId>206</UserId>
    <Text>Hi all, is there any other useful databases for chromosomal variation? I would like to know the useful database that recoreds disease-causing variations which mapped by using STS markers and so on (not microarrays).


Followings are useful links. Any help would be great thanks. &lt;br&gt;
dbVar http://www.ncbi.nlm.nih.gov/dbvar/ &lt;br&gt;
CHOP (The Copy Number Variation project at the Children's Hospital of Philadelphia) http://cnv.chop.edu &lt;br&gt;
DGV (Database of Genomic Variants) http://projects.tcag.ca/variation &lt;br&gt;
DECIPHER https://decipher.sanger.ac.uk/ &lt;br&gt;
ECARUCA http://agserver01.azn.nl:8080/ecaruca/ecaruca.jsp &lt;br&gt;
</Text>
  </row>
  <row>
    <Id>1074</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>582</PostId>
    <RevisionGUID>ba08bfcf-65bf-4ec2-916d-f2a665e0fb25</RevisionGUID>
    <CreationDate>2010-04-03T04:12:59.507</CreationDate>
    <IPAddress>124.100.33.210</IPAddress>
    <UserId>206</UserId>
    <Text>How to search disease-causing chromosomal structure variation? </Text>
  </row>
  <row>
    <Id>1075</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>582</PostId>
    <RevisionGUID>ba08bfcf-65bf-4ec2-916d-f2a665e0fb25</RevisionGUID>
    <CreationDate>2010-04-03T04:12:59.507</CreationDate>
    <IPAddress>124.100.33.210</IPAddress>
    <UserId>206</UserId>
    <Text> écnvà  édatabaseà </Text>
  </row>
  <row>
    <Id>1076</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>583</PostId>
    <RevisionGUID>d6effcb8-d1fc-4e8b-b0ee-d3ac5b7a57a7</RevisionGUID>
    <CreationDate>2010-04-03T08:55:11.153</CreationDate>
    <IPAddress>82.126.29.128</IPAddress>
    <UserId>30</UserId>
    <Text>You can use [NCBI ELink][1] to map from the diseases in OMIM to UniSTS. For example, to map the STS linked to the ['LYNCH SYNDROME I' ( omim:120435 )][2] :

http://www.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=omim&amp;db=unists&amp;id=120435

Result:

    &lt;eLinkResult&gt;
    
    	&lt;LinkSet&gt;
    		&lt;DbFrom&gt;omim&lt;/DbFrom&gt;
    		&lt;IdList&gt;
    			&lt;Id&gt;120435&lt;/Id&gt;
    		&lt;/IdList&gt;
    		&lt;LinkSetDb&gt;
    
    			&lt;DbTo&gt;unists&lt;/DbTo&gt;
    			&lt;LinkName&gt;omim_unists&lt;/LinkName&gt;
    			&lt;Link&gt;
    				&lt;Id&gt;64072&lt;/Id&gt;
    			&lt;/Link&gt;
    			&lt;Link&gt;
    				&lt;Id&gt;888&lt;/Id&gt;
    
    			&lt;/Link&gt;
    		&lt;/LinkSetDb&gt;
    	&lt;/LinkSet&gt;
    &lt;/eLinkResult&gt;

both sts (64072 and 888) are [unists: 64072][3] = **D2S123**


  [1]: http://www.ncbi.nlm.nih.gov/corehtml/query/static/elink_help.html
  [2]: http://www.ncbi.nlm.nih.gov/entrez/dispomim.cgi?id=120435
  [3]: http://www.ncbi.nlm.nih.gov/genome/sts/sts.cgi?uid=64072</Text>
  </row>
  <row>
    <Id>1077</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>579</PostId>
    <RevisionGUID>692b784b-e2b0-4666-a767-11a9f7d43577</RevisionGUID>
    <CreationDate>2010-04-03T21:31:14.903</CreationDate>
    <IPAddress>82.245.142.157</IPAddress>
    <UserId>205</UserId>
    <Comment>added 361 characters in body</Comment>
    <Text>If I understood your problem, I think it corresponds to enumerate all possible combinations of substitutions on all combinations of k positions in a sequence. (k is the edit distance)

This can be done by Knuth algorithm for combination enumeration. First you enumerate combinations of positions then you enumerate combinations of modifications.

I made a brute force solver for alignments based on this idea. But you can not avoid complexity. 

For example, if you want to generate sequences at an edit distance 2 (k) from a reference sequence of length 5 (m) with an alphabet of 4 (a) letters:
First, you choose 2 positions from 5 without repeats (10 pairs)
Second, on these positions, you enumerate the combinations of modifications with repeats (6).
So you have 60 sequences.

I think the number of solutions is like that : (m! / (k!*(m-k)!)) * ((a+k-2)!/(k!(a-2)!))

I hope it will helps you ;)

Bilou.

Edit :

After discussion, I think the best way to generate your sequences is the following :

 - Generate sequences with distance k with 0 indel
 - Generate sequences with distance k-1 with 1 indel
 - Generate sequences with distance k-2 with 2 indels
 - ...
 - Generate sequences with distance 0 with k indels

It is a huge number of sequences !!
</Text>
  </row>
  <row>
    <Id>1078</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>584</PostId>
    <RevisionGUID>6c65efaa-18d8-4a19-9e7b-3fe7320a94aa</RevisionGUID>
    <CreationDate>2010-04-05T15:11:57.193</CreationDate>
    <IPAddress>52.129.8.52</IPAddress>
    <UserId>73</UserId>
    <Text>Typically I will start a sequence analysis project in which users later email me crucial details, which I have to record somewhere in the project folder.

This is getting out of control as the number of project folders expands. It seems obvious that I need some kind of LIMS system. It has to be loose since I do so many different types of analyses. Perhaps a wiki?

One feature I would need is a filter which reads my email and collects relevant messages based on keywords or some way to add easily add emails to a project, like a issue tracker would offer (we have JIRA). I really need some way to easily designate emails as being relevant to a project so I am not relying on copy-and-paste.

How do you manage this problem?</Text>
  </row>
  <row>
    <Id>1079</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>584</PostId>
    <RevisionGUID>6c65efaa-18d8-4a19-9e7b-3fe7320a94aa</RevisionGUID>
    <CreationDate>2010-04-05T15:11:57.193</CreationDate>
    <IPAddress>52.129.8.52</IPAddress>
    <UserId>73</UserId>
    <Text>Does anyone have a LIMS that handles emails?</Text>
  </row>
  <row>
    <Id>1080</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>584</PostId>
    <RevisionGUID>6c65efaa-18d8-4a19-9e7b-3fe7320a94aa</RevisionGUID>
    <CreationDate>2010-04-05T15:11:57.193</CreationDate>
    <IPAddress>52.129.8.52</IPAddress>
    <UserId>73</UserId>
    <Text> élimsà  éwikià  éprojectà  éemailsà  éjiraà </Text>
  </row>
  <row>
    <Id>1081</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>585</PostId>
    <RevisionGUID>f16ddd99-0a03-4f19-98f5-71acae67d637</RevisionGUID>
    <CreationDate>2010-04-05T16:26:16.357</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>There is an easy way to add this if your LIMS supports adding comments.

You can set up a cron job that periodically reads the inbox, parses the emails of interest then uploads them to the right destination. 


</Text>
  </row>
  <row>
    <Id>1082</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>586</PostId>
    <RevisionGUID>13b54d5d-d508-45d6-8b89-b146c13aa7d5</RevisionGUID>
    <CreationDate>2010-04-05T17:02:23.157</CreationDate>
    <IPAddress>151.66.182.20</IPAddress>
    <UserId>207</UserId>
    <Text>I doubt there's such a thing. You can say a reduced-dimensionality space,
perhaps, but in that case "dimensionality" is attached to "reduced" not to "space".

"Reduced-dimensionality" space is a space which has a smaller dimension with respect to some other space.

What's the dimension of a space? 

Typically, one refers to the dimension of a vector space.

1-A vector space is a set of elements called vectors such that the sum of two elements is still in the set, and one can multiply each element by a real number and still get an element of the set.

2-A subset (of cardinality k, with elements v_1,...,v_k) of a vector space V is said to be linearly independent if there are no nonzero real numbers
c_1,...,c_k such that

c_1*v_1+...+c_k*v_k=0

(remember that you can multiply vectors by numbers, and you can sum vectors, so the above makes sense. 0 means the 0 vector.)


3-The cardinality of the biggest possible such subset of V is the dimension of V.

Example:
--------

For example you can give the plane the structure of a vector space by choosing on it coordinates (x,y).

one possible linearly independent subset of the plane is given by the two vectors (1,0) and (0,1). Indeed it is not possible to find non-zero c_1,c_2 such that

c_1*(1,0)+c2*(0,1)=(0,0)

It turns out that you cannot build bigger linearly independent subsets of the plane : 
hence it is a vector space of dimension 2.


You can read this:

http://en.wikipedia.org/wiki/Linear_independence

and go on hopping on Wikipedia.








</Text>
  </row>
  <row>
    <Id>1083</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>587</PostId>
    <RevisionGUID>2061789d-564e-4c0f-ab20-95e55de4fea6</RevisionGUID>
    <CreationDate>2010-04-05T17:29:40.283</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>This is an interesting situation which we all found at least once during our bioinformatics life. The simple solution is that of Istvan. Just set up a bunch of shell scripts with you favorite job scheduler and parse the mails &amp; cia with sed/awk/grep. This approach is secure, robust and can be specifically tailored to your very needs.

Another solution is to setup a CMS and configure it as your LIMS. You can find some examples that use Plone as a LIMS. An example is the now obsolete Bika LIMS or Cerium Labs. You can use Plone4Bio as a LIMS too. The great advantage of it is that people themselves will do the parse part. They can add data to the filetree online, safely. And is trivial to add a issue tracker, a wiki, a board, schedule, etc. The problem is: Plone uses a server. So, security is a concern.

Of course, there are other CMS with different flavors, like Apache Lenya. You just need to adapt them to your needs.
</Text>
  </row>
  <row>
    <Id>1084</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>588</PostId>
    <RevisionGUID>13cae3aa-5874-437f-8d4c-d1919565b081</RevisionGUID>
    <CreationDate>2010-04-06T12:13:07.723</CreationDate>
    <IPAddress>131.174.146.243</IPAddress>
    <UserId>211</UserId>
    <Text>I've tried  Arachne, Newbler and WGS on 454 datasets with varying results. In metagenomes from soil with many species and relative low coverage per species you will get  more of your reads assembled into contigs that in metagenomes with a low amount of different species. In such a dataset contigs tend to break on variations between the different but similar species (WGS) or include ambiguities (Newbler). Binning may improve things. I'm curious about what options others tried.</Text>
  </row>
  <row>
    <Id>1085</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>589</PostId>
    <RevisionGUID>ab649002-ab48-484b-a51e-1f7f680de4de</RevisionGUID>
    <CreationDate>2010-04-06T15:07:30.977</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Hello

&lt;p&gt;I am trying to connect to the mysql database available at ensembl in order to perform some query with the follwoing code but i Get a "Could not connect:" message so I am wondering if I failed because I am not allowed to perform connection out of my network for security reason.&lt;/p&gt;
&lt;p&gt;So if someone has the time to test it and to connect successfully I would appreciate.&lt;/p&gt;
&lt;p&gt;Thanks in advance.&lt;/p&gt;

    &lt;?php
    $link = mysql_connect('ensembldb.ensembl.org:3306', 'anonymous', '');

    if (!$link) {
        die('Could not connect: ' . mysql_error());
    }
    echo 'Connected successfully';
    mysql_close($link);
    ?&gt;

</Text>
  </row>
  <row>
    <Id>1086</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>589</PostId>
    <RevisionGUID>ab649002-ab48-484b-a51e-1f7f680de4de</RevisionGUID>
    <CreationDate>2010-04-06T15:07:30.977</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Failed to connect to the Ensembl mysql database</Text>
  </row>
  <row>
    <Id>1087</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>589</PostId>
    <RevisionGUID>ab649002-ab48-484b-a51e-1f7f680de4de</RevisionGUID>
    <CreationDate>2010-04-06T15:07:30.977</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text> émysqlà  éensemblà  éphpà </Text>
  </row>
  <row>
    <Id>1088</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>590</PostId>
    <RevisionGUID>4bb5e707-8674-4f82-923c-a46d537b292d</RevisionGUID>
    <CreationDate>2010-04-06T15:19:03.557</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>Try port 5306 to connect.</Text>
  </row>
  <row>
    <Id>1089</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>590</PostId>
    <RevisionGUID>93207335-ebf5-4849-a7bb-9a075416a7ba</RevisionGUID>
    <CreationDate>2010-04-06T15:24:26.627</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>89</UserId>
    <Text>[{"Id":89,"DisplayName":"Yuri"}]</Text>
  </row>
  <row>
    <Id>1090</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>591</PostId>
    <RevisionGUID>7ff6c67c-6fd4-4187-8793-99289ed08e4b</RevisionGUID>
    <CreationDate>2010-04-06T15:33:46.76</CreationDate>
    <IPAddress>129.215.82.131</IPAddress>
    <UserId>169</UserId>
    <Text>Well this works for me so my guess would be you need to check your firewall settings (both outgoing and incoming http://www.ensembl.org/info/data/mysql.html)

    &lt;?php
    $link = mysql_connect('ensembldb.ensembl.org:3306', 'anonymous', '');

    if (!$link) {
        die('Could not connect: ' . mysql_error());
    }
    echo 'Connected successfully';

    $db_list = mysql_list_dbs($link);

    while ($row = mysql_fetch_object($db_list)) {
         echo $row-&gt;Database . "\n";
    }

    mysql_close($link);
    ?&gt;</Text>
  </row>
  <row>
    <Id>1091</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>592</PostId>
    <RevisionGUID>615c4de7-56ce-432a-9826-a15686fcb051</RevisionGUID>
    <CreationDate>2010-04-06T19:37:27.593</CreationDate>
    <IPAddress>93.39.160.16</IPAddress>
    <UserId>23</UserId>
    <Text>The port is 5306 and not 3306. I had the same problem two years ago and they answered me that:

   

&gt;  **helpdesk@ensembl.org, on May 22th 2008**: From release 48
&gt; onwards the Ensembl databases are on
&gt; port 5306 instead of 3306 of ensembldb
&gt; …

I asked them if they could update their docs but they didn't do it yet, I don't know why.</Text>
  </row>
  <row>
    <Id>1092</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>593</PostId>
    <RevisionGUID>216080a6-7d81-46de-b006-83823ae890db</RevisionGUID>
    <CreationDate>2010-04-07T06:07:07.73</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text>I thought this is a simple question, but after some searching over the Internet, I just found several out-of-date databases like http://data.kew.org/cvalues/

There are several useful resources though:
http://www.phytozome.net/ 
http://www.plantgdb.org/ 
But I did not find any direct information on genome size.

A workaround would be to download all the fasta files of chromosome sequences of these species and just look at the file size..

I'm just wondering is there any resources on plant genome size, or if not, an efficient way to get this information?

Thank you!</Text>
  </row>
  <row>
    <Id>1093</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>593</PostId>
    <RevisionGUID>216080a6-7d81-46de-b006-83823ae890db</RevisionGUID>
    <CreationDate>2010-04-07T06:07:07.73</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text>Where to find the genome sizes of sequenced plant species?</Text>
  </row>
  <row>
    <Id>1094</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>593</PostId>
    <RevisionGUID>216080a6-7d81-46de-b006-83823ae890db</RevisionGUID>
    <CreationDate>2010-04-07T06:07:07.73</CreationDate>
    <IPAddress>128.118.123.176</IPAddress>
    <UserId>14</UserId>
    <Text> égenomeà  égenomeösizeà  éplantögenomeösizeà </Text>
  </row>
  <row>
    <Id>1095</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>594</PostId>
    <RevisionGUID>3eea7870-2bc1-47c7-a72a-001971260312</RevisionGUID>
    <CreationDate>2010-04-07T07:15:17.653</CreationDate>
    <IPAddress>94.196.67.47</IPAddress>
    <UserId>198</UserId>
    <Text>Setting up a cron job and using awk/perl or whatever seems rather over-engineered to me, and does not negate the problem of keyword searching being unreliable.  

I would change the business process and set up a CMS, or a small bespoke website.</Text>
  </row>
  <row>
    <Id>1096</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>595</PostId>
    <RevisionGUID>b941015f-a178-4052-b201-0b1786b99028</RevisionGUID>
    <CreationDate>2010-04-07T07:19:18.72</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>Did you try to fill out the query form available at [http://data.kew.org/cvalues/CvalServlet?querytype=1][1]

It should allow you to get the statistics you are looking for


  [1]: http://data.kew.org/cvalues/CvalServlet?querytype=1</Text>
  </row>
  <row>
    <Id>1097</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>594</PostId>
    <RevisionGUID>20dde71b-9fae-4898-a83f-b12de022634c</RevisionGUID>
    <CreationDate>2010-04-07T07:21:49.213</CreationDate>
    <IPAddress>94.196.67.47</IPAddress>
    <UserId>198</UserId>
    <Comment>better; added 96 characters in body</Comment>
    <Text>Setting up a cron job and using awk/perl or whatever would not be my choice as it does not negate the problem of keyword searching being unreliable. You can't rely on e-mails always being spelt correctly etc etc, well in my experience you can't. 

I would change the business process and set up a CMS, or a small bespoke website.</Text>
  </row>
  <row>
    <Id>1098</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>596</PostId>
    <RevisionGUID>44d3df14-e3c0-44d7-81c0-4b8f779f0304</RevisionGUID>
    <CreationDate>2010-04-07T07:31:50.34</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>From NCBI genome projects: http://www.ncbi.nlm.nih.gov/sites/entrez?Db=genomeprj
Clink on "Plant" http://www.ncbi.nlm.nih.gov/sites/entrez?cmd=Search&amp;db=genomeprj&amp;term=%22Viridiplantae%22[Organism]
Each record contains the genome size (if available)

I would also suggest to have a the field &amp;lt;gp:EstimatedGenomeSize/&amp;gt; in ftp://ftp.ncbi.nih.gov/genomes/genomeprj/gp.xml but it seems that not all the organisms are present in that file...




</Text>
  </row>
  <row>
    <Id>1099</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>594</PostId>
    <RevisionGUID>32e306dd-013f-4fa9-807c-cf9568192aed</RevisionGUID>
    <CreationDate>2010-04-07T07:37:24.017</CreationDate>
    <IPAddress>92.40.151.198</IPAddress>
    <UserId>198</UserId>
    <Comment>client</Comment>
    <Text>Setting up a cron job and using awk/perl or whatever would not be my choice; what e-mail client are you using - does it have "rules" or equivalent ? Keyword searching is also unreliable - you can't rely on e-mails always being spelt correctly, using the same terms, etc etc.

I would change the business process and set up a CMS, or a small bespoke website.</Text>
  </row>
  <row>
    <Id>1100</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>597</PostId>
    <RevisionGUID>ca5b68af-fc78-44e0-a29e-35d5c5ae1cb3</RevisionGUID>
    <CreationDate>2010-04-07T12:36:58.22</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi Zhaorong,

Genome size or C-value as commonly used by biologists is a hard to find information. For instance, most biomolecular databases do not have this information readily available. NCBI has only a few hundred estimates on plant genomes. But, as of 2005 there are at least tens of thousands high quality estimates.

A good place is [Plant C-value database][1] in the Royal Botanic Gardens. But, be advised, I do not know database layout. So, it might not be possible to programmatically query the entries.

Anyway, for more information you can use T. Gregory 2004 book ([The Evolution of the Genome][2]) and check Michael Lynch's masterpiece ([The Origins of Genome Architecture][3]). Both bring a wealth of information on genome size, motif (TE, TFBS, etc.) contents, mutation rates, effective population size and other very useful estimates.



[1]: http://data.kew.org/cvalues/
[2]: http://www.amazon.com/Evolution-Gregory-Evolutionary-Biology-University/dp/0123014638
[3]: http://www.amazon.com/Origins-Genome-Architecture-Michael-Lynch/dp/0878934847/ref=pd_bxgy_b_img_b</Text>
  </row>
  <row>
    <Id>1101</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>598</PostId>
    <RevisionGUID>a9da54ac-9ec2-48e9-ba2c-30b1c52cb97a</RevisionGUID>
    <CreationDate>2010-04-07T13:38:04.25</CreationDate>
    <IPAddress>159.92.206.174</IPAddress>
    <UserId>120</UserId>
    <Text>Does anyone have any recommendations for motif-finding algorithms that can use ChIP-seq scale data? Approaches that can use all of the data, ideally incorporating ranking information, rather than just running MEME or similar on the top 50 ChIPseq peaks. 

I'm also looking for methods that can handle motifs with substructure - for example I'm looking at some TFBS data and the binding site has left and right half sites which can appear on their own, or together in different orientations and with different spacers between them. Any suggestions on strategies for de novo identification of such patterns?

TIA, Cass.</Text>
  </row>
  <row>
    <Id>1102</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>598</PostId>
    <RevisionGUID>a9da54ac-9ec2-48e9-ba2c-30b1c52cb97a</RevisionGUID>
    <CreationDate>2010-04-07T13:38:04.25</CreationDate>
    <IPAddress>159.92.206.174</IPAddress>
    <UserId>120</UserId>
    <Text>Tools for ChIPseq scale motif finding?</Text>
  </row>
  <row>
    <Id>1103</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>598</PostId>
    <RevisionGUID>a9da54ac-9ec2-48e9-ba2c-30b1c52cb97a</RevisionGUID>
    <CreationDate>2010-04-07T13:38:04.25</CreationDate>
    <IPAddress>159.92.206.174</IPAddress>
    <UserId>120</UserId>
    <Text> émotifödiscoveryà  émotifà  échipöseqà </Text>
  </row>
  <row>
    <Id>1104</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>599</PostId>
    <RevisionGUID>bb3c79b9-847d-4843-b5d2-b8d473498e04</RevisionGUID>
    <CreationDate>2010-04-07T14:11:16.103</CreationDate>
    <IPAddress>70.240.211.40</IPAddress>
    <UserId>117</UserId>
    <Text>It's not comprehensive, but there are a few listed in the [BioNumbers database](http://bionumbers.hms.harvard.edu/search.aspx?log=y&amp;task=searchbytrmorg&amp;trm=genome+size&amp;org=%25)</Text>
  </row>
  <row>
    <Id>1105</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>600</PostId>
    <RevisionGUID>a5f4fa3b-b11b-4cc0-94ac-c2912aca6ff4</RevisionGUID>
    <CreationDate>2010-04-07T14:42:03.32</CreationDate>
    <IPAddress>218.186.8.237</IPAddress>
    <UserId>91</UserId>
    <Text>I use [CisFinder][1], which comfortable handles ChIP-seq scale data. It has a (pretty user-friendly) web interface, although I often use the command-line version as well. 


  [1]: http://lgsun.grc.nia.nih.gov/CisFinder/</Text>
  </row>
  <row>
    <Id>1106</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>601</PostId>
    <RevisionGUID>4cc89324-7a10-4915-b087-8d8d21314f15</RevisionGUID>
    <CreationDate>2010-04-07T14:57:32.227</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>These pages are a bit dated, but still should contain something usable:

* http://openwetware.org/wiki/Wikiomics:Sequence_motifs (see the top points)

* http://openwetware.org/wiki/Wikiomics:ChIP-chip (older)

In short, you may not be better by feeding probably any motif finding programs with hundreds of sequences. Going for sequences conserved between species is a low hanging fruit strategy, but should get you something to test fairly quickly.  
</Text>
  </row>
  <row>
    <Id>1107</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>602</PostId>
    <RevisionGUID>d508c0a8-b4af-4491-8cf3-87472ad80458</RevisionGUID>
    <CreationDate>2010-04-08T03:17:18.627</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>I have worked with 454, Illumina and Solid platforms commonly referred to as 2nd generation (or next gen) sequencing platforms. Has anyone here worked with the Helicos system? 

What other novel sequencing methodology/technology do you know of?

*In lieu of first hand experience we'll take hearsay as well.*</Text>
  </row>
  <row>
    <Id>1108</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>602</PostId>
    <RevisionGUID>d508c0a8-b4af-4491-8cf3-87472ad80458</RevisionGUID>
    <CreationDate>2010-04-08T03:17:18.627</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>What 3rd generation sequencing methods are out there</Text>
  </row>
  <row>
    <Id>1109</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>602</PostId>
    <RevisionGUID>d508c0a8-b4af-4491-8cf3-87472ad80458</RevisionGUID>
    <CreationDate>2010-04-08T03:17:18.627</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text> énextgenà  ésequencingà </Text>
  </row>
  <row>
    <Id>1110</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>603</PostId>
    <RevisionGUID>77d2d585-c461-4215-afd5-7eed7f44f871</RevisionGUID>
    <CreationDate>2010-04-08T04:42:00.133</CreationDate>
    <IPAddress>130.102.117.54</IPAddress>
    <UserId>214</UserId>
    <Text>If you require ab-initio motif discovery, then perhaps DRIM ([http://bioinfo.cs.technion.ac.il/drim/][1]) may be of use. From memory, I don't think it's quite as sophisticated as what you're ideally after (left and right halves and so forth), but it does use ranking data. Possibly GLAM2 would be the most appropriate tool (if you need to represent a gap between two binding domains). GLAM2 does not take rank into account, though.

If you decide to use MEME on ChIP-seq data, you're best off running it in OOPS mode (according to our testing).

If you're able to scan the ChIP-seq peak regions with a library such as UniProbe or Transfac, then you have many more tools available that use rank information such as [PASTAA][2] or [AME][3].

Disclaimer: I recently (on April 1st, what does that say?!) published AME in this paper:

http://www.biomedcentral.com/1471-2105/11/165/abstract 

It focuses on rank-based motif enrichment analysis methods (i.e. identifying statistically enriched motifs from a library of motifs). It compares several different MEA methods. Perhaps it (and the papers/tools it cites) will be of some use ;).


  [1]: http://bioinfo.cs.technion.ac.il/drim/
  [2]: http://trap.molgen.mpg.de/
  [3]: http://bioinformatics.org.au/ame/</Text>
  </row>
  <row>
    <Id>1111</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>604</PostId>
    <RevisionGUID>fe8c8885-55ba-4bc4-95ce-2f18f81dba20</RevisionGUID>
    <CreationDate>2010-04-08T10:12:43.793</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>You may try searching "Genome Projects" at NCBI with "txid33090[Organism:exp]" (green plants). 

It is a crappy solution, since some entries seem to be duplicated, plastid/ chromosomal/ESTs projects are listed among WGS projects, but at least you should be able to extract info what is being sequenced and where. Individual genome centers/sequencing projects web pages may be the best one can get.

</Text>
  </row>
  <row>
    <Id>1112</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>605</PostId>
    <RevisionGUID>0b236932-95b7-44c7-809f-22a8d11cd3f3</RevisionGUID>
    <CreationDate>2010-04-08T11:36:07.023</CreationDate>
    <IPAddress>121.120.100.208</IPAddress>
    <UserId>215</UserId>
    <Text>Where can I find the genomic GC content of fungal species? Thanks</Text>
  </row>
  <row>
    <Id>1113</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>605</PostId>
    <RevisionGUID>0b236932-95b7-44c7-809f-22a8d11cd3f3</RevisionGUID>
    <CreationDate>2010-04-08T11:36:07.023</CreationDate>
    <IPAddress>121.120.100.208</IPAddress>
    <UserId>215</UserId>
    <Text>GC content fungal</Text>
  </row>
  <row>
    <Id>1114</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>605</PostId>
    <RevisionGUID>0b236932-95b7-44c7-809f-22a8d11cd3f3</RevisionGUID>
    <CreationDate>2010-04-08T11:36:07.023</CreationDate>
    <IPAddress>121.120.100.208</IPAddress>
    <UserId>215</UserId>
    <Text> égcà  écontentà </Text>
  </row>
  <row>
    <Id>1115</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>606</PostId>
    <RevisionGUID>4e8297ac-43b4-4d5d-9b4d-8a3f74e64230</RevisionGUID>
    <CreationDate>2010-04-08T11:45:00.973</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Just had a look at a pubmed search for "Helicos" (14 hits) . The idea of being able to sequence RNA directly is promising. However to me this seems more like big marketing fuzz than real science. I didn't find an independent publication using Helicos, seemingly at present only Helicos uses/can use Helicos, at least what I saw all the Nature papers were "tightly affiliated" to the company. If there is one independent, please put it here. This at least would qualify for 3rd generation, in the sense of "not ready yet". </Text>
  </row>
  <row>
    <Id>1116</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>607</PostId>
    <RevisionGUID>ffacc8d9-90dd-4682-be90-88e501aedb9a</RevisionGUID>
    <CreationDate>2010-04-08T13:14:15.45</CreationDate>
    <IPAddress>82.41.77.33</IPAddress>
    <UserId>169</UserId>
    <Text>The quick answer is that you can find the whole genome sequence for the organism of choice (assuming it has been sequenced) at NCBI and then click on the accession. For example http://www.ncbi.nlm.nih.gov/sites/entrez?Db=genome&amp;Cmd=ShowDetailView&amp;TermToSearch=5883, note the GC content has been calculated.

Alternatively you might want to take a look at this web page http://insilico.ehu.es/oligoweb/index2.php?m=all which lists a lot of genomes with their corresponding GC content. I guess you might not be quite so confident that this page is as up to date as the latest sequence entries at NCBI.</Text>
  </row>
  <row>
    <Id>1117</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>608</PostId>
    <RevisionGUID>03b4977c-452d-4926-8bc8-3c9d591673b5</RevisionGUID>
    <CreationDate>2010-04-08T13:34:31.22</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>After performing a GLM in R, I get back a set of p-values. Does anybody know whether these p-values still need to be adjusted using `p.adjust` or similar to account for repeated hypothesis testing or is this already accounted for by the GLM? If the values need to be corrected, which adjustment method(s) are suitable/recommended?</Text>
  </row>
  <row>
    <Id>1118</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>608</PostId>
    <RevisionGUID>03b4977c-452d-4926-8bc8-3c9d591673b5</RevisionGUID>
    <CreationDate>2010-04-08T13:34:31.22</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text>Do p-values from a Generalised Linear Model need correction for multiple testing?</Text>
  </row>
  <row>
    <Id>1119</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>608</PostId>
    <RevisionGUID>03b4977c-452d-4926-8bc8-3c9d591673b5</RevisionGUID>
    <CreationDate>2010-04-08T13:34:31.22</CreationDate>
    <IPAddress>130.60.200.87</IPAddress>
    <UserId>119</UserId>
    <Text> érà  éstatisticsà  ésignificanceà  églmà </Text>
  </row>
  <row>
    <Id>1120</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>609</PostId>
    <RevisionGUID>02d7b957-a931-4018-a160-7d5292a921e0</RevisionGUID>
    <CreationDate>2010-04-08T13:47:43.03</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi there,

There's a lot of new technologies just about to come to market. To name a few of the ones already with some benchmarks:

- [Pacific Biosciences][1]
- [Oxford Nanopore][2]
- [Ion Torrent][3]
- [Polonator][4]

By definition, Heliscope is still a 2nd gen. It uses the same technology (very sensitive/fast with high resolution CCD and reaction/synthesis followed by light emission). There's no real science on Heliscope yet because it's quite expensive (~U$ 1M, just the equip). But, as RIKEN acquired four of them, I believe they're worth the try. Just to mention, anyone can follow high throughput tech on this clever assembled [map][5]. 

PacBio, Nanopore and Ion Torrent are real 3rd gen. They use a completely different approach. And Ion Torrent is truly amazing !!!

There a lot of discussion about 3rd gen in [SeqAnswers][6] in topics about the [AGBT][7] meeting.

In my opinion, Polonator is the most overlooked one. Despite being 2nd gen, it's open hardware approach ensues the possibility of transforming it on a heliscope-like machine or in a ion torrent-like.


[1]: http://www.pacificbiosciences.com/
[2]: http://www.nanoporetech.com/
[3]: http://www.iontorrent.com/
[4]: http://www.polonator.org/
[5]: http://pathogenomics.bham.ac.uk/hts/
[6]: http://seqanswers.com/
[7]: http://agbt.org/</Text>
  </row>
  <row>
    <Id>1121</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>610</PostId>
    <RevisionGUID>05085887-89e2-48a3-9d6f-7b9994cf463e</RevisionGUID>
    <CreationDate>2010-04-08T14:49:43.31</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>There was a message on the Bioconductor mailing list last month describing a workflow for doing this in R:

https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2010-March/000976.html

Made up of 3 tools, 2 of which are in Bioconductor devel:

* PICS (ChIP-seq): I don't think this is in Bioconductor yet: http://www.rglab.org/pics-probabilistic-inference-for-chip-seq/

* rGADEM (motif discovery): http://bioconductor.org/packages/devel/bioc/html/rGADEM.html

* MotIV (motif validation): http://bioconductor.org/packages/devel/bioc/html/MotIV.html
</Text>
  </row>
  <row>
    <Id>1122</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>611</PostId>
    <RevisionGUID>f86177f9-38ee-4da7-9957-f1790c294fe8</RevisionGUID>
    <CreationDate>2010-04-08T16:39:33.107</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Hi PhiS,

When doing multiple regressions in R, you are typically doing one regression at a time, and repeat the process multiple times, while storing the p-values. If these test (the regressions) are indeed 'multiple test', then you do have the responsibility to do some form of correction, as the regression function you used is 'unaware' of the fact that you were doing many of these test, side by side.

In these cases, many options are offered to you, the most stringent being the infamous Bonferoni correction and the least stringent being the False Discovery Rate (FDR), which is very appropriate for large numbers of parallel testing.

The package Qvalue is available to install in R and would provide you with a method for doing such a FDR correction. Beware that this approach may be inappropriate for small (maybe lower than 50 or 30) parallel tests since it uses the distribution of p-values in the correction.

Hope this helps you!</Text>
  </row>
  <row>
    <Id>1123</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>612</PostId>
    <RevisionGUID>b6a51bc9-9389-49c1-96e5-abc0f2c3858b</RevisionGUID>
    <CreationDate>2010-04-08T16:54:00.35</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>We are using a non-free solution, the CLC Genomic Workbench. This software has MANY capabilities. In the role you are asking about, it would easily assemble millions and millions of short reads (given enough RAM, and, of course, a 64bit system to use it). You can easily put in data from different taxa, specify different criteria for the assembly, or alternatively, use a reference genome to assemble your data on, so as to potentially get a less messy result (less influenced by sequence divergence, paralogy...).

This software could be somewhat pricey for a small lab, but in the context of a group of research, I have found that it was many times worth it's price just in time saved on student projects.

The sortware also has A LOT of features for biologists working with sequences. Not only assembling NGS data.

DISCLAIMER (just in case...): I am IN NOW WAY connected to this company. I just happen to be a happy user :)

Cheers.</Text>
  </row>
  <row>
    <Id>1124</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>613</PostId>
    <RevisionGUID>659695a5-e162-4862-8ce5-96ea420d9edf</RevisionGUID>
    <CreationDate>2010-04-08T17:06:00.54</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text>After [you've mapped your short reads on a reference sequence][1], what is your favorite method/workflow to detect some (new) SNP/insertions/deletions. Did you compare various strategies ?

On my side, [I played with MAQ/SAM/BWA][2] but I wonder if there is 'widely' adopted (robust) workflow to find some new SNPs.

Thanks
Pierre


  [1]: http://biostar.stackexchange.com/questions/137
  [2]: http://plindenbaum.blogspot.com/2010/04/bam-bwa-and-samtools-my-notebook.html</Text>
  </row>
  <row>
    <Id>1125</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>613</PostId>
    <RevisionGUID>659695a5-e162-4862-8ce5-96ea420d9edf</RevisionGUID>
    <CreationDate>2010-04-08T17:06:00.54</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text>What methods do you use for In/Del/SNP calling?</Text>
  </row>
  <row>
    <Id>1126</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>613</PostId>
    <RevisionGUID>659695a5-e162-4862-8ce5-96ea420d9edf</RevisionGUID>
    <CreationDate>2010-04-08T17:06:00.54</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text> ésequencingà  éshortöreadöalignerà  ésnpà  ébaseöcallingà </Text>
  </row>
  <row>
    <Id>1127</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>614</PostId>
    <RevisionGUID>c334909f-e3cc-45ba-bafb-97dcebb0a2f5</RevisionGUID>
    <CreationDate>2010-04-08T17:17:02.483</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text>After you've mapped your short reads and found [some new/old mutations][1], how would you select a list of candidate genes for a given genetic disease ?

For example, there is [SIFT][2] : 

&gt; SIFT  predicts whether an amino acid
&gt; substitution affects protein function 
&gt; based on sequence homology and the
&gt; physical properties of amino acids.

did you try any other tool ? do those tools give the same results ?


  [1]: http://biostar.stackexchange.com/questions/613
  [2]: http://sift.jcvi.org/</Text>
  </row>
  <row>
    <Id>1128</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>614</PostId>
    <RevisionGUID>c334909f-e3cc-45ba-bafb-97dcebb0a2f5</RevisionGUID>
    <CreationDate>2010-04-08T17:17:02.483</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text>What methods do you use to select somes genes from a list of mutation ?</Text>
  </row>
  <row>
    <Id>1129</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>614</PostId>
    <RevisionGUID>c334909f-e3cc-45ba-bafb-97dcebb0a2f5</RevisionGUID>
    <CreationDate>2010-04-08T17:17:02.483</CreationDate>
    <IPAddress>82.126.83.97</IPAddress>
    <UserId>30</UserId>
    <Text> ésnpà  épredictionà  émutationà  égeneà  éselectionà </Text>
  </row>
  <row>
    <Id>1130</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>615</PostId>
    <RevisionGUID>fb0dabc1-9c15-479e-aa0b-eadbe1602a63</RevisionGUID>
    <CreationDate>2010-04-08T17:18:13.963</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text>I'm doing some work with exon expression arrays for the first time (Affy HuEx 1.0), and I was wondering what analysis packages or tools exist.  Specifically, I'm looking to identify truncated genes, where the last few exons are missing.


I've found 'exonmap' in the bioconductor repository - are there are others? What experiences have you had with them?</Text>
  </row>
  <row>
    <Id>1131</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>615</PostId>
    <RevisionGUID>fb0dabc1-9c15-479e-aa0b-eadbe1602a63</RevisionGUID>
    <CreationDate>2010-04-08T17:18:13.963</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text>Exon Array analysis tools</Text>
  </row>
  <row>
    <Id>1132</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>615</PostId>
    <RevisionGUID>fb0dabc1-9c15-479e-aa0b-eadbe1602a63</RevisionGUID>
    <CreationDate>2010-04-08T17:18:13.963</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text> éexonarrayà  éexpressionà  émicroarrayà  étoolà </Text>
  </row>
  <row>
    <Id>1133</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>611</PostId>
    <RevisionGUID>c6d5d543-b6b1-4d83-9d90-2b28862a7f67</RevisionGUID>
    <CreationDate>2010-04-08T17:27:34.77</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>corrected typos</Comment>
    <Text>Hi PhiS,

When doing multiple regressions in R, you are typically doing one regression at a time, and repeating the process multiple times, while storing the p-values. If these tests (the regressions) are indeed 'multiple tests', then you do have the responsibility to do some form of correction, as the regression function you used is 'unaware' of the fact that you were doing many of these tests, side by side.

In this case, many options are offered to you, the most stringent being the infamous Bonferoni correction and the least stringent being the False Discovery Rate (FDR), which is very appropriate for large numbers of parallel testing.

The package Qvalue is available to install in R and would provide you with a method for doing such a FDR correction. Beware that this approach may be inappropriate for small (maybe lower than 50 or 30) parallel tests since it uses the distribution of p-values in the correction.

Hope this helps you!</Text>
  </row>
  <row>
    <Id>1134</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>616</PostId>
    <RevisionGUID>ff46e525-8f99-4c89-ac4b-da6871fdbcf7</RevisionGUID>
    <CreationDate>2010-04-08T17:29:35.767</CreationDate>
    <IPAddress>218.186.8.237</IPAddress>
    <UserId>91</UserId>
    <Text>I use [Affymetrix Power Tools][1] (APT), which are pretty nice when you have figured out how to use them (it took a while for me..) Before that, I was using [exonmap][2] for R, but I found it a bit slow on my puny laptop. I think it also required the installation of a huge index. Both APT and exonmap are nice in their own ways.


  [1]: http://www.affymetrix.com/support/developer/powertools/index.affx
  [2]: http://rss.acs.unt.edu/Rdoc/library/exonmap/html/00Index.html</Text>
  </row>
  <row>
    <Id>1135</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>2ad27e4b-a1f9-4012-9fb0-c37347ae5227</RevisionGUID>
    <CreationDate>2010-04-08T17:37:31.853</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Hi,

I'm interested in seeing your favorite bit of Python code that you programmed for bioinformatics purposes.

It can be a function, class, parser, you name it!

Cheers to you pythoneers!</Text>
  </row>
  <row>
    <Id>1136</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>2ad27e4b-a1f9-4012-9fb0-c37347ae5227</RevisionGUID>
    <CreationDate>2010-04-08T17:37:31.853</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Post your prefered bioinformatics short Python code</Text>
  </row>
  <row>
    <Id>1137</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>2ad27e4b-a1f9-4012-9fb0-c37347ae5227</RevisionGUID>
    <CreationDate>2010-04-08T17:37:31.853</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text> épythonà  ébioinformaticsà </Text>
  </row>
  <row>
    <Id>1138</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>2ad27e4b-a1f9-4012-9fb0-c37347ae5227</RevisionGUID>
    <CreationDate>2010-04-08T17:37:31.853</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
  </row>
  <row>
    <Id>1139</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>618</PostId>
    <RevisionGUID>f071a6c5-5e1c-4aa3-b570-b5e479814cc2</RevisionGUID>
    <CreationDate>2010-04-08T17:45:08.183</CreationDate>
    <IPAddress>128.249.106.234</IPAddress>
    <UserId>117</UserId>
    <Text>- [PolyPhen](http://genetics.bwh.harvard.edu/pph/) does something similar - predicts whether a mutation will alter protein function

- If you're lucky enough to have multiple samples, recurrence can be a strong indicator of functional importance.</Text>
  </row>
  <row>
    <Id>1140</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>619</PostId>
    <RevisionGUID>1af218d4-f5ff-4e24-ba49-5fc33c278131</RevisionGUID>
    <CreationDate>2010-04-08T18:02:51.977</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>Mosaik for alignment and GigaBayes(PbShort) has worked well for me in the past:

http://bioinformatics.bc.edu/marthlab/Mosaik

http://bioinformatics.bc.edu/marthlab/PbShort

For my next SNP project will be using Broad's Genome Analysis Toolkit (GATK):

http://www.broadinstitute.org/gsa/wiki/index.php/The_Genome_Analysis_Toolkit
</Text>
  </row>
  <row>
    <Id>1141</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>620</PostId>
    <RevisionGUID>252fc7e1-1794-4973-8b54-1eac8c874ea5</RevisionGUID>
    <CreationDate>2010-04-08T18:18:22.66</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Here is my own example. Although simplistic, I have used the following FASTA parser numerous times. Quick and dirty, it produces a list of lists. Each of the inner lists contains two strings, one with the sequence name and the other with the sequence itself. Here it is:

    def read_fasta(path):
    
        """
        Read FASTA file into a list of lists.
        Each inner list contains a name and a sequence.
        
        """
        out = []
        line_counter = -1
        with open(path) as file_:
            for line in file_:
                if line.startswith("&gt;"):
                    contig_name = line.split()[0]
                    contig_seq = ""
                    out.append([contig_name, contig_seq])
                else:
                    out[line_counter][1] += line.rstrip()
        return out

Cheers!</Text>
  </row>
  <row>
    <Id>1142</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>620</PostId>
    <RevisionGUID>252fc7e1-1794-4973-8b54-1eac8c874ea5</RevisionGUID>
    <CreationDate>2010-04-08T18:18:22.66</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1143</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>621</PostId>
    <RevisionGUID>f6e0e0d0-2e55-44f0-a113-540d5f820196</RevisionGUID>
    <CreationDate>2010-04-08T18:21:40.097</CreationDate>
    <IPAddress>132.216.77.22</IPAddress>
    <UserId>217</UserId>
    <Text>We use [samtools pileup+varfilter][2] with [SNVmix][1] to filter 'valid' SNPs (it all depends on coverage and experiment.


[1]: http://compbio.bccrc.ca/?page_id=204
[2]: http://samtools.sourceforge.net/samtools.shtml</Text>
  </row>
  <row>
    <Id>1144</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>622</PostId>
    <RevisionGUID>b7c7a1aa-8f8a-4287-8824-179763a120ea</RevisionGUID>
    <CreationDate>2010-04-08T19:19:20.43</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text>I've got a large collection of trace sequence files which are in .ab1 file format.  I need to import the TRACE DATA (not just the base-calls) into Matlab.  Matlab has an scf reader so I though it would be easy to find a little tool that could convert ab1 files to scf files, but alas.

 - I've tried SeqVerter (doesn't output in trace format only base-calls)
 - DNA Baser (doesn't install)
 - Staden (can't get to install)

Any suggestions,
Thanks
Will
</Text>
  </row>
  <row>
    <Id>1145</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>622</PostId>
    <RevisionGUID>b7c7a1aa-8f8a-4287-8824-179763a120ea</RevisionGUID>
    <CreationDate>2010-04-08T19:19:20.43</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text>Converting ab1 trace files into scf trace files</Text>
  </row>
  <row>
    <Id>1146</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>622</PostId>
    <RevisionGUID>b7c7a1aa-8f8a-4287-8824-179763a120ea</RevisionGUID>
    <CreationDate>2010-04-08T19:19:20.43</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Text> ésequenceà  éconversionà </Text>
  </row>
  <row>
    <Id>1147</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>622</PostId>
    <RevisionGUID>ae8b32b7-44a0-49dd-b29e-08eb5ae60e70</RevisionGUID>
    <CreationDate>2010-04-08T19:36:42.007</CreationDate>
    <IPAddress>129.25.28.15</IPAddress>
    <UserId>122</UserId>
    <Comment>added 46 characters in body</Comment>
    <Text>I've got a large collection of trace sequence files which are in .ab1 file format.  I need to import the TRACE DATA (not just the base-calls) into Matlab.  Matlab has an scf reader so I though it would be easy to find a little tool that could convert ab1 files to scf files, but alas.

 - I've tried SeqVerter (doesn't output in trace format only base-calls)
 - DNA Baser (doesn't install)
 - Staden (can't get to install)
 - Tried abiparser.py (error in file format)

Any suggestions,
Thanks
Will
</Text>
  </row>
  <row>
    <Id>1148</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>88c28014-1306-47be-9541-c69208b2407d</RevisionGUID>
    <CreationDate>2010-04-08T19:47:52.567</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 47 characters in body; edited title</Comment>
    <Text>Hi,

I'm interested in seeing your favorite bit of code that you programmed yourself for bioinformatics purposes.

It can be a function, class, parser, you name it! Mention the language you coded it in.

Cheers to you bioinformaticians!</Text>
  </row>
  <row>
    <Id>1149</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>88c28014-1306-47be-9541-c69208b2407d</RevisionGUID>
    <CreationDate>2010-04-08T19:47:52.567</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 47 characters in body; edited title</Comment>
    <Text>Post your prefered bioinformatics short code</Text>
  </row>
  <row>
    <Id>1150</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>620</PostId>
    <RevisionGUID>baa4ebd4-6cf2-4c8c-9734-4ef7319494d3</RevisionGUID>
    <CreationDate>2010-04-08T19:48:37.84</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 15 characters in body</Comment>
    <Text>Here is my own example. Although simplistic, I have used the following FASTA parser numerous times. Code quick and dirty in Python, it produces a list of lists. Each of the inner lists contains two strings, one with the sequence name and the other with the sequence itself. Here it is:

    def read_fasta(path):
    
        """
        Read FASTA file into a list of lists.
        Each inner list contains a name and a sequence.
        
        """
        out = []
        line_counter = -1
        with open(path) as file_:
            for line in file_:
                if line.startswith("&gt;"):
                    contig_name = line.split()[0]
                    contig_seq = ""
                    out.append([contig_name, contig_seq])
                else:
                    out[line_counter][1] += line.rstrip()
        return out

Cheers!</Text>
  </row>
  <row>
    <Id>1151</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>623</PostId>
    <RevisionGUID>0dd726c3-e323-4efa-b669-9c5ca74cdcf6</RevisionGUID>
    <CreationDate>2010-04-08T19:50:37.497</CreationDate>
    <IPAddress>81.62.176.166</IPAddress>
    <UserId>119</UserId>
    <Text>I think Bioperl should have this functionality. The `Bio::SeqIO` [documentation][1] states it can handle both ABI/AB1 and SCF trace file formats.


  [1]: http://doc.bioperl.org/releases/bioperl-1.4/Bio/SeqIO.html

</Text>
  </row>
  <row>
    <Id>1152</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>623</PostId>
    <RevisionGUID>7edfc352-f61b-47e3-a66f-bc1d03370650</RevisionGUID>
    <CreationDate>2010-04-08T19:58:51.6</CreationDate>
    <IPAddress>81.62.176.166</IPAddress>
    <UserId>119</UserId>
    <Comment>Added info on ABI Data Collection software and format specification</Comment>
    <Text>I think Bioperl should have this functionality. The `Bio::SeqIO` [documentation][1] states it can handle both ABI/AB1 and SCF trace file formats.

Also, if you have access to an ABI Sequencer, the current version of the Data Collection software can be made to write .scf files in addition to .ab1 files. And if you ever wish to do anything really funky with ABI raw files, ABI provides the full specification for the ABIF file format [here][2].


  [1]: http://doc.bioperl.org/releases/bioperl-1.4/Bio/SeqIO.html
  [2]: http://www.appliedbiosystems.com/support/software_community/ABIF_File_Format.pdf</Text>
  </row>
  <row>
    <Id>1153</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>624</PostId>
    <RevisionGUID>b4a96280-eb2a-4d8f-8089-2674c81d6241</RevisionGUID>
    <CreationDate>2010-04-08T21:14:47.427</CreationDate>
    <IPAddress>77.170.91.52</IPAddress>
    <UserId>115</UserId>
    <Text>This works for me (5 minutes ago on OSX) :

 - Download the source for iolib : http://sourceforge.net/projects/staden/files/io_lib/1.12.2/io_lib-1.12.2.tar.gz/download
 - Extract
 - Compile (read README if you need help with that)
 - This gives me convert_trace in the progs subdirectory
 - Using the info at http://staden.sourceforge.net/manual/manpages_unix_1.html, I converted a abi file to scf, using this commandline:

`./convert_trace -out_format scf &lt; trace.ab1  &gt; trace.scf`

After conversion I viewed both in a trace viewer(FinchTV), and they looked the same.</Text>
  </row>
  <row>
    <Id>1154</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>624</PostId>
    <RevisionGUID>d629fc1f-dcce-4958-ab6b-9b86a3b5350f</RevisionGUID>
    <CreationDate>2010-04-08T21:21:46.46</CreationDate>
    <IPAddress>77.170.91.52</IPAddress>
    <UserId>115</UserId>
    <Comment>added 1 characters in body</Comment>
    <Text>This works for me (5 minutes ago on OSX) :

 - Download the source for iolib : http://sourceforge.net/projects/staden/files/io_lib/1.12.2/io_lib-1.12.2.tar.gz/download
 - Extract
 - Compile (read README if you need help with that)
 - This gives me convert_trace in the progs subdirectory
 - Using the info at http://staden.sourceforge.net/manual/manpages_unix_1.html, I converted an abi file to scf, using this commandline:

`./convert_trace -out_format scf &lt; trace.ab1  &gt; trace.scf`

After conversion I viewed both in a trace viewer(FinchTV), and they looked the same.</Text>
  </row>
  <row>
    <Id>1155</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>625</PostId>
    <RevisionGUID>d330ab86-7bfc-4184-81eb-7bd23d55d988</RevisionGUID>
    <CreationDate>2010-04-08T21:22:46.517</CreationDate>
    <IPAddress>81.147.37.71</IPAddress>
    <UserId>218</UserId>
    <Text>Something to think about is whether you really want to do *de-novo* motif finding. It sounds like you already know what you are looking for so maybe doing pattern matching with a consensus or matrix would be better? The benefits of this are that it is far less computationally intensive and you can easily incorporate rank information. For example you could look to see how the enrichment of PWMs change down your rank list. You could either do with this with all matrices from Jaspar, for example, or a selected set, which would limit the needs for correction for multiple testing.

 Unless you are going to follow up on a novel motif discovered by *de-novo* methods pattern matching often gives faster and easier to interpret results. 

 There are lots of tools available for this, though no web-based tools really handle chIPseq scale data or rank information effectively. I would user either [patser][1] wrapped in perl or R, or [Biostrings][2] in R. [MotIV][3] might be worth looking at too. 


  [1]: http://ural.wustl.edu/software.html
  [2]: http://www.bioconductor.org/packages/release/bioc/html/Biostrings.html
  [3]: http://www.bioconductor.org/packages/devel/bioc/html/MotIV.html</Text>
  </row>
  <row>
    <Id>1156</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>626</PostId>
    <RevisionGUID>ea74fcb6-5085-4c5d-9fc0-8cfc0bf80bb6</RevisionGUID>
    <CreationDate>2010-04-08T21:39:50.543</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>A bioperl solution extremely simple for a multi seq abi file, tested in every OS you can imagine:


     use Bio::SeqIO;
    
     $in = shift or die;
     $out = shift or die;
    
     $seq_in = Bio::SeqIO-&gt;new('-file' =&gt; "&lt;$in", '-format' =&gt; "abi");
     $seq_out = Bio::SeqIO-&gt;new('-file' =&gt; "&gt;$out", '-format' =&gt; "scf");
    
     while ($seq = $seq_in-&gt;next_seq) {
    
           $seq_out-&gt;write_seq($seq);
    
     }

Of course, it's bioperl. So, check the consistency of your result.

</Text>
  </row>
  <row>
    <Id>1157</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>627</PostId>
    <RevisionGUID>869ebbba-7717-4a6a-a197-1a72771596e3</RevisionGUID>
    <CreationDate>2010-04-08T21:54:05.923</CreationDate>
    <IPAddress>81.147.37.71</IPAddress>
    <UserId>218</UserId>
    <Text>I would vote for [IGB][1] (Integrated Genome Browser). It can handle a large number of tracks and large genome scale data sets. It is highly configurable and very fast. You can also talk to it via some ports . I sometimes generate excel files with hyperlinks that make IGB jump to specific locations, which can be really useful. So you can have an excel sheet with a list of genes which you can click in one window and IGB jumps to that gene. 

 Another great feature is the ability to do data manipulation, such as merging tracks using logic, to get overlapping or unique features. You can also do things like log2 transformations. 


  [1]: http://www.bioviz.org/igb/</Text>
  </row>
  <row>
    <Id>1158</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>620</PostId>
    <RevisionGUID>68a45458-0988-4826-9e3c-61fc2eb85118</RevisionGUID>
    <CreationDate>2010-04-09T00:52:32.28</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Comment>code modif</Comment>
    <Text>Here is my own example. Although simplistic, I have used the following FASTA parser numerous times. Code quick and dirty in Python, it produces a list of lists. Each of the inner lists contains two strings, one with the sequence name and the other with the sequence itself. Here it is:

    def read_fasta(path):
    
        """
        Read FASTA file into a list of lists.
        Each inner list contains a name and a sequence.
        
        """
        out = []
        last_record = -1
        with open(path) as file_:
            for line in file_:
                if line.startswith("&gt;"):
                    contig_name = line.split()[0]
                    contig_seq = ""
                    out.append([contig_name, contig_seq])
                else:
                    out[last_record][1] += line.rstrip()
        return out

Cheers!</Text>
  </row>
  <row>
    <Id>1159</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>628</PostId>
    <RevisionGUID>6fd33365-c682-43ae-89da-e18baed962ce</RevisionGUID>
    <CreationDate>2010-04-09T01:12:03.76</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text>Hi,

I am working on a few projects right now using 454 cDNA data. For these projects, we have made the sequence libraries ourselves in order that each (in fact, about 97%) of the sequences posses a tag that allows us to identify the individual from which it comes. We can have, let's say, 20 individuals, all tagged using 10 coded nucleotides that are placed at the beginning of the sequence by being part of the primers.

I then scan through the .fasta file using a Python program I made to change the names of the sequences to represent the tag found in the sequence (eg: Tag01) and remove any primers present. With these sequences, we do a *de novo* alignment, and then we re-align the sequences to the consensus contigs created in the *de novo* part. We then export the alignements in ACE format, which I parse using Biopython to FASTA format. Then, the fun begins :)

Using a list of SNP positions and contig numbers, I extract the genotypes from each sequence with another Python program I made. I'll then have to parse my result to do the rest of the job (stats and further analysis). I also do sequence counts for each of the tags in order to do gene expression (remember this is from cDNA) with these data.

My question is. **How would you do the SNP individual genotyping?** I really like the Python coding part, but I wonder if there is not an already made solution for just that.

Thanks!</Text>
  </row>
  <row>
    <Id>1160</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>628</PostId>
    <RevisionGUID>6fd33365-c682-43ae-89da-e18baed962ce</RevisionGUID>
    <CreationDate>2010-04-09T01:12:03.76</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text>SNP detection and genotyping in NGS (Next Generation Sequencing)</Text>
  </row>
  <row>
    <Id>1161</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>628</PostId>
    <RevisionGUID>6fd33365-c682-43ae-89da-e18baed962ce</RevisionGUID>
    <CreationDate>2010-04-09T01:12:03.76</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text> épythonà  énextögenerationösequencinà  ésnpà  égenotypingà </Text>
  </row>
  <row>
    <Id>1162</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>629</PostId>
    <RevisionGUID>777983b6-3511-46f4-a68f-c1830a4cbff5</RevisionGUID>
    <CreationDate>2010-04-09T01:22:06.343</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text>Hi Pierre,

I am sorry that I cannot answer precisely to your question since I am not familiar with fastPHASE. However, here is a website with some information about HaploBlock, which claims to be able to do haplotype construction. The site also has a section with additional information and links, including a link to the huge HapMap project and other software of interest.

Hope it can be of use. I'll ask around the lab tomorrow to see if anybody is more acquainted with haplotype construction than I am.

Cheers!</Text>
  </row>
  <row>
    <Id>1163</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>628</PostId>
    <RevisionGUID>97cb2642-5301-4072-89ed-d86f094e54bf</RevisionGUID>
    <CreationDate>2010-04-09T01:24:51.147</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> épythonà  énextögenösequencingà  ésnpà  égenotypingà </Text>
  </row>
  <row>
    <Id>1164</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>620</PostId>
    <RevisionGUID>e050d4e1-f756-4d9f-87ee-315e0c9f4bed</RevisionGUID>
    <CreationDate>2010-04-09T02:12:39.243</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Comment>added 1 characters in body</Comment>
    <Text>Here is my own example. Although simplistic, I have used the following FASTA parser numerous times. Coded quick and dirty in Python, it produces a list of lists. Each of the inner lists contains two strings, one with the sequence name and the other with the sequence itself. Here it is:

    def read_fasta(path):
    
        """
        Read FASTA file into a list of lists.
        Each inner list contains a name and a sequence.
        
        """
        out = []
        last_record = -1
        with open(path) as file_:
            for line in file_:
                if line.startswith("&gt;"):
                    contig_name = line.split()[0]
                    contig_seq = ""
                    out.append([contig_name, contig_seq])
                else:
                    out[last_record][1] += line.rstrip()
        return out

Cheers!</Text>
  </row>
  <row>
    <Id>1165</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>630</PostId>
    <RevisionGUID>e93a02aa-0849-4448-bf30-ce45102dab21</RevisionGUID>
    <CreationDate>2010-04-09T02:16:52.16</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text>Hi,

I want to convert an ACE file containing data about contigs following alignment of 454 data to a FASTA alignment file.

What method would you suggest?

Thanks!</Text>
  </row>
  <row>
    <Id>1166</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>630</PostId>
    <RevisionGUID>e93a02aa-0849-4448-bf30-ce45102dab21</RevisionGUID>
    <CreationDate>2010-04-09T02:16:52.16</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text>Parsing ACE file to FASTA formated alignement</Text>
  </row>
  <row>
    <Id>1167</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>630</PostId>
    <RevisionGUID>e93a02aa-0849-4448-bf30-ce45102dab21</RevisionGUID>
    <CreationDate>2010-04-09T02:16:52.16</CreationDate>
    <IPAddress>74.13.160.49</IPAddress>
    <UserId>216</UserId>
    <Text> éfastaà  éaceà  éparsingà  éconversionà </Text>
  </row>
  <row>
    <Id>1168</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>631</PostId>
    <RevisionGUID>3762b4d3-2a40-40dc-98da-1d3c6d837d06</RevisionGUID>
    <CreationDate>2010-04-09T02:57:26.983</CreationDate>
    <IPAddress>124.82.231.62</IPAddress>
    <UserId>185</UserId>
    <Text>did anybody use blast2go which map the interpro and blast hits to GO term?</Text>
  </row>
  <row>
    <Id>1169</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>588e5ec9-4870-48a4-af92-42ccb97559e0</RevisionGUID>
    <CreationDate>2010-04-09T08:54:00.377</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Tried PHRED http://www.phrap.com/phred/ ? 
Btw, are you sure about which data you have in which format?</Text>
  </row>
  <row>
    <Id>1170</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>cab1f9d1-e330-4764-853a-c8be5c2b1e62</RevisionGUID>
    <CreationDate>2010-04-09T08:58:37.56</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>55</UserId>
    <Text>[{"Id":55,"DisplayName":"Michael Dondrup"}]</Text>
  </row>
  <row>
    <Id>1171</Id>
    <PostHistoryTypeId>13</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>384f409f-3fa2-42df-90eb-193fb345fd7a</RevisionGUID>
    <CreationDate>2010-04-09T09:01:55.977</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>55</UserId>
    <Text>[{"Id":55,"DisplayName":"Michael Dondrup"}]</Text>
  </row>
  <row>
    <Id>1172</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>0d96137a-2909-42ec-a6c9-52a6b267635a</RevisionGUID>
    <CreationDate>2010-04-09T09:02:23.993</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>deleted 1 characters in body</Comment>
    <Text>Tried PHRED&amp;PHRAP http://www.phrap.com ? 
Btw, are you sure about which data you have in which format?</Text>
  </row>
  <row>
    <Id>1173</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>d95bfdc8-cb70-4fdf-ba37-355809091a86</RevisionGUID>
    <CreationDate>2010-04-09T09:24:13.123</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added 78 characters in body</Comment>
    <Text>Tried PHRED&amp;PHRAP http://www.phrap.com ? 
Also, Newbler should have an option to give you a fasta file after assembly.
Btw, are you sure about which data you have in which format?</Text>
  </row>
  <row>
    <Id>1174</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>633</PostId>
    <RevisionGUID>c0f254bb-4904-48fd-8cee-5cf3ac918fa1</RevisionGUID>
    <CreationDate>2010-04-09T11:06:22.417</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>Regarding the validity of PFAM predictions. Some studies (e.g. [GISMO (Gene prediction)][1], [CARMA (Phylogenetic classification of environmental metagenomics samples)][2]) have used PFAM domains as input to generate training sets for classification. The underlying assumption: sequences with hits to know protein domains have a high probability of being real protein coding regions. This is at least in my oppinion very much justified and also proven by the high precision of the resulting methods. 




  [1]: http://nar.oxfordjournals.org/cgi/content/full/35/2/540
  [2]: http://nar.oxfordjournals.org/cgi/content/full/36/7/2230</Text>
  </row>
  <row>
    <Id>1175</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>634</PostId>
    <RevisionGUID>20c9bb46-eaa4-414f-beee-96e4afb030d5</RevisionGUID>
    <CreationDate>2010-04-09T12:04:21.687</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Another quick and dirty bioperl solution. Well, not so quick. This script is quite sequential. 

    use Bio::Assembly;
    use Bio::SeqIO;
    use Bio::Seq;
    
    $infile = shift or die;
    $outfile = shift or die;
    
    $seqio_obj = Bio::SeqIO-&gt;new(-file =&gt; "&gt;$outfile", -format =&gt; 'fasta' );
    
    $assembly_obj = Bio::Assembly::IO-&gt;new(-file=&gt;"&lt;$infile", -format=&gt;'ace');
    
    $assembly = $assembly_obj-&gt;next_assembly;
    
    foreach $contig ($assembly-&gt;all_contigs) {
    
    	$seq = $contig-&gt;get_consensus_sequence()
    
    	$seq_obj = Bio::Seq-&gt;new(-seq =&gt; $seq-&gt;seq(),                        
                              -display_id =&gt; "ID_is_always_good",                        
                              -desc =&gt; "Say_smth_about_it",                        
                              -alphabet =&gt; "dna" );
    
    	$seqio_obj-&gt;write_seq($seq_obj);
    
    }

I'm not sure if it works cause I'm without any ACE files. Of course, you can write your own parser as ACE files are very simple in structure, as one can see [here][1].

[1]: http://www.cbcb.umd.edu/research/contig_representation.shtml#ACE

</Text>
  </row>
  <row>
    <Id>1176</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>635</PostId>
    <RevisionGUID>f93ec334-16df-4ddc-a6b7-eaaa60411a93</RevisionGUID>
    <CreationDate>2010-04-09T12:18:36.643</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi everyone,

I'm looking for NGS/Arrays sample datasets for teaching purposes. Most people I know that have this kind of data are somewhat jealous about them. I'm interested in the whole data pipeline. So, raw data is very much wanted too. Don't need to be a huge dataset, just a very illustrative one. If you know where can I find any, please, let me know too !!!</Text>
  </row>
  <row>
    <Id>1177</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>635</PostId>
    <RevisionGUID>f93ec334-16df-4ddc-a6b7-eaaa60411a93</RevisionGUID>
    <CreationDate>2010-04-09T12:18:36.643</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Where can I find NGS/Arrays sample datasets?</Text>
  </row>
  <row>
    <Id>1178</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>635</PostId>
    <RevisionGUID>f93ec334-16df-4ddc-a6b7-eaaa60411a93</RevisionGUID>
    <CreationDate>2010-04-09T12:18:36.643</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text> éngsà  éarraysà  édatasetà  éteachingà </Text>
  </row>
  <row>
    <Id>1179</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>628</PostId>
    <RevisionGUID>5a039374-f080-4b7e-afc4-c3a011f2784b</RevisionGUID>
    <CreationDate>2010-04-09T12:21:26.503</CreationDate>
    <IPAddress>74.13.149.124</IPAddress>
    <UserId>216</UserId>
    <Comment>changed de novo 'alignment' for 'assembly"</Comment>
    <Text>Hi,

I am working on a few projects right now using 454 cDNA data. For these projects, we have made the sequence libraries ourselves in order that each (in fact, about 97%) of the sequences posses a tag that allows us to identify the individual from which it comes. We can have, let's say, 20 individuals, all tagged using 10 coded nucleotides that are placed at the beginning of the sequence by being part of the primers.

I then scan through the .fasta file using a Python program I made to change the names of the sequences to represent the tag found in the sequence (eg: Tag01) and remove any primers present. With these sequences, we do a *de novo* assembly, and then we re-align the sequences to the consensus contigs created in the *de novo* part. We then export the alignements in ACE format, which I parse using Biopython to FASTA format. Then, the fun begins :)

Using a list of SNP positions and contig numbers, I extract the genotypes from each sequence with another Python program I made. I'll then have to parse my result to do the rest of the job (stats and further analysis). I also do sequence counts for each of the tags in order to do gene expression (remember this is from cDNA) with these data.

My question is. **How would you do the SNP individual genotyping?** I really like the Python coding part, but I wonder if there is not an already made solution for just that.

Thanks!</Text>
  </row>
  <row>
    <Id>1180</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>630</PostId>
    <RevisionGUID>2ab8b66f-d2db-4d2c-a9d9-1b96a34b6d00</RevisionGUID>
    <CreationDate>2010-04-09T12:23:08.08</CreationDate>
    <IPAddress>74.13.149.124</IPAddress>
    <UserId>216</UserId>
    <Comment>Rephrasing; added 252 characters in body</Comment>
    <Text>Hi,

Following alignment of 454 data, I want to convert an ACE file containing contig data to a FASTA file containing the 'aligned' consensus sequences. By aligned, I mean that each sequence within a contig has the same length. Characters (-) are added as needed on each side of a sequence in order to make it the same length as the consensus sequence from it's contig.

What method would you suggest?

Thanks!</Text>
  </row>
  <row>
    <Id>1181</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>632</PostId>
    <RevisionGUID>46630b24-aca5-4ff9-ae16-166a9ff4a80e</RevisionGUID>
    <CreationDate>2010-04-09T12:51:17.073</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>Consed would do this not phrap. </Comment>
    <Text>Tried PhRED/PHRAP/CONSED http://www.phrap.org/phredphrapconsed.html? 
Actually it would be the consed application that allows you view and edit the 
assembly and to export it. You could also think about using the Newbler pipeline instead of your proprietary pipeline, or a combination of Newbler and Consed. 
 
Also, Newbler should have an option to give you a fasta file after assembly.
</Text>
  </row>
  <row>
    <Id>1182</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>634</PostId>
    <RevisionGUID>2ceebc2a-cc4d-4e9d-885f-a98926a262e2</RevisionGUID>
    <CreationDate>2010-04-09T12:58:46.467</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 144 characters in body</Comment>
    <Text>Another quick and dirty bioperl solution. Well, not so quick. This script is quite sequential. 

    use Bio::Assembly;
    use Bio::SeqIO;
    use Bio::Seq;
    
    $infile = shift or die;
    $outfile = shift or die;
    
    $seqio_obj = Bio::SeqIO-&gt;new(-file =&gt; "&gt;$outfile", -format =&gt; 'fasta' );
    
    $assembly_obj = Bio::Assembly::IO-&gt;new(-file=&gt;"&lt;$infile", -format=&gt;'ace');
    
    $assembly = $assembly_obj-&gt;next_assembly;
    
    foreach $contig ($assembly-&gt;all_contigs) {
    
    	$seq = $contig-&gt;get_consensus_sequence()
    
    	$seq_obj = Bio::Seq-&gt;new(-seq =&gt; $seq-&gt;seq(),                        
                              -display_id =&gt; "ID_is_always_good",                        
                              -desc =&gt; "Say_smth_about_it",                        
                              -alphabet =&gt; "dna" );
    
    	$seqio_obj-&gt;write_seq($seq_obj);
    
    }

I'm not sure if it works cause I'm without any ACE files. Of course, you can write your own parser as ACE files are very simple in structure, as one can see [here][1]. Check out Bio::Assembly methods. There a lot of ready-to-use utilities for size, quality, features, etc. I'll check for a biopython solution.  

[1]: http://www.cbcb.umd.edu/research/contig_representation.shtml#ACE

</Text>
  </row>
  <row>
    <Id>1183</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>636</PostId>
    <RevisionGUID>daa3e69c-5283-46ab-8964-d74c1122756a</RevisionGUID>
    <CreationDate>2010-04-09T13:02:50.67</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Text>How about the NCBI Sequence Reads Archive:

http://www.ncbi.nlm.nih.gov/Traces/home/

And for arrays and RNA-seq (it's a bit hard to find exactly that):

GEO: http://www.ncbi.nlm.nih.gov/geo/
ArrayExpress http://www.ebi.ac.uk/microarray-as/ae/

An illustrative RNA-seq example which is also not too big:
http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE15651</Text>
  </row>
  <row>
    <Id>1184</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>637</PostId>
    <RevisionGUID>24712c89-d215-427f-95b4-a433ff3a1975</RevisionGUID>
    <CreationDate>2010-04-09T13:51:39.82</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>My favorite codes are those that allow me to use powerful algorithms directly from my favorite language without any penalty. Here is such a code using the [bx-python][1] intersecter (a module written by [Brent Pedersen][2]). It intersects 100,000 query intervals with 100,000 reference intervals, each of random size of up to 10,000 spanning a region of 10 million). And it only takes ... drumroll ... 7 seconds!

    import time, random
    from itertools import imap
    from bx.intervals.intersection import Intersecter, Interval
    
    
    def random_interval(x):
        start = random.randint(1, 10**7) 
        end = start + random.randint(1, 10**4) 
        return start, end
    
    # create 100K reference intervals
    source_intervals = imap(random_interval, xrange(10**5))
    
    print "Building:",
    tick = time.time()
    inter = Intersecter()
    for i, ( start, end ) in enumerate( source_intervals ):
        inter.add_interval( Interval( start, end, i ) )
    print time.time( ) - tick
    
    # create 100K query intervals
    query_intervals = imap(random_interval, xrange(10**5))
    
    print "Using:",
    tick = time.time()
    for start, end in query_intervals:
        inter.find( start, end )
    print time.time( ) - tick

The output is:

    ---------- Python 2.5 ----------
    Building: 2.11999988556
    Using: 5.25200009346
    
    Output completed (7 sec consumed) - Normal Termination


  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home
  [2]: http://hackmap.blogspot.com/</Text>
  </row>
  <row>
    <Id>1185</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>637</PostId>
    <RevisionGUID>24712c89-d215-427f-95b4-a433ff3a1975</RevisionGUID>
    <CreationDate>2010-04-09T13:51:39.82</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1186</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>637</PostId>
    <RevisionGUID>8489f2db-5869-4568-b30e-dab5da4060bf</RevisionGUID>
    <CreationDate>2010-04-09T14:04:07.003</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Comment>added 75 characters in body</Comment>
    <Text>My favorite codes are those that allow me to use powerful algorithms directly from my favorite language without any penalty. Here is such a code using the [bx-python][1] intersecter (a module written by [Brent Pedersen][2]). It queries 100,000 times a prebuilt data structure containing 100,000 reference intervals. Each interval is of a random size of up to 10,000 spanning a region of 10 million. And it only takes ... drumroll ... 7 seconds, thus performing at around 50 ms per query!

    import time, random
    from itertools import imap
    from bx.intervals.intersection import Intersecter, Interval
    
    
    def random_interval(x):
        start = random.randint(1, 10**7) 
        end = start + random.randint(1, 10**4) 
        return start, end
    
    # create 100K reference intervals
    source_intervals = imap(random_interval, xrange(10**5))
    
    print "Building:",
    tick = time.time()
    inter = Intersecter()
    for i, ( start, end ) in enumerate( source_intervals ):
        inter.add_interval( Interval( start, end, i ) )
    print time.time( ) - tick
    
    # create 100K query intervals
    query_intervals = imap(random_interval, xrange(10**5))
    
    print "Using:",
    tick = time.time()
    for start, end in query_intervals:
        inter.find( start, end )
    print time.time( ) - tick

The output is:

    ---------- Python 2.5 ----------
    Building: 2.11999988556
    Using: 5.25200009346
    
    Output completed (7 sec consumed) - Normal Termination


  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home
  [2]: http://hackmap.blogspot.com/</Text>
  </row>
  <row>
    <Id>1187</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>563</PostId>
    <RevisionGUID>6c76819b-53b7-456c-8938-43f1edb5ef7f</RevisionGUID>
    <CreationDate>2010-04-09T14:17:15.4</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>148</UserId>
    <Text>[{"Id":148,"DisplayName":"Jarretinha"}]</Text>
  </row>
  <row>
    <Id>1188</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>636</PostId>
    <RevisionGUID>d78a55dd-a713-4cac-943f-202f238a17be</RevisionGUID>
    <CreationDate>2010-04-09T14:24:05.043</CreationDate>
    <IPAddress>129.177.123.4</IPAddress>
    <UserId>55</UserId>
    <Comment>added a link to swift</Comment>
    <Text>How about the NCBI Sequence Reads Archive:

http://www.ncbi.nlm.nih.gov/Traces/home/

And for arrays and RNA-seq (it's a bit hard to find exactly that):

GEO: http://www.ncbi.nlm.nih.gov/geo/
ArrayExpress http://www.ebi.ac.uk/microarray-as/ae/

An illustrative RNA-seq example which is also not too big:
http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE15651

Edit: a link to Illumina raw image data and the SWIFT software:

Found the SWIFT software for primary analysis of Illumina data: http://sgenomics.org/swift/ There's a link to example tile data: http://sgenomics.org/swift/gapipeline.tar.gz. Here's the article: http://bioinformatics.oxfordjournals.org/cgi/content/full/25/17/2194
Maybe the authors know how to get more sample data.

</Text>
  </row>
  <row>
    <Id>1189</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>638</PostId>
    <RevisionGUID>e665ad43-f51d-47fa-9553-19a21a45c8de</RevisionGUID>
    <CreationDate>2010-04-09T17:15:13.7</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text>I often see the word **depth** in the manuals of the tools for NGS, what is its meaning  ?

thanks.</Text>
  </row>
  <row>
    <Id>1190</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>638</PostId>
    <RevisionGUID>e665ad43-f51d-47fa-9553-19a21a45c8de</RevisionGUID>
    <CreationDate>2010-04-09T17:15:13.7</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text>What is the sequencing 'depth' ?</Text>
  </row>
  <row>
    <Id>1191</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>638</PostId>
    <RevisionGUID>e665ad43-f51d-47fa-9553-19a21a45c8de</RevisionGUID>
    <CreationDate>2010-04-09T17:15:13.7</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text> éngsà  ésequencingà </Text>
  </row>
  <row>
    <Id>1192</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>639</PostId>
    <RevisionGUID>61e6070d-6309-437f-99a6-6bcbf0dfdc7c</RevisionGUID>
    <CreationDate>2010-04-09T17:34:42.43</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>I believe it is the same concept as [coverage][1], it might come from a shorthand of saying **depth of coverage**.


  [1]: http://en.wikipedia.org/wiki/Shotgun_sequencing#Coverage</Text>
  </row>
  <row>
    <Id>1193</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>640</PostId>
    <RevisionGUID>f6e3c58f-49f8-4459-a2fe-443d7ea6d837</RevisionGUID>
    <CreationDate>2010-04-09T17:35:48.75</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Sequencing depth represents the (often average) number of nucleotides contributing to a portion of a NGS assembly.

On a genome basis, it means that, on average, each base has been sequenced a certain number of times (10X, 20X...).

For a specific nucleotide, it represents the number of sequences that added information about that nucleotide.

Such depth varies quite a lot depending on the genomic region. In consequence, an average sequencing depth of 30X leaves a lot of small portions of a genome unsequenced while other receive a lot more sequences.

Cheers!</Text>
  </row>
  <row>
    <Id>1194</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>641</PostId>
    <RevisionGUID>39c3ae80-54cc-4465-8168-c69234555bc7</RevisionGUID>
    <CreationDate>2010-04-09T17:58:44.363</CreationDate>
    <IPAddress>128.249.107.38</IPAddress>
    <UserId>117</UserId>
    <Text>It's also worth noting that you can use read depth to infer copy number, given a sufficient number of reads.  On average, you'll get 1.5x more reads from a triploid region than you will from the rest of the diploid genome.</Text>
  </row>
  <row>
    <Id>1195</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>642</PostId>
    <RevisionGUID>0eff5d6e-8d39-4ddf-b0d4-2415685b484d</RevisionGUID>
    <CreationDate>2010-04-09T20:18:14.413</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text>The [FASTQ Format Specification][1] says: 

&gt; Although Solexa/Illumina read file
&gt; looks pretty much like FASTQ, they are
&gt; different in that the qualities are
&gt; scaled differently. In the quality
&gt; string, if you can see a character
&gt; with its ASCII code higher than 90,
&gt; probably your file is in the
&gt; Solexa/Illumina format.

should I care about this when I use some tools such as MAQ, SAMTOOLS, GATK, etc... ?


  [1]: http://maq.sourceforge.net/fastq.shtml</Text>
  </row>
  <row>
    <Id>1196</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>642</PostId>
    <RevisionGUID>0eff5d6e-8d39-4ddf-b0d4-2415685b484d</RevisionGUID>
    <CreationDate>2010-04-09T20:18:14.413</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text>FASTQ qualities for Solexa/Illumina</Text>
  </row>
  <row>
    <Id>1197</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>642</PostId>
    <RevisionGUID>0eff5d6e-8d39-4ddf-b0d4-2415685b484d</RevisionGUID>
    <CreationDate>2010-04-09T20:18:14.413</CreationDate>
    <IPAddress>82.126.13.22</IPAddress>
    <UserId>30</UserId>
    <Text> éngsà  ésequencingà  équalityà  éformatà  éfastqà </Text>
  </row>
  <row>
    <Id>1198</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>643</PostId>
    <RevisionGUID>27d30128-a568-4516-a0c6-011b537c6283</RevisionGUID>
    <CreationDate>2010-04-09T20:37:50.373</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Usually you will need to pass a flag to specify the encoding type. When using the [bowtie][1] aligner for example you will have to pass the flag:

    --phred64-quals


PS. The Illumina software with version prior to 1.3 uses a different formula for producing the quality measures

  [1]: http://bowtie-bio.sourceforge.net/manual.shtml#options</Text>
  </row>
  <row>
    <Id>1199</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>643</PostId>
    <RevisionGUID>6e595c19-a6b3-419c-8c1a-827aa843c03e</RevisionGUID>
    <CreationDate>2010-04-09T20:43:11.527</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Comment>added 42 characters in body; added 14 characters in body</Comment>
    <Text>Usually you will need to pass a flag to specify the encoding type. When using the [bowtie][1] aligner for example you will have to pass the flag:

    --phred64-quals

For some tools you may need to convert them yourself. 

PS. The Illumina software with version prior to 1.3 uses a different formula for producing the quality measures

  [1]: http://bowtie-bio.sourceforge.net/manual.shtml#options</Text>
  </row>
  <row>
    <Id>1200</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>644</PostId>
    <RevisionGUID>c3bcdff7-bb6d-405e-bbb8-83bf6b418efc</RevisionGUID>
    <CreationDate>2010-04-09T21:06:04.593</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>Simulate your own and be merry.

http://linuxjunk.blogspot.com/2009/08/attempt-to-use-bowtie-on-simulared.html</Text>
  </row>
  <row>
    <Id>1201</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>645</PostId>
    <RevisionGUID>e9379f37-82ab-43c4-93a9-379dfe471cbc</RevisionGUID>
    <CreationDate>2010-04-09T21:07:12.58</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>grep -c "^&gt;" [fasta_file]</Text>
  </row>
  <row>
    <Id>1202</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>645</PostId>
    <RevisionGUID>e9379f37-82ab-43c4-93a9-379dfe471cbc</RevisionGUID>
    <CreationDate>2010-04-09T21:07:12.58</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1203</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>646</PostId>
    <RevisionGUID>67bba079-dcf7-49ce-970e-f399464bb57d</RevisionGUID>
    <CreationDate>2010-04-09T21:07:17.947</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>Absolutely. There are, annoyingly, 3 different fastq quality encodings. The wikipedia page is a very good resource:

http://en.wikipedia.org/wiki/FASTQ_format

and this paper from several OpenBio folks:

http://nar.oxfordjournals.org/cgi/content/abstract/38/6/1767

All aligners that use quality scores will have a flag to specify which encoding your fastq file is in.

The approach Galaxy takes is to use a groomer to convert everything to Sanger format, and then work from there:

http://wwwportalmlekozyjestart.g2.bx.psu.edu/u/dan/p/fastq
</Text>
  </row>
  <row>
    <Id>1204</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>647</PostId>
    <RevisionGUID>7d74096f-b758-4c15-a123-73f2586e56f6</RevisionGUID>
    <CreationDate>2010-04-09T21:08:46.51</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>Circos would get my vote too.</Text>
  </row>
  <row>
    <Id>1205</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>648</PostId>
    <RevisionGUID>7eae9a8c-6479-470c-83f7-5be8ab676e36</RevisionGUID>
    <CreationDate>2010-04-09T23:54:51.237</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>Hi,

Given a microarray experiment data set, how would you create clusters of co-expressed genes?

The data set can best be simplified as an matrix of GxI dimensions. G number of genes and I number of individuals. The aim is to cluster together genes for which the expression is highly (read significantly) correlated across all the individuals, ideally after having removed the effect of factors responsible experimental variation and biases.

The final result is a statistically based grouping of genes in such clusters from which the individual gene ID can be recovered.

(NOTE: I am not looking for a software to make a visual clustering of the genes)

Any ideas?</Text>
  </row>
  <row>
    <Id>1206</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>648</PostId>
    <RevisionGUID>7eae9a8c-6479-470c-83f7-5be8ab676e36</RevisionGUID>
    <CreationDate>2010-04-09T23:54:51.237</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>Gene expression: clustering co-expressed genes</Text>
  </row>
  <row>
    <Id>1207</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>648</PostId>
    <RevisionGUID>7eae9a8c-6479-470c-83f7-5be8ab676e36</RevisionGUID>
    <CreationDate>2010-04-09T23:54:51.237</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text> égeneöexpressionà  éclusteringà  émicroarrayà </Text>
  </row>
  <row>
    <Id>1208</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>649</PostId>
    <RevisionGUID>5110dd9e-a79b-458f-947d-70731f857362</RevisionGUID>
    <CreationDate>2010-04-10T00:02:14.467</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>**What open software have you used for microarray analysis?**

I am using custom made arrays and can easily extract matrices of gene expression levels for each individual and each gene.

I am looking for a replacement for the R-maanova package that we have been using for years now in the lab, but given our good experience with this one, I don't want to waste time trying to learn an only half-assed solution. :)

So, what have you used that you would unconditionally recommend?</Text>
  </row>
  <row>
    <Id>1209</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>649</PostId>
    <RevisionGUID>5110dd9e-a79b-458f-947d-70731f857362</RevisionGUID>
    <CreationDate>2010-04-10T00:02:14.467</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>Microarray analysis open software</Text>
  </row>
  <row>
    <Id>1210</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>649</PostId>
    <RevisionGUID>5110dd9e-a79b-458f-947d-70731f857362</RevisionGUID>
    <CreationDate>2010-04-10T00:02:14.467</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text> émicroarrayà  éopenösoftwareà  éanalysisösoftwareà </Text>
  </row>
  <row>
    <Id>1211</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>650</PostId>
    <RevisionGUID>92aa8282-d052-4675-9b68-e7463aea270c</RevisionGUID>
    <CreationDate>2010-04-10T00:12:32.837</CreationDate>
    <IPAddress>70.54.0.56</IPAddress>
    <UserId>127</UserId>
    <Text>http://www.tm4.org/mev/

That's basically all you need for custom made arrays.</Text>
  </row>
  <row>
    <Id>1212</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>12a57744-1a72-457e-bd37-7192e50b46fe</RevisionGUID>
    <CreationDate>2010-04-10T00:23:14.347</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>Hi people!

I've been using StackOverflow for some time and I appreciate the invaluable support this community has provided me to learn better tricks with my coding. (if you don't know about it and do some coding in your work or for fun, I highly suggest you go have a look there!). There is, however, a definitive lack of interest or knowledge concerning bio-informatics on StackOverflow.

I have only found BioStar a few days ago and already feel how tremendously helpful this community could be, if it grew to reach it's critical mass. The cross-breed that are bio-informaticians could definitely use such a common space and no doubt make it a fun place to share precious experience and information.

We can all take part in contributing to the growth of this community. The [http://biostar.stackexchange.com/bootstrap][1] page already lists three suggestions to do just that:

 1. Invite people (kind of makes sens by itself...)
 2. Ask questions (to populate the wiki with useful information)
 3. Create tags (to help classifying this information)

We can even add other concrete actions to these. What about:

 - Publicity (talk about BioStar on your blog, facebook page, twitter, you name it!)
 - Add your own!

I suggest that we give a few minutes of our time in the coming week to help that community grow into the incredible ressource it has the potential of becoming :)

Please contribute your ideas on how to achieve this goal!

Cheers

  [1]: http://biostar.stackexchange.com/bootstrap</Text>
  </row>
  <row>
    <Id>1213</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>12a57744-1a72-457e-bd37-7192e50b46fe</RevisionGUID>
    <CreationDate>2010-04-10T00:23:14.347</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>Making BioStar grow</Text>
  </row>
  <row>
    <Id>1214</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>12a57744-1a72-457e-bd37-7192e50b46fe</RevisionGUID>
    <CreationDate>2010-04-10T00:23:14.347</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text> ébiostarà  écommunityà  écriticalömassà </Text>
  </row>
  <row>
    <Id>1215</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>12a57744-1a72-457e-bd37-7192e50b46fe</RevisionGUID>
    <CreationDate>2010-04-10T00:23:14.347</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
  </row>
  <row>
    <Id>1216</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>652</PostId>
    <RevisionGUID>01778103-0ecc-49e6-b54b-db6920d21c4f</RevisionGUID>
    <CreationDate>2010-04-10T00:37:59.947</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Text>@Jarretinha,

Thanks for your BioPerl solution! It gave me the urge to look at Biopython could do for me, since I only speak the later...

Here is what I found:

    from Bio.Sequencing import Ace
    from Bio.Align.Generic import Alignment
    from Bio.Alphabet import IUPAC, Gapped
    
    with open(output_file, "w") as output_file:
        while 1:
            try:
                contig = ace_gen.next()
            except:
                print "***All contigs treated***"
                break
            align = Alignment(Gapped(IUPAC.ambiguous_dna, "-"))
            align.add_sequence(contig.name, contig.sequence)
            for readn in xrange(len(contig.reads)):
                clipst = contig.reads[readn].qa.qual_clipping_start
                clipe = contig.reads[readn].qa.qual_clipping_end
                start = contig.af[readn].padded_start
                seq = cut_ends(contig.reads[readn].rd.sequence, clipst, clipe)
                seq = pad_read(seq, start, len(contig.sequence))
            sequences = read_fasta(align.format("fasta"))
            contig_name = re.findall("(Contig_[0-9]+)", sequences[0][0])[0]
            # Put your code here to work with the contig's sequences

I removed a lot of comments from the code and added a few features. The original example can be found [HERE][1] among the Biopython pages.

Thanks again!


  [1]: http://biopython.org/wiki/ACE_contig_to_alignment</Text>
  </row>
  <row>
    <Id>1217</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>653</PostId>
    <RevisionGUID>1eff547b-4799-4755-9216-4f033cf0db82</RevisionGUID>
    <CreationDate>2010-04-10T01:01:09.477</CreationDate>
    <IPAddress>70.54.0.56</IPAddress>
    <UserId>127</UserId>
    <Text>Start with k-means, either w/ an arbitrary number of clusters or w/ some pre-defined number. You can also use some self-learning k-means clustering and from that determine the best number of clusters with some expression profiles. From there you can try some other advanced techniques to filter the data more and more.</Text>
  </row>
  <row>
    <Id>1218</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>652</PostId>
    <RevisionGUID>652e7a77-3e58-4f07-8fde-92782e881213</RevisionGUID>
    <CreationDate>2010-04-10T01:19:29.49</CreationDate>
    <IPAddress>74.13.153.27</IPAddress>
    <UserId>216</UserId>
    <Comment>not much</Comment>
    <Text>@Jarretinha,

Thanks for your BioPerl solution! It gave me the urge to look at Biopython could do for me, since I only speak snake...

Here is what I found:

    from Bio.Sequencing import Ace
    from Bio.Align.Generic import Alignment
    from Bio.Alphabet import IUPAC, Gapped
    
    with open(output_file, "w") as output_file:
        while 1:
            try:
                contig = ace_gen.next()
            except:
                print "***All contigs treated***"
                break
            align = Alignment(Gapped(IUPAC.ambiguous_dna, "-"))
            align.add_sequence(contig.name, contig.sequence)
            for readn in xrange(len(contig.reads)):
                clipst = contig.reads[readn].qa.qual_clipping_start
                clipe = contig.reads[readn].qa.qual_clipping_end
                start = contig.af[readn].padded_start
                seq = cut_ends(contig.reads[readn].rd.sequence, clipst, clipe)
                seq = pad_read(seq, start, len(contig.sequence))
            sequences = read_fasta(align.format("fasta"))
            contig_name = re.findall("(Contig_[0-9]+)", sequences[0][0])[0]
            # Put your code here to work with the contig's sequences

I removed a lot of comments from the code and added a few features. The original example can be found [HERE][1] among the Biopython pages.

Thanks again!


  [1]: http://biopython.org/wiki/ACE_contig_to_alignment</Text>
  </row>
  <row>
    <Id>1219</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>654</PostId>
    <RevisionGUID>486430ea-7b72-4378-81cf-f3f4e20f8c2b</RevisionGUID>
    <CreationDate>2010-04-10T01:45:11.747</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>Roughly speaking clustering methods require you to define *a metric* that you will use to quantify the similarity between two elements, and *a linkage* that deals with combining the similarities for the elements that happen to be classified in the same cluster.</Text>
  </row>
  <row>
    <Id>1220</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>655</PostId>
    <RevisionGUID>1f7fe099-6ec9-48d2-8fbf-70abc478d138</RevisionGUID>
    <CreationDate>2010-04-10T01:57:01.933</CreationDate>
    <IPAddress>71.58.72.201</IPAddress>
    <UserId>2</UserId>
    <Text>We been having a little trouble attracting the audience that may benefit the most from this site: beginner bioinformaticians, wetlab biologists looking to expand their skills,  etc. 

I am planning to implement a new rule at work: I'll direct everyone asking me a bioinformatics question here: aka *I'll help you if you ask it on BioStar first*. 


PS1: A tip, use your full name! BioStar is also a place to demonstrate your skills. Why not ensure that future employers can associate your persona with the expertise.

PS2. We do have a domain name, but I forgot to turn it on early on, and if I were to do so now everyone with Google OpenID would lose their account. This is specific to Google ID as it is the only OpenID provider that adds the url into the login hash.</Text>
  </row>
  <row>
    <Id>1221</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>655</PostId>
    <RevisionGUID>1f7fe099-6ec9-48d2-8fbf-70abc478d138</RevisionGUID>
    <CreationDate>2010-04-10T01:57:01.933</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1222</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>656</PostId>
    <RevisionGUID>772793d8-cc1f-4c90-a6f4-525f3b1b3123</RevisionGUID>
    <CreationDate>2010-04-10T05:03:00.31</CreationDate>
    <IPAddress>218.186.8.237</IPAddress>
    <UserId>91</UserId>
    <Text>This is perhaps a bit convoluted, but if you could get your assembly into SAM format, running [SAMTools][1] with the pileup subcommand and then [VarScan][2] on the pileup output will help you deal with SNP detection and stats.

I am not sure how to get from ACE to SAM, but [this SeqAnswers thread][3] seems to contain a solution for that. 

  [1]: http://samtools.sourceforge.net/
  [2]: http://sourceforge.net/projects/varscan/
  [3]: http://seqanswers.com/forums/showthread.php?t=2112</Text>
  </row>
  <row>
    <Id>1223</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>08e05b80-02db-4177-a135-80b4e2fe6e16</RevisionGUID>
    <CreationDate>2010-04-10T17:57:22.84</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>Modified title "making" --&gt; "helping"</Comment>
    <Text>Helping BioStar grow</Text>
  </row>
  <row>
    <Id>1224</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>657</PostId>
    <RevisionGUID>a5658d96-6457-4e21-9b34-688221ccd9f6</RevisionGUID>
    <CreationDate>2010-04-11T07:38:00.08</CreationDate>
    <IPAddress>202.127.18.254</IPAddress>
    <UserId>220</UserId>
    <Text>Tigr MEV, very useful.</Text>
  </row>
  <row>
    <Id>1225</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>658</PostId>
    <RevisionGUID>80c6bcb3-5a6a-4627-b3ad-2a97961b9569</RevisionGUID>
    <CreationDate>2010-04-12T03:14:18.673</CreationDate>
    <IPAddress>130.102.117.54</IPAddress>
    <UserId>214</UserId>
    <Text>I used to be a sysadmin at a wholesale telco that ran CentOS exclusively on IBM and Dell equipment. They were just ordered without an OS. Neither company had any problems whatsoever with honouring service contracts (and we used to call them fairly frequently for warranty part replacements and so forth). Keep in mind though, that we didn't want software support.

So long as you're ordering them without an OS, and you're ordering actual servers (so you don't need to ring the desktop support line) you shouldn't have a problem with any of the big vendors.</Text>
  </row>
  <row>
    <Id>1226</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>659</PostId>
    <RevisionGUID>724574c0-e8cd-4f97-a219-c8245cf1ab37</RevisionGUID>
    <CreationDate>2010-04-12T07:26:26.507</CreationDate>
    <IPAddress>122.163.193.41</IPAddress>
    <Text>Thanks for giving me an amazing post, its great time to read your post. I’ve got some more interesting topic for discussion. So keep it up.
	
&lt;a href="http://www.articlesbase.com/supplements-and-vitamins-articles/acai-berry-weight-loss-try-acai-berry-for-free-1798369.html"&gt;Acai Berry Weight Loss&lt;/a&gt;</Text>
    <UserDisplayName>david leonen</UserDisplayName>
    <UserEmail>davidleoen10@gmail.comn</UserEmail>
  </row>
  <row>
    <Id>1227</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>660</PostId>
    <RevisionGUID>5fc7b52d-5f58-46d5-8d5d-a84c305ebb9b</RevisionGUID>
    <CreationDate>2010-04-12T08:24:54.97</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>What are the best phrap parameters for assembling sequence reads(forward and reverse) in cloned parasite isolates that are known to undergo recombination?


</Text>
  </row>
  <row>
    <Id>1228</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>660</PostId>
    <RevisionGUID>5fc7b52d-5f58-46d5-8d5d-a84c305ebb9b</RevisionGUID>
    <CreationDate>2010-04-12T08:24:54.97</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text>using Phrap assembly for recombinining sequences</Text>
  </row>
  <row>
    <Id>1229</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>660</PostId>
    <RevisionGUID>5fc7b52d-5f58-46d5-8d5d-a84c305ebb9b</RevisionGUID>
    <CreationDate>2010-04-12T08:24:54.97</CreationDate>
    <IPAddress>41.206.62.70</IPAddress>
    <UserId>40</UserId>
    <Text> éphrapà  éassemblyà  érecombinationà </Text>
  </row>
  <row>
    <Id>1230</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>661</PostId>
    <RevisionGUID>f91a3df4-d518-47e3-b85f-d52cfeefe249</RevisionGUID>
    <CreationDate>2010-04-12T13:52:02.8</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>Hi all,
I'm playing with MAQ/BWA and I'm trying to map the following short read on chr22/hg19:


    @repeat_1
    GGTGTCTGGGACCAGAAAATAGTGAGGACCCTCTTAC
    +
    zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz


it should match twice at 

     22   +   22678160  22678196
     22   +   22759880  22759916

when I use **GWA** , the read is mapped at 51304531 (?? 51304531+37 = length(chr22) ???)


    bwa aln -N chr22.fa chr22.sai repeat.fastq &gt; chr22.sai
    bwa  samse chr22.fa chr22.sai repeat.fastq
    @SQ	SN:Chr22	LN:51304566
    repeat_1	4	Chr22	51304531	0	37M	*	0	0	GGTGTCTGGGACCAGAAAATAGTGAGGACCCTCTTAC	zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz	XT:A:N	NM:i:27	XN:i:36X0:i:4	X1:i:0	XM:i:0	XO:i:0	XG:i:0	MD:Z:2A0T0C2A0T0C0C0T1G1G0C0C0T1C0C0A0C0C2T0T1G0C0A0A0C0T0A0

when I use **MAQ**, **only one position** was reported.


I'm sure I'm missing something here, help ! :-)

Many thanks,
pierre 



</Text>
  </row>
  <row>
    <Id>1231</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>661</PostId>
    <RevisionGUID>f91a3df4-d518-47e3-b85f-d52cfeefe249</RevisionGUID>
    <CreationDate>2010-04-12T13:52:02.8</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>Mapping one repeat (37pb) with BWA/MAQ </Text>
  </row>
  <row>
    <Id>1232</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>661</PostId>
    <RevisionGUID>f91a3df4-d518-47e3-b85f-d52cfeefe249</RevisionGUID>
    <CreationDate>2010-04-12T13:52:02.8</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text> émaqà  ébwaà  éngsà  émappingà </Text>
  </row>
  <row>
    <Id>1233</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>662</PostId>
    <RevisionGUID>4a3d7815-5812-4ea2-9691-9b07e946ec20</RevisionGUID>
    <CreationDate>2010-04-12T14:18:44.923</CreationDate>
    <IPAddress>139.124.153.193</IPAddress>
    <UserId>222</UserId>
    <Text>I am using Agilent-014850 4x44k and I am analysing the data on genespring. I am also doing manual search of some specific genes to determine their expression levels. I am facing lots of problems with gene IDs.
I tried using DAVID (April 09, 2010) also, but there are hundreds of agilent ids not recognized by DAVID.
Also can any one find me agilent id for MRC1 (mannose receptor, C type 1) gene (human), please. I could find only MRC1L1, MRC3 and MRC2.
</Text>
  </row>
  <row>
    <Id>1234</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>662</PostId>
    <RevisionGUID>4a3d7815-5812-4ea2-9691-9b07e946ec20</RevisionGUID>
    <CreationDate>2010-04-12T14:18:44.923</CreationDate>
    <IPAddress>139.124.153.193</IPAddress>
    <UserId>222</UserId>
    <Text>Info needed regarding gene id conversion from agilent to others</Text>
  </row>
  <row>
    <Id>1235</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>662</PostId>
    <RevisionGUID>4a3d7815-5812-4ea2-9691-9b07e946ec20</RevisionGUID>
    <CreationDate>2010-04-12T14:18:44.923</CreationDate>
    <IPAddress>139.124.153.193</IPAddress>
    <UserId>222</UserId>
    <Text> éidà  éconversionà </Text>
  </row>
  <row>
    <Id>1236</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>663</PostId>
    <RevisionGUID>43526e9f-09bd-4a4f-9c16-906229a601d8</RevisionGUID>
    <CreationDate>2010-04-12T14:43:01.55</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>Maq does not handle repeats, and will randomly report one of the mapped positions:

http://maq.sourceforge.net/faq.shtml

BWA has similar behavior by default, but the -R flag to aln will give you repeats:

http://bio-bwa.sourceforge.net/bwa.shtml

Last time I checked, multiple hit reports are not in SAM format. For projects needing repeats, I normally use Bowtie:

http://bowtie-bio.sourceforge.net/index.shtml

For your question about the BWA output -- that SAM line indicates the read is unmapped. The easiest cue to pick up on is the 4 in the flag field. I'd expect it to give you one hit randomly assigned with either of those positions, so not sure why that is.</Text>
  </row>
  <row>
    <Id>1237</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>664</PostId>
    <RevisionGUID>eee73fab-228f-453e-afda-38dd0bf68b8b</RevisionGUID>
    <CreationDate>2010-04-12T15:00:14.18</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text>My favourite clustering software is R. Some people may disagree about the 'easy to use' part but once you get over the initial slope of the learning curve it is very easy and hugely powerful. No other tool can really compare in my opinion. 

 However if R is not for you then [Cluster 3.0][1] and [MapleTree][2] are the way forward.


  [1]: http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/
  [2]: http://mapletree.sourceforge.net/</Text>
  </row>
  <row>
    <Id>1238</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>665</PostId>
    <RevisionGUID>d612973b-e6ae-486a-bf11-e175fbad9513</RevisionGUID>
    <CreationDate>2010-04-12T15:03:36.27</CreationDate>
    <IPAddress>204.56.6.94</IPAddress>
    <UserId>74</UserId>
    <Text>Can't you summarize your results in terms of gene symbols or other gene ids and then use those with other tools like DAVID? You should have agilent annotation files that allow you to translate probe ids into genes.

In terms of a gene not being represented on the array, that is best solved by looking at the annotation files provided by Agilent and contacting them if you have a question.</Text>
  </row>
  <row>
    <Id>1239</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>666</PostId>
    <RevisionGUID>c15d284b-3cd0-4c8a-9cfb-84c0589a56ca</RevisionGUID>
    <CreationDate>2010-04-12T15:17:57.847</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text>[David][1] is a great place to start. I also like [GeneTrail][2], which can do GSEA analysis as well as standard enrichment on a gene list. Out of the web world I really like [ClueGO][3] and to a lesser degree [BInGO][4] in [Cytoscape][5].

In case they were ever useful I put up some slides from a short course I give on functional analysis using [web tools][6] and [Cytoscape][7].

  [1]: http://david.abcc.ncifcrf.gov/
  [2]: http://genetrail.bioinf.uni-sb.de/
  [3]: http://www.ici.upmc.fr/cluego/cluegoDownload.shtml
  [4]: http://www.psb.ugent.be/cbd/papers/BiNGO/
  [5]: http://www.cytoscape.org/
  [6]: http://www.slideshare.net/Stewbacca/functional-and-pathway-analysis-2010
  [7]: http://www.slideshare.net/Stewbacca/cytoscape-talk-2010</Text>
  </row>
  <row>
    <Id>1240</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>667</PostId>
    <RevisionGUID>4a60571a-d5a2-4bed-ba06-aa17c2733558</RevisionGUID>
    <CreationDate>2010-04-12T15:54:24.69</CreationDate>
    <IPAddress>137.187.210.160</IPAddress>
    <UserId>89</UserId>
    <Text>Related question:
http://biostar.stackexchange.com/questions/22/gene-id-conversion-tool
</Text>
  </row>
  <row>
    <Id>1241</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>668</PostId>
    <RevisionGUID>15a2453f-0099-4351-a45e-30094f05f1c1</RevisionGUID>
    <CreationDate>2010-04-12T19:09:44.877</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>I just started playing with the pyfasta Python module, which is described as a **fast, memory-efficient, pythonic (and command-line) access to fasta sequence files**.

It looks very promising for my work, but I am currently unable to use it for a very simple application, namely: I want to treat sequences from a fasta file sequentially, respecting the order of the sequences in the fasta file from which I read them. I have tried the following:

    import pyfasta
    
    f = pyfasta.Fasta("coreg.fa")
    
    for header in f.keys():
        seq = f[header]
        with open("output.file", "a") as out_file:
            out_file.write(str(header) + "\n")
            out_file.write(str(seq) + "\n")

This simple example only reads my input fasta file and write back an output fasta file with the same sequences. However, the initial order is randomized, since the headers seem to be fitted into a dictionary (which modifies the order but permits a faster recovery time). This is NOT the behaviour I intended.

Is there a way to maintain the order from the original file?

I do NOT want to iterate on `sorted(f.keys())` since this does not give back the original order either.

Many thanks!</Text>
  </row>
  <row>
    <Id>1242</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>668</PostId>
    <RevisionGUID>15a2453f-0099-4351-a45e-30094f05f1c1</RevisionGUID>
    <CreationDate>2010-04-12T19:09:44.877</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>Iterating through fasta sequences with pyfasta Python module</Text>
  </row>
  <row>
    <Id>1243</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>668</PostId>
    <RevisionGUID>15a2453f-0099-4351-a45e-30094f05f1c1</RevisionGUID>
    <CreationDate>2010-04-12T19:09:44.877</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text> épythonà  épyfastaà  éfastaà </Text>
  </row>
  <row>
    <Id>1244</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>668</PostId>
    <RevisionGUID>6eb39a3e-7724-4b49-858c-b444f5f4b2d2</RevisionGUID>
    <CreationDate>2010-04-12T19:36:56.73</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 134 characters in body; deleted 12 characters in body</Comment>
    <Text>I just started playing with the pyfasta Python module, which is described as a **fast, memory-efficient, pythonic (and command-line) access to fasta sequence files**.

It looks very promising for my work, but I am currently unable to use it for a very simple application, namely: I want to treat sequences from a fasta file sequentially, respecting the order of the sequences in the fasta file from which I read them. I have tried the following:

    import pyfasta
    
    f = pyfasta.Fasta("coreg.fa")
    ncar = 60
    
    with open("output.file", "w") as out_file:
        for header in f.keys():
            name = str(header)
            seq = str(f[header])
            out_file.write(name + "\n")
            while len(seq) &gt; 0:
                out_file.write(seq[:ncar] + "\n")
                seq = seq[ncar:]

This simple example only reads my input fasta file and write back an output fasta file with the same sequences. However, the initial order is randomized, since the headers seem to be fitted into a dictionary (which modifies the order but permits a faster recovery time). This is NOT the behaviour I intended.

Is there a way to maintain the order from the original file?

I do NOT want to iterate on `sorted(f.keys())` since this does not give back the original order either.

Many thanks!</Text>
  </row>
  <row>
    <Id>1245</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>668</PostId>
    <RevisionGUID>69ea57e4-6946-4276-a46d-11357982363f</RevisionGUID>
    <CreationDate>2010-04-12T19:53:27.663</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 67 characters in body</Comment>
    <Text>I just started playing with the pyfasta Python module, which is described as a **fast, memory-efficient, pythonic (and command-line) access to fasta sequence files**.

It looks very promising for my work, but I am currently unable to use it for a very simple application, namely: I want to treat sequences from a fasta file sequentially, respecting the order of the sequences in the fasta file from which I read them. I have tried the following:

    import pyfasta
    
    f = pyfasta.Fasta("coreg.fa")
    ncar = 60
    
    with open("output.file", "w") as out_file:
        for header in f.keys():
            name = str(header)
            seq = str(f[header])
            out_file.write(name + "\n")
            while len(seq) &gt; 0:
                out_file.write(seq[:ncar] + "\n")
                seq = seq[ncar:]

This simple example only reads my input fasta file and writes them back to an output fasta file. However, the initial order is randomized, since the headers are fitted into a dictionary based class (if I understood well), which modifies the order but permits a faster research time. This is not, however, exactly the behavior I am trying to achieve. So, my question is:

**Is there a way to maintain the order from the original file?**

(I do not want to iterate on `sorted(f.keys())` since this does not give back the original order either.)

Many thanks!</Text>
  </row>
  <row>
    <Id>1246</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>669</PostId>
    <RevisionGUID>f4c37155-ff66-43ec-af88-5771bc537817</RevisionGUID>
    <CreationDate>2010-04-12T19:56:17.647</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>One easy way to convert different ids from different sources is to use Martview in Biomart's website. Just upload a file with your IDs as a filter set and get some other ID as a result in the features set. But without more information is difficult to give you a correct answer.</Text>
  </row>
  <row>
    <Id>1247</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>670</PostId>
    <RevisionGUID>80e2f006-95a8-47eb-99d7-729507f2f32f</RevisionGUID>
    <CreationDate>2010-04-12T23:03:46.343</CreationDate>
    <IPAddress>128.32.8.28</IPAddress>
    <UserId>36</UserId>
    <Text>that's a use-case i never thought of, but, as it happens, you can do that with the index.
mostly, you dont need to know about the index, but since it saves the file position, you can use that to order your chromosomes:

    f = pyfasta.Fasta('some.fasta')
    sorted_keys = [x[0] for x in sorted(f.index.items(), key=lambda a: a[1][0])]

and that doesn't re-parse the file.</Text>
  </row>
  <row>
    <Id>1248</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>659</PostId>
    <RevisionGUID>29ef5b0c-1104-4233-8caf-fa3fbce947c6</RevisionGUID>
    <CreationDate>2010-04-13T01:30:11.993</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>2</UserId>
    <Text>[{"Id":2,"DisplayName":"Istvan Albert"}]</Text>
  </row>
  <row>
    <Id>1249</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>565</PostId>
    <RevisionGUID>ccd0b859-1b73-48ea-9a99-960ddfe47f81</RevisionGUID>
    <CreationDate>2010-04-13T10:26:07.373</CreationDate>
    <IPAddress>130.223.9.49</IPAddress>
    <UserId>141</UserId>
    <Comment>small bug fixed ("\n")</Comment>
    <Text>Following up on Pierre's answer &amp; my comment, here's how to do it in ruby, using NCBI's eutils.
 
    #!/sw/bin/ruby
    require 'bio'
        
    ncbi        = Bio::NCBI::REST.new
    sequenceIDs = ncbi.esearch("Hymenoptera[organism]",
                               { "db"=&gt;"protein", "rettype"=&gt;"gb", "retmax"=&gt; 10000000})    
    sequences   = ncbi.efetch(ids = sequenceIDs,
                              {"db"=&gt;"protein", "rettype"=&gt;"fasta", "retmax"=&gt; 10000000})

    # ncbi returns a single big string with records separated by two newlines              
    sequences.gsub!("\n\n", "\n")
    File.open('genbankHymenopteranProts.fasta', 'w') {|f| f.write(sequences +"\n") }


</Text>
  </row>
  <row>
    <Id>1250</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>965f97db-01f9-435c-bdb9-dce3bc3e5e0b</RevisionGUID>
    <CreationDate>2010-04-13T12:09:47.887</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>Initially my problem was to extract all entries from a FASTQ file with names not present in a FASTA file. Using biopython I wrote:

&lt;pre&gt;&lt;code&gt;
from Bio.SeqIO.QualityIO import FastqGeneralIterator

corrected_fn   = "my_input_fasta.fas"
uncorrected_fn = "my_input_fastq.ftq"
output_fn      = "differences_fastq.ftq"

corrected_names = []
for line in open(corrected_fn):
        if line[0] == "&gt;":
                read_name = line.split()[0][1:] 
                corrected_names.append(read_name)

corrected_names.sort()

handle = open(output_fn, "w")
for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
        if title not in corrected_names:
                handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
handle.close()
&lt;/code&gt;&lt;/pre&gt;

Problem is, it is very slow. On 2Ghz workstation starting from a local disc it can take two days per pair of files:

* 4870868 seqs in FASTQ 
* 4299464 seqs in FASTA

Removing title from corrected_names speeds up things a bit (this version I used for running). 

Am I doing something obviously silly or simply FastqGeneralIterator is not a best construct to use here? While I like Python best, I am open to answers in Perl/Ruby. 

Slicing and dicing FASTQ files based on lists seems to be fairly common task.

</Text>
  </row>
  <row>
    <Id>1251</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>965f97db-01f9-435c-bdb9-dce3bc3e5e0b</RevisionGUID>
    <CreationDate>2010-04-13T12:09:47.887</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text>extracting a subset of sequences from a FASTQ file (BioPython speed)</Text>
  </row>
  <row>
    <Id>1252</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>965f97db-01f9-435c-bdb9-dce3bc3e5e0b</RevisionGUID>
    <CreationDate>2010-04-13T12:09:47.887</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Text> éfastqà  ébiopythonà  énextögenösequencingà </Text>
  </row>
  <row>
    <Id>1253</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>672</PostId>
    <RevisionGUID>801ac6e4-d17c-4bae-a39a-e63f714505b6</RevisionGUID>
    <CreationDate>2010-04-13T12:22:04.593</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>I can suggest a modification that should improve the speed issue, though I don't know by how much. Instead of making a list of your corrected_names, you could make a dictionary and use the .haskey() method to see if the key exists. Searching through a huge dictionary for keys should be much faster than searching through a sorted list (unless you do a binary search).

It is, in addition, much more pythonic :)

    from Bio.SeqIO.QualityIO import FastqGeneralIterator
    
    corrected_fn   = "my_input_fasta.fas"
    uncorrected_fn = "my_input_fastq.ftq"
    output_fn      = "differences_fastq.ftq"
    
    corrected_names = {} # Use of dictionary instead of list
    for line in open(corrected_fn):
            if line[0] == "&gt;":
                    read_name = line.split()[0][1:] 
                    corrected_names[read_name] = 0 # Add key to dict
    
    # corrected_names.sort() # No need anymore
    
    handle = open(output_fn, "w")
    for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
            if title not in corrected_names:
                    handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
    handle.close()

Tell me if this improves things! (Note: I didn't test this as it is)

Cheers</Text>
  </row>
  <row>
    <Id>1254</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>828c0d4a-9beb-4aff-86d3-1c5a3811ad2d</RevisionGUID>
    <CreationDate>2010-04-13T12:22:16.707</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>python/biopython vers.</Comment>
    <Text>Initially my problem was to extract all entries from a FASTQ file with names not present in a FASTA file. Using biopython I wrote:

&lt;pre&gt;&lt;code&gt;
from Bio.SeqIO.QualityIO import FastqGeneralIterator

corrected_fn   = "my_input_fasta.fas"
uncorrected_fn = "my_input_fastq.ftq"
output_fn      = "differences_fastq.ftq"

corrected_names = []
for line in open(corrected_fn):
        if line[0] == "&gt;":
                read_name = line.split()[0][1:] 
                corrected_names.append(read_name)

corrected_names.sort()

handle = open(output_fn, "w")
for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
        if title not in corrected_names:
                handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
handle.close()
&lt;/code&gt;&lt;/pre&gt;

Problem is, it is very slow. On 2Ghz workstation starting from a local disc it can take two days per pair of files:

* 4870868 seqs in FASTQ 
* 4299464 seqs in FASTA

Removing title from corrected_names speeds up things a bit (this version I used for running). 

Am I doing something obviously silly or simply FastqGeneralIterator is not a best construct to use here? While I like Python best, I am open to answers in Perl/Ruby. 

Slicing and dicing FASTQ files based on lists seems to be fairly common task.

Edit: Python 2.6.4, biopython 1.53, Linux Fedora 8. </Text>
  </row>
  <row>
    <Id>1255</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>672</PostId>
    <RevisionGUID>290530b0-ff45-473f-a89f-bf1d6398b753</RevisionGUID>
    <CreationDate>2010-04-13T12:27:13.343</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>corrected mistakes in the description; added 4 characters in body</Comment>
    <Text>I can suggest a modification that should improve the speed issue, though I don't know by how much. Instead of making a list of your corrected_names, you could make a dictionary and look if the key exists. Searching through a huge dictionary for keys should be much faster than searching through a sorted list.

It is, in addition, much more pythonic :)

    from Bio.SeqIO.QualityIO import FastqGeneralIterator
    
    corrected_fn   = "my_input_fasta.fas"
    uncorrected_fn = "my_input_fastq.ftq"
    output_fn      = "differences_fastq.ftq"
    
    corrected_names = {} # Use of dictionary instead of list
    for line in open(corrected_fn):
            if line[0] == "&gt;":
                    read_name = line.split()[0][1:] 
                    corrected_names[read_name] = 0 # Add key to dict
    
    # corrected_names.sort() # No need anymore
    
    handle = open(output_fn, "w")
    for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
            if title not in corrected_names:
                    handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
    handle.close()

Tell me if this improves things! (Note: I didn't test this as it is)

Cheers</Text>
  </row>
  <row>
    <Id>1256</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>673</PostId>
    <RevisionGUID>69e9c701-5bf4-4ef8-aa5d-0ba9acd83143</RevisionGUID>
    <CreationDate>2010-04-13T12:27:45.603</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>I have been contributing to a scientific online community in Italian for a few years now ([molecularlab][1]), and now I have some experience on how to publicize a website like this and make it grow faster.

One of the most important points is that we should all respect the netiquette carefully, especially by making sure that all the discussions have good titles and that no flames arise. Luckly, the stackexchange layout is great at doing this, as in principle everybody can contribute to moderation.

As for publicizing it, I told it to my friends and colleagues, and wrote a post on it on my blog: I think this may be sufficent. Maybe, if the website is successful, you could submit a paper or a letter to a peer-reviewed journal on it.

In any case, the best way to attract people is to ask interesting questions and make nice answers. When you post a new question or provide an answer, think on how google and other search engines will index it, so try to use a clean language and use tags and titles properly.

One possible obstacle is that most of the questions asked here will be very technical, so a newcomer could be scared by this as he won't be able to answer any question at the beginning. So I think it would be nice to post some generic questions now, something like 'What is the best programming language for bioinformaticians', etc., where newcomers will be able to answer and accumulate their first points.


  [1]: http://www.molecularlab.it/forum/</Text>
  </row>
  <row>
    <Id>1257</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>673</PostId>
    <RevisionGUID>69e9c701-5bf4-4ef8-aa5d-0ba9acd83143</RevisionGUID>
    <CreationDate>2010-04-13T12:27:45.603</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1258</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>672</PostId>
    <RevisionGUID>b92cb3a9-f805-49a3-8895-e3b524c32413</RevisionGUID>
    <CreationDate>2010-04-13T13:09:22.95</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 2 characters in body</Comment>
    <Text>I can suggest a modification that should improve the speed issue, though I don't know by how much. Instead of making a list of your corrected_names, you could make a dictionary and look if the key exists. Searching through a huge dictionary for keys should be much faster than searching through a sorted list.

It is, in addition, much more pythonic :)

    from Bio.SeqIO.QualityIO import FastqGeneralIterator
    
    corrected_fn   = "my_input_fasta.fas"
    uncorrected_fn = "my_input_fastq.ftq"
    output_fn      = "differences_fastq.ftq"
    
    corrected_names = {} # Use of dictionary instead of list
    for line in open(corrected_fn):
            if line[0] == "&gt;":
                    read_name = line.split()[0][1:] 
                    corrected_names[read_name] = 0 # Add key to dict
    
    # corrected_names.sort() # No need anymore
    
    handle = open(output_fn, "w")
    for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
            if title not in corrected_names:
                    handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
    handle.close()

Tell me if this improves things! (Note: I didn't test this as a whole)

Cheers</Text>
  </row>
  <row>
    <Id>1259</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>674</PostId>
    <RevisionGUID>aade4526-5116-46b7-8259-d006eb6bbac2</RevisionGUID>
    <CreationDate>2010-04-13T13:22:25.643</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>A smallish change would be from

    if line[0] == "&gt;":

to

    if line.startswith('&gt;'):



</Text>
  </row>
  <row>
    <Id>1260</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>675</PostId>
    <RevisionGUID>617b9fb9-f44b-42d7-9a68-d1cdff1a2f61</RevisionGUID>
    <CreationDate>2010-04-13T13:23:39.327</CreationDate>
    <IPAddress>130.15.144.239</IPAddress>
    <UserId>127</UserId>
    <Text>Why not send an email to EvolDir? It might work as an extension for questions posted there.</Text>
  </row>
  <row>
    <Id>1261</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>675</PostId>
    <RevisionGUID>617b9fb9-f44b-42d7-9a68-d1cdff1a2f61</RevisionGUID>
    <CreationDate>2010-04-13T13:23:39.327</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1262</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>09fe5628-14b1-44fc-b66c-718ea3480e1c</RevisionGUID>
    <CreationDate>2010-04-13T13:31:16.257</CreationDate>
    <IPAddress>84.88.18.54</IPAddress>
    <UserId>62</UserId>
    <Comment>see edit 2</Comment>
    <Text>Initially my problem was to extract all entries from a FASTQ file with names not present in a FASTA file. Using biopython I wrote:

&lt;pre&gt;&lt;code&gt;
from Bio.SeqIO.QualityIO import FastqGeneralIterator

corrected_fn   = "my_input_fasta.fas"
uncorrected_fn = "my_input_fastq.ftq"
output_fn      = "differences_fastq.ftq"

corrected_names = []
for line in open(corrected_fn):
        if line[0] == "&gt;":
                read_name = line.split()[0][1:] 
                corrected_names.append(read_name)

input_fastq_fn = uncorrected_fn
corrected_names.sort()

handle = open(output_fn, "w")
for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)) :
        if title not in corrected_names:
                handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
handle.close()
&lt;/code&gt;&lt;/pre&gt;

Problem is, it is very slow. On 2Ghz workstation starting from a local disc it can take two days per pair of files:

* 4870868 seqs in FASTQ 
* 4299464 seqs in FASTA

Removing title from corrected_names speeds up things a bit (this version I used for running). 

Am I doing something obviously silly or simply FastqGeneralIterator is not a best construct to use here? While I like Python best, I am open to answers in Perl/Ruby. 

Slicing and dicing FASTQ files based on lists seems to be fairly common task.

Edit: Python 2.6.4, biopython 1.53, Linux Fedora 8. 

Edit 2: 

* corrected one line of code, see comment to giovanni
* code snippet taken from: http://news.open-bio.org/news/2009/09/biopython-fast-fastq/</Text>
  </row>
  <row>
    <Id>1263</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>676</PostId>
    <RevisionGUID>be4b2621-1213-4319-840f-86280d4cebe1</RevisionGUID>
    <CreationDate>2010-04-13T13:56:06.053</CreationDate>
    <IPAddress>150.237.85.229</IPAddress>
    <UserId>227</UserId>
    <Text>Problem: I have a multiple alignment of sequence reads. Each individual is represented by two sequences, forward and reverse (e.g. individual1_For and individual1_Rev) that don't overlap at the ends. I want my alignment to have one sequence per individual that is the consensus of the forward and reverse sequences. NB I don't want to create a consensus across all individuals. I want to recognise sequences that share a name e.g. "individual1" and replace them with a full-length consensus of those two sequences.

Does anybody know of existing script or programs to do this? If it doesn't already exist I shall probably start putting something together with BioPerl, any suggestions of best approach?</Text>
  </row>
  <row>
    <Id>1264</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>676</PostId>
    <RevisionGUID>be4b2621-1213-4319-840f-86280d4cebe1</RevisionGUID>
    <CreationDate>2010-04-13T13:56:06.053</CreationDate>
    <IPAddress>150.237.85.229</IPAddress>
    <UserId>227</UserId>
    <Text>Create consensus sequences for sequence pairs within a multiple alignment?</Text>
  </row>
  <row>
    <Id>1265</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>676</PostId>
    <RevisionGUID>be4b2621-1213-4319-840f-86280d4cebe1</RevisionGUID>
    <CreationDate>2010-04-13T13:56:06.053</CreationDate>
    <IPAddress>150.237.85.229</IPAddress>
    <UserId>227</UserId>
    <Text> éalignmentà  émultiplealignmentà  éfastaà  éconsensusà </Text>
  </row>
  <row>
    <Id>1266</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>677</PostId>
    <RevisionGUID>e03128cd-44f5-4918-8c80-51502d2af03e</RevisionGUID>
    <CreationDate>2010-04-13T14:00:45.977</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text>Hi Guys,

Does anyone have experienced the search of microsatellite motifs in high-throughput sequencing data, such as contigs built from the assembly of 454 data? I would like to screen and eventually map these markers associated to contigs that don't show SNP polymorphism.

Regards,
Christopher</Text>
  </row>
  <row>
    <Id>1267</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>677</PostId>
    <RevisionGUID>e03128cd-44f5-4918-8c80-51502d2af03e</RevisionGUID>
    <CreationDate>2010-04-13T14:00:45.977</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text>Searching for Microsatellites Motifs in NGS Data</Text>
  </row>
  <row>
    <Id>1268</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>677</PostId>
    <RevisionGUID>e03128cd-44f5-4918-8c80-51502d2af03e</RevisionGUID>
    <CreationDate>2010-04-13T14:00:45.977</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text> émicrosatelliteà  éngsödataà </Text>
  </row>
  <row>
    <Id>1269</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>676</PostId>
    <RevisionGUID>e81e8296-934f-41f5-8de6-d9cb7fbd3558</RevisionGUID>
    <CreationDate>2010-04-13T14:21:38.327</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> éalignmentà  émultipleöalignmentà  éfastaà  éconsensusà </Text>
  </row>
  <row>
    <Id>1270</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>678</PostId>
    <RevisionGUID>599ce7a6-7031-4c9d-96cc-44f2dca5cb5e</RevisionGUID>
    <CreationDate>2010-04-13T14:35:14.053</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>it's also worth noting that there are a couple good options for random access in fasta sequences. with a [branch][1] in biopython:
    
    fi = SeqIO.indexed_dict(corrected_fn, corrected_fn + ".idx", "fastq")
    handle = open(output_fn, "w")
    for title, seq, qual in FastqGeneralIterator(open(input_fastq_fn)):
            if title not in fi: continue
            handle.write("@%s\n%s\n+\n%s\n" % (title, seq, qual))
    handle.close()


and also check out &lt;a href="http://github.com/acr/screed"&gt;screed&lt;/a&gt; which does something very similar. these will both have overhead when first indexing the file but should be quite fast after that.


  [1]: http://github.com/peterjc/biopython/commits/index-sqlite</Text>
  </row>
  <row>
    <Id>1271</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>670</PostId>
    <RevisionGUID>030a9c90-8c23-405a-80ba-d47ebf725e34</RevisionGUID>
    <CreationDate>2010-04-13T14:39:34.76</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Comment>add subclass example</Comment>
    <Text>that's a use-case i never thought of, but, as it happens, you can do that with the index.
mostly, you dont need to know about the index, but since it saves the file position, you can use that to order your chromosomes:

    f = pyfasta.Fasta('some.fasta')
    sorted_keys = [x[0] for x in sorted(f.index.items(), key=lambda a: a[1][0])]

and that doesn't re-parse the file. and in if you're doing that frequently, you could use a subclass:

    class Fasta(pyfasta.Fasta):
        def sorted_keys(self):
            return [x[0] for x in sorted(f.index.items(), key=lambda a: a[1][0])]</Text>
  </row>
  <row>
    <Id>1272</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>679</PostId>
    <RevisionGUID>f260ff54-4b63-4102-8d55-10d54bd5b4b0</RevisionGUID>
    <CreationDate>2010-04-13T14:40:19.527</CreationDate>
    <IPAddress>137.205.75.226</IPAddress>
    <UserId>169</UserId>
    <Text>Finding co-regulated genes is actually quite a difficult task, using straight clustering like k-means is in my experience not that productive on straight expression data. As I am sure you're aware k-means is by far and away the most commonly used clustering method. Any one clustering method has it's problems and the lack of associated statistics and statistically informed decision making when doing things like picking cluster numbers for the partitioning are big problems.

Now to what I do. Firstly no harm in doing what has been proposed, but what I bet you will find is profiles that are mainly segregated on the basis of variations in expression magnitude rather than expression shape and that is a big problem biologically. When you think about what (I believe) you are looking for, you are trying to find genes that share expression profiles, that is shapes. I often show a simulated example in lectures of why you will often end up co-clustering genes based on magnitude variation rather than similarity in shape if you use the standard approach. The way past this is actually very simple and we have found it incredibly useful in identifying co-regulated genes in Drosophila PNS development.

Take your original expression matrix [genes x conditions] and unitise the vectors, that is make the matrix magnitude invariant. The way to do this is to normalise the rows by the length of their vectors

    #for an expression matrix sim_class, get the length sqrt(sum of squares)
    norm_factors &lt;- sqrt(apply(sim_class^2,1,sum));

    #divide the rows by the norm factor
    normalised_sim_class &lt;- sim_class/norm_factors;

Now clustering this expression matrix pulls out genes that have the same shape irrespective of magnitude. Biologically this means you are pulling together genes that might be direct targets of a particular set of transcription factors, with identical profiles but simply a different response scale. This is what you often find in reality, it is more often the case that co-regulated genes are responding in different scales, but in our experience with similar expression profile shapes. I hope that's of some use, even if only to run alongside your current analyses to see the differences this approach produces.</Text>
  </row>
  <row>
    <Id>1273</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>680</PostId>
    <RevisionGUID>a2f109b2-5baa-4679-b679-296714d7b4ef</RevisionGUID>
    <CreationDate>2010-04-13T15:28:35.607</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>I know some public databases that offer annotations on pathways: for example, [KEGG/Pathways][1] or the [Reactome][2].

Do you know other resources apart from these two? Can you recommend any specific one?


  [1]: http://www.genome.jp/kegg/pathway.html
  [2]: http://reactome.org/</Text>
  </row>
  <row>
    <Id>1274</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>680</PostId>
    <RevisionGUID>a2f109b2-5baa-4679-b679-296714d7b4ef</RevisionGUID>
    <CreationDate>2010-04-13T15:28:35.607</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>Which are all the databases for annotations on pathways?</Text>
  </row>
  <row>
    <Id>1275</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>680</PostId>
    <RevisionGUID>a2f109b2-5baa-4679-b679-296714d7b4ef</RevisionGUID>
    <CreationDate>2010-04-13T15:28:35.607</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text> épathwaysà  éannotationà  édatabaseà  éresourcesà </Text>
  </row>
  <row>
    <Id>1276</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>671</PostId>
    <RevisionGUID>7c76a5cd-b21e-45fc-ac20-1e7d181d40f3</RevisionGUID>
    <CreationDate>2010-04-13T15:50:35.293</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Comment>edited tags</Comment>
    <Text> éfastqà  ébiopythonà  énextögenösequencingà  épythonà </Text>
  </row>
  <row>
    <Id>1277</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>681</PostId>
    <RevisionGUID>a3b9447e-09f3-4c03-931f-3eff2a333ac3</RevisionGUID>
    <CreationDate>2010-04-13T15:55:39.24</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>in my delicious bookmarks :

http://www.ncbi.nlm.nih.gov/biosystems

http://www.biocarta.com/genes/index.asp

http://biocyc.org/

http://www.wikipathways.org/index.php/WikiPathways



</Text>
  </row>
  <row>
    <Id>1278</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>682</PostId>
    <RevisionGUID>83a3f776-418c-41f5-8c00-908a5b5c1297</RevisionGUID>
    <CreationDate>2010-04-13T16:02:21.243</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>You can do it with Unix command line tools instead of python: it should be faster because these tools are written in C directly.

First, use grep on the first file to get the list of all the ids:

    $: grep '&gt;' my_input_fasta.fas|sed 's/&gt;//g'|sort &gt; my_input_fasta.ids
    $: grep '&gt;' my_input_fastq.ftq|sed 's/&gt;//g'|sort &gt; my_input_fastq.ids

Then, use comm to get the differences:

     $: comm fas_ids ftq_ids 
    		seq1
     seq2
    	 seq3
    	 seq4

The first column tells you the ids belonging to fas_ids, the second the ones belonging to ftq_ids, and the third the ones in common.
You can use the -1, -2, -3 options to get only the ids belonging to one file, e.g.:

     $: comm fas_ids ftq_ids  -23
     seq2


will give you the ids present in fas_ids but not in the other.
</Text>
  </row>
  <row>
    <Id>1279</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>683</PostId>
    <RevisionGUID>29803bc9-e414-49cc-b01d-cc964e21afb4</RevisionGUID>
    <CreationDate>2010-04-13T16:16:41.503</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>The approach to solving your problem requires 3 steps. Here is my take:

 1. Use Python with Biopython to pass through your sequence couples, one individual at a time. Reverse complement the second sequence. (use any other preferred approach)
 2. Use the "dialign2" program repeatedly for each individual to create alignments. In this way, your 2 sequences will have the same length (with "-" characters to complete the missing parts).
 3. Use Python to pass through each alignment (2 sequences each time) and create a consensus. This should be easy. Here is an attempt:

    def create_consensus(seq1, seq2):
        """Sequences must be strings,dr have the same length and be aligned"""
        out_seq = ""
        for i, nucleotide in enumerate(seq1):
            couple = [nucleotide, seq2[i]]
            if couple[0] == "-":
                out_seq += couple[1]
            elif couple[1] == "-":
                out_seq += couple[0]
            elif couple[0] == couple[1]:
                out_seq += couple[0]
            elif not couple[0] == couple[1]:
                out_seq += "N"
        return out_seq
    
    seq1 = "-----CAGATACGCGCACATAGACATAG"
    seq2 = "ACTGACAGATACAGACACATA-------"
    
    print seq1
    print seq2
    print create_consensus(seq1, seq2)

This is admittedly quickly done and there may be both 1) mistakes or special cases 2) a better way to do this, maybe with Biopython.

Hope it helps!

Cheers
        
(NOTE: sorry, I have no idea why the code does not appear properly. Maybe the list I made just above it?)</Text>
  </row>
  <row>
    <Id>1280</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>684</PostId>
    <RevisionGUID>4277c73d-cc74-4514-ae8c-8f6c45067f0e</RevisionGUID>
    <CreationDate>2010-04-13T16:19:02.45</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Text>The approach to solving your problem requires 3 steps. Here is my take:

 - Use Python with Biopython to pass
   through your sequence couples, one
   individual at a time. Reverse
   complement the second sequence. (use
   any other preferred approach)
 - Use the "dialign2" program repeatedly
   for each individual to create
   alignments. In this way, your 2
   sequences will have the same length
   (with "-" characters to complete the
   missing parts).
 - se Python to pass through each
   alignment (2 sequences each time) and
   create a consensus. This should be
   easy.

Here is an attempt:

    def create_consensus(seq1, seq2):
        """Sequences must be strings,dr have the same length and be aligned"""
        out_seq = ""
        for i, nucleotide in enumerate(seq1):
            couple = [nucleotide, seq2[i]]
            if couple[0] == "-":
                out_seq += couple[1]
            elif couple[1] == "-":
                out_seq += couple[0]
            elif couple[0] == couple[1]:
                out_seq += couple[0]
            elif not couple[0] == couple[1]:
                out_seq += "N"
        return out_seq
    
    seq1 = "-----CAGATACGCGCACATAGACATAG"
    seq2 = "ACTGACAGATACAGACACATA-------"
    
    print seq1
    print seq2
    print create_consensus(seq1, seq2)

This is admittedly quickly done and there may be both 1) mistakes or special cases 2) a better way to do this, maybe with Biopython.

Hope it helps!

Cheers
</Text>
  </row>
  <row>
    <Id>1281</Id>
    <PostHistoryTypeId>12</PostHistoryTypeId>
    <PostId>683</PostId>
    <RevisionGUID>b97154a9-8a19-4427-bd05-d391e0480d12</RevisionGUID>
    <CreationDate>2010-04-13T16:19:49.347</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>216</UserId>
    <Text>[{"Id":216,"DisplayName":"Eric Normandeau"}]</Text>
  </row>
  <row>
    <Id>1282</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>683</PostId>
    <RevisionGUID>9624e31f-4bbc-400c-a8cb-a4d18ba3e8f7</RevisionGUID>
    <CreationDate>2010-04-13T16:27:23.2</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>there was a big formating bug here</Comment>
    <Text>removed this reply</Text>
  </row>
  <row>
    <Id>1283</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>684</PostId>
    <RevisionGUID>0368adde-3539-4e96-b9c9-119f776cc676</RevisionGUID>
    <CreationDate>2010-04-13T16:28:08.643</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 1 characters in body; deleted 1 characters in body; added 130 characters in body</Comment>
    <Text>The approach to solving your problem requires 3 steps. Here is my take:

 - Use Python with Biopython to pass
   through your sequence couples, one
   individual at a time. Reverse
   complement the second sequence. (use
   any other preferred approach)
 - Use the "dialign2" program repeatedly
   for each individual to create
   alignments. In this way, your 2
   sequences will have the same length
   (with "-" characters to complete the
   missing parts).
 - Use Python to pass through each
   alignment (2 sequences each time) and
   create a consensus. This should be
   easy.

Here is an attempt:

    def create_consensus(seq1, seq2):
        """Sequences must be strings, have the same length, and be aligned"""
        out_seq = ""
        for i, nucleotide in enumerate(seq1):
            couple = [nucleotide, seq2[i]]
            if couple[0] == "-":
                out_seq += couple[1]
            elif couple[1] == "-":
                out_seq += couple[0]
            elif couple[0] == couple[1]:
                out_seq += couple[0]
            elif not couple[0] == couple[1]:
                out_seq += "N"
        return out_seq
    
    seq1 = "-----CAGATACGCGCACATAGACATAG"
    seq2 = "ACTGACAGATACAGACACATA-------"
    
    print seq1
    print seq2
    print create_consensus(seq1, seq2)

The printed result is:

    -----CAGATACGCGCACATAGACATAG
    ACTGACAGATACAGACACATA-------
    ACTGACAGATACNNNCACATAGACATAG

This is admittedly quickly done and there may be both 1) mistakes or special cases 2) a better way to do this, maybe with Biopython.

Hope it helps!

Cheers
</Text>
  </row>
  <row>
    <Id>1284</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>684</PostId>
    <RevisionGUID>086cf024-34b5-4cb5-a3b7-531527ad724d</RevisionGUID>
    <CreationDate>2010-04-13T16:39:06.39</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>added 19 characters in body; added 53 characters in body</Comment>
    <Text>I have had to do something very similar recently.

The approach to solving your problem requires 3 steps. Here is my take:

 - Use Python with Biopython to pass
   through your sequence couples, one
   individual at a time. Reverse
   complement the second sequence. (use
   any other preferred approach)
 - Use the "dialign2" program repeatedly
   for each individual to create
   alignments. In this way, your 2
   sequences will have the same length
   (with "-" characters to complete the
   missing parts).
 - Use Python to pass through each
   alignment (2 sequences each time) and
   create a consensus. This should be
   easy.

Here is an attempt for the third part:

    def create_consensus(seq1, seq2):
        """Sequences must be strings, have the same length, and be aligned"""
        out_seq = ""
        for i, nucleotide in enumerate(seq1):
            couple = [nucleotide, seq2[i]]
            if couple[0] == "-":
                out_seq += couple[1]
            elif couple[1] == "-":
                out_seq += couple[0]
            elif couple[0] == couple[1]:
                out_seq += couple[0]
            elif not couple[0] == couple[1]:
                out_seq += "N"
        return out_seq
    
    seq1 = "-----CAGATACGCGCACATAGACATAG"
    seq2 = "ACTGACAGATACAGACACATA-------"
    
    print seq1
    print seq2
    print create_consensus(seq1, seq2)

The printed result is:

    -----CAGATACGCGCACATAGACATAG
    ACTGACAGATACAGACACATA-------
    ACTGACAGATACNNNCACATAGACATAG

This is admittedly quickly done and there may be both 1) mistakes or special cases 2) a better way to do this, maybe with Biopython.

Hope it helps!

Cheers
</Text>
  </row>
  <row>
    <Id>1285</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>685</PostId>
    <RevisionGUID>42176717-0891-4577-8ea9-97195d051a3e</RevisionGUID>
    <CreationDate>2010-04-13T16:41:30.417</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>&lt;p&gt;One additional one :&lt;/p&gt;
[http://pid.nci.nih.gov/index.shtml][1]
&lt;p&gt;Personnaly I like KEGG Pathways because they provide an XML file related to each graphical representation of the pathways&lt;/p&gt;
&lt;p&gt;It gives you the location in x,y coordinates of all the items that are in the pathway. So, with some Ajax and SVG you can easily draw interactive pathways and higlight proteins that match different kind of criteria (e.g. : In this pathway, what are the kinases, Proteases, mutated Proteins or Proteins tested by Western Blot in a given cell lines etc.).&lt;/p&gt;
&lt;p&gt;Please find below a screen shot of such a generated SVG file.&lt;/p&gt;
&lt;p&gt;It seems that Wikipathways also provide such XML files with each pathway.&lt;/p&gt;
![alt text][2]


  [1]: http://pid.nci.nih.gov/index.shtml
  [2]: http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif</Text>
  </row>
  <row>
    <Id>1286</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>685</PostId>
    <RevisionGUID>6b2e07a3-9bb0-4da7-a171-de3e7f980e41</RevisionGUID>
    <CreationDate>2010-04-13T17:08:53.267</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Comment>deleted 11 characters in body</Comment>
    <Text>&lt;p&gt;One more:&lt;/p&gt;
[http://pid.nci.nih.gov/index.shtml][1]
&lt;p&gt;Personnaly I like KEGG Pathways because they provide an XML file related to each graphical representation of the pathways&lt;/p&gt;
&lt;p&gt;It gives you the location in x,y coordinates of all the items that are in the pathway. So, with some Ajax and SVG you can easily draw interactive pathways and higlight proteins that match different kind of criteria (e.g. : In this pathway, what are the kinases, Proteases, mutated Proteins or Proteins tested by Western Blot in a given cell lines etc.).&lt;/p&gt;
&lt;p&gt;Please find below a screen shot of such a generated SVG file.&lt;/p&gt;
&lt;p&gt;It seems that Wikipathways also provide such XML files with each pathway.&lt;/p&gt;
![alt text][2]


  [1]: http://pid.nci.nih.gov/index.shtml
  [2]: http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif</Text>
  </row>
  <row>
    <Id>1287</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>686</PostId>
    <RevisionGUID>a0fce4db-690b-4fac-9c32-fd897c334d67</RevisionGUID>
    <CreationDate>2010-04-13T17:31:35.17</CreationDate>
    <IPAddress>63.196.132.64</IPAddress>
    <UserId>86</UserId>
    <Text>http://www.pathwaycommons.org

and of course the commercial players Ingenuity and GeneGo...</Text>
  </row>
  <row>
    <Id>1288</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>677</PostId>
    <RevisionGUID>0ccf48e3-147f-4f38-9d35-61cec534fc1b</RevisionGUID>
    <CreationDate>2010-04-13T18:43:30.013</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> émicrosatellitesà  éngsà </Text>
  </row>
  <row>
    <Id>1289</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>670</PostId>
    <RevisionGUID>bd947fad-9f45-40e8-ac6e-91fb49a5c17a</RevisionGUID>
    <CreationDate>2010-04-13T19:18:35.75</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Comment>added 3 characters in body</Comment>
    <Text>that's a use-case i never thought of, but, as it happens, you can do that with the index.
mostly, you dont need to know about the index, but since it saves the file position, you can use that to order your chromosomes:

    f = pyfasta.Fasta('some.fasta')
    sorted_keys = [x[0] for x in sorted(f.index.items(), key=lambda a: a[1][0])]

and that doesn't re-parse the file. and in if you're doing that frequently, you could use a subclass:

    class Fasta(pyfasta.Fasta):
        def sorted_keys(self):
            return [x[0] for x in sorted(self.index.items(), key=lambda a: a[1][0])]</Text>
  </row>
  <row>
    <Id>1290</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>617</PostId>
    <RevisionGUID>a25750ba-eea9-4658-9753-8e176c8e521d</RevisionGUID>
    <CreationDate>2010-04-13T19:25:12.223</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>deleted 18 characters in body; added 18 characters in body</Comment>
    <Text>Hi,

I'm interested in seeing your favorite bit of code that you programmed yourself for bioinformatics purposes.

It can be a function, class, parser, you name it! Mention the language you coded it in.

Cheers to you bioinformaticians!</Text>
  </row>
  <row>
    <Id>1291</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>687</PostId>
    <RevisionGUID>678ae6fa-2fd1-4f69-a18f-f1fba2309356</RevisionGUID>
    <CreationDate>2010-04-13T19:32:31.82</CreationDate>
    <IPAddress>85.168.36.7</IPAddress>
    <UserId>142</UserId>
    <Text>I have been managing a Google group called [Group4Bioinformatics][1].
&lt;p&gt;Since I think BioStar is the best way to offer a technical Bioinformatics Forum I decided to frozen Group4Bioinformatics and to encourage members to join BioStar.&lt;/p&gt;
More over I decided to change the Bioinformatics Forum links on my Website [http://www.bioinformatics.fr][2] and now there are directed to BioStar.
&lt;p&gt;So it is my little contribution in order to help BioStar to grow.&lt;/p&gt;
&lt;p&gt;Hope this will help to get nice contributors.&lt;/p&gt;


  [1]: http://groups-beta.google.com/group/group4bioinformatics?hl=en
  [2]: http://www.bioinformatics.fr</Text>
  </row>
  <row>
    <Id>1292</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>687</PostId>
    <RevisionGUID>678ae6fa-2fd1-4f69-a18f-f1fba2309356</RevisionGUID>
    <CreationDate>2010-04-13T19:32:31.82</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1293</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>688</PostId>
    <RevisionGUID>b10e10c1-3757-46cf-9933-9836367d91f5</RevisionGUID>
    <CreationDate>2010-04-13T20:11:00.317</CreationDate>
    <IPAddress>83.100.237.176</IPAddress>
    <UserId>227</UserId>
    <Text>Not sure this is exactly what you need but Mohammed Noor's lab used a perl script to find microsats in 454 seq fasta file
http://www.biology.duke.edu/noorlab/microscan.plx
Looks like it just counts rather than records positions though.</Text>
  </row>
  <row>
    <Id>1294</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>689</PostId>
    <RevisionGUID>6673c965-357f-41f4-8861-1bafb179a9ac</RevisionGUID>
    <CreationDate>2010-04-13T20:22:51.16</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I have used KEGG, PID and Panther. You may also check PathGuide http://www.pathguide.org/ : Pathguide contains information about 318 biological pathway resources.</Text>
  </row>
  <row>
    <Id>1295</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>690</PostId>
    <RevisionGUID>f825dd4f-f1cb-473d-afc3-f92a7b90683f</RevisionGUID>
    <CreationDate>2010-04-13T20:34:07.337</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I had similar issues Affy array, as suggested mmarchin and nuin, you may start with the conversion using DAVID or BioMart. I would also recommend you to check the latest annotation file from Agilent as well.

I have tried for the MRC-1 in BioMart using HGNC ID. Agile wholegenome ID is A_23_P12746 : http://www.biomart.org/biomart/martview/7312850d734d8b6436f1a79969cf1ab2. 
</Text>
  </row>
  <row>
    <Id>1296</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>690</PostId>
    <RevisionGUID>d5a66834-f6c9-418d-8997-e7d4a72d9e56</RevisionGUID>
    <CreationDate>2010-04-13T20:49:58.397</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Comment>added 7 characters in body</Comment>
    <Text>I had similar issues with Affy array, as suggested mmarchin and nuin, you may start with the conversion using DAVID or BioMart. I would also recommend you to check the latest annotation file from Agilent as well.

I have tried for the MRC-1 in BioMart using HGNC ID. Agilent wholegenome ID is A_23_P12746 : http://www.biomart.org/biomart/martview/7312850d734d8b6436f1a79969cf1ab2. 
</Text>
  </row>
  <row>
    <Id>1297</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>691</PostId>
    <RevisionGUID>1b024cbe-65b5-4b5e-bcf8-74c971a10d13</RevisionGUID>
    <CreationDate>2010-04-13T20:58:25.353</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Have you tried Haploview ? I can see a tab for HapMap PHASE on Haploview 4.2. http://www.broadinstitute.org/haploview/haploview.  And google fetch me this link with a set of haplotyping tools http://www.soph.uab.edu/ssg/linkage/haplotyping. </Text>
  </row>
  <row>
    <Id>1298</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>692</PostId>
    <RevisionGUID>3bdd29b4-dc6c-4227-8e80-a99f9e1e5244</RevisionGUID>
    <CreationDate>2010-04-13T21:08:53.307</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>    chomp (@a = `cat list.txt`); 
    foreach $a(@a) 
     {
     `&lt;whatever&gt; system commands*`; 
     }

* most of my project starts with a list of IDs, first step will be mostly a BLAST or hmmpfam search or to run a custom-program using files in list.txt
</Text>
  </row>
  <row>
    <Id>1299</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>692</PostId>
    <RevisionGUID>3bdd29b4-dc6c-4227-8e80-a99f9e1e5244</RevisionGUID>
    <CreationDate>2010-04-13T21:08:53.307</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1300</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>693</PostId>
    <RevisionGUID>9ee3f1d7-e7a0-484f-9496-ffa074c74468</RevisionGUID>
    <CreationDate>2010-04-13T21:36:17.04</CreationDate>
    <IPAddress>83.101.70.142</IPAddress>
    <UserId>68</UserId>
    <Text>I helped spreading the word by [tweeting][1] and [posting in The Life Scientists, Python for Bioinformatics and Ruby for Bioinformatics groups on Friendfeed][2] about BioStar. I can't quantify it in any way but what I think has had the most impact eyeball-wise is the link to BioStar I added to the sidebar of the [bioinformatics subreddit][3] (a community of 850+ subscribers).

Regarding helping BioStar grow, [Joel Spolsky just made an announcement][4] about the second version of StackExchange, the software which is the basis of this site. Most import change: **Stack Exchange will now be free**. I don't know what this means for the [grant money that Istvan Albert has secured to keep this site running][5], but maybe that money can now be used to reach out to the people who we now have trouble attracting, the beginner bioinformaticians and wetlab biologists looking to expand their skills

The second important change is that *new* Stack Exchange sites are created to move to a more democratic, community process. This isn't relevant for us, but they describe what happens to existing StackExchange sites:

&gt; **Q: What happens with existing Stack Exchange sites?** 
&gt;
&gt; We don’t want to harm
&gt; any communities that have already
&gt; successfully gotten off the ground.
&gt; This harks back to our corporate goal:
&gt;
&gt; *Make the Internet a better place to
&gt; get expert answers to your questions.*
&gt;
&gt; Community is hard to build, and we
&gt; want to work with you to preserve it
&gt; if you’ve already done that with Stack
&gt; Exchange. If we closed down or
&gt; competed with the existing, successful
&gt; Stack Exchange sites, that would
&gt; conflict with our goals. 
&gt; 
&gt; 1. Existing Stack Exchange sites will be kept
&gt; open, under existing rules, for at
&gt; *least* three months, and at least one
&gt; year if you have an active site
&gt; (defined as ten or more visitors or
&gt; more on April 8th). 
&gt; 2. You will not have
&gt; to pay for these sites, ever. 
&gt; 3. We’ll
&gt; give you at least 3 months notice
&gt; before shutting down any site. 
&gt; 4. We’ll
&gt; always make your data available for
&gt; download. 
&gt; 5. If your site remains very
&gt; active, we’d love to work with you to
&gt; migrate it to the new, community-owned
&gt; Stack Exchange platform. That would be
&gt; the best thing that could happen to a
&gt; Stack Exchange 1.0 site, in our
&gt; opinion: that way your site can take
&gt; advantage of our existing resources
&gt; and expansive community.

We meet the criteria in point 1 so I think we'll have to see how we can best do point 5: migrating to the new platform (I don't know how much of a break this will be,but maybe this is also the right time to start with a new slate and solve the Google OpenID login issue.)



PS: in response to the [PS1 by Istvan Albert above][6] I've changed my screen name from the moniker I use everywhere on the net (BioGeek) to my real name.


  [1]: http://twitter.com/BioGeek/status/9966728054
  [2]: http://friendfeed.com/the-life-scientists/92ee04be/biostar-stackoverflow-based-q-site-for
  [3]: http://www.reddit.com/r/bioinformatics
  [4]:  http://blog.stackexchange.com/post/518474918/stack-exchange-2-0
  [5]: http://groups.google.com/group/biostar-central/browse_thread/thread/91493c63c78f042b
  [6]: http://biostar.stackexchange.com/questions/651/helping-biostar-grow/655#655</Text>
  </row>
  <row>
    <Id>1301</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>693</PostId>
    <RevisionGUID>9ee3f1d7-e7a0-484f-9496-ffa074c74468</RevisionGUID>
    <CreationDate>2010-04-13T21:36:17.04</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1302</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>694</PostId>
    <RevisionGUID>36f14e1a-f373-42af-bc7c-39ebba07b17c</RevisionGUID>
    <CreationDate>2010-04-14T03:01:01.793</CreationDate>
    <IPAddress>124.82.231.62</IPAddress>
    <UserId>185</UserId>
    <Text>i will like to know what is the tools used for GO annotation? I am using blast2go at the moment. 

Is it also better to simply blast against Swissprot and directly transfer the GO ?</Text>
  </row>
  <row>
    <Id>1303</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>694</PostId>
    <RevisionGUID>36f14e1a-f373-42af-bc7c-39ebba07b17c</RevisionGUID>
    <CreationDate>2010-04-14T03:01:01.793</CreationDate>
    <IPAddress>124.82.231.62</IPAddress>
    <UserId>185</UserId>
    <Text>GO functional annotation</Text>
  </row>
  <row>
    <Id>1304</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>694</PostId>
    <RevisionGUID>36f14e1a-f373-42af-bc7c-39ebba07b17c</RevisionGUID>
    <CreationDate>2010-04-14T03:01:01.793</CreationDate>
    <IPAddress>124.82.231.62</IPAddress>
    <UserId>185</UserId>
    <Text> égoà </Text>
  </row>
  <row>
    <Id>1305</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>2de4654a-03ca-4959-8d48-c4e96defe4ef</RevisionGUID>
    <CreationDate>2010-04-14T05:48:23.147</CreationDate>
    <IPAddress>81.10.131.15</IPAddress>
    <UserId>136</UserId>
    <Comment>fixed a typo</Comment>
    <Text>Hi people!

I've been using StackOverflow for some time and I appreciate the invaluable support this community has provided me to learn better tricks with my coding. (if you don't know about it and do some coding in your work or for fun, I highly suggest you go have a look there!). There is, however, a definitive lack of interest or knowledge concerning bio-informatics on StackOverflow.

I have only found BioStar a few days ago and already feel how tremendously helpful this community could be, if it grew to reach it's critical mass. The cross-breed that are bio-informaticians could definitely use such a common space and no doubt make it a fun place to share precious experience and information.

We can all take part in contributing to the growth of this community. The [http://biostar.stackexchange.com/bootstrap][1] page already lists three suggestions to do just that:

 1. Invite people (kind of makes sense by itself...)
 2. Ask questions (to populate the wiki with useful information)
 3. Create tags (to help classifying this information)

We can even add other concrete actions to these. What about:

 - Publicity (talk about BioStar on your blog, facebook page, twitter, you name it!)
 - Add your own!

I suggest that we give a few minutes of our time in the coming week to help that community grow into the incredible ressource it has the potential of becoming :)

Please contribute your ideas on how to achieve this goal!

Cheers

  [1]: http://biostar.stackexchange.com/bootstrap</Text>
  </row>
  <row>
    <Id>1306</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>680</PostId>
    <RevisionGUID>2a3291fc-ecd7-4cbc-8c7b-757c43c4093c</RevisionGUID>
    <CreationDate>2010-04-14T08:23:45.787</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Comment>fixed grammar</Comment>
    <Text>Which are all the databases for annotations of biological pathways?</Text>
  </row>
  <row>
    <Id>1307</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>695</PostId>
    <RevisionGUID>fcca302d-afc3-4232-a822-4c5d49ff4ef7</RevisionGUID>
    <CreationDate>2010-04-14T08:59:52.077</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>Is there a kind of **grep** fro [GeneOntology][1] ? I would like to filter a tsv file containing a gene/protein identifier having a Go annotation that would be a children of a given GO term. For example:

    cat myfile.txt |\
    gogrep -f &lt;path-to-my-go-db&gt; \
           -d &lt;column delimiter&gt; \
           -c &lt;column-index-for-identifier&gt; \
           -t &lt;serched GO term  e.g: GO:0003146&gt; \
           -s &lt;identifier-type (uniprot...) &gt; result.txt

Thanks
Pierre


  [1]: http://www.geneontology.org/</Text>
  </row>
  <row>
    <Id>1308</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>695</PostId>
    <RevisionGUID>fcca302d-afc3-4232-a822-4c5d49ff4ef7</RevisionGUID>
    <CreationDate>2010-04-14T08:59:52.077</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text>A grep for Gene Ontology ?</Text>
  </row>
  <row>
    <Id>1309</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>695</PostId>
    <RevisionGUID>fcca302d-afc3-4232-a822-4c5d49ff4ef7</RevisionGUID>
    <CreationDate>2010-04-14T08:59:52.077</CreationDate>
    <IPAddress>193.52.108.46</IPAddress>
    <UserId>30</UserId>
    <Text> égoà  étoolà  égeneontologyà  éfilterà  égrepà </Text>
  </row>
  <row>
    <Id>1310</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>696</PostId>
    <RevisionGUID>ca74fd8a-e57c-4d74-afc1-3b1605a1bd24</RevisionGUID>
    <CreationDate>2010-04-14T09:38:57.54</CreationDate>
    <IPAddress>141.30.193.8</IPAddress>
    <UserId>235</UserId>
    <Text>You could probably query AmiGO, at least if you're doing this on a small scale:

http://amigo.geneontology.org/cgi-bin/amigo/gp-assoc.cgi?gp=UniProtKB/Swiss-Prot:P21728&amp;format=go_assoc

(Though you in particular might prefer the [RDF/XML format][1] ;-)


  [1]: http://amigo.geneontology.org/cgi-bin/amigo/gp-assoc.cgi?gp=UniProtKB/Swiss-Prot:P21728&amp;format=rdfxml</Text>
  </row>
  <row>
    <Id>1311</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>697</PostId>
    <RevisionGUID>e1c23d03-e02b-41c6-97c6-96c1a069b768</RevisionGUID>
    <CreationDate>2010-04-14T09:45:48.4</CreationDate>
    <IPAddress>82.132.248.93</IPAddress>
    <UserId>169</UserId>
    <Text>There is a Perl package called GoPerl http://search.cpan.org/~cmungall/go-perl/ to traverse GO architecture which you could pull into a Perl script to do the same as you describe. Might be a bit of a sledge-hammer to crack a walnut though.</Text>
  </row>
  <row>
    <Id>1312</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>694</PostId>
    <RevisionGUID>ea9f99f3-a0fa-453b-adc0-b99bd7104c71</RevisionGUID>
    <CreationDate>2010-04-14T13:43:33.797</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneöontologyà  ésoftwareà  ébestöapproachà </Text>
  </row>
  <row>
    <Id>1313</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>245</PostId>
    <RevisionGUID>3abbedd3-dee4-4f7e-adc2-07199ef83f06</RevisionGUID>
    <CreationDate>2010-04-14T13:44:10.673</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> égeneöontologyà  éenrichmentà  étoolà  égoà </Text>
  </row>
  <row>
    <Id>1314</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>695</PostId>
    <RevisionGUID>7ba19118-aca8-4e82-bdb5-c2fefcbe3d64</RevisionGUID>
    <CreationDate>2010-04-14T13:44:38.583</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> égoà  étoolà  égeneöontologyà  éfilterà  égrepà </Text>
  </row>
  <row>
    <Id>1315</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>41</PostId>
    <RevisionGUID>c11242fa-54a2-45a6-b8ff-979982878385</RevisionGUID>
    <CreationDate>2010-04-14T13:44:57.96</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> ésubjectiveà  égeneöontologyà  égoà </Text>
  </row>
  <row>
    <Id>1316</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>cb753d94-ac5e-45a8-b833-877575a1d16c</RevisionGUID>
    <CreationDate>2010-04-14T14:47:03.663</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> éproteinà  ésequenceà  émultiplealignmentà  éscoringömatrixà </Text>
  </row>
  <row>
    <Id>1317</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>161</PostId>
    <RevisionGUID>837db50e-9e5b-4bf5-8566-847f3db3cbc3</RevisionGUID>
    <CreationDate>2010-04-14T14:47:27.737</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> ésequenceà  éalignmentà  éscoringömatrixà </Text>
  </row>
  <row>
    <Id>1318</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>183</PostId>
    <RevisionGUID>40ce082d-36ca-458f-9d62-4ebf3ef378ac</RevisionGUID>
    <CreationDate>2010-04-14T14:49:03.023</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> éproteinà  ésequenceà  émultipleöalignmentà  éscoringömatrixà </Text>
  </row>
  <row>
    <Id>1319</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>162</PostId>
    <RevisionGUID>57b01e5c-0889-413d-bc1f-079a6fe01849</RevisionGUID>
    <CreationDate>2010-04-14T14:49:20.577</CreationDate>
    <IPAddress>132.203.89.161</IPAddress>
    <UserId>216</UserId>
    <Comment>edited tags</Comment>
    <Text> émultipleöalignmentà  éalignmentà  édnaà </Text>
  </row>
  <row>
    <Id>1320</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>698</PostId>
    <RevisionGUID>743e4da3-cb23-4a9d-b09d-82af1ded234a</RevisionGUID>
    <CreationDate>2010-04-14T14:57:53.133</CreationDate>
    <IPAddress>132.203.89.197</IPAddress>
    <UserId>224</UserId>
    <Text>Hi !
I tried to use Blast2Go to find GO terms but it's quite slow. So the approach I am currently used is to blast all my sequences on swiss-prot and find GO terms with a python script I wrote. It finds same GO terms as [AmiGo][1] but faster.

So, to answer your question, I think you can use [AmiGo][1] if you want to find GO terms related to a swiss-prot id. But if you have lots of swiss-prot ids it going to be reeeally long.

  [1]: http://amigo.geneontology.org/cgi-bin/amigo/go.cgi</Text>
  </row>
  <row>
    <Id>1321</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>699</PostId>
    <RevisionGUID>c386d37c-cfbd-4c9e-9ecf-e62cb427e2c3</RevisionGUID>
    <CreationDate>2010-04-14T15:11:55.627</CreationDate>
    <IPAddress>195.220.70.21</IPAddress>
    <UserId>199</UserId>
    <Text>
In a microarray experiment, what people often do in first place (after preprocessing and normalization steps) is a hierachical clustering to observe how arrays and genes "*naturally*" organize themselves. That way, you could then identify subgroups of arrays (or genes, it depends what you are interested in) with a similar profile, depending on the distance and linkage you chose. 

But when looking at this first picture of your data, you often identify arrays that would also nicely fit in another cluster. In contrast, each cluster have a set of arrays which is the heart of the cluster, which means the reason why this cluster exists.


Is there any known method(bootstrapping?)/Rpackage to assess clusters robustness/stability ? to identify a *heart* of cluster, exclude non relevant array from the cluster and move it to a cluster where it is more relevant ?
 
Most of all, if you have experience regarding these questions, which method would you advocate ?

Regards,

tony</Text>
  </row>
  <row>
    <Id>1322</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>699</PostId>
    <RevisionGUID>c386d37c-cfbd-4c9e-9ecf-e62cb427e2c3</RevisionGUID>
    <CreationDate>2010-04-14T15:11:55.627</CreationDate>
    <IPAddress>195.220.70.21</IPAddress>
    <UserId>199</UserId>
    <Text>Assessing cluster reliability/stability in microarray experiments</Text>
  </row>
  <row>
    <Id>1323</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>699</PostId>
    <RevisionGUID>c386d37c-cfbd-4c9e-9ecf-e62cb427e2c3</RevisionGUID>
    <CreationDate>2010-04-14T15:11:55.627</CreationDate>
    <IPAddress>195.220.70.21</IPAddress>
    <UserId>199</UserId>
    <Text> éclusteringà  émicroarrayà  égeneöexpressionà </Text>
  </row>
  <row>
    <Id>1324</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>700</PostId>
    <RevisionGUID>cb7913d6-6c88-4afc-ba9c-39b32cab8cb0</RevisionGUID>
    <CreationDate>2010-04-14T15:12:55.683</CreationDate>
    <IPAddress>129.31.194.137</IPAddress>
    <UserId>236</UserId>
    <Text>While I think that GO is very useful especially for exploratory data analysis. It does have a number of problems (its weird graph structure for one). I found that it was very useful for generating a feel for my data and what was going on (in the case of gsea of diff. exp GX data).

I read this paper a while ago: 

Quantifying the biological signiﬁcance of gene ontology biological 
processes—implications for the analysis of systems-wide data 

http://www.ncbi.nlm.nih.gov/pubmed/19965879

and although I have a few minor issues with some of the methods, it has a very clear message in that the gene ontology does contain some terms and relationships which are artifacts of human annotations and should be removed prior to analysis (depending of course on the analysis) otherwise they will bias any statistics/conclusions.

Annotation bias of GO terms is problematic .... but unfortunately thats the way it works. </Text>
  </row>
  <row>
    <Id>1325</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>701</PostId>
    <RevisionGUID>7a110f83-f36e-4136-8238-d904b86eecb8</RevisionGUID>
    <CreationDate>2010-04-14T15:22:18.873</CreationDate>
    <IPAddress>78.241.130.49</IPAddress>
    <UserId>205</UserId>
    <Text>I use such profile matrices but I don't know any public implementation, 
I have done my own in C++. It is not so long to do.

I create an array of array "tab[L][20]" with L the size of the alignment.

Then I read the sequences of the alignment and I count the number of amino acids in each column. I also count the number of gaps. Then I can calculate a log odd score like in Fano [1]

Something to care about is the similarity between the sequences in the alignment.
If sequences are too similar then some amino acids might be over-represented at a position.
This can introduce a bias in the statistics.

[1] Fano RM. Transmition of information: a statistical theory of communication. Cambridge, MA: MIT Press; 1961.</Text>
  </row>
  <row>
    <Id>1326</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>702</PostId>
    <RevisionGUID>74ce3310-2466-4ea8-b024-b62234fbff2d</RevisionGUID>
    <CreationDate>2010-04-14T15:24:59.417</CreationDate>
    <IPAddress>132.203.89.197</IPAddress>
    <UserId>224</UserId>
    <Text>I think clear help function is really important for users. So, even if it is not a bioinformatic code, this is a useful code for me. It is a python code which reproduce the "man" aspect.

    import sys
    
    print """
    test(1)                           User Commands                         test(1)
    
    \033[1mNAME\033[0m
    \t%s - small description
    
    \033[1mSYNOPSIS\033[0m
    \t\033[1mpython %s \033[0m[\033[4mOPTION\033[0m]... [\033[4mFILE\033[0m]...
    
    \033[1mDESCRIPTION\033[0m
    \tLong description
    
    \twith differents paragraphs
    
    \t\033[1m-f, --file\033[0m
    \t\tThe file...
    
    \t\033[1m-h, --help\033[0m
    \t\tDisplay the man of this program
    
    \033[1mAUTHOR\033[0m
    \tWritten by Nico.
    """ % (sys.argv[0],sys.argv[0])

A screenshot to show result :

![alt text][1]


  [1]: http://ftp.yark.fr/Glock21/pythonMan.png

It is definitely NOT a bioinformatic code... ^^'</Text>
  </row>
  <row>
    <Id>1327</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>702</PostId>
    <RevisionGUID>74ce3310-2466-4ea8-b024-b62234fbff2d</RevisionGUID>
    <CreationDate>2010-04-14T15:24:59.417</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1328</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>580</PostId>
    <RevisionGUID>c38d332f-2458-42a4-a9d0-d7166309d95a</RevisionGUID>
    <CreationDate>2010-04-14T15:33:11.257</CreationDate>
    <IPAddress>78.241.130.49</IPAddress>
    <UserId>205</UserId>
    <Comment>Added link to dynamic programming</Comment>
    <Text>My answer comes late but I just discovered this web site.

Instead of writing the blosum matrix in a data struct, I think it is a better idea to create a function to read your matrix in a text file.

Thus, if you want to try another scoring matrix than blosum 62, you just have to read another file.

Bilou.

[Edit]

The Needleman-Wunsch algorithm is a simple dynamic programming approach. Perhaps this page can helps you with pseudo-code : http://en.wikipedia.org/wiki/Dynamic_programming</Text>
  </row>
  <row>
    <Id>1329</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>701</PostId>
    <RevisionGUID>3cca0788-7c69-4c62-9bb4-c8a9bf300c81</RevisionGUID>
    <CreationDate>2010-04-14T15:44:35.827</CreationDate>
    <IPAddress>78.241.130.49</IPAddress>
    <UserId>205</UserId>
    <Comment>added 107 characters in body</Comment>
    <Text>I use such profile matrices but I don't know any public implementation, 
I have done my own in C++. It is not so long to do.

I create an array of array "tab[L][20]" with L the size of the alignment.

Then I read the sequences of the alignment and I count the number of amino acids in each column. I also count the number of gaps. Then I can calculate a log odd score like in Fano [1]

Something to care about is the similarity between the sequences in the alignment.
If sequences are too similar then some amino acids might be over-represented at a position.
This can introduce a bias in the statistics.

You can read this if you want to see how I use profiles : FROST: a filter-based fold recognition method

[1] Fano RM. Transmition of information: a statistical theory of communication. Cambridge, MA: MIT Press; 1961.</Text>
  </row>
  <row>
    <Id>1330</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>703</PostId>
    <RevisionGUID>eea8cfcd-76f4-4c4a-90bc-192fe6b7b35b</RevisionGUID>
    <CreationDate>2010-04-14T15:53:29.503</CreationDate>
    <IPAddress>85.2.218.144</IPAddress>
    <UserId>119</UserId>
    <Text>To test the robustness/stability of groups of samples in clustering, typically **bootstrapping** is used (or related techniques, such as jackknifing), and summarised in a (typically majority-rule) consensus tree. That your input data for the clustering come from microarrays is largely irrelevant. 

Essentially, in bootstrapping you're asking the question what proportion of your input data support a certain grouping. </Text>
  </row>
  <row>
    <Id>1331</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>703</PostId>
    <RevisionGUID>13559a41-9938-43d3-ad40-3f26b9f01f23</RevisionGUID>
    <CreationDate>2010-04-14T16:00:21.703</CreationDate>
    <IPAddress>85.2.218.144</IPAddress>
    <UserId>119</UserId>
    <Comment>expanded answer</Comment>
    <Text>To test the robustness/stability of groups of samples in clustering, typically **bootstrapping** is used (or related techniques, such as jackknifing), and summarised in a (typically majority-rule) consensus tree. That your input data for the clustering come from microarrays is largely irrelevant. 

Essentially, in bootstrapping you're asking the question what proportion of your input data support a certain grouping. It is done by making a pseudo-replicate of your input data (`N` samples x `M` data rows), keeping the same number of samples `N` constant, but `M` times randomly choosing new data rows, like such (pseudo-code):

    for j= 1 to M {i= random(1,M)
                   DataReplicate[j]:= Data[i]}
where Data[i] is an array of values with entries for each sample. So, in the end, your pseudo-replicate has the same dimensions `N x M` as your input data matrix. The entire procedure of clustering is then repeated for each pseudo-replicates and clustering results compared by consensus tree methods.</Text>
  </row>
  <row>
    <Id>1332</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>704</PostId>
    <RevisionGUID>01104e80-5cab-4eff-ae0b-c5107c072977</RevisionGUID>
    <CreationDate>2010-04-14T16:04:59.023</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text>I tried [multicore][1] today and was up and running on multiple processors in minutes. I think it is best suited to utilizing unused cores on a desktop machine working locally. Though I am now also using it on an LSF managed compute cluster by requesting multiple cores for my R jobs (with the -n option). 

Is almost as simple as doing a find and replace for lapply with mclapply, almost. That is if your code used lapply of course. Multicore also has parallel and collect functions which make it easy to split any functions across cores, not just with lapply. 


  [1]: http://www.rforge.net/doc/packages/multicore/multicore.html</Text>
  </row>
  <row>
    <Id>1333</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>702</PostId>
    <RevisionGUID>6aa83ecb-8e8d-4282-af1b-fb7de08baeab</RevisionGUID>
    <CreationDate>2010-04-14T16:05:09.633</CreationDate>
    <IPAddress>132.203.89.197</IPAddress>
    <UserId>224</UserId>
    <Comment>corrected spelling</Comment>
    <Text>I think clear help function is really important for users. So, even if it is not a bioinformatic code, this is a useful code for me. It is a small code which reproduce the "man" aspect.

    import sys
    
    print """
    test(1)                           User Commands                         test(1)
    
    \033[1mNAME\033[0m
    \t%s - small description
    
    \033[1mSYNOPSIS\033[0m
    \t\033[1mpython %s \033[0m[\033[4mOPTION\033[0m]... [\033[4mFILE\033[0m]...
    
    \033[1mDESCRIPTION\033[0m
    \tLong description
    
    \twith differents paragraphs
    
    \t\033[1m-f, --file\033[0m
    \t\tThe file...
    
    \t\033[1m-h, --help\033[0m
    \t\tDisplay the man of this program
    
    \033[1mAUTHOR\033[0m
    \tWritten by Nico.
    """ % (sys.argv[0],sys.argv[0])

A screenshot to show result :

![alt text][1]


  [1]: http://ftp.yark.fr/Glock21/pythonMan.png

It is definitely NOT a bioinformatic code... ^^'</Text>
  </row>
  <row>
    <Id>1334</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>705</PostId>
    <RevisionGUID>dafbd9b5-51aa-4aed-b383-878ddbf59cac</RevisionGUID>
    <CreationDate>2010-04-14T16:17:25.057</CreationDate>
    <IPAddress>80.203.61.32</IPAddress>
    <UserId>55</UserId>
    <Text>In their critical and excellent [2006 Review, Allison et al.][1] provide a good overview of methods for MA data analysis. I personally would agree mostly with their conclusion: 

&gt; We believe that unsupervised
&gt; classification is overused; first,
&gt; little information is available about
&gt; the absolute validity or relative
&gt; merits of clustering procedures
&gt; second, the evidence indicates that
&gt; the clusterings that are produced with
&gt; typical sample sizes (&lt;50) are
&gt; generally not reproducible
&gt; third, and most importantly,
&gt; unsupervised classification rarely
&gt; seems to address the questions that
&gt; are asked by biologists, who are
&gt; usually interested in identifying
&gt; differential expression.

However, clustering can be useful to examine the values for a first glance overview, and also to see, if arrays correlate well, and if techn./biol. replicates are falling into the same cluster. An alternative if you are interested in how well arrays or experimental conditions correlate overall is to cluster the correlation matrix of the arrays (or of joint replicate measurements) and to plot a heatmap of the array correlation coefficient instead of plotting the expression heatmap.

Cluster analysis is an exploratory technique, as such there is no way to determine what is the "real" outcome. Any solution that helps you discover something is good and valid. (There exists an optimal solution for  the clustering plroblem, given the optimization criterion (e.g. minimize inter/intra cluster-distance)  of the algorithm though, but this is only of theoretical relevance, because all algorithms are approximative). 

Thus, you can freely exchange cluster members of a hierarchical cluster analysis of manually as you see fit, you might be able to find a solution that suits the data better.

**Some things to look at:**

 - We have some time ago internally
   tried out different cluster
   validation techniques (cluster
   indices), one that convinced me most
   conceptually is the Figure of Merit
   (FOM), [Yeung et. al 2001.][2] They use "jackknifing" (leave on out) which related to bootstrapping you mention.
 - Some more cluster indices are
   implemented in the R function
   cluster.stats in the fpc package
   http://cran.r-project.org/web/packages/fpc/index.html
 - or the randIndex in the flexClust
   package
   http://cran.r-project.org/web/packages/flexclust/index.html.
 - Also: the clusterRepro package looks
   like something to try (haven't
   myself)
   http://cran.r-project.org/web/packages/clusterRepro/index.html.

My personal conclusion was however that all methods evaluate something very different but they do not help a millimetre to get to the answer of biological questions. 




  [1]: http://www.ncbi.nlm.nih.gov/pubmed/16369572
  [2]: http://www.ncbi.nlm.nih.gov/pubmed/11301299</Text>
  </row>
  <row>
    <Id>1335</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>706</PostId>
    <RevisionGUID>9504da62-147a-4a25-be9b-0d173c8d34dc</RevisionGUID>
    <CreationDate>2010-04-14T16:20:30.447</CreationDate>
    <IPAddress>85.2.218.144</IPAddress>
    <UserId>119</UserId>
    <Text>This probably counts as *insane*, but my favourite bits of code are those where I've optimised a speed-critical function in x86/x86-64 **assembly** for the latest SIMD instruction set I have hardware capable of running (damn, haven't got to SSE4.2, yet). It never results in *short* code, though.</Text>
  </row>
  <row>
    <Id>1336</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>706</PostId>
    <RevisionGUID>9504da62-147a-4a25-be9b-0d173c8d34dc</RevisionGUID>
    <CreationDate>2010-04-14T16:20:30.447</CreationDate>
    <IPAddress>127.0.0.1</IPAddress>
    <UserId>-1</UserId>
  </row>
  <row>
    <Id>1337</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>705</PostId>
    <RevisionGUID>e931430d-fbed-45e8-b951-a19f15a86b27</RevisionGUID>
    <CreationDate>2010-04-14T16:22:39.163</CreationDate>
    <IPAddress>80.203.61.32</IPAddress>
    <UserId>55</UserId>
    <Comment>added 157 characters in body</Comment>
    <Text>In their critical and excellent [2006 Review, Allison et al.][1] provide a good overview of methods for MA data analysis. I personally would agree mostly with their conclusion: 

&gt; We believe that unsupervised
&gt; classification is overused; first,
&gt; little information is available about
&gt; the absolute validity or relative
&gt; merits of clustering procedures
&gt; second, the evidence indicates that
&gt; the clusterings that are produced with
&gt; typical sample sizes (&lt;50) are
&gt; generally not reproducible
&gt; third, and most importantly,
&gt; unsupervised classification rarely
&gt; seems to address the questions that
&gt; are asked by biologists, who are
&gt; usually interested in identifying
&gt; differential expression.

However, clustering can be useful to examine the values for a first glance overview, and also to see, if arrays correlate well, and if techn./biol. replicates are falling into the same cluster. An alternative if you are interested in how well arrays or experimental conditions correlate overall is to cluster the correlation matrix of the arrays (or of joint replicate measurements) and to plot a heatmap of the array correlation coefficient instead of plotting the expression heatmap.

Cluster analysis is an exploratory technique, as such there is no way to determine what is the "real" outcome. Any solution that helps you discover something is good and valid. (There exists an optimal solution for  the clustering plroblem, given the optimization criterion (e.g. minimize inter/intra cluster-distance)  of the algorithm though, but this is only of theoretical relevance, because all algorithms are approximative). 

Thus, you can freely exchange cluster members of a hierarchical cluster analysis of manually as you see fit, you might be able to find a solution that suits the data better.

**Some things to look at:**

 - We have some time ago internally
   tried out different cluster
   validation techniques (cluster
   indices), one that convinced me most
   conceptually is the Figure of Merit
   (FOM), [Yeung et. al 2001.][2] They use "jackknifing" (leave on out) which related to bootstrapping you mention.
 - Some more cluster indices are
   implemented in the R function
   cluster.stats in the fpc package
   http://cran.r-project.org/web/packages/fpc/index.html
 - or the randIndex in the flexClust
   package
   http://cran.r-project.org/web/packages/flexclust/index.html.
 - Also: the clusterRepro package looks
   like something to try (haven't
   myself)
   http://cran.r-project.org/web/packages/clusterRepro/index.html.
 - And another article with overviews of cluster indices used for microarrays: [Smolkin &amp; Ghosh, 2003][3]


My personal conclusion was however that all methods evaluate something very different but they do not help a millimetre to get to the answer of biological questions. 


  [1]: http://www.ncbi.nlm.nih.gov/pubmed/16369572
  [2]: http://www.ncbi.nlm.nih.gov/pubmed/11301299
  [3]: http://www.ncbi.nlm.nih.gov/pubmed/12959646</Text>
  </row>
  <row>
    <Id>1338</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>770869f8-c9d1-4f81-bcc7-ef256874eb1e</RevisionGUID>
    <CreationDate>2010-04-14T17:06:15.4</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>In 1999, when the Celera Genomics company announced they had sequenced the first human genome before the International Consortium, the value of their actions raised quickly from ~7$ to ~200$ each, to slowly return to the original values after a few years.

So, investing on a biotek company is in general a lot risky and you have to look for a company that is developing something that will interest the media, e.g. a new drug or a new important technology.

On which biotek/bioinfo company would you invest if you had enough money? I don't think there are many bioinformatics companies indexed on the market yet, but maybe some of those working in the 'Sequence your personal genome' business are there. The situation is different for some biotek companies, there are more in the market and some of them are developing new interesting technologies.

Have you ever tried to invest money on a biotek company? How much would you recommend? By chance, can anyone here borrow me some spare millions of dollars to invest and become rich? :-)</Text>
  </row>
  <row>
    <Id>1339</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>770869f8-c9d1-4f81-bcc7-ef256874eb1e</RevisionGUID>
    <CreationDate>2010-04-14T17:06:15.4</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text>investing on biotek/bioinfo companies</Text>
  </row>
  <row>
    <Id>1340</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>770869f8-c9d1-4f81-bcc7-ef256874eb1e</RevisionGUID>
    <CreationDate>2010-04-14T17:06:15.4</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Text> émarketà  éinvestmentà  ébecomingörichöeventuallyà  éhopeà </Text>
  </row>
  <row>
    <Id>1341</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>8fdf9f19-b99e-4b2f-8e7e-c1cb4fbb17c6</RevisionGUID>
    <CreationDate>2010-04-14T17:11:39.753</CreationDate>
    <IPAddress>82.126.11.30</IPAddress>
    <UserId>30</UserId>
    <Comment>edited tags</Comment>
    <Text> émarketà  éinvestmentà  ébecomingörichöeventuallyà  éhopeà  énotà </Text>
  </row>
  <row>
    <Id>1342</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>137bcc23-8a24-4b41-8d45-2f0bf2456423</RevisionGUID>
    <CreationDate>2010-04-14T17:11:49.44</CreationDate>
    <IPAddress>82.126.11.30</IPAddress>
    <UserId>30</UserId>
    <Comment>edited tags</Comment>
    <Text> émarketà  éinvestmentà  ébecomingörichöeventuallyà  éhopeà  énotöprogrammingörelatedà </Text>
  </row>
  <row>
    <Id>1343</Id>
    <PostHistoryTypeId>16</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>6393085d-44c2-4af9-838a-ceb7c1d39856</RevisionGUID>
    <CreationDate>2010-04-14T19:03:56.323</CreationDate>
    <IPAddress>83.57.6.128</IPAddress>
    <UserId>23</UserId>
  </row>
  <row>
    <Id>1344</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>707</PostId>
    <RevisionGUID>6393085d-44c2-4af9-838a-ceb7c1d39856</RevisionGUID>
    <CreationDate>2010-04-14T19:03:56.323</CreationDate>
    <IPAddress>83.57.6.128</IPAddress>
    <UserId>23</UserId>
    <Comment>made community-wiki, changed tags</Comment>
    <Text> émarketà  éinvestmentà  ésubjectiveà  énotöprogrammingörelatedà </Text>
  </row>
  <row>
    <Id>1345</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>708</PostId>
    <RevisionGUID>defb2f50-db66-4ef5-93be-e062c8fdc66e</RevisionGUID>
    <CreationDate>2010-04-14T20:08:14.97</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>I am looking for a content management systems for our lab server. It will be nice, if I can integrate the CMS with bioinformatics dbs and apps that we develop. I know about moinmoin, docuwiki and plone and have tried some of the websites implemented in them. Feedback on these CMS from a bioinformatics perspectives are welcome. You may suggest other CMS that you have tried. 
</Text>
  </row>
  <row>
    <Id>1346</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>708</PostId>
    <RevisionGUID>defb2f50-db66-4ef5-93be-e062c8fdc66e</RevisionGUID>
    <CreationDate>2010-04-14T20:08:14.97</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text>Content management systems for bioinformatics websites</Text>
  </row>
  <row>
    <Id>1347</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>708</PostId>
    <RevisionGUID>defb2f50-db66-4ef5-93be-e062c8fdc66e</RevisionGUID>
    <CreationDate>2010-04-14T20:08:14.97</CreationDate>
    <IPAddress>129.176.151.24</IPAddress>
    <UserId>87</UserId>
    <Text> éwebödevelopmentà  écmsà </Text>
  </row>
  <row>
    <Id>1348</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>709</PostId>
    <RevisionGUID>8e46d0a5-563e-4742-a7ed-828d4329d9a9</RevisionGUID>
    <CreationDate>2010-04-14T20:14:24.127</CreationDate>
    <IPAddress>132.203.89.197</IPAddress>
    <UserId>224</UserId>
    <Text>I have tried [Joomla][1] to create a website for french students in bioinformatics but we've been hacked couple of times... So we just open a phpBB forum :-/

But [Joomla][1] is one of the best cms I used. There is a big community around it and lot's of good plugins / extensions.


  [1]: http://www.joomla.org/</Text>
  </row>
  <row>
    <Id>1349</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>710</PostId>
    <RevisionGUID>99696968-0404-42fe-9307-02f61c8863d6</RevisionGUID>
    <CreationDate>2010-04-14T21:46:21.647</CreationDate>
    <IPAddress>137.205.75.226</IPAddress>
    <UserId>169</UserId>
    <Text>I have just written an R package called clusterCons that is an implementation of the method for clustering robustness assessment described in :-

S. Monti. Consensus clustering: A resampling-based method for class discovery and visualization of gene expression microarray data. Machine Learning, 52, July 2003.

Which follows something very similar to the re-sampling approach very nicely described by PhiS (above). The package is in alpha at the moment, but is being used by quite a few other groups right now as part of our functionality testing, we are just finishing a paper describing the package and its application to cluster and gene prioritisation. The method described by Monti is very simple and elegant and has been cited in &gt;100 papers to date. The clusterCons package can use any kind of clustering provided that the clustering function used returns a result that can be formatted as a cluster membership list, so could be used with supervised clustering (all you have to do is write a small very simple custom wrapper for any new functions), but is currently written to use the methods provided by the 'cluster' package in R which are all unsupervised (so you can currently use 'agnes', 'pam', 'hclust', diana' and 'kmeans' out of the box). If you are interested in trying it you can get it through CRAN http://cran.r-project.org/web/packages/clusterCons/index.html or sourceforge http://bit.ly/clusterCons and I am very happy to help you on your way if you decide to try it out.

Unfortunately, although I understand where he is coming from I actually disagree with Michael and the review by Allison, and I am both a biologist and a computational biologist. I think that supervised clustering is often used with a belief that it is going to provide biologically meaningful clusters when in fact it produces clusters that are heavily biased by the supervising information. The problem with this is that the biological supervising information is almost always of very poor and often unverifiable quality. It could be for example transcription factor binding data (hugely biased, data sparse and noisy), ChIP-ChIP/ChIP-seq (very high noise), patient classification (unquantified, obtuse, unverifiable or just plain wrong) to name but a few. I'm not saying that supervised clustering doesn't have a place, but I avoid it like the plague and much prefer to follow up unsupervised clustering (with robustness measures) with some proper biological validation. I hope this doesn't come across as antagonistic to Michael, clearly he has a lot of experience with clustering as well, just wanted to let you know how we handle the problem.

</Text>
  </row>
  <row>
    <Id>1350</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>612</PostId>
    <RevisionGUID>dc0fd58e-e620-44b9-884e-c2a173b7e2ee</RevisionGUID>
    <CreationDate>2010-04-15T00:28:30.047</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Comment>deleted 1 characters in body</Comment>
    <Text>We are using a non-free solution, the CLC Genomic Workbench. This software has MANY capabilities. In the role you are asking about, it would easily assemble millions and millions of short reads (given enough RAM, and, of course, a 64bit system to use it). You can easily put in data from different taxa, specify different criteria for the assembly, or alternatively, use a reference genome to assemble your data on, so as to potentially get a less messy result (less influenced by sequence divergence, paralogy...).

This software could be somewhat pricey for a small lab, but in the context of a group of research, I have found that it was many times worth it's price just in time saved on student projects.

The software also has A LOT of features for biologists working with sequences. Not only assembling NGS data.

DISCLAIMER (just in case...): I am IN NO WAY connected to this company. I just happen to be a happy user :)

Cheers.</Text>
  </row>
  <row>
    <Id>1351</Id>
    <PostHistoryTypeId>8</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>9aebe90d-8a0c-4e2c-bcc2-618e44c00129</RevisionGUID>
    <CreationDate>2010-04-15T00:37:37.177</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Comment>Rollback to [08e05b80-02db-4177-a135-80b4e2fe6e16]</Comment>
    <Text>Hi people!

I've been using StackOverflow for some time and I appreciate the invaluable support this community has provided me to learn better tricks with my coding. (if you don't know about it and do some coding in your work or for fun, I highly suggest you go have a look there!). There is, however, a definitive lack of interest or knowledge concerning bio-informatics on StackOverflow.

I have only found BioStar a few days ago and already feel how tremendously helpful this community could be, if it grew to reach it's critical mass. The cross-breed that are bio-informaticians could definitely use such a common space and no doubt make it a fun place to share precious experience and information.

We can all take part in contributing to the growth of this community. The [http://biostar.stackexchange.com/bootstrap][1] page already lists three suggestions to do just that:

 1. Invite people (kind of makes sens by itself...)
 2. Ask questions (to populate the wiki with useful information)
 3. Create tags (to help classifying this information)

We can even add other concrete actions to these. What about:

 - Publicity (talk about BioStar on your blog, facebook page, twitter, you name it!)
 - Add your own!

I suggest that we give a few minutes of our time in the coming week to help that community grow into the incredible ressource it has the potential of becoming :)

Please contribute your ideas on how to achieve this goal!

Cheers

  [1]: http://biostar.stackexchange.com/bootstrap</Text>
  </row>
  <row>
    <Id>1352</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>845eb499-1d7f-4cf0-91d0-8caafd377aab</RevisionGUID>
    <CreationDate>2010-04-15T00:38:11.637</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Comment>typo</Comment>
    <Text>Hi people!

I've been using StackOverflow for some time and I appreciate the invaluable support this community has provided me to learn better tricks with my coding. (if you don't know about it and do some coding in your work or for fun, I highly suggest you go have a look there!). There is, however, a definitive lack of interest or knowledge concerning bio-informatics on StackOverflow.

I have only found BioStar a few days ago and already feel how tremendously helpful this community could be, if it grew to reach it's critical mass. The cross-breed that are bio-informaticians could definitely use such a common space and no doubt make it a fun place to share precious experience and information.

We can all take part in contributing to the growth of this community. The [http://biostar.stackexchange.com/bootstrap][1] page already lists three suggestions to do just that:

 1. Invite people (kind of makes sens by itself...)
 2. Ask questions (to populate the wiki with useful information)
 3. Create tags (to help classifying this information)

We can even add other concrete actions to these. What about:

 - Publicity (talk about BioStar on your blog, facebook page, twitter, you name it!)
 - Add your own!

I suggest that we give a few minutes of our time in the coming week to help that community grow into the incredible resource it has the potential of becoming :)

Please contribute your ideas on how to achieve this goal!

Cheers

  [1]: http://biostar.stackexchange.com/bootstrap</Text>
  </row>
  <row>
    <Id>1353</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>711</PostId>
    <RevisionGUID>2b5bc09a-4b37-4664-9013-5ea7b6a37960</RevisionGUID>
    <CreationDate>2010-04-15T00:51:33.133</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Text>Hi,

I have been wandering at the correct approach in Python, maybe using Biopython, of parsing a fasta file without having to place it in memory (eg: reading it to a list, dictionary or fasta class) before using it.

The desired result would behave like a generator, as in the pseudo-code example below:

    fasta_sequences = fasta_generator(input_file) # The function I miss
    with open(output_file) as out_file:
        for fasta in fasta_sequences:
            name, sequence = fasta
            new_sequence = some_function(sequence)
            write_fasta(out_file) # Function defined elsewhere

Important aspects are:

 - Read sequences one at a time
 - Does not put all the sequences into memory
 - The approach is safe and well tested

Thanks for your suggestions!</Text>
  </row>
  <row>
    <Id>1354</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>711</PostId>
    <RevisionGUID>2b5bc09a-4b37-4664-9013-5ea7b6a37960</RevisionGUID>
    <CreationDate>2010-04-15T00:51:33.133</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Text>Correct way to parse a fasta file in Python</Text>
  </row>
  <row>
    <Id>1355</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>711</PostId>
    <RevisionGUID>2b5bc09a-4b37-4664-9013-5ea7b6a37960</RevisionGUID>
    <CreationDate>2010-04-15T00:51:33.133</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Text> éfastaà  éparsingà  égeneratorà  épythonà </Text>
  </row>
  <row>
    <Id>1356</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>712</PostId>
    <RevisionGUID>5c0d50ba-f504-45c0-a408-01797970be94</RevisionGUID>
    <CreationDate>2010-04-15T01:07:45.8</CreationDate>
    <IPAddress>71.58.68.17</IPAddress>
    <UserId>14</UserId>
    <Text>I think you can just use Biopython

    from Bio import SeqIO
    
    fasta_sequences = SeqIO.parse(open(input_file),'fasta')
    with open(output_file) as out_file:
        for fasta in fasta_sequences:
            name, sequence = fasta.id, fasta.seq.tostring()
            new_sequence = some_function(sequence)
            write_fasta(out_file)

You can take a look at the Biopython tutorial:
http://www.biopython.org/DIST/docs/tutorial/Tutorial.html#htoc11</Text>
  </row>
  <row>
    <Id>1357</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>713</PostId>
    <RevisionGUID>149839b1-ff66-484e-bce5-cb59b0784eba</RevisionGUID>
    <CreationDate>2010-04-15T01:17:05.413</CreationDate>
    <IPAddress>70.54.0.56</IPAddress>
    <UserId>127</UserId>
    <Text>A very simple and not really elegant approach I have on Beginning Python for Bioinformatics website:

    class FastaSeq:
	def __init__(self, name, sequence):
		self.name = name
		self.sequence = sequence


    def get_seqs(file):
    	items = []
    	index = 0
    	for line in file:
    		if line.startswith("&gt;"):
    			if index &gt;= 1:
    				items.append(aninstance)
    			index+=1
    			name = line[:-1]
    			seq = ''
    			aninstance = FastaSeq(name, seq)
    		else:
    			seq += line[:-1]
    			aninstance = FastaSeq(name, seq)
    	items.append(aninstance)
    	
    	return items

It works as a learning experience. But you don't want to reinvent the wheel on this one.

</Text>
  </row>
  <row>
    <Id>1358</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>714</PostId>
    <RevisionGUID>77d9811a-7755-4fb5-90ec-e2726f9cb840</RevisionGUID>
    <CreationDate>2010-04-15T01:52:18.907</CreationDate>
    <IPAddress>173.177.117.170</IPAddress>
    <UserId>226</UserId>
    <Text>Hi Guys,

I think you can have a look to this link: http://seqanswers.com/forums/showthread.php?t=43

This an exhaustive list of Free and commercial solutions to perform NGS data assembly.

More specifically to the initial question, I agree with Eric, CLC Genomic Workbench is a very interesting integrated solution. Moreover, you can try MIRA3 (Linux, http://www.chevreux.org/mira_downloads.html). 

Regards.</Text>
  </row>
  <row>
    <Id>1359</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>711</PostId>
    <RevisionGUID>bbfdb043-38ea-412c-ada0-60cd86ddebb4</RevisionGUID>
    <CreationDate>2010-04-15T02:04:53.903</CreationDate>
    <IPAddress>74.12.230.144</IPAddress>
    <UserId>216</UserId>
    <Comment>typos</Comment>
    <Text>Hi,

I have been wondering at the correct approach in Python, maybe using Biopython, of parsing a fasta file without having to place it in memory (eg: NOT having to read it to a list, dictionary or fasta class) before using it.

The desired result would behave like a generator, as in the pseudo-code example below:

    fasta_sequences = fasta_generator(input_file) # The function I miss
    with open(output_file) as out_file:
        for fasta in fasta_sequences:
            name, sequence = fasta
            new_sequence = some_function(sequence)
            write_fasta(out_file) # Function defined elsewhere

Important aspects are:

 - Read sequences one at a time
 - Does not put all the sequences into memory
 - The approach is safe and well tested

Thanks for your suggestions!</Text>
  </row>
  <row>
    <Id>1360</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>715</PostId>
    <RevisionGUID>f4cd5d8a-1ebf-4915-a3eb-55fcc1cc4949</RevisionGUID>
    <CreationDate>2010-04-15T03:14:05.28</CreationDate>
    <IPAddress>69.109.126.130</IPAddress>
    <UserId>36</UserId>
    <Text>in another thread, someone pointed you to this:
http://drj11.wordpress.com/2010/02/22/python-getting-fasta-with-itertools-groupby/

which i think is pretty beautiful.
but this is trivial in any library.</Text>
  </row>
  <row>
    <Id>1361</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>651</PostId>
    <RevisionGUID>4bc90ba2-94ba-4f3a-aa1f-e4fd28f74005</RevisionGUID>
    <CreationDate>2010-04-15T05:22:27.843</CreationDate>
    <IPAddress>81.10.131.15</IPAddress>
    <UserId>136</UserId>
    <Comment>typo. http://www.merriam-webster.com/dictionary/sens vs http://www.merriam-webster.com/dictionary/sense !</Comment>
    <Text>Hi people!

I've been using StackOverflow for some time and I appreciate the invaluable support this community has provided me to learn better tricks with my coding. (if you don't know about it and do some coding in your work or for fun, I highly suggest you go have a look there!). There is, however, a definitive lack of interest or knowledge concerning bio-informatics on StackOverflow.

I have only found BioStar a few days ago and already feel how tremendously helpful this community could be, if it grew to reach it's critical mass. The cross-breed that are bio-informaticians could definitely use such a common space and no doubt make it a fun place to share precious experience and information.

We can all take part in contributing to the growth of this community. The [http://biostar.stackexchange.com/bootstrap][1] page already lists three suggestions to do just that:

 1. Invite people (kind of makes sense by itself...)
 2. Ask questions (to populate the wiki with useful information)
 3. Create tags (to help classifying this information)

We can even add other concrete actions to these. What about:

 - Publicity (talk about BioStar on your blog, facebook page, twitter, you name it!)
 - Add your own!

I suggest that we give a few minutes of our time in the coming week to help that community grow into the incredible resource it has the potential of becoming :)

Please contribute your ideas on how to achieve this goal!

Cheers

  [1]: http://biostar.stackexchange.com/bootstrap</Text>
  </row>
  <row>
    <Id>1362</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>716</PostId>
    <RevisionGUID>50ba7131-29d6-43cb-962e-2615ff47f909</RevisionGUID>
    <CreationDate>2010-04-15T06:35:17.403</CreationDate>
    <IPAddress>82.150.28.126</IPAddress>
    <UserId>142</UserId>
    <Text>&lt;p&gt;Do you have a preference regarding the language in which you CMS is developed ?
&lt;p&gt;Anyway in Java there is HalX: an open-source LIMS (Laboratory Information Management System) for small- to large-scale laboratories. [link][1].
&lt;p&gt;In PHP/Ajax you have [Drupal][2].
&lt;p&gt;If you are familiar with the Blogging platform Wordpress you can turn it into a Content Management System (CMS). [Article link][3].


  [1]: http://www.ccpn.ac.uk/ccpn/projects/lims/meeting-23_1_08/annepoupon_ccpnjan2008anne.ppt/download
  [2]: http://drupal.org
  [3]: http://codex.wordpress.org/User:Lastnode/Wordpress_CMS</Text>
  </row>
  <row>
    <Id>1363</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>717</PostId>
    <RevisionGUID>c67ca8c4-5a33-4f52-b6d3-e8047b455999</RevisionGUID>
    <CreationDate>2010-04-15T07:13:51.557</CreationDate>
    <IPAddress>141.30.193.8</IPAddress>
    <UserId>235</UserId>
    <Text>A similar question has been asked by Lars J. Jensen on [FriendFeed][1], where Drupal seems to have gotten the most votes. Depending on how much you do integration with your own databases, you might want to look at a [Django-based system][2]. I make most of my database-frontends in Django nowadays (e.g. [SIDER][3]). 


  [1]: http://friendfeed.com/larsjuhljensen/8922e306/dear-lazyweb-which-framework-would-you-use-to
  [2]: http://code.djangoproject.com/wiki/CMSAppsComparison
  [3]: http://sideeffects.embl.de/</Text>
  </row>
  <row>
    <Id>1364</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>718</PostId>
    <RevisionGUID>a8baebc0-0cdc-48b6-8989-02064487cf8c</RevisionGUID>
    <CreationDate>2010-04-15T07:52:56.867</CreationDate>
    <IPAddress>130.102.158.16</IPAddress>
    <UserId>90</UserId>
    <Text>I have a FASTQ* file with reads from an Illumina machine and try to do the quality control filtering with the [FASTX-Toolkit][1] but get problems with the quality scores (see this [post][2] for a nice discussion about the scores)

While 'fastx_quality_stats' and 'fastx_trimmer' run without complaining, 'fastq_quality_filter' is suddenly not happy with the files 

fastq_quality_filter: Error: invalid quality score data on line 148 (quality_tok = "`Z]aaaaa]O]aabaaaaa`]"
Hannibal_FC30MEJAAXX_seqsPool1_index10_read2.fasta

The particular read looks like this :

    @Petra_4_1_1_10_1327/1
    AGTATTTTTGAATCTCATCATCGTCACTTCACTAAG
    +Petra_4_1_1_10_1327/1
    `Z]aaaaa]O]aabaaaaa`][FW`__a`\FW_X[M

Does anyone have a suggestion (other than deleting this read) or some experience?


*well it is labeled .FASTA but looks like a FASTQ file


  [1]: http://hannonlab.cshl.edu/fastx_toolkit/
  [2]: http://biostar.stackexchange.com/questions/642/fastq-qualities-for-solexa-illumina</Text>
  </row>
  <row>
    <Id>1365</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>718</PostId>
    <RevisionGUID>a8baebc0-0cdc-48b6-8989-02064487cf8c</RevisionGUID>
    <CreationDate>2010-04-15T07:52:56.867</CreationDate>
    <IPAddress>130.102.158.16</IPAddress>
    <UserId>90</UserId>
    <Text>What to do with an error in the FASTQ Illumina quality scores</Text>
  </row>
  <row>
    <Id>1366</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>718</PostId>
    <RevisionGUID>a8baebc0-0cdc-48b6-8989-02064487cf8c</RevisionGUID>
    <CreationDate>2010-04-15T07:52:56.867</CreationDate>
    <IPAddress>130.102.158.16</IPAddress>
    <UserId>90</UserId>
    <Text> éngsà  équalityà  éformatà  éfastqà  éfastxötoolkità </Text>
  </row>
  <row>
    <Id>1367</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>719</PostId>
    <RevisionGUID>c737bca7-1c15-4b98-af08-b90859dd5e31</RevisionGUID>
    <CreationDate>2010-04-15T08:06:27.67</CreationDate>
    <IPAddress>150.237.85.229</IPAddress>
    <UserId>227</UserId>
    <Text>I've not used it myself but I've seen some good sites, including labs, done with Plone http://plone.org/</Text>
  </row>
  <row>
    <Id>1368</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>720</PostId>
    <RevisionGUID>e26ec969-9a57-484a-b673-47a3217c3580</RevisionGUID>
    <CreationDate>2010-04-15T08:41:39.167</CreationDate>
    <IPAddress>128.240.229.65</IPAddress>
    <UserId>38</UserId>
    <Text>We use [Drupal][1] a lot, but our [own website][2] is in [Wordpress][3], which is overlooked as a general CMS a lot of the time.

If your lab use a lot of Python, there is a [Django CMS][4], though last time I investigated it, it was a bit of a pain. It looks like it has changed a lot since then. You could argue that with the powerful templating provided by web frameworks like Django, a CMS isn't really necessary. Just develop apps in your framework of choice, and apply the same templates to all of them.


  [1]: http://drupal.org/
  [2]: http://bsu.ncl.ac.uk/support
  [3]: http://www.wordpress.org/
  [4]: http://www.django-cms.org/</Text>
  </row>
  <row>
    <Id>1369</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>f8608739-dbd3-46e3-b373-2772aa80c6f4</RevisionGUID>
    <CreationDate>2010-04-15T10:08:30.167</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Comment>fixed the English in the title and the text. Removed the comment that I don't like perl. sorry, it costs me a bit to write correctly in English :-); added 210 characters in body</Comment>
    <Text>This is also a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?

This topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:

 - [Bioinformatics.org poll][1]
 - [Bioinformatics Career survey 2008 by Michael Barton][2]


  [1]: http://www.bioinformatics.org/poll/index.php?dispid=17
  [2]: http://openwetware.org/wiki/Biogang:Projects/Bioinformatics_Career_Survey_2008</Text>
  </row>
  <row>
    <Id>1370</Id>
    <PostHistoryTypeId>4</PostHistoryTypeId>
    <PostId>34</PostId>
    <RevisionGUID>f8608739-dbd3-46e3-b373-2772aa80c6f4</RevisionGUID>
    <CreationDate>2010-04-15T10:08:30.167</CreationDate>
    <IPAddress>193.145.46.51</IPAddress>
    <UserId>23</UserId>
    <Comment>fixed the English in the title and the text. Removed the comment that I don't like perl. sorry, it costs me a bit to write correctly in English :-); added 210 characters in body</Comment>
    <Text>Which are the best programming languages to study for a bioinformatician?</Text>
  </row>
  <row>
    <Id>1371</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>721</PostId>
    <RevisionGUID>19ce81ac-34e1-4738-b6ea-7009ebb559b9</RevisionGUID>
    <CreationDate>2010-04-15T10:52:31.033</CreationDate>
    <IPAddress>131.254.13.196</IPAddress>
    <UserId>205</UserId>
    <Text>I think you need different kind of programming languages for different purposes.

The bases are :

 - a script language (Unix, perl...) for every day small tasks 
 - a programming language (C, C++,
   JAVA...) for software development
 - and a language    for statistics (R,
   matlab...)

You will also have to learn how to use databases with SQL and perhaps some basic things about HTML and CSS.

But more important, learning a language is easy, but learning how to design efficient algorithms or reusable code is not so easy. And also, like Manuel Corpas said, "reinventing the wheel" is something to avoid. So you will have to know the classic algorithms and classes which are already implemented in public libraries.</Text>
  </row>
  <row>
    <Id>1372</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>722</PostId>
    <RevisionGUID>97309974-caa8-4d97-b2ab-a178456d65f8</RevisionGUID>
    <CreationDate>2010-04-15T11:56:54.187</CreationDate>
    <IPAddress>195.220.70.21</IPAddress>
    <UserId>199</UserId>
    <Text>In the section "Cluster Analysis" from the book *Bioinformatics and Computational Biology Solutions using R and Bioconductor*, HOPACH clustering is described. HOPACH stands for Hierarchical Ordered Partioning and Collapsing Hybrid. As its name suggests, this is a hybrid method of partitioning and hierarchical cluster analysis, which recursively alternates splitting and collapsing steps based on a criterion called median split silhouhette (MSS). MSS is a measure aiming at answering the question : shoud I split this (sub-)cluster again or is it homogeneous enough ? The silhouette of a gene is a measure indicating how well this gene fits into its own cluster comparing to other clusters. So maximizing the MSS criterion allows one to decide when splitting should be stopped and then remaining unsplit clusters are "what you are looking for".

There is a R (bioconductor) package available : [**hopach**][1].
As well as the package, you will also find a detailled manuscript (pdf) of the methodology.

This package provides a bootstrap resampling function allowing one to obtain membership estimates for a gene in each cluster.

Here are useful references associated with this package/method :

Van der Laan and Pollard. Hybrid clustering of gene expression data with visualization and the bootstrap. 2003. *Journal of Statistical Planning and Inference*.

K.Pollard and M. van der Laan. A method to identify significant clusters in gene expression data. In *SCI2002 Proceedings*, volume II, pages 318-325, Orlando, 2002a. International Institute of Informatics and Systemics.

K.Pollard and M. van der Laan. Statistical inference for simultaneous clustering of gene expression data. *Mathematical Biosciences*, 176(1):99-121, 2002b.


This may be a starting point to get what you want, that is to say highly correlated or significantly coexpressed genes.


Hope it helps.
I was thinking that this package should be interesting.

(I do not have personally a strong experience with this package)

regards,

tony.


  [1]: http://www.bioconductor.org/packages/release/bioc/html/hopach.html</Text>
  </row>
  <row>
    <Id>1373</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>723</PostId>
    <RevisionGUID>f1412d4c-ff87-416e-aebd-e5c20ab75916</RevisionGUID>
    <CreationDate>2010-04-15T12:07:10.963</CreationDate>
    <IPAddress>132.183.101.77</IPAddress>
    <UserId>56</UserId>
    <Text>Which version of the fastx toolkit do you have installed? This seems to be working with the latest version (0.0.13):

    % cat test.fastq
    @Petra_4_1_1_10_1327/1
    AGTATTTTTGAATCTCATCATCGTCACTTCACTAAG
    +Petra_4_1_1_10_1327/1
    `Z]aaaaa]O]aabaaaaa`][FW`__a`\FW_X[M
    mothra:fastq % fastq_quality_filter -q 20 -p 50 -i test.fastq
    @Petra_4_1_1_10_1327/1
    AGTATTTTTGAATCTCATCATCGTCACTTCACTAAG
    +Petra_4_1_1_10_1327/1
    `Z]aaaaa]O]aabaaaaa`][FW`__a`\FW_X[M

You might have a version before support for the latest 1.3+ Illumina pipeline scores were introduced. An alternative to upgrading the fastx toolkit is to use Galaxy to convert the scores into Solexa format.



</Text>
  </row>
  <row>
    <Id>1374</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>724</PostId>
    <RevisionGUID>ec8b50c1-56dd-4afa-ba04-2f3a085fcea2</RevisionGUID>
    <CreationDate>2010-04-15T12:15:48.687</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text>Hi Guys,

We often read in NGS papers a descriptive value, called "N50", which seems to provide a standard measure of assembly connectivity. Could someone please explain, in details, the meaning of "N50" and how to compute this value?

Regards</Text>
  </row>
  <row>
    <Id>1375</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>724</PostId>
    <RevisionGUID>ec8b50c1-56dd-4afa-ba04-2f3a085fcea2</RevisionGUID>
    <CreationDate>2010-04-15T12:15:48.687</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text>What does the "N50" mean?</Text>
  </row>
  <row>
    <Id>1376</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>724</PostId>
    <RevisionGUID>ec8b50c1-56dd-4afa-ba04-2f3a085fcea2</RevisionGUID>
    <CreationDate>2010-04-15T12:15:48.687</CreationDate>
    <IPAddress>132.203.89.213</IPAddress>
    <UserId>226</UserId>
    <Text> éngsà  én50à  éassemblyà  éconnectivityà </Text>
  </row>
  <row>
    <Id>1377</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>725</PostId>
    <RevisionGUID>dbfcbd28-1640-442f-a8b8-d3c7ad6ef1a8</RevisionGUID>
    <CreationDate>2010-04-15T13:07:09.8</CreationDate>
    <IPAddress>130.223.48.241</IPAddress>
    <UserId>141</UserId>
    <Text>http://seqanswers.com/forums/showthread.php?t=2332</Text>
  </row>
  <row>
    <Id>1378</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>726</PostId>
    <RevisionGUID>cd730b2e-ffad-46cc-a305-f8b69f84ccba</RevisionGUID>
    <CreationDate>2010-04-15T13:13:57.147</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text>There are a number of peak callers available for chIP seq data. We are running [MACS][2] and [SWEMBL][3] and using overlaps but I would like some feedback about your experiences with chIP seq peak callers. I am aware of the [ChIP-Seq Challenge][4] but this was far from a complete study. What do you use? 


  [1]: http://liulab.dfci.harvard.edu/MACS/
  [2]: http://liulab.dfci.harvard.edu/MACS/
  [3]: http://www.ebi.ac.uk/~swilder/SWEMBL/
  [4]: http://seqanswers.com/forums/showthread.php?t=1039</Text>
  </row>
  <row>
    <Id>1379</Id>
    <PostHistoryTypeId>1</PostHistoryTypeId>
    <PostId>726</PostId>
    <RevisionGUID>cd730b2e-ffad-46cc-a305-f8b69f84ccba</RevisionGUID>
    <CreationDate>2010-04-15T13:13:57.147</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text>Which chIP seq peak callers do you use? </Text>
  </row>
  <row>
    <Id>1380</Id>
    <PostHistoryTypeId>3</PostHistoryTypeId>
    <PostId>726</PostId>
    <RevisionGUID>cd730b2e-ffad-46cc-a305-f8b69f84ccba</RevisionGUID>
    <CreationDate>2010-04-15T13:13:57.147</CreationDate>
    <IPAddress>143.65.99.20</IPAddress>
    <UserId>218</UserId>
    <Text> échipöseqà  épeaköcallerà </Text>
  </row>
  <row>
    <Id>1381</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>727</PostId>
    <RevisionGUID>40010cde-e37c-4c6b-a2e4-dccb050630e0</RevisionGUID>
    <CreationDate>2010-04-15T13:30:25.537</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Text>Hi there,

I'm a strong advocate of CMS for lab sites and lab management. My choice was Plone for several reasons:

 - Natively secure and has a lot of authentication procedures/protocols;
 - Mature software and very well supported;
 - OO/Templated underlying architeture (it's kind of OO CMS);
 - Totally written in python !!!
 - Works over Zope/Django or any other CMF python-compatible.
 - Runs everywhere python runs;
 - Connects nicely to a wealth of database systems;

Of course, there are some cons:

 - Hard to debug;
 - Hard to tune for performance;
 - Depends on specific python versions (for now, 2.4);
 - Time consuming layout/theming customization.
 - Support is good only if you had a moderate experience with the CMS;


I've tried to use PHP CMS (Joomla, Wordpress, etc.) but they're not flexible/dynamic enough. PHP can really limit your creativity. There are some Java CMS that are very powerfull like Sakai, tought it's was designed for a different purpose. And of course there's Apache Lenya in Java/XML. IMHO Lenya and Plone are the best ones for their language choice, architecture and flexibility. They're somewhat harder to grasp than PHP ones, but totally worth a try.


</Text>
  </row>
  <row>
    <Id>1382</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>727</PostId>
    <RevisionGUID>74094fec-bebc-4bd7-a34c-85f2128de078</RevisionGUID>
    <CreationDate>2010-04-15T13:39:09.213</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 302 characters in body</Comment>
    <Text>Hi there,

I'm a strong advocate of CMS for lab sites and lab management as I demonstrated at other [posts][3]. My choice was Plone for several reasons:

 - Natively secure and has a lot of authentication procedures/protocols;
 - Mature software and very well supported;
 - OO/Templated underlying architeture (it's kind of OO CMS);
 - Totally written in python !!!
 - Works over Zope/Django or any other CMF python-compatible.
 - Runs everywhere python runs;
 - Connects nicely to a wealth of database systems;

Of course, there are some cons:

 - Hard to debug;
 - Hard to tune for performance;
 - Depends on specific python versions (for now, 2.4);
 - Time consuming layout/theming customization.
 - Support is good only if you had a moderate experience with the CMS;


I've tried to use PHP CMS (Joomla, Wordpress, etc.) but they're not flexible/dynamic enough. PHP can really limit your creativity. There are some Java CMS that are very powerfull like Sakai, tought it's was designed for a different purpose. And of course there's Apache Lenya in Java/XML. IMHO Lenya and Plone are the best ones for their language choice, architecture and flexibility. They're somewhat harder to grasp than PHP ones, but totally worth a try.

In terms of real application, I know [Plone4Bio][2]. [CBMI][1] at harvard uses Lenya. Of course, I've never searched for ir throughly.

[1]: https://cbmi.med.harvard.edu
[2]: http://www.plone4bio.org/trac/
[3]: http://biostar.stackexchange.com/questions/584/

</Text>
  </row>
  <row>
    <Id>1383</Id>
    <PostHistoryTypeId>5</PostHistoryTypeId>
    <PostId>727</PostId>
    <RevisionGUID>5b8eb5e5-1243-4879-ae75-9f0a92b4f3fe</RevisionGUID>
    <CreationDate>2010-04-15T14:02:22.43</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>added 200 characters in body</Comment>
    <Text>Hi there,

-- Edit --

Just received from insideHPC a link to [Hubzero][1]. It seems to be the solution for a lot of my problems in a CMSish like sytle !!!!

-- EndEdit --

I'm a strong advocate of CMS for lab sites and lab management as I demonstrated at other [posts][2]. My choice was Plone for several reasons:

 - Natively secure and has a lot of authentication procedures/protocols;
 - Mature software and very well supported;
 - OO/Templated underlying architeture (it's kind of OO CMS);
 - Totally written in python !!!
 - Works over Zope/Django or any other CMF python-compatible.
 - Runs everywhere python runs;
 - Connects nicely to a wealth of database systems;

Of course, there are some cons:

 - Hard to debug;
 - Hard to tune for performance;
 - Depends on specific python versions (for now, 2.4);
 - Time consuming layout/theming customization.
 - Support is good only if you had a moderate experience with the CMS;


I've tried to use PHP CMS (Joomla, Wordpress, etc.) but they're not flexible/dynamic enough. PHP can really limit your creativity. There are some Java CMS that are very powerfull like Sakai, tought it's was designed for a different purpose. And of course there's Apache Lenya in Java/XML. IMHO Lenya and Plone are the best ones for their language choice, architecture and flexibility. They're somewhat harder to grasp than PHP ones, but totally worth a try.

In terms of real application, I know [Plone4Bio][3]. [CBMI][4] at harvard uses Lenya. Of course, I've never searched for ir throughly.


  [1]: http://hubzero.org/
  [2]: http://biostar.stackexchange.com/questions/584/
  [3]: http://www.plone4bio.org/trac/
  [4]: https://cbmi.med.harvard.edu</Text>
  </row>
  <row>
    <Id>1384</Id>
    <PostHistoryTypeId>6</PostHistoryTypeId>
    <PostId>708</PostId>
    <RevisionGUID>99c7ba59-7c4b-418c-abf6-93caa62e89c4</RevisionGUID>
    <CreationDate>2010-04-15T14:05:44.053</CreationDate>
    <IPAddress>143.107.179.59</IPAddress>
    <UserId>148</UserId>
    <Comment>edited tags</Comment>
    <Text> éwebödevelopmentà  écmsà  éintegrationà </Text>
  </row>
  <row>
    <Id>1385</Id>
    <PostHistoryTypeId>2</PostHistoryTypeId>
    <PostId>728</PostId>
    <RevisionGUID>f38bd4a7-7d2d-4864-8c6c-02ef9d8d8c00</RevisionGUID>
    <CreationDate>2010-04-15T14:11:47.227</CreationDate>
    <IPAddress>128.118.200.167</IPAddress>
    <UserId>2</UserId>
    <Text>Here is a paper that might be of interest:

[A practical comparison of methods for detecting transcription factor binding sites in ChIP-seq experiments][1]

We use our self developed method called [GeneTrack][2] (also discussed in the comparison above). 


  [1]: http://www.biomedcentral.com/1471-2164/10/618
  [2]: http://code.google.com/p/genetrack/</Text>
  </row>
</PostHistory>